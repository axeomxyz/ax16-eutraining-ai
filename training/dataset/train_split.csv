CS ID,Name,Instructions,Abbreviations,Email Instructions,Content,Evaluation ID,Overall Score,Overall Summary,Communication Score,Communication Summary,Communication Errors,Communication Tips,Trainee's Ans
1,0_Lithium Supply Chain (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG MOVE. 
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Analysis and Problem Solving, Communicating (Drafting Skills), Delivering Quality & Results, and Prioritising & Organising.

Specifically, your task will be to draft a memo for your Head of Unit.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations


ACEA - European Automobile Manufacturers’ Association 

DLE - direct lithium extraction

DLP - direct lithium to product 

ECHA - European Chemicals Agency

ESG - environmental, social, and governance

EV – Electric Vehicle

INN – Investing News Network

IRA – Inflation reduction Act (US)

LCE - lithium carbonate equivalent

LiPo – Lithium Polymer







EMAIL 1","Subject: Towards a sustainable, circular, European battery supply chain 
Dear YOU,

In December 20XX-2, the Commission presented a proposal for a regulation on batteries and waste batteries. The proposal aims to strengthen the functioning of the internal market, promoting a circular economy and reducing the environmental and social impact throughout all stages of the battery life cycle. The initiative is closely linked to the European Green Deal, the Circular Economy Action Plan, and the New Industrial Strategy. 
At the end of last year, The Council and the European Parliament reached a provisional political agreement on the proposal. For the first time the legislation will regulate the entire life cycle of a battery – from the supply chain of raw materials, over the production to reuse and recycling of batteries – and ensure that they are safe, sustainable, and competitive.
As you know, our unit has the lead on this important file and our DG intends to launch the formal interservice consultation over the coming weeks. Before this, our DG wants to organize an internal reflection and brainstorming meeting, and I have been appointed to chair this meeting.
Could you produce an internal memo, summarizing the main ins and outs of this file and the agenda for the internal meeting with concrete proposals and recommendations to fine-tune the original proposal, in line with the political priorities of the co-legislators. 
I’m on mission tomorrow so please could you get this done for me today. It doesn’t need to be long – in fact the shorter, the better.  

Many thanks",",

Ferdinand
Head of Unit




Is Europe Moving Fast Enough to Build a Resilient Lithium Supply Chain? 
Priscila Barrera
Nov. 16, 20XX-1


Europe will soon release its Critical Raw Materials Act to identify potential strategic projects and build up reserves where supply is at risk.
Europe’s green energy transition plans give a central role to the electrification of transportation. 
The European Union (EU) has ambitious goals to become climate neutral by 2050, meaning it would be an economy with net-zero greenhouse gas emissions. Recently proposed legislation is looking to effectively ban all internal combustion engine cars by 2035.
In 20XX-2, electric car registrations for the year were close to 1,729,000, up from 1,061,000 in 2020, with prospects for the region remaining positive. Last year, the market share of battery electric cars almost doubled to around 10 percent, but challenges faced by carmakers continue to weigh on demand as inflation and fears of a recession put pressure on targets. 
In its most recent forecast, the European Automobile Manufacturers’ Association (ACEA) said it expects the overall EU car market to shrink again this year, slipping by 1 percent to reach 9.6 million units.
“To ensure a return to growth — with an even greater share of electric vehicle sales so climate targets can be met — we urgently need the right framework conditions to be put in place,” said Oliver Zipse, ACEA president and CEO of BMW. “These include greater resilience in Europe’s supply chains, an EU Critical Raw Materials Act that ensures strategic access to the raw materials needed for e-mobility, and an accelerated roll-out of charging infrastructure.”
As sales of electric vehicles increase, carmakers are looking to secure supply of key metals used in batteries, including lithium. Today, Europe is quite dependent on Australia and Chile for lithium supply and China for lithium refining, but the region is taking steps to strengthen its supply chain for the important battery metal. 
What is the European Critical Raw Materials Act? 
In September, news broke that Europe will be putting forward the European Critical Raw Materials Act, a new piece of legislation. Its aim is to identify potential strategic projects and build up reserves where supply is at risk.
European Commission President Ursula von der Leyen said the bloc has learned its lesson about the risks of being dependent on Russia, and realizes the need to be vigilant toward China.
""In the case of China, it is the risk of dependency on technologies and raw materials,"" she said, adding that the EU needs to boost its production capacity and shift more towards trustworthy suppliers.
In October, von der Leyen said the EU is witnessing quite an acceleration of trends and tensions with China. 
""The Chinese system is fundamentally different from ours and we are aware of the nature of the rivalry,'' she said.
The moves from the EU are in line with pushes seen in other regions such as North America, where the US has committed billions of dollars to reach its carbon emissions targets.
In June, the Biden administration launched the Inflation Reduction Act, which includes climate incentives. The legislation, which was signed into law in August, requires automakers to source 50 percent of critical minerals used in electric vehicle batteries from North America or free trade agreement countries by 2024, with that amount rising to 80 percent by the end of 20XX+3.
For its part, Canada recently ordered three Chinese companies to divest from lithium companies following a “multi-step national security review process.” China has opposed the move, and Canada is expected to release its China strategy soon.
Europe-Asia relationship in the lithium space 
Jack Bedder of Project Blue said Asia will always be a part of the European lithium-ion battery supply chain. Major Asian companies, including Panasonic, Samsung, BYD Company and CATL, all have operating capacity on the continent.
“As a result, it will be almost impossible to detach fully from Chinese-owned supply across all stages of the lithium-ion supply chain,” he told the Investing News Network.
However, as lithium processing capacity is built up globally at non-Chinese-owned companies, particularly within the EU, the opportunities to reduce the EU's dependency on China-owned supply will improve. “It is very unlikely that the EU will implement legislation directly prohibiting lithium supply from Chinese-owned companies, as further constraints on supply availability to the European market will only hinder growth in the industry over the coming decade,” Bedder added.
For Allan Pedersen of Wood Mackenzie, Europe cannot move forward without influence from Asia in the short to medium term.
That’s due to a few reasons. As mentioned, many of the battery plants being constructed in Europe have Asian companies behind them, and the cathodes needed in batteries are still largely produced in Asia, where the know-how is strongest. Additionally, lithium refining is mainly done in China and most mineral concentrate is produced in Australia.
“China has a multi-year advantage over the rest of the world in terms of investing in the entire supply chain — it will be challenging for Europe to catch up to that in terms of investment in know-how, processing equipment and resources,” he said. 
“This doesn’t mean that Europe cannot make progress in this space. In lithium, we see some resource developments and processing facilities being considered and constructed.”
For the analyst, in the long-term Europe has the potential to become more self-sufficient for raw materials as recycling becomes a larger part of the supply landscape and can supplement domestic resources.
European Commission could classify lithium as toxic. 
Although Europe is pushing to build a resilient supply chain by partnering with allies and developing domestic resources, it might not all be good news for miners in the region — at the end of last year, the European Commission said it will weigh a proposal from the European Chemicals Agency to classify lithium carbonate, chloride and hydroxide as dangerous for human health.
If the proposal is approved, this could undermine the EU’s attempt to create and support a domestic battery materials supply chain, research firm Rystad Energy said in a statement. “The EU currently relies heavily on imports of lithium to supply its nascent electric vehicle production sector and the classification may increase its reliance on other regions, at a time when the union is focused on energy security and reducing emissions,” the document reads.
If the classification goes ahead, it would not stop lithium usage, but it is highly likely to have an impact on at least four stages: lithium mining, processing, cathode production and recycling.
“This potential ruling comes at a time when the EU is itself scrambling to build and establish local lithium supply chains. The permitting issue has repeatedly been highlighted at recent industry events as one of the main barriers to new mining projects ramping up quickly in the EU,” according to Rystad Energy analysts. “There is also further risk of potential projects losing local community support for building lithium mines and processing operations.”
Editorial Disclosure: The Investing News Network does not guarantee the accuracy or thoroughness of the information reported in the interviews it conducts. The opinions expressed in these interviews do not reflect the opinions of the Investing News Network and do not constitute investment advice. All readers are encouraged to perform their own due diligence.




Lithium salts could be declared health hazard in EU
June 9, 20XX-1 by Igor Todorović


A major lithium producer threatened to close its plant in Germany if the European Union declares the material dangerous to human health. The European Chemicals Agency or ECHA initiated the process.
The European Union has been making its environmental and climate rules stricter for decades. The administration in Brussels wants to make the entire continent carbon neutral by mid-century. At the same time, it is striving to achieve the highest level of protection from pollution in the world.
The energy transition and the decarbonization of industrial activity and power plants imply massive deployment of renewables, mostly solar and wind farms. However, as they depend on unstable weather conditions, the electric power system requires energy storage, in which the EU counts a lot on batteries.
Dangerous critical raw material
Lithium-ion solutions still dominate the sector, though there are other technologies emerging that could popularize less harmful material for home units and the batteries for electronic devices, electric vehicles, and utility systems. At the same time, the European Commission is struggling to secure supply chains that would make the availability of lithium stable and make the EU almost self-sufficient by 20XX+7.
The European Union has added lithium to a list of critical raw materials as demand is expected to increase dramatically in the coming years.
Initiatives to open mines and ore processing plants such as the ones in Serbia and Portugal have caused a public uproar as environmentalists and the local population are fearful about the impact on nature and people’s livelihoods. In other projects, engineers are trying to make the extraction of lithium from geothermal waters cost effective and harmless, without any mining.
Stricter rules for handling lithium would lift costs
However, the entire concept could falter with the European Commission’s upcoming legislation. Namely, it is considering the proposal from the European Chemicals Agency, ECHA, to declare key lithium salts hazardous for human health, Reuters reported. If lithium carbonate, lithium chloride and lithium hydroxide are classified as dangerous, it would complicate the import procedure, production, and handling of the materials.
ECHA’s Risk Assessment Committee accepted the demand from France in September to classify lithium salts as damaging for fertility and unborn children and to declare the substances harmful for breastfed children.
Adding lithium salts to the list of materials hazardous for health may prompt the revision of a range of projects in the industry.
Stricter rules mean higher costs, so any lithium ore processing plant project, like the one in the Jadar area in Serbia, would need to be given a second look regarding its environmental impact and feasibility.
Albemarle, based in Charlotte, North Carolina, has indicated it may be forced to close its plant in Langelsheim in north Germany if the plan is accepted. In that case, Chief Financial Officer Scott Tozier said, the company wouldn’t be able to import lithium chloride, its primary feedstock.
The unit’s annual revenue is USD 500 million, and the plant has over 600 employees. Tozier warned a decision to declare lithium salts hazardous would prompt an exodus of EU producers including battery recyclers.
The decision is expected to be reached by early next year, the article adds.





The Really Big Battery Deal in the IRA That People Are Missing
By Zachary Shahan – Published September 23, 20XX-1
When it comes to electric vehicles and the Inflation Reduction Act of 2022, almost all the discussion has been around the consumer tax credit for buying an electric vehicle, including the interesting new battery aspects of that. That’s a big topic, but there’s a whole other battery angle separate from the consumer tax credit, and it’s huge.
The short summary of the whole thing is that the IRA incentives for nearly every stage of battery production and the battery supply chain are very attractive, and since they stack on top of each other, the IRA is likely to stimulate a “gold rush” of sorts in battery mineral mining, battery mineral refining, battery cell production, battery recycling, and battery pack production in the United States. When you also consider that consumers will need to get batteries whose components don’t come from China, and that come from North America eventually, then it’s essentially a given that everyone in the industry now knows it should have battery mineral mining and refining as well as battery cell and pack production in North America.

SK Innovation Georgia battery factory rendering, courtesy of SK Innovation.
The Current EV Battery Mineral Situation
First, let’s note where we’re starting from. The USA currently mines and refines close to 0% of the minerals that go into EV battery packs. China, on the other hands, mines or refines the majority of all the big ones, including lithium, cobalt, nickel, and graphite. Here’s a chart on Chinese EV battery mineral domination:

Money, Money, Money
Looking at the data, the idea that Joe Biden was going to stimulate a gold rush in the EV battery mineral mining and refining space was a dream some of us had, but it seemed like one of the more outlandish dreams we could have in this time and age. However, the market does respond to three things pretty well: money, money, money, and money. And the Biden administration, Prime Minister Manchin, Senate Majority Leader Chuck Schumer, and others involved in crafting the legislation took note and decided to offer all four.
The slight joke here, aimed at emphasizing the key point, is that the IRA seems to be offering cash money (tax credits) for mining battery minerals, for refining battery minerals, for putting together battery cells, and for putting together battery packs (or “modules”). If you do all those things, you don’t get one bonus, you get four bonuses. If you count all the different minerals in a battery, the number of potential bonuses is much larger. Those bonuses add up, and they make it much more appealing to bring full-cycle battery production to the USA. At the very least, it should open mining and refining projects — which are more or less non-existent in the United States — by making them much more bankable. (Side note: Canadian and Mexican locations hoping to attract battery manufacturing investment may not have figured it out yet, but their competitive position versus the US took a major hit when Biden signed the IRA.)
That’s why we recently got news of Tesla reportedly deciding to scrap some investments it had already made in Germany (but not all of them) and move some battery cell production stateside. That’s why Tesla is reportedly exploring lithium refining in Texas now as well. That’s why GM is reportedly accelerating its exploration of EV battery mineral supplies from US soil. “Our thought process was that we would do this over a period of time, but with the IRA, we are actively working on figuring out how to accelerate,” said Sham Kunjur, GM’s executive director for EV raw materials. But this is only the beginning. These are just the leaks from early movers and leaky groups. Whether it’s Tesla, GM, Volkswagen, Ford, Panasonic, SK Innovation, LG Energy Solution (previously known as LG Chem), Samsung SDI, Albemarle, Livent, Piedmont Lithium, Talon Metals, Lithium Americas, Pilbara Minerals, or others, corporate teams are looking at the IRA, having their lawyers look at it, and starting to look much more seriously at what production opportunities they can launch in the United States.
Looking at the Actual IRA Language
Section 45X of the IRA concerns “components produced and sold after December 31, 2022.” Near the beginning, it states that “any taxable year is an amount equal to the sum of the credit amounts determined under subsection (b) with respect to each eligible component.” In other words, if you get a tax credit for one component of a battery (raw lithium, for example), you can also go and get a tax credit for another component or even later stage of the same component (the refined lithium, for example). The tax credits are for each major stage of the production process, and that means you can get them for various components of a battery and various stages of processing or putting together those components. You can get the following credits:
10% of the cost of battery electrode active materials
$35/kWh of battery cell capacity
$10/kW of battery module capacity (or, for a battery module that does not use battery cells, $45/kWh)
10% of the cost of producing a battery mineral.
Also, while there’s a phaseout for some of these between 2030 and 2032, there is no phaseout at all for the critical mineral subsidies! That’s long-term stability for a market that needs it.
What Minerals & Battery Components Are Eligible?
Regarding electrode active materials, those include “cathode materials, anode materials, anode foils, and electrochemically active materials, including solvents, additives, and electrolyte salts that contribute to the electrochemical processes necessary for energy storage.”
Applicable critical minerals include aluminum/alumina, antimony/antimony trisulfide concentrate, barite/barium sulfate, beryllium/copper-beryllium master alloy, cerium/cerium oxide, cesium/cesium formate/cesium carbonate, chromium/ferrochromium, cobalt/cobalt sulfate, graphite/graphitic carbon, lithium/lithium carbonate and lithium hydroxide, manganese, nickel/nickel sulphate, and many others.
Notably, at the end, it’s noted that only production that takes place in the United States is eligible for these tax credits. This creates a “USA premium” in the supply of raw materials to facilities that want to get the maximum benefit from 45X. Any manufacturer will be eligible for a 45X tax credit which covers the yearly cost of production if their facility is using raw material from the US. For most manufacturing, raw material cost is the most significant component of OPEX after labor and energy. So, Biden, Schumer, Manchin, and their aides have been very clever here: “want the maximum benefit, Buy American.”
So, let’s go back to the example of Tesla (or you can use Ford, GM, or some other company in this hypothetical if you prefer). Tesla could, theoretically, get a tax credit for mining lithium, get a tax credit for refining lithium, get a tax credit for mining nickel, get a tax credit for refining nickel, get a tax credit for producing battery anodes, get a tax credit for producing battery cells, and get a tax credit for producing battery modules. Of course, Tesla isn’t going to do all those things. However, I think that helps to explain the potential here. Whereas Tesla won’t do all those things itself, companies and investors will be pouring into the United States to do them, and some automakers will deepen their vertical integration in the battery space as well.
As a final note, and perhaps as a teaser for something we’ll come back to, while the incentives from the IRA are attractive, so is the potential for pricing control over raw materials! Whether Ford, GM, or Tesla, having more secure, stable, predictable control over key raw material costs could go a long way in being competitive and financially sustainable in the coming decade. How much is that pricing control worth as we go from ~5% EV market share in the US auto industry to 50% or more?

Russia may launch lithium production in the coming four years
June 17, 20XX-1
| As said at the SPIEF Oleg Kazanov, Director of the All-Russian Institute of Mineral Resources (VIMS) under Federal Subsoil Resources Management Agency, Russia may start lithium mining based on the ore deposits in the Murmansk region in 3-4 years and become one of the world’s five largest producers in eight years’ time.  |  |
“Russia has a lithium resource base, which is 10% of the world’s reserves and explored back in the 60s of the previous century. This is almost 4 million tons in 15 explored deposits. The first two objects in the Murmansk region will gain licensing and active subsoil use by the end of the current year. I think production might start there already in the next three or four years. Moreover, these are world-class deposits, both in terms of the lithium reserves and content,” O. Kazanov said.
According to him, now the demand for lithium is boosting in the world. Its driver is the battery industry. “Already in the next 10 years, we will see an increase from the current 100,000 tons of lithium consumption to about 700,000 tons. In total, 88 deposits of ore lithium will be launched in the world soon, but it is not enough to cover its entire global demand,” the expert notes.
Meanwhile, in Russia, a peculiar situation has developed in the lithium industry. The country has huge reserves of ore lithium reaching 10% of the world’s. Besides, Russia discovered lithium reserves in solutions in the bottom waters of the oil and gas fields in the Angara-Lena region, but they have not been fully assessed yet. The lithium content in solutions is very high by the world standards, i.e., about 300 mg/l.
There are two large lithium processing plants in Russia the Krasnoyarsk chemical-metallurgical plant, which buy raw lithium from Chile, bring it up to battery quality and ship to Southeast Asia.
Against the background of this situation, Federal Subsoil Resources Management Agency has recognized development of the lithium ore and brine reserves as a priority area.
Lithium ore mining technologies already exist; they scale well, especially considering increase of the demand for lithium and its price rise. “I think already on ore lithium, in the prospect of the next eight years, we are going to be among the top five producers of this metal along with Chile, Argentina, China and Australia,” O. Kazanov noted.
The next stage in the Russia’s lithium industry development after the ore deposits have been commissioned will be application of the technologies for lithium production from solutions. In the world, this is the DLE technology mainly used for solutions at geothermal power plants. In Russia, lithium solutions are found in the bottom waters of oil and gas fields. This water is somehow extracted from the subsoil and injected back into the reservoir to maintain pressure in an oil and gas well.
The engineering center created based on the Krasnoyarsk chemical-metallurgical plant and VIMS developed its own technologies for lithium extraction just during a year, and now they are tested under the laboratory conditions.

By Marcelo Azevedo, Magdalena Baczyńska, Ken Hoffman, and Aleksandra Krauze
Lithium is the driving force behind electric vehicles, but will supply keep pace with demand? New technologies and sources of supply can fill the gap. 
Despite expectations that lithium demand will rise from approximately 500,000 metric tons of lithium carbonate equivalent (LCE) in 2021 to some three million to four million metric tons in 2030, we believe that the lithium industry will be able to provide enough product to supply the burgeoning lithium-ion battery industry. Alongside increasing the conventional lithium supply, which is expected to expand by over 300 percent between 2021 and 2030, direct lithium extraction (DLE) and direct lithium to product (DLP) can be the driving forces behind the industry’s ability to respond more swiftly to soaring demand. Although DLE and DLP technologies are still in their infancy and subject to volatility given the industry’s “hockey stick” 1 demand growth and lead times, they offer significant promise of increasing supply, reducing the industry’s environmental, social, and governance (ESG) footprint, and lowering costs, with already announced capacity contributing to around 10 percent of the 2030 lithium supply, as well as to other less advanced projects in the pipeline.
However, satisfying the demand for lithium will not be a trivial problem. Despite COVID-19’s impact on the automotive sector, electric vehicle (EV) sales grew by around 50 percent in 2020 and doubled to approximately seven million units in 2021. At the same time, surging EV demand has seen lithium prices skyrocket by around 550 percent in a year: by the beginning of March 2022, the lithium carbonate price had passed $75,000 per metric ton and lithium hydroxide prices had exceeded $65,000 per metric ton (compared with a five-year average of around $14,500 per metric ton). 
Lithium is needed to produce virtually all traction batteries currently used in EVs as well as consumer electronics. Lithium-ion (Li-ion) batteries are widely used in many other applications as well, from energy storage to air mobility. As battery content varies based on its active materials mix, and with new battery technologies entering the market, there are many uncertainties around how the battery market will affect future lithium demand. For example, a lithium metal anode, which boosts energy density in batteries, has nearly double the lithium requirements per kilowatt-hour compared with the current widely used mixes incorporating a graphite anode.
So, will there be enough lithium to cover the needs of a new electrified world? As discussed in our recent article, “The raw-materials challenge: How the metals and mining sector will be at the core of enabling the energy transition,” arriving at a considered answer and understanding the entire supply-and-demand context will be crucial for every player along the value chain—mining companies, refiners, battery manufacturers, and automotive OEMs.
Lithium demand factors
Over the next decade, McKinsey forecasts continued growth of Li-ion batteries at an annual compound rate of approximately 30 percent. By 2030, EVs, along with energy-storage systems, e-bikes, electrification of tools, and other battery-intensive applications, could account for 4,000 to 4,500 gigawatt-hours of Li-ion demand.
  
Not long ago, in 2015, less than 30 percent of lithium demand was for batteries; the bulk of demand was split between ceramics and glasses (35 percent) and greases, metallurgical powders, polymers, and other industrial uses (35-plus percent). By 2030, batteries are expected to account for 95 percent of lithium demand, and total needs will grow annually by 25 to 26 percent to reach 3.3 million to 3.8 million metric tons LCE depending on the scenarios outlined in Exhibit 2. 


Reuse and recycle
A frequently asked question is whether L-ion batteries can be recycled. With expected battery lifetimes of around ten to 15 years for passenger vehicles, and the possibility of extending EV battery life through use in the energy-storage sector, battery recycling is expected to increase during the current decade, but not to game-changing levels. Depending on the recycling process employed, it is possible to recover between zero and 80 percent of the lithium contained in end-of-life batteries. By 2030, such secondary supply is expected to account for slightly more than 6 percent of total lithium production (Exhibit 7).",6,4.0,"Summary

According to the Notice of Competitions of current EPSO competitions, the only competency that will be assessed in the Case Study exam is Written Communication",4.0,"Observations

With this competence, we basically evaluate the style of the case study. Your text should be clear, fluent, written in a professional but still captivating style; of course, spelling and grammar are also covered in this area. Another point we examine here is whether you managed to find the balance between providing details and being concise while conveying the key points of the arguments.",,"Tips to Improve

The text is cohesive and informative, but the amount of typos, grammatical inaccuracies, and overcomplicated sentences negatively impact the readability of the text.","Trainee's Answer
 
Brussels, 01 March 20XX
 
NOTE  FOR THE ATTENTION OF HEAD OF UNIT
Subject: Commission proposal regulation on batteries
1. INTRODUCTION
From September  20XX the Commission will propose  ""The new European critical act"" a new  regulation on ricycle and waste of the Lithium Battery, linked to circular Economy and to Green Deal. The new piece of legislation aims to guarantee Europe's green transition and  point out new potential strategic project to ensure strategic access to raw material, promoting a circular economy and reducing the environmental and social impact throughout all stages of the battery cycle.
2. UNDERLYING ISSUES OF THE GROWING REQUEST OF LITHIUM BATTERY
Last year the market share of battery electric cars doubled around 10 percent and as declared from Oliver Zipse Acea president and Ceo of Bmw : ""Europe needs an Eu Critical Raw Materials Act that ensure strategic access to the raw materials needed for e-mobility, and an accelerated roll-out of charging infrastructure"" (source ""Inn"", Priscilla Barrera, Nov 16, 20xx-1).
As underlined from European Commission President Ursula Von Der Leyen, the goal of the European Critical Material act is to  identify strategic projects  and build up reserves where supply is at risk. Europe needs to improve charging infrastructure in order to avoid the risk to be fully dependent from China.
At the moment Eu is looking at North America that recently introduced a policy of climate incentives and to detach from China. Europe has the capacity to improve his autonomy from Asia, even if the scenario can deeply change after the Commission will decide about how classify lithium carbonate.
2.1 The European Chemicals Agency point out the health risk of lithium carbonate.
The European Commission will analyze the proposal of European Chemical Agency to classify lithium carbonate, chloride and hydroxide as dangerous for human health. European Commission has the responsibility to guarantee the right to health of European Citizens but at the same time adds lithium to a list of critical raw material will impact on the  improvement of Eu supply chains. 
2.2 Economic consequences of declare lithium as toxic.
- Increasing costs of mining, processing, cathode production and recycling;
- Increasing costs of import procedure;
- Closing of some plants: recently Albemarle declared that will close his plan in  Langelsheim (north Germany) if this decision will be adopted.  This issue will influence 600 employees. 
- Exodus of Eu producers including battery recyclers.
- Protests of citizens against the plants.
3. THE US POLICY, PRO AND CONS
China dominates the Ev battery market and the USA currently mines and refines close to 0% of the minerals that go into EV battery packs. To improve lithium market conditions, the Biden administration launched the Ira incentives, a series of bonuses that make the American market appealing from many point of view. The main corporate teams are looking at the Ira seriously and starting to reconsider where is more opportune to launch the production with potential negative impact on the Eu market.
4. RUSSIA  AS ONE OF THE NEXT MAIN PRODUCERS  
It is important to consider that also Russia could become one of the worlds's five largest producers in eight years' time, due to his lithium resources that are 10% of the world's reserves.
This aspect must be analyzed as related to a strong impact on world market.
5. LITHIUM BATTERY : REUSE AND RECYCLE
Lithium batteries have a lifetimes of around ten to 15 years for passenger vehicles and depending on the recycling process employed it is possible to recover between zero and 80 percent of the lithium contained in end-of-life batteries. This means that by 2030 recycled batteries will account for slightly more than 6 percent o total lithium production.
6. RECOMMENDATIONS
The lithium market is growing and changing very fast, there are structural problems and different factors that need to be analyzed from our side in order to consider all the options and solution. It is essential that Europe will be a primary actor of this global trend otherwise the Green Deal could be put at risk. The Commission has to step up effort to investigate and prosecute the best strategy and evaluete incentive policy and alliances with realiable partners.
You
 
 AGENDA OF 2 MARCH 20XX
- Regulation on lithium battery advantages and disadvantages. 
- Increase of lithium demand: how che circular economy can help this trend, the needs to increase the lithium production and become more independent from Russia and China.
- Build a net of infrastructure able to guarantee the growth of the demand.
- How to satisfy the demand and be sustainable at the same time ? Considering the lithium carbonate toxic and general repercussion on the European supply chain.
- Lithium on the global market: analysis of Us policy, China and Russia actors.
- Final considerations and recommendations."
3,0_Generative AI (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. 

Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG CONNECT in the unit in charge of fighting against disinformation.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Critical thinking, analysing & creative problem-solving, Decision-making and getting results, Information management,  Communication.

Specifically, your task will be to draft a 2 to 2.5 - page speaking note for the Commisioner to clarify the intentions of the Commission with respect to generative AI (GAI). This document must include: 

What is GAI and what are the potential benefits.
What are the dangers associated with GAI and how does the EU want to address them.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations

AI - Artificial intelligence
AIA – Artificial Intelligence Act
AGI - Artificial general intelligence 
ANI - Artificial narrow intelligence
ANN - Artificial neural network
DSA – Digital Services Act
GAI – Generative AI
ML - Machine learning
NLP - Natural language processing


EMAIL 1","Subject: Press Release on generative AI

Dear YOU,

Earlier today, Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton met with representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation.
Jourová asked the signatories to create a dedicated and separate track within the code to deal with disinformation generated by Artificial Intelligence. It should aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them. 
Jourová will present her initiative at a press point tomorrow at 11:15 a.m. so could you prepare her talking points and send them to me this evening before closing of the office hours. She has asked to stress the importance of the fight against disinformation in the context of defending democracy and the EU values. 

Many thanks",",

Charles
Head of Unit





What are the most pressing dangers of AI?
As AI systems prove to be increasingly beneficial in real-world applications, they have broadened their reach, causing risks of misuse, overuse, and explicit abuse to proliferate. As AI systems increase in capability and as they are integrated more fully into societal infrastructure, the implications of losing meaningful control over them become more concerning. New research efforts are aimed at re-conceptualizing the foundations of the field to make AI systems less reliant on explicit, and easily mis specified, objectives. A particularly visible danger is that AI can make it easier to build machines that can spy and even kill at scale. But there are many other important and subtler dangers at present.
Techno-Solutionism
One of the most pressing dangers of AI is techno-solutionism, the view that AI can be seen as a panacea when it is merely a tool. As we see more AI advances, the temptation to apply AI decision-making to all societal problems increases. But technology often creates larger problems in the process of solving smaller ones. For example, systems that streamline and automate the application of social services can quickly become rigid and deny access to migrants or others who fall between the cracks. 
When given the choice between algorithms and humans, some believe algorithms will always be the less-biased choice. Yet, in 2018, Amazon found it necessary to discard a proprietary recruiting tool because the historical data it was trained on resulted in a system that was systematically biased against women. Automated decision-making can often serve to replicate, exacerbate, and even magnify the same bias we wish it would remedy.
Indeed, far from being a cure-all, technology can actually create feedback loops that worsen discrimination. Recommendation algorithms, like Google’s page rank, are trained to identify and prioritize the most “relevant” items based on how other users engage with them. As biased users feed the algorithm biased information, it responds with more bias, which informs users’ understandings and deepens their bias, and so on. Because all technology is the product of a biased system, techno-solutionism’s flaws run deep: a creation is limited by the limitations of its creator.
Dangers of Adopting a Statistical Perspective on Justice
Automated decision-making may produce skewed results that replicate and amplify existing biases. A potential danger, then, is when the public accepts AI-derived conclusions as certainties. This determinist approach to AI decision-making can have dire implications in both criminal and healthcare settings. AI-driven approaches like PredPol, software originally developed by the Los Angeles Police Department and UCLA that purports to help protect one in 33 US citizens, predict when, where, and how crime will occur. A 2016 case study of a US city noted that the approach disproportionately projected crimes in areas with higher populations of non-white and low-income residents. When datasets disproportionately represent the lower power members of society, flagrant discrimination is a likely result.
Sentencing decisions are increasingly decided by proprietary algorithms that attempt to assess whether a defendant will commit future crimes, leading to concerns that justice is being outsourced to software. As AI becomes increasingly capable of analyzing more and more factors that may correlate with a defendant's perceived risk, courts and society at large may mistake an algorithmic probability for fact. This dangerous reality means that an algorithmic estimate of an individual’s risk to society may be interpreted by others as a near certainty—a misleading outcome even the original tool designers warned against. Even though a statistically driven AI system could be built to report a degree of credence along with every prediction, there’s no guarantee that the people using these predictions will make intelligent use of them. Taking probability for certainty means that the past will always dictate the future.
There is an aura of neutrality and impartiality associated with AI decision-making in some corners of the public consciousness, resulting in systems being accepted as objective even though they may be the result of biased historical decisions or even blatant discrimination. All data insights rely on some measure of interpretation. As a concrete example, an audit of a resume-screening tool found that the two main factors it associated most strongly with positive future job performance were whether the applicant was named Jared, and whether he played high school lacrosse. Undesirable biases can be hidden behind both the opaque nature of the technology used and the use of proxies, nominally innocent attributes that enable a decision that is fundamentally biased. An algorithm fueled by data in which gender, racial, class, and ableist biases are pervasive can effectively reinforce these biases without ever explicitly identifying them in the code. 
Without transparency concerning either the data or the AI algorithms that interpret it, the public may be left in the dark as to how decisions that materially impact their lives are being made. Lacking adequate information to bring a legal claim, people can lose access to both due process and redress when they feel they have been improperly or erroneously judged by AI systems. Large gaps in case law make applying Title VII—the primary existing legal framework in the US for employment discrimination—to cases of algorithmic discrimination incredibly difficult. These concerns are exacerbated by algorithms that go beyond traditional considerations such as a person’s credit score to instead consider any and all variables correlated to the likelihood that they are a safe investment. A statistically significant correlation has been shown among Europeans between loan risk and whether a person uses a Mac or PC and whether they include their name in their email address—which turn out to be proxies for affluence. Companies that use such attributes, even if they do indeed provide improvements in model accuracy, may be breaking the law when these attributes also clearly correlate with a protected class like race. Loss of autonomy can also result from AI-created “information bubbles” that narrowly constrict each individual’s online experience to the point that they are unaware that valid alternative perspectives even exist.
Disinformation and Threat to Democracy
AI systems are being used in the service of disinformation on the internet, giving them the potential to become a threat to democracy and a tool for fascism. From deepfake videos to online bots manipulating public discourse by feigning consensus and spreading fake news, there is the danger of AI systems undermining social trust. The technology can be co-opted by criminals, rogue states, ideological extremists, or simply special interest groups, to manipulate people for economic gain or political advantage. Disinformation poses serious threats to society, as it effectively changes and manipulates evidence to create social feedback loops that undermine any sense of objective truth. The debates about what is real quickly evolve into debates about who gets to decide what is real, resulting in renegotiations of power structures that often serve entrenched interests. 
Discrimination and Risk in the Medical Setting
While personalized medicine is a good potential application of AI, there are dangers. Current business models for AI-based health applications tend to focus on building a single system—for example, a deterioration predictor—that can be sold to many buyers. However, these systems often do not generalize beyond their training data. Even differences in how clinical tests are ordered can throw off predictors, and, over time, a system’s accuracy will often degrade as practices change. Clinicians and administrators are not well-equipped to monitor and manage these issues, and insufficient thought given to the human factors of AI integration has led to oscillation between mistrust of the system (ignoring it) and over-reliance on the system (trusting it even when it is wrong), a central concern of the 2016 AI100 report.
These concerns are troubling in general in the high-risk setting that is healthcare, and even more so because marginalized populations—those that already face discrimination from the health system from both structural factors (like lack of access) and scientific factors (like guidelines that were developed from trials on other populations)—may lose even more. Today and in the near future, AI systems built on machine learning are used to determine post-operative personalized pain management plans for some patients and in others to predict the likelihood that an individual will develop breast cancer. AI algorithms are playing a role in decisions concerning distributing organs, vaccines, and other elements of healthcare. Biases in these approaches can have literal life-and-death stakes.
In 2019, the story broke that Optum, a health-services algorithm used to determine which patients may benefit from extra medical care, exhibited fundamental racial biases. The system designers ensured that race was precluded from consideration, but they also asked the algorithm to consider the future cost of a patient to the healthcare system. While intended to capture a sense of medical severity, this feature in fact served as a proxy for race: controlling for medical needs, care for Black patients averages $1,800 less per year.
New technologies are being developed every day to treat serious medical issues. A new algorithm trained to identify melanomas was shown to be more accurate than doctors in a recent study, but the potential for the algorithm to be biased against Black patients is significant as the algorithm was trained using majority light-skinned groups. The stakes are especially high for melanoma diagnoses, where the five-year survival rate is 17 percentage points less for Black Americans than white. While technology has the potential to generate quicker diagnoses and thus close this survival gap, a machine-learning algorithm is only as good as its data set. An improperly trained algorithm could do more harm than good for patients at risk, missing cancers altogether or generating false positives. As new algorithms saturate the market with promises of medical miracles, losing sight of the biases ingrained in their outcomes could contribute to a loss of human biodiversity, as individuals who are left out of initial data sets are denied adequate care. While the exact long-term effects of algorithms in healthcare are unknown, their potential for bias replication means any advancement they produce for the population in aggregate—from diagnosis to resource distribution—may come at the expense of the most vulnerable.








Regulatory framework proposal on artificial intelligence 
The Commission is proposing the first-ever legal framework on AI, which addresses the risks of AI and positions Europe to play a leading role globally. 

© gorodenkoff - iStock Getty Images Plus
The regulatory proposal aims to provide AI developers, deployers and users with clear requirements and obligations regarding specific uses of AI. At the same time, the proposal seeks to reduce administrative and financial burdens for business, in particular small and medium-sized enterprises (SMEs).
The proposal is part of a wider AI package, which also includes the updated Coordinated Plan on AI. Together, the Regulatory framework and Coordinated Plan will guarantee the safety and fundamental rights of people and businesses when it comes to AI. And they will strengthen uptake, investment and innovation in AI across the EU.
Why do we need rules on AI?
The proposed AI regulation ensures that Europeans can trust what AI has to offer. While most AI systems pose limited to no risk and can contribute to solving many societal challenges, certain AI systems create risks that we must address to avoid undesirable outcomes.
For example, it is often not possible to find out why an AI system has made a decision or prediction and taken a particular action. So, it may become difficult to assess whether someone has been unfairly disadvantaged, such as in a hiring decision or in an application for a public benefit scheme.
Although existing legislation provides some protection, it is insufficient to address the specific challenges AI systems may bring.
The proposed rules will:
address risks specifically created by AI applications.
propose a list of high-risk applications.
set clear requirements for AI systems for high-risk applications.
define specific obligations for AI users and providers of high-risk applications.
propose a conformity assessment before the AI system is put into service or placed on the market.
propose enforcement after such an AI system is placed in the market.
propose a governance structure at European and national level.
A risk-based approach

The Regulatory Framework defines 4 levels of risk in AI:
Unacceptable risk
High risk
Limited risk
Minimal or no risk
Unacceptable risk
All AI systems considered a clear threat to the safety, livelihoods and rights of people will be banned, from social scoring by governments to toys using voice assistance that encourages dangerous behaviour.
High risk
AI systems identified as high-risk include AI technology used in:
critical infrastructures (e.g., transport), that could put the life and health of citizens at risk.
educational or vocational training, that may determine the access to education and professional course of someone’s life (e.g., scoring of exams).
safety components of products (e.g., AI application in robot-assisted surgery).
employment, management of workers and access to self-employment (e.g., CV-sorting software for recruitment procedures).
essential private and public services (e.g., credit scoring denying citizens opportunity to obtain a loan).
law enforcement that may interfere with people’s fundamental rights (e.g., evaluation of the reliability of evidence).
migration, asylum, and border control management (e.g., verification of authenticity of travel documents).
administration of justice and democratic processes (e.g., applying the law to a concrete set of facts).
High-risk AI systems will be subject to strict obligations before they can be put on the market:
adequate risk assessment and mitigation systems.
high quality of the datasets feeding the system to minimize risks and discriminatory outcomes.
logging of activity to ensure traceability of results.
detailed documentation providing all information necessary on the system and its purpose for authorities to assess its compliance.
clear and adequate information to the user.
appropriate human oversight measures to minimize risk.
high level of robustness, security and accuracy.
All remote biometric identification systems are considered high risk and subject to strict requirements. The use of remote biometric identification in publicly accessible spaces for law enforcement purposes is, in principle, prohibited.
Narrow exceptions are strictly defined and regulated, such as such as when necessary to search for a missing child, to prevent a specific and imminent terrorist threat or to detect, locate, identify, or prosecute a perpetrator or suspect of a serious criminal offence.
Such use is subject to authorization by a judicial or other independent body and to appropriate limits in time, geographic reach and the data bases searched.
Limited risk
Limited risk refers to AI systems with specific transparency obligations. When using AI systems such as chatbots, users should be aware that they are interacting with a machine so they can take an informed decision to continue or step back.
Minimal or no risk
The proposal allows the free use of minimal-risk AI. This includes applications such as AI-enabled video games or spam filters. Most AI systems currently used in the EU fall into this category.



How does it all work in practice for providers of high-risk AI systems?
Once an AI system is on the market, authorities oversee market surveillance, users ensure human oversight and monitoring, and providers have a post-market monitoring system in place. Providers and users will also report serious incidents and malfunctioning.
Future-proof legislation
As AI is a fast-evolving technology, the proposal has a future-proof approach, allowing rules to adapt to technological change. AI applications should remain trustworthy even after they have been placed on the market. This requires ongoing quality and risk management by providers.




The 5 biggest risks of generative AI, according to an expert 
AI makes our lives easier in many different ways. However, these benefits can come with costs. 



Written by Sabrina Ortiz, Associate Editor on April 25, 20XX

Generative AIs, such as ChatGPT, have revolutionized how we interact with and view AI. Activities like writing, coding, and applying for jobs have become much easier and quicker. With all the positives, however, there are some pretty serious risks.
A major concern with AI is trust and security, which has even caused some countries to completely ban ChatGPT as a whole or to reconsider policy around AI to protect users from harm. 
According to Gartner analyst Avivah Litan, some of the biggest risks of generative AI concern trust and security and include hallucinations, deepfakes, data privacy, copyright issues, and cybersecurity problems.
1. Hallucinations
Hallucinations refer to the errors that AI models are prone to make because, although they are advanced, they are still not human and rely on training and data to provide answers. 
If you've used an AI chatbot, then you have probably experienced these hallucinations through a misunderstanding of your prompt or a blatantly wrong answer to your question.
Litan says the training data can lead to biased or factually incorrect responses, which can be a serious problem when people are relying on these bots for information. 
""Training data can lead to biased, off base or wrong responses, but these can be difficult to spot, particularly as solutions are increasingly believable and relied upon,"" says Litan. 
2. Deepfakes
A deepfake uses generative AI to create videos, photos, and voice recordings that are fake but take the image and likeness of another individual. 
Perfect examples are the AI-generated viral photo of Pope Francis in a puffer jacket or the AI-generated Drake and the Weeknd song, which garnered hundreds of thousands of streams. 
""These fake images, videos and voice recordings have been used to attack celebrities and politicians, to create and spread misleading information, and even to create fake accounts or take over and break into existing legitimate accounts,"" says Litan. 
Like hallucinations, deepfakes can contribute to the massive spread of fake content, leading to the spread of misinformation, which is a serious societal problem. 
3. Data privacy
Privacy is also a major concern with generative AI since user data is often stored for model training. This concern was the overarching factor that pushed Italy to ban ChatGPT, claiming OpenAI was not legally authorized to gather user data. 
""Employees can easily expose sensitive and proprietary enterprise data when interacting with generative AI chatbot solutions,"" says Litan. ""These applications may indefinitely store information captured through user inputs, and even use information to train other models -- further compromising confidentiality.""
Litan highlights that, in addition to compromising user confidentiality, the stored information also poses the risk of ""falling into the wrong hands"" in an instance of a security breach.
4. Cybersecurity
The advanced capabilities of generative AI models, such as coding, can also fall into the wrong hands, causing cybersecurity concerns.
""In addition to more advanced social engineering and phishing threats, attackers could use these tools for easier malicious code generation,"" says Litan. 
Litan says even though vendors who offer generative AI solutions typically assure customers that their models are trained to reject malicious cybersecurity requests, these suppliers don't equip end users with the ability to verify all the security measures that have been implemented. 
5. Copyright issues
Copyright is a big concern because generative AI models are trained on massive amounts of internet data that is used to generate an output. 
This process of training means that works that have not been explicitly shared by the original source can then be used to generate new content. 
Copyright is a particularly thorny issue for AI-generated art of any form, including photos and music. 
To create an image from a prompt, AI-generating tools, such as DALL-E, will refer back to the large database of photos they were trained on. The result of this process is that the final product might include aspects of an artist's work or style that are not attributed to them. 
Since the exact works that generative AI models are trained on are not explicitly disclosed, it is hard to mitigate these copyright issues. 
What's next?
Despite the many risks associated to generative AI, Litan doesn't think that organizations should stop exploring the technology. Instead, they should create an enterprise-wide strategy that targets AI trust, risk, and security management. 
""AI developers must urgently work with policymakers, including new regulatory authorities that may emerge, to establish policies and practices for generative AI oversight and risk management,"" says Litan. 
 

What is generative AI?
In simple terms, generative AI is a subfield of artificial intelligence in which computer algorithms are used to generate outputs that resemble human-created content, be it text, images, graphics, music, computer code or otherwise.
In generative AI, algorithms are designed to learn from training data that includes examples of the desired output. By analyzing the patterns and structures within the training data, generative AI models can produce new content that shares characteristics with the original input data. In doing so, generative AI has the capacity to generate content that appears authentic and human-like.
How does generative AI work?
Generative AI is based on machine learning processes inspired by the inner workings of the human brain, known as neural networks. Training the model involves feeding algorithms large amounts of data, which serves as the foundation for the AI model to learn from. This can consist of text, code, graphics, or any other type of content relevant to the task at hand.
Once the training data has been collected, the AI model analyzes the patterns and relationships within the data to understand the underlying rules governing the content. The AI model continuously fine-tunes its parameters as it learns, improving its ability to simulate human-generated content. The more content the AI model generates, the more sophisticated and convincing its outputs become.
Examples of generative AI
Generative AI has made significant advancements in recent years, with several tools capturing the public attention and creating a stir amongst content creators. Big tech companies have also jumped on the bandwagon, with Google, Microsoft, Amazon, and others all lining up their own generative AI tools.
Depending on the application, generative AI tools may rely on an input prompt that guides it towards producing a desired outcome — think ChatGPT and DALL-E 2.
Some of the most notable examples of generative AI tools include:
ChatGPT: Developed by OpenAI, ChatGPT is an AI language model that can generate human-like text based on given prompts.
DALL-E 2: Another generative AI model from OpenAI, DALL-E is designed to create images and artwork based on text-based prompts.
Midjourney: Developed by San Francisco-based research lab Midjourney Inc., Midjourney interprets text prompts and context to produce visual content, like DALL-E 2.
GitHub Copilot: An AI-powered coding tool created by GitHub and OpenAI, GitHub Copilot suggests code completions for users of development environments like Visual Studio and JetBrains.
Benefits of generative AI
The most compelling advantage generative AI proposes is efficiency, in that it can enable businesses to automate specific tasks and focus their time, energy and resources on more important strategic objectives. This often results in lower labor costs and an increase in operational efficiency.
Generative AI can offer additional advantages to businesses and entrepreneurs, including:
Easily customizing or personalizing marketing content.
Generating new ideas, designs, or content.
Writing, checking, and optimizing computer code.
Drafting templates for essays or articles.
Enhancing customer support with chatbots and virtual assistants.
Facilitating data augmentation for machine learning models.
Analyzing data to improve decision-making.
Streamlining research and development processes.
Use cases of generative AI
Despite generative AI still being in its relative infancy, the technology has already found a firm foothold in various applications and industries.
In content creation, for instance, generative AI can produce text, images and even music, assisting marketers, journalists, and artists with their creative processes. In customer support, AI-driven chatbots and virtual assistants can provide more personalized assistance and reduce response times while reducing the burden on customer service agents.
Other uses of generative AI include:
Healthcare: Generative AI is used in medicine to accelerate the discovery of novel drugs, saving time and money in research.
Marketing: Advertisers use generative AI to craft personalized campaigns and adapt content to consumers’ preferences.
Education: Some educators use generative AI models to develop customized learning materials and assessments that cater to students’ individual learning styles.
Finance: Financial analysts use generative AI to examine market patterns and predict stock market trends.
Environment: Climate scientists employ generative AI models to predict weather patterns and simulate the effects of climate change.
Dangers and limitations of generative AI
It’s important to note that generative AI presents numerous issues requiring attention. One major concern is its potential for spreading misinformation or malicious or sensitive content, which could cause profound damage to people and businesses — and potentially pose a threat to national security.
These risks have not escaped policymakers. In April 20XX, the European Union proposed new copyright rules for generative AI that would require companies to disclose any copyrighted material used to develop these tools. Hopes are that such rules will encourage transparency and ethics in AI development, while minimizing any misuse or infringement of intellectual property. This should also offer some protection to content creators whose work may be unwittingly mimicked or plagiarized by generative AI tools.
The automation of tasks by generative AI could also affect the workforce and contribute to job displacement, requiring impacted employees to reskill or upskill. Additionally, generative AI models can unintentionally learn and amplify biases present in training data, leading to problematic outputs that perpetuate stereotypes and harmful ideologies.
ChatGPT, Bing AI and Google Bard have all drawn controversy for producing incorrect or harmful outputs since their launch, and these concerns must be addressed as generative AI evolves, particularly given the difficulty of scrutinizing the sources used to train AI models.
Generative AI vs. general AI
Generative AI and general AI represent different aspects of artificial intelligence. Generative AI focuses on creating new content or ideas based on existing data. It has specific applications and is a subset of AI that excels at solving particular tasks.
General AI, also known as artificial general intelligence, broadly refers to the concept of AI systems that possess human-like intelligence. General AI is still the stuff of science fiction; it represents an imagined future stage of AI development in which computers are able to think, reason and act autonomously.
Is generative AI the future?
It depends on who you ask, but many experts believe that generative AI has a significant role to play in the future of various industries. The capabilities of generative AI have already proven valuable in areas like content creation, software development and healthcare, and as the technology continues to evolve, so too will its applications and use cases.
That said, the future of generative AI is inextricably tied to addressing the potential risks it presents. Ensuring AI is used ethically by minimizing biases, enhancing transparency and accountability and upholding data governance will be critical as the technology progresses. At the same time, striking a balance between automation and human involvement will be crucial for maximizing the benefits of generative AI while mitigating any potential negative consequences on the workforce.






STOCKHOLM, April 27 (Reuters) - Companies deploying generative AI tools, such as ChatGPT, will have to disclose any copyrighted material used to develop their systems, according to an early EU agreement that could pave the way for the world's first comprehensive laws governing the technology.
The European Commission began drafting the AI Act nearly two years ago to regulate emerging artificial intelligence technology, which underwent a boom in investment and popularity following the release of OpenAI's AI-powered chatbot ChatGPT.
Members of the European Parliament agreed to push the draft through to the next stage, the trilogue, during which EU lawmakers and member states will thrash out the final details of the bill.
Under the proposals, AI tools will be classified according to their perceived risk level: from minimal through to limited, high, and unacceptable. Areas of concern could include biometric surveillance, spreading misinformation or discriminatory language.
While high-risk tools will not be banned, those using them will need to be highly transparent in their operations.
Companies deploying generative AI tools, such as ChatGPT or image generator Midjourney, will also have to disclose any copyrighted material used to develop their systems.
This provision was a late addition drawn up within the past two weeks, according to a source familiar with discussions. Some committee members initially proposed banning copyrighted material being used to train generative AI models altogether, the source said, but this was abandoned in favour of a transparency requirement.
""Against conservative wishes for more surveillance and leftist fantasies of over-regulation, parliament found a solid compromise that would regulate AI proportionately, protect citizens' rights, as well as foster innovation and boost the economy,"" said Svenja Hahn, a European Parliament deputy.
Macquarie analyst Fred Havemeyer said the EU's proposal was ""tactful"" rather than a ""ban first, and ask questions later"" approach proposed by some.
""The EU has been on the frontier of regulating AI technology,"" he told Reuters.
RACE TO MARKET
Microsoft-backed (MSFT.O) OpenAI provoked awe and anxiety around the world when it unveiled ChatGPT late last year. The chatbot became the fastest-growing consumer application in history, reaching 100 million monthly active users in a matter of weeks.
The ensuing race among tech companies to bring generative AI products to market concerned some onlookers, with Twitter-owner Elon Musk backing a proposal to halt development of such systems for six months. Shortly after signing the letter, the Financial Times reported Musk was planning to launch his own startup to rival OpenAI.


Sharon Goldman
@sharongoldman

December 5, 20XX-1

The hidden danger of ChatGPT and generative AI | The AI Beat
Since OpenAI launched its early demo of ChatGPT last Wednesday, the tool already has over a million users, according to CEO Sam Altman — a milestone, he points out, that took GPT-3 nearly 24 months to get to and DALL-E over 2 months. 
The “interactive, conversational model,” based on the company’s GPT-3.5 text-generator, certainly has the tech world in full swoon mode. Aaron Levie, CEO of Box, tweeted that “ChatGPT is one of those rare moments in technology where you see a glimmer of how everything is going to be different going forward.” Y Combinator cofounder Paul Graham tweeted that “clearly something big is happening.” Alberto Romero, author of The Algorithmic Bridge, calls it “by far, the best chatbot in the world.” And even Elon Musk weighed in, tweeting that ChatGPT is “scary good. We are not far from dangerously strong AI.” 
But there is a hidden problem lurking within ChatGPT: That is, it quickly spits out eloquent, confident responses that often sound plausible and true even if they are not. 
ChatGPT can sound plausible even if its output is false.
Like other generative large language models, ChatGPT makes up facts. Some call it “hallucination” or “stochastic parroting,” but these models are trained to predict the next word for a given input, not whether a fact is correct or not. 
Some have noted that what sets ChatGPT apart is that it is so darn good at making its hallucinations sound reasonable. 
Technology analyst Benedict Evans, for example, asked ChatGPT to “write a bio for Benedict Evans.” The result, he tweeted, was “plausible, almost entirely untrue.” 
More troubling is the fact that there are obviously an untold number of queries where the user would only know if the answer was untrue if they already knew the answer to the posed question. 
That’s what Arvind Narayanan, a computer science professor at Princeton, pointed out in a tweet: “People are excited about using ChatGPT for learning. It’s often very good. But the danger is that you can’t tell when it’s wrong unless you already know the answer. I tried some basic information security questions. In most cases the answers sounded plausible but were in fact BS.” 
Fact-checking generative AI
Back in the waning days of print magazines in the 2000s, I spent several years as a fact-checker for publications including GQ and Rolling Stone. Each fact had to include authoritative primary or secondary sources — and Wikipedia was frowned upon. 
Few publications have staff fact-checkers anymore, which puts the onus on reporters and editors to make sure they get their facts straight — especially at a time when misinformation already moves like lightning across social media, while search engines are constantly under pressure to surface verifiable information and not BS. 
That’s certainly why Stack Overflow, the Q&A site for coders and programmers, has temporarily banned users from sharing ChatGPT responses. 
And if StackOverflow can’t keep up with misinformation due to AI, it’s hard to imagine others being able to manage a tsunami of potential AI-driven BS. As Gary Marcus tweeted, “If StackOverflow can’t keep up with plausible but incorrect information, what about social media and search engines?” 
And while many are salivating at the idea that LLMs like ChatGPT could someday replace traditional search engines, others are strongly pushing back. 
Emily Bender, professor of linguistics at the University of Washington, has long pushed back on this notion. 
She recently emphasized again that LLMs are “not fit” for search —” both because they are designed to just make sh** up and because they don’t support information literacy.” She pointed to a paper she co-authored on the topic published in March. 
Is it better for ChatGPT to look right? Or be right? 
BS is obviously something that humans have perfected over the centuries. And ChatGPT and other large language models have no idea what it means, really, to “BS.” But OpenAI made this weakness very clear in its blog announcing the demo and explained that fixing it is “challenging,” saying: 
“ChatGPT sometimes writes plausible sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: (1) during RL [reinforcement learning] training, there’s currently no source of truth; (2) training the model to be more cautious causes it to decline questions that it can answer correctly; and (3) supervised training misleads the model because the ideal answer depends on what the model knows, rather than what the human demonstrator knows.” 
So, it’s clear that OpenAI knows perfectly well that ChatGPT is filled with BS under the surface. They never meant the technology to offer up a source of truth. 
But the question is: Are human users okay with that? 
Unfortunately, they might be. If it sounds good, many humans may think that’s good enough. And, perhaps, that’s where the real danger lies beneath the surface of ChatGPT. 





By JAKOB HANKE VELA
Send tips here | Tweet @HankeVela | Listen to Playbook and view in your browser
LABELING AI CONTENT        
TODAY: EU PUSHES FOR ‘AI LABEL’ TO FIGHT DEEPFAKES: Brussels wants to prevent artificial intelligence from blurring the lines between fact and fiction — and will today ask companies for the first time ever to come up with a label to identify AI-generated texts and images to fight disinformation, officials tell Playbook.
Brave new world: Generative AI is making breathtaking advances — from writing texts and code to creating ever more realistic pictures and videos — which will have enormous consequences not just for the future of society and work, but for politics, Commission officials reckon. 
Balenc-ai-ga: The fake images of the Pope and famous politicians wearing a Balenciaga coat that went viral earlier this year have clearly spooked them — and they now want to label such deepfakes.
Fake porn: “Today it is mostly still a game, but tomorrow you could see a fake porn with a candidate,” one official who is working on the file but was not authorized to speak on the record told Playbook, referring to AI-generated images of politicians. 
Race to regulate: The Commission (the EU’s executive, which proposes and enforces laws) — has proposed an AI Act to regulate high-risk applications and ban the most dangerous ones. But even before that act enters into force, the Commission will urge industry to cut down on trickery by labeling AI-generated work.
Happening today: Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton will meet representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation. They include Microsoft, Google, Meta, TikTok, Twitch and smaller companies — but not Twitter, which has left the code — as well as NGOs.
Disinformation risks: “I will ask the signatories to create a dedicated and separate track within the code” to deal with disinformation generated by Artificial Intelligence, Jourová told Playbook. “It should … aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them.”
EU pushes for safeguards: How does Brussels want the companies to tackle the risks? “Signatories who integrate generative AI into their services like Bingchat for Microsoft, Bard for Google should build in necessary safeguards that these services cannot be used by malicious actors to generate disinformation,” Jourová said.
Clear labels: “Signatories who have services with a potential to disseminate AI-generated disinformation should in turn put in place technology to recognize such content and clearly label this to users.”
More about this label: Two officials working on the file told Playbook the label should apply to all AI-generated material that can be used to create disinformation, including text, images, audio and video.
Voluntary — for now: It wouldn’t be mandatory, given that it would be part of the voluntary Code of Practice. However, the Commission aims to make the code enforceable by including it as a code of conduct in the Digital Services Act (DSA). Obligations on labeling AI content may also make it into the AI Act during negotiations between EU countries, Parliament, and the Commission, one official said.
How can companies do this? “They can develop, and they probably already have tools to check whether an image was AI-generated or not,” the first official said.
Playbook wonders: Given how easy it is for AI to proliferate across jurisdictions, will such a technology ever be able to identify all deepfakes — or won’t we, on the contrary, one day need some chain of custody procedure for authentic images that can be used, for example, as evidence in court?
Stay tuned: Jourová will present her initiative at a press point tomorrow at 11:15 a.m.
SPEAKING OF WHICH: While the Commission is calling on others to do more, it was recently reported that it awarded and signed a €3.7 million tender to help analyze issues like disinformation, foreign meddling in elections and global threats from a French firm that’s mired in controversy.
Avisa Partners has previously been accused of manipulating information in France and working for authoritarian regimes. The company was recently at the center of a controversy as the organizer of a cybersecurity forum boycotted by the French armed forces ministry and several government officials. More here for our Pro Cybersecurity subscribers.
Looking into this: The Commission is looking into the allegations and “is in contact with French counterparts to seek more clarity on those claim[s],” Peter Stano, the Commission’s spokesperson for foreign affairs and security policy, told my POLITICO Pro Technology colleagues. The EU executive is “closely monitoring the implementation of this project,” he added. 
Jean Tillinac, from Avisa Partners, told my Pro Tech colleagues that the bid was “defended by a team of seasoned experts from our Strategic Intelligence Division” doing research and which was different from the “Digital Communications Division” facing criticism.



Annex I – Glossary of Terms
Algorithm: a formula given to a computer for it to complete a task (i.e., a set of rules for a computer) 
Artificial intelligence: a subset of computer science that deals with computer systems performing tasks with similar, equal, or superior intelligence to that of a human (e.g., decision-making, object classification and detection, speech recognition and translation)
Artificial general intelligence (AGI): also known as strong AI, AGI is a type of artificial intelligence that is considered human-like, and still in its preliminary stages (more of a hypothetical existence in present day)
Artificial narrow intelligence (ANI): also known as weak AI, ANI is a type of artificial intelligence that can only focus on one task or problem at a given time (e.g., playing a game against a human competitor). This is the current existing form of AI.
Artificial neural network (ANN): a network modeled after the human brain by creating an artificial neural system via a pattern-recognizing computer algorithm that learns from, interprets, and classifies sensory data.
Big data: large amounts of structured and unstructured data that is too complex to be handled by standard data-processing software.
Chatbots: a chat robot that can converse with a human user through text or voice commands. Utilized by e-commerce, education, health, and business industries for ease of communication and to answer user questions. 
Cognitive computing: computerized model that mimics human thought processes by data mining, NLP, and pattern recognition.
Computer vision: when a machine processes visual input from image files (JPEGs) or camera feeds
Data mining: the process of sorting through large sets of data to identify recurring patterns while establishing problem-solving relationships.
Deep learning: a machine learning technique that teaches computers how to learn by rote (i.e., machines mimic learning as a human mind would, by using classification techniques)
Generative AI: Generative artificial intelligence or generative AI is a type of artificial intelligence (AI) system capable of generating text, images, or other media in response to prompts. Generative AI models learn the patterns and structure of their input training data, and then generate new data that has similar characteristics. 
Genetic algorithm: an algorithm based on principles of genetics that is used to find solutions efficiently and quickly to difficult problems.
Machine learning (ML): focuses on developing programs that access and use data on their own, leading machines to learn for themselves and improve from learned experiences.
Natural language processing (NLP): helps computers process, interpret, and analyze human language and its characteristics by using natural language data. 
Pattern recognition: automated recognition of patterns found in data.
Reinforcement learning: a machine learning method where the reinforcement algorithm learns by interacting with its environment and is then penalized or rewarded based on decisions it makes.
Strong AI: see artificial general intelligence (AGI)  
Structured data: clearly defined data with easily searchable patterns.
Supervised learning: a type of machine learning where output datasets teach machines to generate desired outcomes or algorithms (akin to a teacher-student relationship).
Transfer learning: a system that uses previously learned data and applies it to a new set of tasks.
Turing Test: a test created by computer scientist Alan Turing (1950) to see if machines could exhibit intelligence equal to or indistinguishable from that of a human.
Unstructured data: data without easily searchable patterns (e.g., audio, video, social media content)
Unsupervised learning: a type of machine learning where an algorithm is trained with information that is neither classified nor labeled, thus allowing the algorithm to act without guidance.",20,7.0,"Summary
According to the Notice of Competitions of current EPSO competitions, the only competency that will be assessed in the Case Study exam is Written Communication",7.0,"Observations
The candidate clearly has a very high level of writing capability. The most relevant information has been summarized and convincing arguments with solid reasoning are employed. 

However, the style and tone is more suited to a written briefing than a speech.  

Although it is a speech, it is still advisable to clearly mark sections on the document for the speaker: e.g., introduction; what is generative AI; the dangers of generative AI; legal framework on AI; new rules for generative AI; conclusion.

Considering this is a press conference, consider an introduction that would better capture the attention of the audience in a couple of impactful, punchy sentences and quickly summarize what the speech will touch on. 

For example, could have alluded to ChatGPT and DALL.E, recognizable names that generative AI is known as in the public sphere. 

Again, considering this is a speech, include something that would immediately connect with the emotion of the audience. For example, people are fearful of losing their jobs in the not-to-distant future.

Use the introduction to also communicate the consequences this technology could have regarding the future of work, for society, politics and democracy. And that the goal is to stop disinformation by way of a clear labelling system. 

The body of the document is written clearly and fluently with a very pleasing style. 

Could have mentioned that generative AI produces text that appears authentic and human-like.

Regarding the legal framework: Perhaps mention what the obligations entail re tools that receive a high-risk classification. They will not be banned, but those using them will need to be highly transparent in their operations. 

Some grammar issues – allow enough time to proof-read the work. 

Unfortunate that the candidate was unable to finish the speech in the time available.  A brief conclusion was omitted as a result. 

Although most key issues were covered, these points were not, most probably due to lack of time. 

-  a clear labelling system for services with potential to disseminate AI-generated disinformation.
- services that integrate generative AI such as Bingchat for Microsoft and Bard for Google should include safeguards so that they cannot be used by malicious actors. 
- the Commission aims to make the code enforceable by including it as a code of conduct in the Digital Services Act.
- obligations on labelling AI content may also make it into the AI Act during negotiations between EU countries, Parliament and the Commission.",,"Tips to Improve
Decide on the amount of detail needed to be able to adequately finish the task in the time available and allow time to proof-read.

Adjust the communication style to the document you are asked to write. 

Clearly marking sections helps not only the writer assemble the information but also the reader/speaker more easily digest it.","Trainee's Answer
Speaking notes for the attention of the Commissioner
Generative AI
Scene setter 
On 10 June 20XX, at 11:15 AM, you will hold a press conference in order to present a dedicated track on disinformation risks presented by generative AI in the context of the EU's Code of Practice against disinformation. This press release follows the meeting with Commissioner Breton and representatives of signatories of the Code of Practice on 9 June 20XX.
Speaking points
- The EU stands at the vanguard of sound regulation of emerging artificial intelligence technology. With the new AI package, the first-ever legal framework on AI, the EU becomes a global leader in this area.
- Today, we are announcing yet another step towards increased transparency and accountability of AI that will help protect the interests of all European citizens - a new dedicated and separate track to the Code of Practice against disinformation, which we have signed with dozens of the leading tech companies, including Microsoft, Google, Meta, TikTok or Twitch.
- This track will focus on fight against disinformation created by generative Artificial Intelligence. Generative AI is a type of artificial intelligence system capable of generating text, images, or other media in response to prompts from users. These are models that can learn from the patterns and structure of their input training data, and generate new data on this basis.
- Generative AI offers many benefits for all European citizens, yet brings along risks too. Along with Commissioner Breton, we want to use this initiative to help European citizens and companies reap the benefits of this new technology, rather than stifle it. This is why it will be done on a voluntary basis.
- Among key benefits of generative AI are increase in operational efficiency and lower labor costs. It can allow European companies to focus on strategic objectives through automation of routine tasks. Industrial uses of generative AI are broad, from healthcare and education, through marketing and finance, all the way to the fight against climate change.
- However, these benefits can only be put in practice if we can guarantee the safety and fundamental rights of people and businesses using it. There are a number of very serious risks when it comes to generative AI. Most importantly, generative AI can seriously increase risk of spreading disinformation and pose a serious threat to democracy and EU values. As the so called Deepfakes, or AI-generated images, videos or voice recordings that can affect any one of us. They can also seriously impact election outcomes, be misused by criminals or rogues states, and become threat to democracy. Among other serious dangers are concerns as to data privacy, cybersecurity, infringements of intellectual property rights, or possibly biases against minorities. 
- In a related piece of legislation, the European Commission has already proposed new copyright rules for generative AI which would require companies to disclose any copyrighted material, thus protecting intellectual property rights.
- In our comprehensive AI Act, we have outlined rules to govern AI technology and a classification of AI tools based on their perceived risk - from unnacceptable, which would entail banning of such AI system, to minimal/no risk, which concerns most AI systems currently used in the EU. Strict obligations will be imposed on the high-risk systems in order to protect EU citizens, companies and security overall. Thus, we will make sure no one is discriminated against based on their race, religion, gender, or other characteristics by an AI system trained on inherently biased historical data.
- The AI Act aims at protecting our citizens without imposing unnecessary regulatory burdens on companies, thus fostering innovation and boosting the economy at the same time.
- The initiative I am presenting here today goes in the same direction. Without imposing mandatory restrictions, Commissioner Breton and myself have asked the 40-odd signatories of the EU's Code of Practice against disinformation to come up with specific measures to tackle disinformation risks presented by generative AI.
- Together, we will formulate a system that will allow us to reap the benefits of generative AI all the while protecting the European citizens from disinformation and"
1,0_Lithium Supply Chain (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG MOVE. 
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Analysis and Problem Solving, Communicating (Drafting Skills), Delivering Quality & Results, and Prioritising & Organising.

Specifically, your task will be to draft a memo for your Head of Unit.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations


ACEA - European Automobile Manufacturers’ Association 

DLE - direct lithium extraction

DLP - direct lithium to product 

ECHA - European Chemicals Agency

ESG - environmental, social, and governance

EV – Electric Vehicle

INN – Investing News Network

IRA – Inflation reduction Act (US)

LCE - lithium carbonate equivalent

LiPo – Lithium Polymer







EMAIL 1","Subject: Towards a sustainable, circular, European battery supply chain 
Dear YOU,

In December 20XX-2, the Commission presented a proposal for a regulation on batteries and waste batteries. The proposal aims to strengthen the functioning of the internal market, promoting a circular economy and reducing the environmental and social impact throughout all stages of the battery life cycle. The initiative is closely linked to the European Green Deal, the Circular Economy Action Plan, and the New Industrial Strategy. 
At the end of last year, The Council and the European Parliament reached a provisional political agreement on the proposal. For the first time the legislation will regulate the entire life cycle of a battery – from the supply chain of raw materials, over the production to reuse and recycling of batteries – and ensure that they are safe, sustainable, and competitive.
As you know, our unit has the lead on this important file and our DG intends to launch the formal interservice consultation over the coming weeks. Before this, our DG wants to organize an internal reflection and brainstorming meeting, and I have been appointed to chair this meeting.
Could you produce an internal memo, summarizing the main ins and outs of this file and the agenda for the internal meeting with concrete proposals and recommendations to fine-tune the original proposal, in line with the political priorities of the co-legislators. 
I’m on mission tomorrow so please could you get this done for me today. It doesn’t need to be long – in fact the shorter, the better.  

Many thanks",",

Ferdinand
Head of Unit




Is Europe Moving Fast Enough to Build a Resilient Lithium Supply Chain? 
Priscila Barrera
Nov. 16, 20XX-1


Europe will soon release its Critical Raw Materials Act to identify potential strategic projects and build up reserves where supply is at risk.
Europe’s green energy transition plans give a central role to the electrification of transportation. 
The European Union (EU) has ambitious goals to become climate neutral by 2050, meaning it would be an economy with net-zero greenhouse gas emissions. Recently proposed legislation is looking to effectively ban all internal combustion engine cars by 2035.
In 20XX-2, electric car registrations for the year were close to 1,729,000, up from 1,061,000 in 2020, with prospects for the region remaining positive. Last year, the market share of battery electric cars almost doubled to around 10 percent, but challenges faced by carmakers continue to weigh on demand as inflation and fears of a recession put pressure on targets. 
In its most recent forecast, the European Automobile Manufacturers’ Association (ACEA) said it expects the overall EU car market to shrink again this year, slipping by 1 percent to reach 9.6 million units.
“To ensure a return to growth — with an even greater share of electric vehicle sales so climate targets can be met — we urgently need the right framework conditions to be put in place,” said Oliver Zipse, ACEA president and CEO of BMW. “These include greater resilience in Europe’s supply chains, an EU Critical Raw Materials Act that ensures strategic access to the raw materials needed for e-mobility, and an accelerated roll-out of charging infrastructure.”
As sales of electric vehicles increase, carmakers are looking to secure supply of key metals used in batteries, including lithium. Today, Europe is quite dependent on Australia and Chile for lithium supply and China for lithium refining, but the region is taking steps to strengthen its supply chain for the important battery metal. 
What is the European Critical Raw Materials Act? 
In September, news broke that Europe will be putting forward the European Critical Raw Materials Act, a new piece of legislation. Its aim is to identify potential strategic projects and build up reserves where supply is at risk.
European Commission President Ursula von der Leyen said the bloc has learned its lesson about the risks of being dependent on Russia, and realizes the need to be vigilant toward China.
""In the case of China, it is the risk of dependency on technologies and raw materials,"" she said, adding that the EU needs to boost its production capacity and shift more towards trustworthy suppliers.
In October, von der Leyen said the EU is witnessing quite an acceleration of trends and tensions with China. 
""The Chinese system is fundamentally different from ours and we are aware of the nature of the rivalry,'' she said.
The moves from the EU are in line with pushes seen in other regions such as North America, where the US has committed billions of dollars to reach its carbon emissions targets.
In June, the Biden administration launched the Inflation Reduction Act, which includes climate incentives. The legislation, which was signed into law in August, requires automakers to source 50 percent of critical minerals used in electric vehicle batteries from North America or free trade agreement countries by 2024, with that amount rising to 80 percent by the end of 20XX+3.
For its part, Canada recently ordered three Chinese companies to divest from lithium companies following a “multi-step national security review process.” China has opposed the move, and Canada is expected to release its China strategy soon.
Europe-Asia relationship in the lithium space 
Jack Bedder of Project Blue said Asia will always be a part of the European lithium-ion battery supply chain. Major Asian companies, including Panasonic, Samsung, BYD Company and CATL, all have operating capacity on the continent.
“As a result, it will be almost impossible to detach fully from Chinese-owned supply across all stages of the lithium-ion supply chain,” he told the Investing News Network.
However, as lithium processing capacity is built up globally at non-Chinese-owned companies, particularly within the EU, the opportunities to reduce the EU's dependency on China-owned supply will improve. “It is very unlikely that the EU will implement legislation directly prohibiting lithium supply from Chinese-owned companies, as further constraints on supply availability to the European market will only hinder growth in the industry over the coming decade,” Bedder added.
For Allan Pedersen of Wood Mackenzie, Europe cannot move forward without influence from Asia in the short to medium term.
That’s due to a few reasons. As mentioned, many of the battery plants being constructed in Europe have Asian companies behind them, and the cathodes needed in batteries are still largely produced in Asia, where the know-how is strongest. Additionally, lithium refining is mainly done in China and most mineral concentrate is produced in Australia.
“China has a multi-year advantage over the rest of the world in terms of investing in the entire supply chain — it will be challenging for Europe to catch up to that in terms of investment in know-how, processing equipment and resources,” he said. 
“This doesn’t mean that Europe cannot make progress in this space. In lithium, we see some resource developments and processing facilities being considered and constructed.”
For the analyst, in the long-term Europe has the potential to become more self-sufficient for raw materials as recycling becomes a larger part of the supply landscape and can supplement domestic resources.
European Commission could classify lithium as toxic. 
Although Europe is pushing to build a resilient supply chain by partnering with allies and developing domestic resources, it might not all be good news for miners in the region — at the end of last year, the European Commission said it will weigh a proposal from the European Chemicals Agency to classify lithium carbonate, chloride and hydroxide as dangerous for human health.
If the proposal is approved, this could undermine the EU’s attempt to create and support a domestic battery materials supply chain, research firm Rystad Energy said in a statement. “The EU currently relies heavily on imports of lithium to supply its nascent electric vehicle production sector and the classification may increase its reliance on other regions, at a time when the union is focused on energy security and reducing emissions,” the document reads.
If the classification goes ahead, it would not stop lithium usage, but it is highly likely to have an impact on at least four stages: lithium mining, processing, cathode production and recycling.
“This potential ruling comes at a time when the EU is itself scrambling to build and establish local lithium supply chains. The permitting issue has repeatedly been highlighted at recent industry events as one of the main barriers to new mining projects ramping up quickly in the EU,” according to Rystad Energy analysts. “There is also further risk of potential projects losing local community support for building lithium mines and processing operations.”
Editorial Disclosure: The Investing News Network does not guarantee the accuracy or thoroughness of the information reported in the interviews it conducts. The opinions expressed in these interviews do not reflect the opinions of the Investing News Network and do not constitute investment advice. All readers are encouraged to perform their own due diligence.




Lithium salts could be declared health hazard in EU
June 9, 20XX-1 by Igor Todorović


A major lithium producer threatened to close its plant in Germany if the European Union declares the material dangerous to human health. The European Chemicals Agency or ECHA initiated the process.
The European Union has been making its environmental and climate rules stricter for decades. The administration in Brussels wants to make the entire continent carbon neutral by mid-century. At the same time, it is striving to achieve the highest level of protection from pollution in the world.
The energy transition and the decarbonization of industrial activity and power plants imply massive deployment of renewables, mostly solar and wind farms. However, as they depend on unstable weather conditions, the electric power system requires energy storage, in which the EU counts a lot on batteries.
Dangerous critical raw material
Lithium-ion solutions still dominate the sector, though there are other technologies emerging that could popularize less harmful material for home units and the batteries for electronic devices, electric vehicles, and utility systems. At the same time, the European Commission is struggling to secure supply chains that would make the availability of lithium stable and make the EU almost self-sufficient by 20XX+7.
The European Union has added lithium to a list of critical raw materials as demand is expected to increase dramatically in the coming years.
Initiatives to open mines and ore processing plants such as the ones in Serbia and Portugal have caused a public uproar as environmentalists and the local population are fearful about the impact on nature and people’s livelihoods. In other projects, engineers are trying to make the extraction of lithium from geothermal waters cost effective and harmless, without any mining.
Stricter rules for handling lithium would lift costs
However, the entire concept could falter with the European Commission’s upcoming legislation. Namely, it is considering the proposal from the European Chemicals Agency, ECHA, to declare key lithium salts hazardous for human health, Reuters reported. If lithium carbonate, lithium chloride and lithium hydroxide are classified as dangerous, it would complicate the import procedure, production, and handling of the materials.
ECHA’s Risk Assessment Committee accepted the demand from France in September to classify lithium salts as damaging for fertility and unborn children and to declare the substances harmful for breastfed children.
Adding lithium salts to the list of materials hazardous for health may prompt the revision of a range of projects in the industry.
Stricter rules mean higher costs, so any lithium ore processing plant project, like the one in the Jadar area in Serbia, would need to be given a second look regarding its environmental impact and feasibility.
Albemarle, based in Charlotte, North Carolina, has indicated it may be forced to close its plant in Langelsheim in north Germany if the plan is accepted. In that case, Chief Financial Officer Scott Tozier said, the company wouldn’t be able to import lithium chloride, its primary feedstock.
The unit’s annual revenue is USD 500 million, and the plant has over 600 employees. Tozier warned a decision to declare lithium salts hazardous would prompt an exodus of EU producers including battery recyclers.
The decision is expected to be reached by early next year, the article adds.





The Really Big Battery Deal in the IRA That People Are Missing
By Zachary Shahan – Published September 23, 20XX-1
When it comes to electric vehicles and the Inflation Reduction Act of 2022, almost all the discussion has been around the consumer tax credit for buying an electric vehicle, including the interesting new battery aspects of that. That’s a big topic, but there’s a whole other battery angle separate from the consumer tax credit, and it’s huge.
The short summary of the whole thing is that the IRA incentives for nearly every stage of battery production and the battery supply chain are very attractive, and since they stack on top of each other, the IRA is likely to stimulate a “gold rush” of sorts in battery mineral mining, battery mineral refining, battery cell production, battery recycling, and battery pack production in the United States. When you also consider that consumers will need to get batteries whose components don’t come from China, and that come from North America eventually, then it’s essentially a given that everyone in the industry now knows it should have battery mineral mining and refining as well as battery cell and pack production in North America.

SK Innovation Georgia battery factory rendering, courtesy of SK Innovation.
The Current EV Battery Mineral Situation
First, let’s note where we’re starting from. The USA currently mines and refines close to 0% of the minerals that go into EV battery packs. China, on the other hands, mines or refines the majority of all the big ones, including lithium, cobalt, nickel, and graphite. Here’s a chart on Chinese EV battery mineral domination:

Money, Money, Money
Looking at the data, the idea that Joe Biden was going to stimulate a gold rush in the EV battery mineral mining and refining space was a dream some of us had, but it seemed like one of the more outlandish dreams we could have in this time and age. However, the market does respond to three things pretty well: money, money, money, and money. And the Biden administration, Prime Minister Manchin, Senate Majority Leader Chuck Schumer, and others involved in crafting the legislation took note and decided to offer all four.
The slight joke here, aimed at emphasizing the key point, is that the IRA seems to be offering cash money (tax credits) for mining battery minerals, for refining battery minerals, for putting together battery cells, and for putting together battery packs (or “modules”). If you do all those things, you don’t get one bonus, you get four bonuses. If you count all the different minerals in a battery, the number of potential bonuses is much larger. Those bonuses add up, and they make it much more appealing to bring full-cycle battery production to the USA. At the very least, it should open mining and refining projects — which are more or less non-existent in the United States — by making them much more bankable. (Side note: Canadian and Mexican locations hoping to attract battery manufacturing investment may not have figured it out yet, but their competitive position versus the US took a major hit when Biden signed the IRA.)
That’s why we recently got news of Tesla reportedly deciding to scrap some investments it had already made in Germany (but not all of them) and move some battery cell production stateside. That’s why Tesla is reportedly exploring lithium refining in Texas now as well. That’s why GM is reportedly accelerating its exploration of EV battery mineral supplies from US soil. “Our thought process was that we would do this over a period of time, but with the IRA, we are actively working on figuring out how to accelerate,” said Sham Kunjur, GM’s executive director for EV raw materials. But this is only the beginning. These are just the leaks from early movers and leaky groups. Whether it’s Tesla, GM, Volkswagen, Ford, Panasonic, SK Innovation, LG Energy Solution (previously known as LG Chem), Samsung SDI, Albemarle, Livent, Piedmont Lithium, Talon Metals, Lithium Americas, Pilbara Minerals, or others, corporate teams are looking at the IRA, having their lawyers look at it, and starting to look much more seriously at what production opportunities they can launch in the United States.
Looking at the Actual IRA Language
Section 45X of the IRA concerns “components produced and sold after December 31, 2022.” Near the beginning, it states that “any taxable year is an amount equal to the sum of the credit amounts determined under subsection (b) with respect to each eligible component.” In other words, if you get a tax credit for one component of a battery (raw lithium, for example), you can also go and get a tax credit for another component or even later stage of the same component (the refined lithium, for example). The tax credits are for each major stage of the production process, and that means you can get them for various components of a battery and various stages of processing or putting together those components. You can get the following credits:
10% of the cost of battery electrode active materials
$35/kWh of battery cell capacity
$10/kW of battery module capacity (or, for a battery module that does not use battery cells, $45/kWh)
10% of the cost of producing a battery mineral.
Also, while there’s a phaseout for some of these between 2030 and 2032, there is no phaseout at all for the critical mineral subsidies! That’s long-term stability for a market that needs it.
What Minerals & Battery Components Are Eligible?
Regarding electrode active materials, those include “cathode materials, anode materials, anode foils, and electrochemically active materials, including solvents, additives, and electrolyte salts that contribute to the electrochemical processes necessary for energy storage.”
Applicable critical minerals include aluminum/alumina, antimony/antimony trisulfide concentrate, barite/barium sulfate, beryllium/copper-beryllium master alloy, cerium/cerium oxide, cesium/cesium formate/cesium carbonate, chromium/ferrochromium, cobalt/cobalt sulfate, graphite/graphitic carbon, lithium/lithium carbonate and lithium hydroxide, manganese, nickel/nickel sulphate, and many others.
Notably, at the end, it’s noted that only production that takes place in the United States is eligible for these tax credits. This creates a “USA premium” in the supply of raw materials to facilities that want to get the maximum benefit from 45X. Any manufacturer will be eligible for a 45X tax credit which covers the yearly cost of production if their facility is using raw material from the US. For most manufacturing, raw material cost is the most significant component of OPEX after labor and energy. So, Biden, Schumer, Manchin, and their aides have been very clever here: “want the maximum benefit, Buy American.”
So, let’s go back to the example of Tesla (or you can use Ford, GM, or some other company in this hypothetical if you prefer). Tesla could, theoretically, get a tax credit for mining lithium, get a tax credit for refining lithium, get a tax credit for mining nickel, get a tax credit for refining nickel, get a tax credit for producing battery anodes, get a tax credit for producing battery cells, and get a tax credit for producing battery modules. Of course, Tesla isn’t going to do all those things. However, I think that helps to explain the potential here. Whereas Tesla won’t do all those things itself, companies and investors will be pouring into the United States to do them, and some automakers will deepen their vertical integration in the battery space as well.
As a final note, and perhaps as a teaser for something we’ll come back to, while the incentives from the IRA are attractive, so is the potential for pricing control over raw materials! Whether Ford, GM, or Tesla, having more secure, stable, predictable control over key raw material costs could go a long way in being competitive and financially sustainable in the coming decade. How much is that pricing control worth as we go from ~5% EV market share in the US auto industry to 50% or more?

Russia may launch lithium production in the coming four years
June 17, 20XX-1
| As said at the SPIEF Oleg Kazanov, Director of the All-Russian Institute of Mineral Resources (VIMS) under Federal Subsoil Resources Management Agency, Russia may start lithium mining based on the ore deposits in the Murmansk region in 3-4 years and become one of the world’s five largest producers in eight years’ time.  |  |
“Russia has a lithium resource base, which is 10% of the world’s reserves and explored back in the 60s of the previous century. This is almost 4 million tons in 15 explored deposits. The first two objects in the Murmansk region will gain licensing and active subsoil use by the end of the current year. I think production might start there already in the next three or four years. Moreover, these are world-class deposits, both in terms of the lithium reserves and content,” O. Kazanov said.
According to him, now the demand for lithium is boosting in the world. Its driver is the battery industry. “Already in the next 10 years, we will see an increase from the current 100,000 tons of lithium consumption to about 700,000 tons. In total, 88 deposits of ore lithium will be launched in the world soon, but it is not enough to cover its entire global demand,” the expert notes.
Meanwhile, in Russia, a peculiar situation has developed in the lithium industry. The country has huge reserves of ore lithium reaching 10% of the world’s. Besides, Russia discovered lithium reserves in solutions in the bottom waters of the oil and gas fields in the Angara-Lena region, but they have not been fully assessed yet. The lithium content in solutions is very high by the world standards, i.e., about 300 mg/l.
There are two large lithium processing plants in Russia the Krasnoyarsk chemical-metallurgical plant, which buy raw lithium from Chile, bring it up to battery quality and ship to Southeast Asia.
Against the background of this situation, Federal Subsoil Resources Management Agency has recognized development of the lithium ore and brine reserves as a priority area.
Lithium ore mining technologies already exist; they scale well, especially considering increase of the demand for lithium and its price rise. “I think already on ore lithium, in the prospect of the next eight years, we are going to be among the top five producers of this metal along with Chile, Argentina, China and Australia,” O. Kazanov noted.
The next stage in the Russia’s lithium industry development after the ore deposits have been commissioned will be application of the technologies for lithium production from solutions. In the world, this is the DLE technology mainly used for solutions at geothermal power plants. In Russia, lithium solutions are found in the bottom waters of oil and gas fields. This water is somehow extracted from the subsoil and injected back into the reservoir to maintain pressure in an oil and gas well.
The engineering center created based on the Krasnoyarsk chemical-metallurgical plant and VIMS developed its own technologies for lithium extraction just during a year, and now they are tested under the laboratory conditions.

By Marcelo Azevedo, Magdalena Baczyńska, Ken Hoffman, and Aleksandra Krauze
Lithium is the driving force behind electric vehicles, but will supply keep pace with demand? New technologies and sources of supply can fill the gap. 
Despite expectations that lithium demand will rise from approximately 500,000 metric tons of lithium carbonate equivalent (LCE) in 2021 to some three million to four million metric tons in 2030, we believe that the lithium industry will be able to provide enough product to supply the burgeoning lithium-ion battery industry. Alongside increasing the conventional lithium supply, which is expected to expand by over 300 percent between 2021 and 2030, direct lithium extraction (DLE) and direct lithium to product (DLP) can be the driving forces behind the industry’s ability to respond more swiftly to soaring demand. Although DLE and DLP technologies are still in their infancy and subject to volatility given the industry’s “hockey stick” 1 demand growth and lead times, they offer significant promise of increasing supply, reducing the industry’s environmental, social, and governance (ESG) footprint, and lowering costs, with already announced capacity contributing to around 10 percent of the 2030 lithium supply, as well as to other less advanced projects in the pipeline.
However, satisfying the demand for lithium will not be a trivial problem. Despite COVID-19’s impact on the automotive sector, electric vehicle (EV) sales grew by around 50 percent in 2020 and doubled to approximately seven million units in 2021. At the same time, surging EV demand has seen lithium prices skyrocket by around 550 percent in a year: by the beginning of March 2022, the lithium carbonate price had passed $75,000 per metric ton and lithium hydroxide prices had exceeded $65,000 per metric ton (compared with a five-year average of around $14,500 per metric ton). 
Lithium is needed to produce virtually all traction batteries currently used in EVs as well as consumer electronics. Lithium-ion (Li-ion) batteries are widely used in many other applications as well, from energy storage to air mobility. As battery content varies based on its active materials mix, and with new battery technologies entering the market, there are many uncertainties around how the battery market will affect future lithium demand. For example, a lithium metal anode, which boosts energy density in batteries, has nearly double the lithium requirements per kilowatt-hour compared with the current widely used mixes incorporating a graphite anode.
So, will there be enough lithium to cover the needs of a new electrified world? As discussed in our recent article, “The raw-materials challenge: How the metals and mining sector will be at the core of enabling the energy transition,” arriving at a considered answer and understanding the entire supply-and-demand context will be crucial for every player along the value chain—mining companies, refiners, battery manufacturers, and automotive OEMs.
Lithium demand factors
Over the next decade, McKinsey forecasts continued growth of Li-ion batteries at an annual compound rate of approximately 30 percent. By 2030, EVs, along with energy-storage systems, e-bikes, electrification of tools, and other battery-intensive applications, could account for 4,000 to 4,500 gigawatt-hours of Li-ion demand.
  
Not long ago, in 2015, less than 30 percent of lithium demand was for batteries; the bulk of demand was split between ceramics and glasses (35 percent) and greases, metallurgical powders, polymers, and other industrial uses (35-plus percent). By 2030, batteries are expected to account for 95 percent of lithium demand, and total needs will grow annually by 25 to 26 percent to reach 3.3 million to 3.8 million metric tons LCE depending on the scenarios outlined in Exhibit 2. 


Reuse and recycle
A frequently asked question is whether L-ion batteries can be recycled. With expected battery lifetimes of around ten to 15 years for passenger vehicles, and the possibility of extending EV battery life through use in the energy-storage sector, battery recycling is expected to increase during the current decade, but not to game-changing levels. Depending on the recycling process employed, it is possible to recover between zero and 80 percent of the lithium contained in end-of-life batteries. By 2030, such secondary supply is expected to account for slightly more than 6 percent of total lithium production (Exhibit 7).",2,6.8,"Summary
The short but largely adequate text focuses on the lithium supply chain and its significance in the electric vehicle (EV) industry, specifically for the European Union (EU). 
It discusses the expected surge in lithium demand, the EU's dependency on China, and suggests several strategies that the EU could employ to mitigate these issues. 
The author argues that it is essential for the EU to act promptly to remain competitive in the global market.
For improvement, the author could focus on organizing the text better. While the main points are present, they could be better sequenced for clarity. 
Some statistics are mentioned but not thoroughly backed up; for instance, the ""500% increase by 2030"" could be supported by referencing a study. 
Grammatically, the text is generally well-written but minor errors in spelling and grammar are present.
Content: More content would have greatly enhanced this submission

Per Competency Score",7.0,"The layout of the text is mostly logical but could be more clear. The use of bullet points helps, but the text could benefit from sub-headings for easier navigation.

The information is communicated fairly clearly but would benefit from better organization and substantiation of claims.

The text does not have a specifically titled Introduction section.

The text does not have a specifically titled Conclusions section.

The text does not have a specifically titled Recommendations section.

The tone of the document is formal and analytical, suitable for the subject matter.

The document is relatively easy to read but could be improved with better organization and sub-headings.","Spelling errors include
: ""enviroment"" should be ""environment,"" ""dependancy"" should be ""dependency,"" ""competitve"" should be ""competitive,"" ""Negotiatie"" should be ""Negotiate,"" and ""incentivise"" is British spelling; if American spelling is desired, it should be ""incentivize.""

Grammar errors include:
 ""an even greater increase is expected in the industry of EV batteries and especially in the demand of lithium,"" could be rephrased to ""an even greater increase is expected in the EV battery industry, especially in lithium demand,"" ""Thus, directly prohibiting supplies from Chinese-owned companies is not advisable,"" could be changed to ""Therefore, directly prohibiting supplies from Chinese-owned companies is not advisable,"" ""Considering that the other main players,"" could be ""Considering that other main players,"" ""EU has to take action,"" should be ""the EU has to take action,"" and ""further increasing costs,"" could be ""which would further increase costs.""",,"Trainee's Answer
In the light of the upcoming surge of the demand of electric vehicles (EV), an even greater increase is expected in the industry of EV batteries and especially in the demand of lithium, which is a key chemical component of them. Demand is expected to increase by 500% until 2030, affecting its price accordingly, forcing EU to be dependable on imports due to the fact that no lithium processing or refining takes place within its territory.
EU's intention to fully detach from Chinese-owned supply across all stages of the lithium-ion supply chain may prove impossible but it is expected to improve in the next decades. Thus, directly prohibiting supplies from Chinese-owned companies is not advisable due to the fact that China has a multi-year advantage over the rest of the world in terms of investment, know-how, processing equipment and resources.
Yet, it is imperative that the EU should take measures in order to remain competitive in the approximate future. Considering that the other main players, such us the USA, Russia and Canada have already started implementing policies aiming to decrease their dependancy for EV battery components from China or boost their own industries, EU has to take action. Specifically, the EU could examine strategies such as:
- Subsidise companies in the industry of lithium extraction and processing that could possibly use new technologies (more efficient or enviroment friendly) to extract the mineral. Technologies such as DLE and DLP may prove a good investment in order for the EU to match the demand of lithium in the near future.
- Incentivise companies that are already active in similar industries to invest in lithium extraction and processing as well or to examine whether some of their byproducts can be refined to be used as EV battery components.
- Offer tax credits for companies in the lithium industry, as a countermeasure to the US IRA.
- Negotiatie long term trade agreements with main producers such as Australia, Chile or Argentina as an attempt to control prices of imported lithium and thus retain a competitve advantage for its companies.
 Additionally, and in order to avoid a gradual exit of big EV manufacturers from EU, classifying lithium derivatives as dangerous will complicate the import procedure, production and handling of the materials, further increasing costs. In order to deal with the ECHA proposal concerning the toxicity of certain lithium salts, the EU could incentivise companies to adopt controls that will ensure that said chemicals are not hazardous for the public health.
 In conclusion, the sharply increasing trend in demand and consequently in prices of EV battery components will force the EU to implement specific measures in order to remain competitive. It has to regulate lithium imports in order to control the price, decrease dependancy from China and boost its own industry since EVs are a crucial factor when it comes to the transition to a greener economy."
1,0_Lithium Supply Chain (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG MOVE. 
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Analysis and Problem Solving, Communicating (Drafting Skills), Delivering Quality & Results, and Prioritising & Organising.

Specifically, your task will be to draft a memo for your Head of Unit.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations


ACEA - European Automobile Manufacturers’ Association 

DLE - direct lithium extraction

DLP - direct lithium to product 

ECHA - European Chemicals Agency

ESG - environmental, social, and governance

EV – Electric Vehicle

INN – Investing News Network

IRA – Inflation reduction Act (US)

LCE - lithium carbonate equivalent

LiPo – Lithium Polymer







EMAIL 1","Subject: Towards a sustainable, circular, European battery supply chain 
Dear YOU,

In December 20XX-2, the Commission presented a proposal for a regulation on batteries and waste batteries. The proposal aims to strengthen the functioning of the internal market, promoting a circular economy and reducing the environmental and social impact throughout all stages of the battery life cycle. The initiative is closely linked to the European Green Deal, the Circular Economy Action Plan, and the New Industrial Strategy. 
At the end of last year, The Council and the European Parliament reached a provisional political agreement on the proposal. For the first time the legislation will regulate the entire life cycle of a battery – from the supply chain of raw materials, over the production to reuse and recycling of batteries – and ensure that they are safe, sustainable, and competitive.
As you know, our unit has the lead on this important file and our DG intends to launch the formal interservice consultation over the coming weeks. Before this, our DG wants to organize an internal reflection and brainstorming meeting, and I have been appointed to chair this meeting.
Could you produce an internal memo, summarizing the main ins and outs of this file and the agenda for the internal meeting with concrete proposals and recommendations to fine-tune the original proposal, in line with the political priorities of the co-legislators. 
I’m on mission tomorrow so please could you get this done for me today. It doesn’t need to be long – in fact the shorter, the better.  

Many thanks",",

Ferdinand
Head of Unit




Is Europe Moving Fast Enough to Build a Resilient Lithium Supply Chain? 
Priscila Barrera
Nov. 16, 20XX-1


Europe will soon release its Critical Raw Materials Act to identify potential strategic projects and build up reserves where supply is at risk.
Europe’s green energy transition plans give a central role to the electrification of transportation. 
The European Union (EU) has ambitious goals to become climate neutral by 2050, meaning it would be an economy with net-zero greenhouse gas emissions. Recently proposed legislation is looking to effectively ban all internal combustion engine cars by 2035.
In 20XX-2, electric car registrations for the year were close to 1,729,000, up from 1,061,000 in 2020, with prospects for the region remaining positive. Last year, the market share of battery electric cars almost doubled to around 10 percent, but challenges faced by carmakers continue to weigh on demand as inflation and fears of a recession put pressure on targets. 
In its most recent forecast, the European Automobile Manufacturers’ Association (ACEA) said it expects the overall EU car market to shrink again this year, slipping by 1 percent to reach 9.6 million units.
“To ensure a return to growth — with an even greater share of electric vehicle sales so climate targets can be met — we urgently need the right framework conditions to be put in place,” said Oliver Zipse, ACEA president and CEO of BMW. “These include greater resilience in Europe’s supply chains, an EU Critical Raw Materials Act that ensures strategic access to the raw materials needed for e-mobility, and an accelerated roll-out of charging infrastructure.”
As sales of electric vehicles increase, carmakers are looking to secure supply of key metals used in batteries, including lithium. Today, Europe is quite dependent on Australia and Chile for lithium supply and China for lithium refining, but the region is taking steps to strengthen its supply chain for the important battery metal. 
What is the European Critical Raw Materials Act? 
In September, news broke that Europe will be putting forward the European Critical Raw Materials Act, a new piece of legislation. Its aim is to identify potential strategic projects and build up reserves where supply is at risk.
European Commission President Ursula von der Leyen said the bloc has learned its lesson about the risks of being dependent on Russia, and realizes the need to be vigilant toward China.
""In the case of China, it is the risk of dependency on technologies and raw materials,"" she said, adding that the EU needs to boost its production capacity and shift more towards trustworthy suppliers.
In October, von der Leyen said the EU is witnessing quite an acceleration of trends and tensions with China. 
""The Chinese system is fundamentally different from ours and we are aware of the nature of the rivalry,'' she said.
The moves from the EU are in line with pushes seen in other regions such as North America, where the US has committed billions of dollars to reach its carbon emissions targets.
In June, the Biden administration launched the Inflation Reduction Act, which includes climate incentives. The legislation, which was signed into law in August, requires automakers to source 50 percent of critical minerals used in electric vehicle batteries from North America or free trade agreement countries by 2024, with that amount rising to 80 percent by the end of 20XX+3.
For its part, Canada recently ordered three Chinese companies to divest from lithium companies following a “multi-step national security review process.” China has opposed the move, and Canada is expected to release its China strategy soon.
Europe-Asia relationship in the lithium space 
Jack Bedder of Project Blue said Asia will always be a part of the European lithium-ion battery supply chain. Major Asian companies, including Panasonic, Samsung, BYD Company and CATL, all have operating capacity on the continent.
“As a result, it will be almost impossible to detach fully from Chinese-owned supply across all stages of the lithium-ion supply chain,” he told the Investing News Network.
However, as lithium processing capacity is built up globally at non-Chinese-owned companies, particularly within the EU, the opportunities to reduce the EU's dependency on China-owned supply will improve. “It is very unlikely that the EU will implement legislation directly prohibiting lithium supply from Chinese-owned companies, as further constraints on supply availability to the European market will only hinder growth in the industry over the coming decade,” Bedder added.
For Allan Pedersen of Wood Mackenzie, Europe cannot move forward without influence from Asia in the short to medium term.
That’s due to a few reasons. As mentioned, many of the battery plants being constructed in Europe have Asian companies behind them, and the cathodes needed in batteries are still largely produced in Asia, where the know-how is strongest. Additionally, lithium refining is mainly done in China and most mineral concentrate is produced in Australia.
“China has a multi-year advantage over the rest of the world in terms of investing in the entire supply chain — it will be challenging for Europe to catch up to that in terms of investment in know-how, processing equipment and resources,” he said. 
“This doesn’t mean that Europe cannot make progress in this space. In lithium, we see some resource developments and processing facilities being considered and constructed.”
For the analyst, in the long-term Europe has the potential to become more self-sufficient for raw materials as recycling becomes a larger part of the supply landscape and can supplement domestic resources.
European Commission could classify lithium as toxic. 
Although Europe is pushing to build a resilient supply chain by partnering with allies and developing domestic resources, it might not all be good news for miners in the region — at the end of last year, the European Commission said it will weigh a proposal from the European Chemicals Agency to classify lithium carbonate, chloride and hydroxide as dangerous for human health.
If the proposal is approved, this could undermine the EU’s attempt to create and support a domestic battery materials supply chain, research firm Rystad Energy said in a statement. “The EU currently relies heavily on imports of lithium to supply its nascent electric vehicle production sector and the classification may increase its reliance on other regions, at a time when the union is focused on energy security and reducing emissions,” the document reads.
If the classification goes ahead, it would not stop lithium usage, but it is highly likely to have an impact on at least four stages: lithium mining, processing, cathode production and recycling.
“This potential ruling comes at a time when the EU is itself scrambling to build and establish local lithium supply chains. The permitting issue has repeatedly been highlighted at recent industry events as one of the main barriers to new mining projects ramping up quickly in the EU,” according to Rystad Energy analysts. “There is also further risk of potential projects losing local community support for building lithium mines and processing operations.”
Editorial Disclosure: The Investing News Network does not guarantee the accuracy or thoroughness of the information reported in the interviews it conducts. The opinions expressed in these interviews do not reflect the opinions of the Investing News Network and do not constitute investment advice. All readers are encouraged to perform their own due diligence.




Lithium salts could be declared health hazard in EU
June 9, 20XX-1 by Igor Todorović


A major lithium producer threatened to close its plant in Germany if the European Union declares the material dangerous to human health. The European Chemicals Agency or ECHA initiated the process.
The European Union has been making its environmental and climate rules stricter for decades. The administration in Brussels wants to make the entire continent carbon neutral by mid-century. At the same time, it is striving to achieve the highest level of protection from pollution in the world.
The energy transition and the decarbonization of industrial activity and power plants imply massive deployment of renewables, mostly solar and wind farms. However, as they depend on unstable weather conditions, the electric power system requires energy storage, in which the EU counts a lot on batteries.
Dangerous critical raw material
Lithium-ion solutions still dominate the sector, though there are other technologies emerging that could popularize less harmful material for home units and the batteries for electronic devices, electric vehicles, and utility systems. At the same time, the European Commission is struggling to secure supply chains that would make the availability of lithium stable and make the EU almost self-sufficient by 20XX+7.
The European Union has added lithium to a list of critical raw materials as demand is expected to increase dramatically in the coming years.
Initiatives to open mines and ore processing plants such as the ones in Serbia and Portugal have caused a public uproar as environmentalists and the local population are fearful about the impact on nature and people’s livelihoods. In other projects, engineers are trying to make the extraction of lithium from geothermal waters cost effective and harmless, without any mining.
Stricter rules for handling lithium would lift costs
However, the entire concept could falter with the European Commission’s upcoming legislation. Namely, it is considering the proposal from the European Chemicals Agency, ECHA, to declare key lithium salts hazardous for human health, Reuters reported. If lithium carbonate, lithium chloride and lithium hydroxide are classified as dangerous, it would complicate the import procedure, production, and handling of the materials.
ECHA’s Risk Assessment Committee accepted the demand from France in September to classify lithium salts as damaging for fertility and unborn children and to declare the substances harmful for breastfed children.
Adding lithium salts to the list of materials hazardous for health may prompt the revision of a range of projects in the industry.
Stricter rules mean higher costs, so any lithium ore processing plant project, like the one in the Jadar area in Serbia, would need to be given a second look regarding its environmental impact and feasibility.
Albemarle, based in Charlotte, North Carolina, has indicated it may be forced to close its plant in Langelsheim in north Germany if the plan is accepted. In that case, Chief Financial Officer Scott Tozier said, the company wouldn’t be able to import lithium chloride, its primary feedstock.
The unit’s annual revenue is USD 500 million, and the plant has over 600 employees. Tozier warned a decision to declare lithium salts hazardous would prompt an exodus of EU producers including battery recyclers.
The decision is expected to be reached by early next year, the article adds.





The Really Big Battery Deal in the IRA That People Are Missing
By Zachary Shahan – Published September 23, 20XX-1
When it comes to electric vehicles and the Inflation Reduction Act of 2022, almost all the discussion has been around the consumer tax credit for buying an electric vehicle, including the interesting new battery aspects of that. That’s a big topic, but there’s a whole other battery angle separate from the consumer tax credit, and it’s huge.
The short summary of the whole thing is that the IRA incentives for nearly every stage of battery production and the battery supply chain are very attractive, and since they stack on top of each other, the IRA is likely to stimulate a “gold rush” of sorts in battery mineral mining, battery mineral refining, battery cell production, battery recycling, and battery pack production in the United States. When you also consider that consumers will need to get batteries whose components don’t come from China, and that come from North America eventually, then it’s essentially a given that everyone in the industry now knows it should have battery mineral mining and refining as well as battery cell and pack production in North America.

SK Innovation Georgia battery factory rendering, courtesy of SK Innovation.
The Current EV Battery Mineral Situation
First, let’s note where we’re starting from. The USA currently mines and refines close to 0% of the minerals that go into EV battery packs. China, on the other hands, mines or refines the majority of all the big ones, including lithium, cobalt, nickel, and graphite. Here’s a chart on Chinese EV battery mineral domination:

Money, Money, Money
Looking at the data, the idea that Joe Biden was going to stimulate a gold rush in the EV battery mineral mining and refining space was a dream some of us had, but it seemed like one of the more outlandish dreams we could have in this time and age. However, the market does respond to three things pretty well: money, money, money, and money. And the Biden administration, Prime Minister Manchin, Senate Majority Leader Chuck Schumer, and others involved in crafting the legislation took note and decided to offer all four.
The slight joke here, aimed at emphasizing the key point, is that the IRA seems to be offering cash money (tax credits) for mining battery minerals, for refining battery minerals, for putting together battery cells, and for putting together battery packs (or “modules”). If you do all those things, you don’t get one bonus, you get four bonuses. If you count all the different minerals in a battery, the number of potential bonuses is much larger. Those bonuses add up, and they make it much more appealing to bring full-cycle battery production to the USA. At the very least, it should open mining and refining projects — which are more or less non-existent in the United States — by making them much more bankable. (Side note: Canadian and Mexican locations hoping to attract battery manufacturing investment may not have figured it out yet, but their competitive position versus the US took a major hit when Biden signed the IRA.)
That’s why we recently got news of Tesla reportedly deciding to scrap some investments it had already made in Germany (but not all of them) and move some battery cell production stateside. That’s why Tesla is reportedly exploring lithium refining in Texas now as well. That’s why GM is reportedly accelerating its exploration of EV battery mineral supplies from US soil. “Our thought process was that we would do this over a period of time, but with the IRA, we are actively working on figuring out how to accelerate,” said Sham Kunjur, GM’s executive director for EV raw materials. But this is only the beginning. These are just the leaks from early movers and leaky groups. Whether it’s Tesla, GM, Volkswagen, Ford, Panasonic, SK Innovation, LG Energy Solution (previously known as LG Chem), Samsung SDI, Albemarle, Livent, Piedmont Lithium, Talon Metals, Lithium Americas, Pilbara Minerals, or others, corporate teams are looking at the IRA, having their lawyers look at it, and starting to look much more seriously at what production opportunities they can launch in the United States.
Looking at the Actual IRA Language
Section 45X of the IRA concerns “components produced and sold after December 31, 2022.” Near the beginning, it states that “any taxable year is an amount equal to the sum of the credit amounts determined under subsection (b) with respect to each eligible component.” In other words, if you get a tax credit for one component of a battery (raw lithium, for example), you can also go and get a tax credit for another component or even later stage of the same component (the refined lithium, for example). The tax credits are for each major stage of the production process, and that means you can get them for various components of a battery and various stages of processing or putting together those components. You can get the following credits:
10% of the cost of battery electrode active materials
$35/kWh of battery cell capacity
$10/kW of battery module capacity (or, for a battery module that does not use battery cells, $45/kWh)
10% of the cost of producing a battery mineral.
Also, while there’s a phaseout for some of these between 2030 and 2032, there is no phaseout at all for the critical mineral subsidies! That’s long-term stability for a market that needs it.
What Minerals & Battery Components Are Eligible?
Regarding electrode active materials, those include “cathode materials, anode materials, anode foils, and electrochemically active materials, including solvents, additives, and electrolyte salts that contribute to the electrochemical processes necessary for energy storage.”
Applicable critical minerals include aluminum/alumina, antimony/antimony trisulfide concentrate, barite/barium sulfate, beryllium/copper-beryllium master alloy, cerium/cerium oxide, cesium/cesium formate/cesium carbonate, chromium/ferrochromium, cobalt/cobalt sulfate, graphite/graphitic carbon, lithium/lithium carbonate and lithium hydroxide, manganese, nickel/nickel sulphate, and many others.
Notably, at the end, it’s noted that only production that takes place in the United States is eligible for these tax credits. This creates a “USA premium” in the supply of raw materials to facilities that want to get the maximum benefit from 45X. Any manufacturer will be eligible for a 45X tax credit which covers the yearly cost of production if their facility is using raw material from the US. For most manufacturing, raw material cost is the most significant component of OPEX after labor and energy. So, Biden, Schumer, Manchin, and their aides have been very clever here: “want the maximum benefit, Buy American.”
So, let’s go back to the example of Tesla (or you can use Ford, GM, or some other company in this hypothetical if you prefer). Tesla could, theoretically, get a tax credit for mining lithium, get a tax credit for refining lithium, get a tax credit for mining nickel, get a tax credit for refining nickel, get a tax credit for producing battery anodes, get a tax credit for producing battery cells, and get a tax credit for producing battery modules. Of course, Tesla isn’t going to do all those things. However, I think that helps to explain the potential here. Whereas Tesla won’t do all those things itself, companies and investors will be pouring into the United States to do them, and some automakers will deepen their vertical integration in the battery space as well.
As a final note, and perhaps as a teaser for something we’ll come back to, while the incentives from the IRA are attractive, so is the potential for pricing control over raw materials! Whether Ford, GM, or Tesla, having more secure, stable, predictable control over key raw material costs could go a long way in being competitive and financially sustainable in the coming decade. How much is that pricing control worth as we go from ~5% EV market share in the US auto industry to 50% or more?

Russia may launch lithium production in the coming four years
June 17, 20XX-1
| As said at the SPIEF Oleg Kazanov, Director of the All-Russian Institute of Mineral Resources (VIMS) under Federal Subsoil Resources Management Agency, Russia may start lithium mining based on the ore deposits in the Murmansk region in 3-4 years and become one of the world’s five largest producers in eight years’ time.  |  |
“Russia has a lithium resource base, which is 10% of the world’s reserves and explored back in the 60s of the previous century. This is almost 4 million tons in 15 explored deposits. The first two objects in the Murmansk region will gain licensing and active subsoil use by the end of the current year. I think production might start there already in the next three or four years. Moreover, these are world-class deposits, both in terms of the lithium reserves and content,” O. Kazanov said.
According to him, now the demand for lithium is boosting in the world. Its driver is the battery industry. “Already in the next 10 years, we will see an increase from the current 100,000 tons of lithium consumption to about 700,000 tons. In total, 88 deposits of ore lithium will be launched in the world soon, but it is not enough to cover its entire global demand,” the expert notes.
Meanwhile, in Russia, a peculiar situation has developed in the lithium industry. The country has huge reserves of ore lithium reaching 10% of the world’s. Besides, Russia discovered lithium reserves in solutions in the bottom waters of the oil and gas fields in the Angara-Lena region, but they have not been fully assessed yet. The lithium content in solutions is very high by the world standards, i.e., about 300 mg/l.
There are two large lithium processing plants in Russia the Krasnoyarsk chemical-metallurgical plant, which buy raw lithium from Chile, bring it up to battery quality and ship to Southeast Asia.
Against the background of this situation, Federal Subsoil Resources Management Agency has recognized development of the lithium ore and brine reserves as a priority area.
Lithium ore mining technologies already exist; they scale well, especially considering increase of the demand for lithium and its price rise. “I think already on ore lithium, in the prospect of the next eight years, we are going to be among the top five producers of this metal along with Chile, Argentina, China and Australia,” O. Kazanov noted.
The next stage in the Russia’s lithium industry development after the ore deposits have been commissioned will be application of the technologies for lithium production from solutions. In the world, this is the DLE technology mainly used for solutions at geothermal power plants. In Russia, lithium solutions are found in the bottom waters of oil and gas fields. This water is somehow extracted from the subsoil and injected back into the reservoir to maintain pressure in an oil and gas well.
The engineering center created based on the Krasnoyarsk chemical-metallurgical plant and VIMS developed its own technologies for lithium extraction just during a year, and now they are tested under the laboratory conditions.

By Marcelo Azevedo, Magdalena Baczyńska, Ken Hoffman, and Aleksandra Krauze
Lithium is the driving force behind electric vehicles, but will supply keep pace with demand? New technologies and sources of supply can fill the gap. 
Despite expectations that lithium demand will rise from approximately 500,000 metric tons of lithium carbonate equivalent (LCE) in 2021 to some three million to four million metric tons in 2030, we believe that the lithium industry will be able to provide enough product to supply the burgeoning lithium-ion battery industry. Alongside increasing the conventional lithium supply, which is expected to expand by over 300 percent between 2021 and 2030, direct lithium extraction (DLE) and direct lithium to product (DLP) can be the driving forces behind the industry’s ability to respond more swiftly to soaring demand. Although DLE and DLP technologies are still in their infancy and subject to volatility given the industry’s “hockey stick” 1 demand growth and lead times, they offer significant promise of increasing supply, reducing the industry’s environmental, social, and governance (ESG) footprint, and lowering costs, with already announced capacity contributing to around 10 percent of the 2030 lithium supply, as well as to other less advanced projects in the pipeline.
However, satisfying the demand for lithium will not be a trivial problem. Despite COVID-19’s impact on the automotive sector, electric vehicle (EV) sales grew by around 50 percent in 2020 and doubled to approximately seven million units in 2021. At the same time, surging EV demand has seen lithium prices skyrocket by around 550 percent in a year: by the beginning of March 2022, the lithium carbonate price had passed $75,000 per metric ton and lithium hydroxide prices had exceeded $65,000 per metric ton (compared with a five-year average of around $14,500 per metric ton). 
Lithium is needed to produce virtually all traction batteries currently used in EVs as well as consumer electronics. Lithium-ion (Li-ion) batteries are widely used in many other applications as well, from energy storage to air mobility. As battery content varies based on its active materials mix, and with new battery technologies entering the market, there are many uncertainties around how the battery market will affect future lithium demand. For example, a lithium metal anode, which boosts energy density in batteries, has nearly double the lithium requirements per kilowatt-hour compared with the current widely used mixes incorporating a graphite anode.
So, will there be enough lithium to cover the needs of a new electrified world? As discussed in our recent article, “The raw-materials challenge: How the metals and mining sector will be at the core of enabling the energy transition,” arriving at a considered answer and understanding the entire supply-and-demand context will be crucial for every player along the value chain—mining companies, refiners, battery manufacturers, and automotive OEMs.
Lithium demand factors
Over the next decade, McKinsey forecasts continued growth of Li-ion batteries at an annual compound rate of approximately 30 percent. By 2030, EVs, along with energy-storage systems, e-bikes, electrification of tools, and other battery-intensive applications, could account for 4,000 to 4,500 gigawatt-hours of Li-ion demand.
  
Not long ago, in 2015, less than 30 percent of lithium demand was for batteries; the bulk of demand was split between ceramics and glasses (35 percent) and greases, metallurgical powders, polymers, and other industrial uses (35-plus percent). By 2030, batteries are expected to account for 95 percent of lithium demand, and total needs will grow annually by 25 to 26 percent to reach 3.3 million to 3.8 million metric tons LCE depending on the scenarios outlined in Exhibit 2. 


Reuse and recycle
A frequently asked question is whether L-ion batteries can be recycled. With expected battery lifetimes of around ten to 15 years for passenger vehicles, and the possibility of extending EV battery life through use in the energy-storage sector, battery recycling is expected to increase during the current decade, but not to game-changing levels. Depending on the recycling process employed, it is possible to recover between zero and 80 percent of the lithium contained in end-of-life batteries. By 2030, such secondary supply is expected to account for slightly more than 6 percent of total lithium production (Exhibit 7).",5,5.0,"Summary
There are strong indicators here of very good writing style, the ability to distill information and offer sound reasoning and insights. 

However, the lack of clear structure after the status section has a detrimental effect. The information conveyed here seems disjointed and impacts its ease of readability. The issues are presented too concisely with little explanation. 


Per Competency Score",5.0,"Observations
The candidate starts off by providing the context to the regulation of batteries and waste batteries in the status section in a well-written and concise fashion. This section illustrates strong potential in presenting key issues with clarity and cohesion. 

However, some further background/overview of the legislative situation could have been added. 
E.g.:
“In December 20XX-2, the Commission presented a proposal for a regulation on batteries and waste batteries.”

Could have had more clarity in expressing the purpose of the memo. 
E.g.:
“The purpose of this memo is to launch the interservice consultation procedure for the new Regulation on Batteries and waste batteries. It is intended to structure the review of the original proposal, considering the observations of the Council and the European Parliament, and to further materialize the specific requirements by setting measurable, achievable, realistic, and time-based targets and objectives.”

The further sections of the memo omit several key issues and data concerning the topic. 

It could also have been structured in a clearer and more coherent way. The information thus seems disjointed and impacts the flow and readability of the document. For a manager with limited understanding of this area, it would be difficult to gain a complete picture of the topic and the interconnectivity of the issues. 

The Agenda section is far too concise. It could still use subheadings and bullet points but also should expand on the key points. 
E.g.: 
1. General points
The new regulation should apply to all batteries including all waste portable batteries, electric vehicle batteries, industrial batteries, starting, lightning and ignition batteries, and batteries for light means of transport (e.g., electric bikes, e-mopeds, e-scooters).
2. Supply chain of raw materials
3. Production of batteries in the EU
4. Functioning of the internal market

Overall, the memo leaves the impression of being a work-in-progress. 

Additionally, the topic of batteries is not related to the Green Deal and possible consequences.",,"Tips to Improve

Practice structuring the document with subheadings for complex topics to ensure clarity of message. 

Read examples of memos to strike the right balance between being concise yet coherent.

Ensure there is enough time to proofread for typos.","Trainee's Answer
Internal memo
for the EC DG MOVE meeting on fine-tuning
""Critical Raw Material Act""
Status
Critical Raw Material Act aims to identify potential strategic projects and build up reserves where supply is at risk. The legislation regulates for the first time the entire life cycle of a battery and ensure they are safe, sustainable, and competitve. Our DG has the lead on this file.
The EU has goals to become climate neutral by 2050, while banning all internal combustion engine cars by 2035. Although the EV demand is thriving, the car market is expected to shrink for a second year in a row making it difficult to achieve the goal. The industry expects the Raw Material Act EU to secure supply of key materials used in batteries, including lithium where Europe is dependent on Australia and Chile for supply and China for refining.
New data after the proposal of the Raw Material Act:
- ECHA accepted the demand from France to classify lithium salts as dangerous for human health and the Commission is considering to adopt the Agency's proposal. If put in effect, the supply chain and the production of EV batteries is expected to increase dramatically, making existing investment plans non-feasible. Already, there are voices within the industry to abandon such projects in Germany and put in jeopardy new plants in Serbia and Portugal.
- The Inflation Reduction Act (IRA) passed in the USA incentives every stage of battery production and battery supply chain. The incentives per production stage and per material are cumulative and it is expected to stimulate a series of investments on USA soil. This puts at risk already made decision to invest on EU countries. Already automotive companies (i.e. Tesla) declare their intention to cut EU project in favor of production capacity in the USA.
- EU decision to reduce China dependency risk. On the other hand, as the President of the European Commission said, EU needs to boost its production capacity and move towards trustworthy suppliers.
- New technologies (uncertainty on future demand). At the same time, new technologies present risks and opportunities. Foe example, there are many uncertainties around how the battery market will affect future lithium demand. Also, there are lithium mining  technologies under development (in Russia that expects to become a top 5 lithium producers in the next 10 years) that are more environmentally friendly and better efficiency.
 
Agenda
- Critical Raw Material Act - Main points nad current status
- New data after the provisional political agreement between the European Parliament and the Council
- EV demand
- Financial situation
- ECHA proposal
- New technologies
- Situation in other countries
- USA and the IRA
- China & Russia
- Discussion
- Conclusion (action plan)
 
Recommendations to fine-tune original proposal
- Explore possible solutions to environmental concerns (ECHA proposal)
- Incentives to reduce financial risks
- R&D programs/Incentives for new lithium extraction technologies
- Ways to make automobile manufacturers to stay in the EU and spark further investments in supply chain and lithium batteries production
- Ways to strengthen collaboration with other lithium producers to reduce exposure to China"
4,0_Case study - Animal welfare - LONG,"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. 

Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG SANTE. 
A citizen’s initiative (“End the cage age”) collected almost 1.4 million signatures demanding a Commission proposal to ban all use of cages for farm animals. DG SANTE has prepared a draft legislative proposal, based on an impact assessment and several rounds of stakeholder consultations. An inter-service consultation (ISC) with the other DGs was recently closed. The Director-General of SANTE now needs to decide how to move forward on this file, so that a compromise text can be agreed in the college of Commissioners.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes, as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the candidate’s drafting skills (Communication) and may be used to assess also the following competencies: Critical thinking, analysing & creative problem-solving, and Decision-making and getting results.

Specifically, your task will be to draft a concise briefing note for your Director-General. This note must include: 

Summary of the main issues, notably the remaining problems to solve
Arguments and facts to help the Director-General make a decision on the file

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.",,"Subject: Briefing for the Director-General – Animal welfare legislative proposal
---
Dear [your name],
Welcome to your first day in the unit! You will have to hit the ground running - we have received an urgent request for a briefing. Our Director-General, Ms Heinrich, needs a summary of state of play concerning the draft revised animal welfare regulation, for her decision on the way forward.
As you have seen in the draft regulation text, we have followed the “preferred options” identified in our thorough impact assessment (those marked green in the impact assessment options table). This draft legislative proposal is what we as DG SANTE believe best serves our policy objectives and this is what we need to defend as far as possible. We received strong support for an ambition line in all the stakeholder consultations.
In the recent inter-service consultation, we also received green light (positive opinion) by all DGs except one. DG AGRI has unfortunately not been able to accept our draft legislative proposal. This means we will either need to make small compromise adjustments to the original proposal and change our preferred option, or we try to somehow convince DG AGRI to accept our main line.
In your briefing, please outline the main issues at hand and explain the options for next step so that our Director-General can make an informed decision on it. She did invite us to already make a recommendation based on our knowledge of the file if we have a preference.
You should keep the briefing short and concise, no more than two pages.
I have placed a file with various materials on your desk. It should contain what you need for the draft briefing. Please have a first version done already today at X o’clock so I can check it before passing it on to Ms Heinrich.
Thank","you and best of luck,
Wiebke
---
Head of Unit
Animal welfare unit, DG SANTE

Attachment 2: Inter-service consultation reply AGRI

Answer of DG AGRI to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 1 (sent on 16 May 202X 14:56:54) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | DENKER Nicholas (AGRI.F.002) | No automatic forward of notifications to this responsible officer |
Opinion | Negative opinion  |  |
Authorised in the DG by | ROBINSON Michael (AGRI.F) |
Comments | For laying hens/cage ban, either the low ambition option or status quo should apply, for protection of the single market and to ensure competitive pricing of European high standard food products, compared with lower-standard import products from third countries with only minimum requirements of animal welfare rules. |  |



Attachment 3: Inter-service consultation reply ENV

Answer of DG ENV to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 2 (sent on 14 May 202X 17:32:04) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | SVOBODA Lisa (ENV.D1) | No automatic forward of notifications to this responsible officer |
Opinion | Positive opinion |  |
Authorised in the DG by | HUEGEL-PEETERS Sabine (ENV.D) |
Comments | Thank you for consulting DG ENV on the proposed revised regulation on animal welfare. This proposal is important and in line with the European Green Deal objectives; we support the general approach and your preferred options. From our review, we have several minor editorial comments, given in track-changes in the attached document, which we request are taken on-board. |  |






Attachment 4: Inter-service consultation reply TRADE

Answer of DG TRADE to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 1 (sent on 15 May 202X 11:46:25) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | LANGE JENSEN Halfdan (TRADE.B.01) | No automatic forward of notifications to this responsible officer |
Opinion | Positive opinion |  |
Authorised in the DG by | GEORGIOU Andreia (TRADE 0) |
Comments | N/a |






Attachment 5: Press statement

Brussels, April 202X-2
Every year across the European Union, around three hundred million farmed animals are confined in cages. Unable to conduct many of their natural behaviours, these animals are treated as nothing more than production machines. No single EU Member State is completely cage free and in some Member States up to 90% of all hens, mother pigs and young calves are kept in cages and crates. This despite farming industry having had more than 15 years to voluntarily change their installations.
Over 170 organisations and caring citizens across Europe therefore joined forces to spearhead the “End the Cage Age” European citizens’ initiative. In total, 1.4 million EU citizens made their voices heard and signed the petition. Only one other citizen’s initiative has so far gathered more signatures than this.
Mr Daniel Müller, campaign leader for “End the Cage Age” said: what we see now is the battle of ethics versus economy. EU citizens do not want cheap food at any cost and certainly not at the cost of pain and suffering of our fellow creatures. Food industry and economic interests will have to adapt to this reality – and finally do what is right.
In response to our tireless campaigning, in April 202X-2, the European Commission committed to proposing legislation before the end of 202X to phase out and finally prohibit the use of animal cages. We must now ensure that a total ban on caged farming is delivered, as soon as possible. The fight also continues to pave the way not only for a cage-free Europe, but for a cage-free world by making sure that all imported products in the EU comply with cage-free standards.


Attachment 6: Website

What is a citizens' initiative?
A European citizens’ initiative is a way for you and other Europeans to take an active part in EU policymaking.
If you want the EU to act on a particular issue, you can launch a citizens’ initiative calling on the European Commission to propose new EU legislation on that issue.
For an initiative to be considered by the Commission, you need to get one million citizens from across the EU to sign it in support.
Step 1: Get started
Before launching an initiative, it is worth considering some of the key practical aspects, including:
is asking for EU legislation to be passed the best way to achieve your goals?
you must first set up a group of organisers composed of at least 7 EU citizens living in seven different EU countries. To do so, you need to find people to team up with across Europe who are willing to support your issue.
how will you organise your campaign to collect the signatures?
You can find detailed advice on all these issues on the European Citizens’ Initiative Forum




Step 2: Get your initiative registered
Before you can start collecting signatures for your initiative, you must ask the Commission to register it.
For this, you will need to:
create an organiser account. You will use this to manage your initiative and liaise with the Commission throughout its lifecycle.
provide a description of your initiative in one of the official EU languages (as well as details and relevant documents on the group of organisers, funding received, etc.)
The Commission is not obliged to register all initiatives. It only registers initiatives that meet certain criteria.
Once you ask for your initiative to be registered, we will assess whether to accept it.
You will receive an answer within 2-4 months.


Step 3: Get support
You need to get the support of at least one million people, with minimum numbers in at least seven EU countries. They must fill in a specific statement of support form.
You can collect:
on paper (pre-filled forms, downloadable from your organiser account) or
online (using the Central Online Collection System).
These forms are available in all EU official languages.
To sign, people must be:
EU nationals (nationals of an EU country)
old enough to vote in European elections or aged at least 16 in some countries
TIP – It is better to collect more signatures than you need. Sometimes the authorities in each country might not be able to validate all the statements of support you provide. Throughout the collection procedure, you must comply with data protection rules.


Step 4: Submit your initiative
Once you have received the last certificate from the national authorities, you have 3 months to submit your initiative to the Commission – together with the information on the support and funding you have received for the initiative.


What next?
If the Commission considers legislation an appropriate response to your initiative, it will start preparing a formal proposal. This can require preparatory steps like public consultations, impact assessments, etc. Once adopted by the Commission, the proposal is submitted to the European Parliament and the EU Council (or in some cases, only to the Council), which will need to adopt it for it to become law.
The Commission is not obliged to propose legislation. Even where it responds positively, the most appropriate follow-up to an initiative may be non-legislative in nature. There are a range of other measures that may be more suitable.
The European Parliament may also assess the measures taken by the Commission.

Attachment 7: E-mail message
 
From: ROBINSON Michael (AGRI)
Sent: Monday, 16 May 202X
To: MUNOZ Wiebke (SANTE)
Subject: Revised animal welfare regulation
 
---

Dear Wiebke,
Just a heads-up about the AGRI response to your animal welfare ISC - you will receive it later today. We can accept all of it, but we have a remaining concern about the proposed new rules for poultry cage rearing.
First, the proposed exception for farms less than 50 livestock units (3500 laying hens) does not make much sense. The overwhelming majority of eggs produced in the EU come from farms with more than 5000 birds (70 livestock units) and the smaller farms can anyway more easily transition to cage-free rearing if they haven’t done so already.
Longer transition time also does not help, it’s not about more time for farms to adapt. It’s about the money and about food prices.
For large-scale installations, cages are simply more efficient and use much less space. With your proposal, notably the requirement of more space per laying hen, production will necessarily be less cost-efficient, and most farms will not be able to keep the same number of birds. Consumers might say they care about animal welfare but when they make their choices in the supermarket, the thing that matters most is the price! If you implement the new rules, the price of eggs might increase by around 20-40% in countries like Spain, Portugal, and Malta where cage systems are still the norm. This means we will see a significant increase in cheap imported eggs from third countries with much worse animal welfare standards. Our European farmers cannot compete on such unfair terms.
There is also the socioeconomic element: the burden of higher food prices will be heavier on the poorest families.
Unless farmers can be compensated economically somehow for taking this risk, we don’t see any need for changing the current rules on poultry caging and we will need to block your proposal.

Call me if you want to discuss this further.

Best,
Michael


Attachment 8: Press release


MEPs endorse EU citizens’ call for gradual end to caged farming
Press releases – AGRI - 20 February 202X-2

The European Parliament has called for the end of caged farming within the next 5 years. The parliament members voted on an own initiative resolution recommending a total ban on the use of cages in animal agriculture by 202X+3.
The vote followed intensive lobbying by the “End the Cage Age” European Citizens Initiative, led by 170 non-governmental organisations (NGOs) across Europe, which garnered 1.4m signatures from EU citizens and demanded the phasing out of cages on farms. Members of the European Parliament (MEPs) voted by 558 to 37 with 85 abstentions on the non-binding resolution.
Unlevel playing field in Europe
Even though the EU has banned the use of battery cages in poultry production and sow stalls during gestation, campaigners said this was not enough, given the perceived unlevel playing field across Europe with some nations already going beyond EU laws.
According to the initiative, five out of 28 countries are currently achieving more than 80% cage-free production, i.e., Austria (97%), Luxembourg (97%), Sweden (92%), Germany (86%) and the Netherlands (82%). Bottom of the list is Malta, with 1%, followed by Spain and Portugal. About sows, the report is based on Eurostat figures, according to the initiative’s website.
In the European Parliament, a working group on cage-free farming established in 202X-10 has been actively supporting the “End the Cage Age” initiative and in October 202X-3, 101 MEPs from various political parties signed a letter of support addressed to EU Commissioners.
Speeding up the review of animal welfare legislation
Last month, the parliament’s AGRI committee adopted a motion for a resolution. Committee members called on the European Commission to speed up the review of the animal welfare legislation and back the phasing out of all cages in farming, possibly already by 202X+3. They also insisted on ensuring compliance with EU standards for all products imported into the EU.
By April this year, the European Commission will have made its decision as to whether to start a legislative process to ban caged farming. EU Food Safety commissioner Stella Kyriakides told MEPs that the Commission was considering a request contained within the resolution to apply the same animal welfare standards to meat imported from outside the EU as European farmers must meet inside the bloc.
Kyriakides also noted the call for farmers to receive compensation and support in their transition from cages. She added the phase-out would happen “as soon as feasible” but did not give a specific date.
The results for pork production could be far-reaching, as it would likely change the current practice using farrowing crates. In recent years, a lot of research initiatives have already been launched to design free farrowing concepts.



Attachment 9: E-mail message 
 
From: CALBI Ana (EFSA)
Sent: Thursday, 16 October 202X-1
To: MUNOZ Wiebke (SANTE)
Subject: Cages and antibiotics
 
---
Dear Ms Munoz,
Congratulations on your concluded impact assessment on the animal welfare regulation!
In view of your upcoming drafting process, I need to point out that there are several scientific studies pointing to higher prevalence of antimicrobial resistance, notably among e-coli bacteria, in non-cage housing systems for poultry - if not implemented correctly and with strict quality standards. I feel this did not come out clearly enough from your impact assessment.
Free-range egg production systems face more challenges related to biosecurity and use of antibiotics. The free-range layer birds have more interaction with each other compared to caged ones, leading to an increased incidence of infectious poultry diseases requiring treatment with antimicrobials, in turn leading to increased emergence of resistant commensal and pathogenic bacteria. This is a major threat to public health.
The main factor to consider is of course, as always, the number of hens per square meter, the hygiene routines, and the overall rules on veterinary prescription of antibiotics. It is the same for pigs: sows in small crates have low life quality but use less medication; pigs in free range but packed close together require lots of antibiotics and pigs in free range with sufficient space are more healthy and less prone to cause antimicrobial resistance. However, they are also much less cost-effective for industrial-size farming. 
Still, to ensure safe food production and avoid antibiotics resistance, livestock density simply must go down. 
If you could take these concerns into account in your draft revised regulation, we would be much grateful.

Best regards,
Ana Calbi

---
Head of Department
The European Food Safety Agency (EFSA)




Attachment 10: Impact assessment


								Brussels, 13 October 202X-1






COMMISSION STAFF WORKING DOCUMENT

IMPACT ASSESSMENT REPORT


Animal welfare: revised regulation


Executive summary
To address the specific objectives of the animal welfare legislation revision, four policy measures have been considered, with low, medium, and high ambition options. Impacts assessed include cost-efficiency, environmental and societal impacts and impacts on the single market. The European Food Safety Agency (EFSA) has confirmed the scientific evidence. Numerous stakeholder consultations and supporting studies have been performed.
For animals kept for economic purposes, the measures/options covered are:
1) 	Phasing out confining cages/crates for the following species and categories of animals:
Pigs
Calves
Laying hens and pullets
Rabbits and fur-producing animals.
A general transition period of between five and twelve years would be considered, depending on the level of ambition. Exceptions e.g., depending on farm size (number of “livestock units” where 1 livestock unit = 1 cow, or 2 pigs, or 71 laying hens) could be considered.
2) 	Banning the killing of day-old male chicks (or, as an alternative option, introducing an obligation of marking eggs from production systems where day-old chicks are killed). In the case of a ban, while a transition period of five years would be technically sufficient, notably if combined with stricter import rules, the impacts could be mitigated by introducing a ten years’ transition period.

3) 	Banning painful mutilations, i.e., beak trimming in poultry and tail docking in pigs (with incentives instead of bans as alternative options). For the bans, a general transition period of ten years has been considered. Incentives for voluntary action would enter into force immediately.
  
4) 	Animal welfare requirements at import. For animals and products of animal origin imported to the EU, either similar or fully equivalent animal welfare requirements with the revised EU animal welfare requirements for kept animals, as regards the use of cages, mutilations, space allowances, enrichment, the killing of day-old chicks and the welfare of fur animals would apply. A transition period of five-ten years has been considered.

A phase-out of the use of cages and stalls would considerably improve the welfare of more than 160 million laying hens, 53 million pullets (young hens), 13 million sows, two million calves, 35 million ducks and geese and 100 million rabbits. They would be able to perform a more natural and healthy behaviour.
A partial or total ban on cages and crates would have an important economic impact on the sectors concerned. For instance, for laying hens we have estimated the required investments for a transition into a cage-free system to about EUR 2,4-2,8 billion. For sows, the cost of demolishing the current system with gestation and farrowing crates could amount to around EUR 64-100 /m². These costs are likely to result in higher consumer prices. 
The situation however differs between Member States. Some have already taken measures to phase out cages and stalls whereas others have not. 
To mitigate these economic impacts, certain measures could be considered, notably awareness-raising vis-à-vis consumers, economic incentives via the Common Agricultural Policy and import rules to ensure a level playing field / reduce unfair competition.
The proposed measures would ensure a positive impact on sustainability as it would imply less intensive food production, causing less pollution to air and water. However, since cage-free animals move around more, they spend more energy and consume more feed. This could have a negative impact on the use of resources.

Table 1: Policy options (most cost-efficient option in terms of added value vs cost is shown in green):
| Low ambition option | Medium ambition option | High ambition option | Comments |
1.a. Crates/cages: pigs | Phase in of crate ban over 10 years. |   | Exceptions allowed for farms with less than 50 livestock units. |   | Allowing temporary confinement from 1 week before farrowing until weaning. |   | Cost-benefit analysis value (-) | Phase in of ban over 5 years. |   | Farms with less than 50 livestock units allowed to phase out crates over 15 years. |   | Temporary confinement allowed from 1 day before farrowing to 5 days post-farrowing. |   | Cost-benefit analysis value (+++) | Total ban phased in over 5 years. |   | No exceptions. |   | Cost-benefit analysis value (+) | Medium and high ambition options can be combined with stricter requirements of minimum living space per animal and/or voluntary guidance on antibiotics use. |
1.b. Crates/cages: calves | No legislative change. |   | Cost-benefit analysis (-) | Phase-out of all use of weaning crates over 10 years. |   | Ban on trade / import of calves kept crated. |   | Cost-benefit analysis (+) | Phase-out of all use of crates within 5 years. |   | Ban on trade / import of calves kept crated. |   | Cost-benefit analysis (++) | Strong public support for total ban. Low impact on food pricing. |
1.c. Cages:  laying hens and pullets | Phase in of ban over 12 years. |   | Farms with less than one hundred livestock units exempted. |   | Cost-benefit analysis (0) | Phase in of ban over 10 years. |   | Farms with less than 50 livestock units allowed to phase out cages over 12 years. |   | Cost-benefit analysis (++) | Total ban phased in over 5 years. |   | Cost-benefit analysis (+++) | Same as with pigs. |
1.d. Cages: rabbits and animals in fur production | No legislative change. |   | Cost-benefit analysis (-) | Transition phase 10 years.  |   | Cost-benefit analysis (+) | Transition phase 5 years. |   | Cost-benefit analysis (++) | Low economic impact (small sector). |
2. Killing of day-old male chickens (laying breeds) | Obligation of marking eggs from production systems applying this practice, starting as from 5 years. |   | Cost-benefit analysis: (0) | Ban of procedure within 10 years + economic incentives via the Common Agricultural Policy for farmers transitioning sooner |   | Immediate obligation of marking eggs from production systems not yet transitioned. |   | Cost-benefit analysis (++) | Phase in of ban over 5 years + stricter import rules to protect internal market |   | Cost-benefit analysis (+) | Strong public support for total ban. Strong impact on food pricing. |   | Viability dependent on development of technology to gender-identify eggs before hatching. |   | Possibility of launching consumer awareness campaigns to explain food price impacts (acceptability). |
3. Ban on painful mutilations (beak trimmings / tail cropping) | N/a | Immediate ban on cross-border trade in tail-docked pigs. |   | No ban on the procedures but economic incentives via the Common Agricultural Policy for voluntary transition. |   | Cost-benefit analysis (+) | Phase in over 10 years of total ban. |   | Cost-benefit analysis (+++) | No justification for no action. |   | Enforcement mechanism needed (inspections). |
4. Animal welfare requirements at import | No legislative change | Minimum set of rules apply for import (low- or medium ambition options). 10 years transition period. | Full EU rules to apply also for imported products. 5 years transition period. | Strong impact on competitiveness of EU farmers. Strong impact on the acceptability of other measures. | Possible difficulty of implementation. |
 

Background
Since 202X-10, EU legislation requires that laying hens be kept either in enriched cages, or alternative systems (single or multi-tier barn or, free-range). The current legislation allows calves being individually housed until the age of eight weeks, while sows and gilts are kept in confinement for a period of four weeks after service and from one week before the expected time of farrowing to weaning of their piglets. 
Approximately one million farms keep laying hens in the EU. Forty-five percent of these are kept in enriched cages. 
There is currently a trend towards using less cages in many EU Member States such as France, the Netherlands and Poland to answer to consumer’s expectations. E.g., Austria and Luxembourg have already banned the use of cages for laying hens. The animal welfare problems related to cages will however remain for many laying hens if no action is taken at EU level.

Problem drivers
Conventional livestock production systems across EU countries are put under pressure by competitive global markets, a rise in input costs and the search for maximum profit margins by farmers and all food business operators along the production chain. The demand of certain consumers’ segments for low price food is expected to be more prevalent in the current inflationary context.
This pressure over production costs has led to further intensification (and specialisation) of the farming and killing practices, as business operators increase the volume of production to reduce overheads costs per livestock unit. Evidence shows that, while the number of livestock farms is decreasing, their size is increasing. Small farms are replaced by very large industrial scale installations.
This trend has led to certain detrimental effects on animal welfare due to high densities, certain management practices, housing/transport conditions and stunning methods, as well as due to certain breeding strategies.
Current EU rules also do not consider new scientific evidence and huge technological developments in relation to agricultural practices, zootechnics and transport operations. For instance, this new scientific evidence relates to a new understanding of stocking densities, behaviour (need for an enriched environment), mutilation practices, journey times and space allowances for animal transports, and stunning methods used for pigs, poultry, and farmed fish.
The lack of update of the EU animal welfare legislation has led Member States to adopt an increasing number of national measures going beyond EU minimum requirements to respond to the growing citizens’ concerns towards animal welfare, leading to a fragmented legal landscape, including as regards animal welfare labelling.
At the same time, consumers are growing more aware and more demanding. The upward trend of societal demands for better animal welfare protection is not reflected in the current legislative requirements. 

Figure 1: Problem tree 

Economic and environmental impacts of the preferred package of options: cages for laying hens
The policy option assessed to be most cost-efficient is a total prohibition on the use of cages for laying hens with a transition period of 5 years (from the date of entry into force of the revised legislation).
However, if no similar requirements apply for eggs and egg products imported into the EU from third countries, since the EU consumers’ demand for eggs is not expected to decrease and since EU production is expected to decrease, an increase in eggs obtained from caged hens imported from non-EU countries with lower standards is expected, thus limiting the positive animal welfare impact of the measure.
The required investments for a transition into a cage-free system for laying hens would amount to around EUR 2,4-2,8 billion.
A prohibition of cages would decrease the number of laying hens by an estimated 30% (i.e., from 186,8 million to 102,9 million) in farms which currently have cage systems.

SME’s
Small farms tend to use cage-free systems more than big farms. A prohibition would therefore primarily have a positive competitiveness impact on small farms.

Public authorities
It is likely that a prohibition would generate additional enforcement costs in the short term for the national competent authorities, however these will come back to current levels in the medium term.

Consumers
A prohibition would lead to an expected increase in the price of eggs, but to which extent is not clear. Some estimates by the EU poultry industry suggest a + 20% price gap between eggs from cages and those from barn systems. However, sales data from the Netherlands and Germany suggests a much smaller difference in prices: less than one eurocent per egg.
With an average per capita consumption of 210 eggs per year, or 4,04 eggs per week, this would mean that transitioning to cage-free systems would add less than four eurocents per person to consumers’ weekly food shopping bill. Furthermore, the experience from Germany, where enriched cages are progressively phased out, even suggests that the price for barn eggs may eventually be the same as for eggs from enriched cages.
 
Environmental impacts
A prohibition would have a positive impact on sustainability as it would imply less intensive production leading to less air and water pollution and less greenhouse gas emissions.



Attachment 11: Website

| A gestation crate, also known as a sow stall, is a metal enclosure in which a   used for breeding may be kept during pregnancy. A standard crate measures 2 m x 60 cm. | Sow stalls contain no bedding material and are instead floored with slatted plastic, concrete, or metal to allow waste to be efficiently collected below. This waste is then flushed into open-air pits known as . A few days before giving birth (farrowing), sows are moved to farrowing crates where they are able to lie down, with an attached crate from which their piglets can nurse. | Most pregnant sows in the US are kept in gestation crates. The crates are banned for new installations in Austria and Canada, but many sows are still confined there in pig breeding facilities. The crates are banned in the United Kingdom, Canada, Switzerland, and Sweden. However, farrowing crates, in which female breeding pigs can be kept for up to five weeks, are not banned in the UK. | Opponents of the crates argue that they constitute animal abuse, while proponents say they are needed to prevent sows from fighting among themselves. |




Attachment 12: Website



Page contents |  | Submission and examination |  |  | Submission and examination | The  initiative was submitted to the Commission on 2 October 202X-3, having gathered 1,397,113 statements of support. See . | The organisers met with the Commissioner for Health and Food Safety, Stella Kyriakides on 30 October 202X-3. | A  took place at the European Parliament on 25 January 202X-2. See . | The initiative was debated at the European Parliament’s plenary session on 20 February 202X-2. In the  adopted on the same day, the European Parliament expressed its strong support for the initiative. See European Parliament’s . | Answer of the European Commission | In its response on 4 April 202X-2, the Commission commits to table, by the end of 202X, a legislative proposal to phase out, and finally prohibit, the use of cage systems for all animals mentioned in the initiative. | In parallel to the legislation and to facilitate a balanced and economically viable transition to cage-free farming, the Commission will seek specific supporting measures in key related policy areas, such as trade and research and innovation.  | In particular, the new Common Agricultural Policy will provide financial support and incentives – such as the new eco-schemes instrument – to help farmers upgrade to more animal-friendly facilities in line with the new standards. |



Attachment 13: News article



 -  -  
Health and food safety Commissioner will fight for ethical food systems in Europe
30 October 202X-3
Earlier today, Commissioner Kyriakides met with the representatives of the citizens’ initiative ‘End the Cage Age’. EURACTIV interviewed the Commissioner after her meeting with the campaign team.
Stella Kyriakides is European Commissioner for Health and Food Safety and in charge of the EU animal welfare legislation. She spoke to EURACTIV about the call for revised animal welfare legislation and the possibility for action ahead.
This is one of the most strongly supported citizens’ initiatives so far with almost 1.4 million signatures collected. How will the Commission respond to all who signed this petition?
I am impressed by the hard work by these dedicated young people. I promised them today that the Commission will investigate this very carefully.
In fact, we recently completed a review of our legislation and have found that there is indeed scope for improvement. However, first we will hear the views of the European Parliament and we will consult across the Commission services and then reply about next steps.
Your colleague, the Commissioner for Agriculture, is less enthusiastic. How will you get the farming community onboard?
As always, there will be a balancing act between several interests. Farmers produce the food we eat and they deserve to be heard as well. Many farmers also already made this transition, showing it is possible to rear animals cage-free.
The Commission always performs a thorough impact assessment, so any legislative proposal will be based on solid facts and on careful consideration of all relevant impacts. We always seek a sustainable compromise.
There could also be other possibilities to make animal welfare more attractive for farmers by e.g., economic incentives, subsidies, trade schemes and awareness campaigns. It is not just about laws and penalties.
On the other hand, I think the farming industry has known for a long time that this is coming, they have had plenty of time to prepare and many Member States have in fact already taken significant steps in the direction of free-range animal rearing.
But is there not a risk that ‘money will talk’, how can you weigh the economic impacts against animal suffering – how will the comparison be done in an impact assessment?
No, economic interests are not the only interests we take into account. It is true that our assessment is expressed as a cost-benefit ratio, but among those ‘benefits’, we consider also softer values such as social, health and environmental impacts – and ethical choices. I guarantee you that industry interests will not dominate this process. 
On the contrary, I think what we see here is a strong message from European citizens that animal rights and animal welfare must be respected, and I agree with them. We cannot ignore this question any longer.",22,6.0,"Summary

This is a good case study with some room for improvement in all competencies.
First and foremost, use sentence structure and length you are confident with, as some style issues can lessen the effect even of an impeccably discussed problem point. Typos and some grammar aspects (e.g., article use, verb agreement, verb forms) can be controlled with some attention even in an exam situation. They can heavily influence your score for the communication competence. 
While list format is more than welcome in some cases (e.g. pro/con lists), we expect a coherent, consistent, professional, and easy-flowing text. Make every connection and causation explicit, no matter how obvious they are; thus, you can enhance the cohesion of your text and achieve stronger content points. Merge short, one-sentence paragraphs to improve your case study's narrative arch. 
If the source documents provide some insight into whether the given subject matter has international aspects , then it is worth discussing in a short list or in one or two sentences such possibilities as well, in order to provide a full picture.
It is helpful to frame your text with an introduction and conclusion; first, you can put the issue in context; second, you can enhance the professional feel of the study; and, finally, you can show that you finished the text as you intended and not because the time ran out. 
For time management issues and other practical ideas, please check out our Tips & Tricks menu and our webinars. 

Per Competency Score",6.0,"Observations
With this competence, we basically evaluate the style of the case study. Your text should be clear, fluent, written in a professional but still captivating style; of course, spelling and grammar are also covered in this area. Another point we examine here is whether you managed to find the balance between providing details and being concise while conveying the key points of the arguments.",,"Tips to Improve
The text is informative, its majority is cohesive, but the amount of typos really influence the readability of the text.","Trainee's Answer
1) Introduction 
Following the ""End the Cage Age"" European citizens initiative, submitted on 2 October 202X-3, after gathering 1,397,113 statements of support, the European Parliament has called for the end of cage farming within the next five years. 
In response to this, the European Commission, on the 4 April 202X, committed to table a legislative proposal to phase out, and finally prohibit, cage systems usage for all animals in the initiative. However, it is important to facilitate a balanced and economically viable transition to cage-free farming, particularly by adopting specific supporting measures in key policy areas areas like trade and research and development. 
2) Animal welfare regulation state of play and main issues 
2.1) State of play of Inter-Service Consultation (ISG) replies: 
DG TRADE and DG ENV provided green light to the draft legislation revision proposal of DG SANTE. On the other hand, DG AGRI blocked the proposal, claiming a series of policy problems that need to be tackled. 
2.2) DG AGRI main opposition motives:
DG AGRI reasons for blocking the proposal are the following:
1) The proposed exception for farms with less than 50 livestock units (3500 laying hens) is not rational. In fact, the large majority of eggs produced in the EU come from farms with more than 5000 birds (70 livestock units) and the smaller farms have already a more easily transition to cage-free rearing if they have not done it; 
2) The legislation has focuses too extensively on money and food prices rather than providing longer transition times; 
3) The proposal of having more space for laying hens as requirement is a less cost-efficient solution, which will lead most farms not being able to maintain the same number of birds;
4) Finally, the price for eggs by implementing DG SANTE new proposed regulation might increase by 20-40%, in countries where cage systems are the norm (i.e. Spain, Portugal and Malta), impacting more significantly the poorest family and resulting in higher imports of cheaper eggs from third countries with worse animal welfare standards.  
In light of the above, DG AGRI would opt for a longer transition period or maintaining the current status quo. 
2.3) Scientific evidence on non-cage housing systems
Moreover, alongside the above-mentioned policy issues, several scientific studies highlighted several public health concerns in regards to the implementation of non-cage housing systems: 
1) The usage of non-cage housin systems for poultry can result in a higher level of antimicrobial resistance prevalence, notably among e-coli bacteria, if the implementation process is not correct and does not follow strict quality standards; 
2) Free-range egg production systems face more challenges in relation to biosecurity and antibiotics usage. In fact, the free-range layer birds interact more with each other in comparison to the ones in cages, increasing the incidence of infectious poultry diseases requiring treatment with antimicrobials, thus resulting in increased emergence of resistant commensal and pathogenic bacteria (major threat to public health). 
2.4) Main factors to consider for an efficient non-cage system:
To implement an efficient non-cage system, is necessary particular attention on the specific aspects:
1) Number of hens per square meter; 
2) Hygiene routines; 
3) Overall rules on veterinary antiobiotics' prescription. 
The same problems aforementioned apply to pigs farming practices. 
3) An assessment of the available policy options:
3.1) Three main possible scenarios:
For adopting a transition phase to cage-free systems, respectively high, medium and low ambition policies may be considered. The high ambition policy provides the quickest transition phase, but it may result in higher burden of cost for farmers and generally have a regressive impact on the poorest households. On the other hand, the low ambition period, providing a transition phase of 10 years, would give farmers the largest span of time to adjust to the policy change, but it is not line with the expectations of both the European Parliament and the European civil society. 
As concerns the medium ambition policy scenario, it looks the most reasonable solution, from a cost- and time perspective. 
3.2) The medium ambition policy scenario implementation: 
In detail, the medium policy ambition scenario would entail the following measures: 
1) For crates / cages (pig): Phase in of the ban over 5 years. Farms with less than 50 livestock units will be allowed to phase out over 15 years. Allowing temporay confinement from 1 day before farrowing to 5 days post-farrowing. 
2) For calves, phase-out of all use of crates within 5 years. Moreover, a ban on trade / import of calves must be created. 
3) For laying hends and pullets a total ban should be phased in over 5 years.
4) For rabbits and animal in fur production a transition phase of 5 years will be put in place.
5) For killing day-old male chickens, ban of procedure within 10 years alongside providing economic incentives through the Common Agricultural Policy for farmers transition sooner. Alongside this, an obligation to mark eggs eggs from production systems not yet transitioned will be put in place.
6) For the painful mutilations ban, a phase in over 10 years will be granted.
7) Finally, the requirements for import from third countries should be in line with the minimum set of rules for welfare implemented by the EU. 
4) Policy recommendation 
4.1) The importance of transition
The EU should  provide financial incentives to farmers through the Common Agricultural Policy for farmers in order to make the burden of shifting to non-cage systems the less expensive and impactful on their activity as possible. 
4.2) The importance of innovation: 
The EU should consider the most recent technological developments in agricultural practices, zooechnics and transport operation, by understanding better stocking densities, behaviour (for enriched environment), mutilation practices, journey times and space allowances for animals transports."
1,0_Lithium Supply Chain (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG MOVE. 
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Analysis and Problem Solving, Communicating (Drafting Skills), Delivering Quality & Results, and Prioritising & Organising.

Specifically, your task will be to draft a memo for your Head of Unit.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations


ACEA - European Automobile Manufacturers’ Association 

DLE - direct lithium extraction

DLP - direct lithium to product 

ECHA - European Chemicals Agency

ESG - environmental, social, and governance

EV – Electric Vehicle

INN – Investing News Network

IRA – Inflation reduction Act (US)

LCE - lithium carbonate equivalent

LiPo – Lithium Polymer







EMAIL 1","Subject: Towards a sustainable, circular, European battery supply chain 
Dear YOU,

In December 20XX-2, the Commission presented a proposal for a regulation on batteries and waste batteries. The proposal aims to strengthen the functioning of the internal market, promoting a circular economy and reducing the environmental and social impact throughout all stages of the battery life cycle. The initiative is closely linked to the European Green Deal, the Circular Economy Action Plan, and the New Industrial Strategy. 
At the end of last year, The Council and the European Parliament reached a provisional political agreement on the proposal. For the first time the legislation will regulate the entire life cycle of a battery – from the supply chain of raw materials, over the production to reuse and recycling of batteries – and ensure that they are safe, sustainable, and competitive.
As you know, our unit has the lead on this important file and our DG intends to launch the formal interservice consultation over the coming weeks. Before this, our DG wants to organize an internal reflection and brainstorming meeting, and I have been appointed to chair this meeting.
Could you produce an internal memo, summarizing the main ins and outs of this file and the agenda for the internal meeting with concrete proposals and recommendations to fine-tune the original proposal, in line with the political priorities of the co-legislators. 
I’m on mission tomorrow so please could you get this done for me today. It doesn’t need to be long – in fact the shorter, the better.  

Many thanks",",

Ferdinand
Head of Unit




Is Europe Moving Fast Enough to Build a Resilient Lithium Supply Chain? 
Priscila Barrera
Nov. 16, 20XX-1


Europe will soon release its Critical Raw Materials Act to identify potential strategic projects and build up reserves where supply is at risk.
Europe’s green energy transition plans give a central role to the electrification of transportation. 
The European Union (EU) has ambitious goals to become climate neutral by 2050, meaning it would be an economy with net-zero greenhouse gas emissions. Recently proposed legislation is looking to effectively ban all internal combustion engine cars by 2035.
In 20XX-2, electric car registrations for the year were close to 1,729,000, up from 1,061,000 in 2020, with prospects for the region remaining positive. Last year, the market share of battery electric cars almost doubled to around 10 percent, but challenges faced by carmakers continue to weigh on demand as inflation and fears of a recession put pressure on targets. 
In its most recent forecast, the European Automobile Manufacturers’ Association (ACEA) said it expects the overall EU car market to shrink again this year, slipping by 1 percent to reach 9.6 million units.
“To ensure a return to growth — with an even greater share of electric vehicle sales so climate targets can be met — we urgently need the right framework conditions to be put in place,” said Oliver Zipse, ACEA president and CEO of BMW. “These include greater resilience in Europe’s supply chains, an EU Critical Raw Materials Act that ensures strategic access to the raw materials needed for e-mobility, and an accelerated roll-out of charging infrastructure.”
As sales of electric vehicles increase, carmakers are looking to secure supply of key metals used in batteries, including lithium. Today, Europe is quite dependent on Australia and Chile for lithium supply and China for lithium refining, but the region is taking steps to strengthen its supply chain for the important battery metal. 
What is the European Critical Raw Materials Act? 
In September, news broke that Europe will be putting forward the European Critical Raw Materials Act, a new piece of legislation. Its aim is to identify potential strategic projects and build up reserves where supply is at risk.
European Commission President Ursula von der Leyen said the bloc has learned its lesson about the risks of being dependent on Russia, and realizes the need to be vigilant toward China.
""In the case of China, it is the risk of dependency on technologies and raw materials,"" she said, adding that the EU needs to boost its production capacity and shift more towards trustworthy suppliers.
In October, von der Leyen said the EU is witnessing quite an acceleration of trends and tensions with China. 
""The Chinese system is fundamentally different from ours and we are aware of the nature of the rivalry,'' she said.
The moves from the EU are in line with pushes seen in other regions such as North America, where the US has committed billions of dollars to reach its carbon emissions targets.
In June, the Biden administration launched the Inflation Reduction Act, which includes climate incentives. The legislation, which was signed into law in August, requires automakers to source 50 percent of critical minerals used in electric vehicle batteries from North America or free trade agreement countries by 2024, with that amount rising to 80 percent by the end of 20XX+3.
For its part, Canada recently ordered three Chinese companies to divest from lithium companies following a “multi-step national security review process.” China has opposed the move, and Canada is expected to release its China strategy soon.
Europe-Asia relationship in the lithium space 
Jack Bedder of Project Blue said Asia will always be a part of the European lithium-ion battery supply chain. Major Asian companies, including Panasonic, Samsung, BYD Company and CATL, all have operating capacity on the continent.
“As a result, it will be almost impossible to detach fully from Chinese-owned supply across all stages of the lithium-ion supply chain,” he told the Investing News Network.
However, as lithium processing capacity is built up globally at non-Chinese-owned companies, particularly within the EU, the opportunities to reduce the EU's dependency on China-owned supply will improve. “It is very unlikely that the EU will implement legislation directly prohibiting lithium supply from Chinese-owned companies, as further constraints on supply availability to the European market will only hinder growth in the industry over the coming decade,” Bedder added.
For Allan Pedersen of Wood Mackenzie, Europe cannot move forward without influence from Asia in the short to medium term.
That’s due to a few reasons. As mentioned, many of the battery plants being constructed in Europe have Asian companies behind them, and the cathodes needed in batteries are still largely produced in Asia, where the know-how is strongest. Additionally, lithium refining is mainly done in China and most mineral concentrate is produced in Australia.
“China has a multi-year advantage over the rest of the world in terms of investing in the entire supply chain — it will be challenging for Europe to catch up to that in terms of investment in know-how, processing equipment and resources,” he said. 
“This doesn’t mean that Europe cannot make progress in this space. In lithium, we see some resource developments and processing facilities being considered and constructed.”
For the analyst, in the long-term Europe has the potential to become more self-sufficient for raw materials as recycling becomes a larger part of the supply landscape and can supplement domestic resources.
European Commission could classify lithium as toxic. 
Although Europe is pushing to build a resilient supply chain by partnering with allies and developing domestic resources, it might not all be good news for miners in the region — at the end of last year, the European Commission said it will weigh a proposal from the European Chemicals Agency to classify lithium carbonate, chloride and hydroxide as dangerous for human health.
If the proposal is approved, this could undermine the EU’s attempt to create and support a domestic battery materials supply chain, research firm Rystad Energy said in a statement. “The EU currently relies heavily on imports of lithium to supply its nascent electric vehicle production sector and the classification may increase its reliance on other regions, at a time when the union is focused on energy security and reducing emissions,” the document reads.
If the classification goes ahead, it would not stop lithium usage, but it is highly likely to have an impact on at least four stages: lithium mining, processing, cathode production and recycling.
“This potential ruling comes at a time when the EU is itself scrambling to build and establish local lithium supply chains. The permitting issue has repeatedly been highlighted at recent industry events as one of the main barriers to new mining projects ramping up quickly in the EU,” according to Rystad Energy analysts. “There is also further risk of potential projects losing local community support for building lithium mines and processing operations.”
Editorial Disclosure: The Investing News Network does not guarantee the accuracy or thoroughness of the information reported in the interviews it conducts. The opinions expressed in these interviews do not reflect the opinions of the Investing News Network and do not constitute investment advice. All readers are encouraged to perform their own due diligence.




Lithium salts could be declared health hazard in EU
June 9, 20XX-1 by Igor Todorović


A major lithium producer threatened to close its plant in Germany if the European Union declares the material dangerous to human health. The European Chemicals Agency or ECHA initiated the process.
The European Union has been making its environmental and climate rules stricter for decades. The administration in Brussels wants to make the entire continent carbon neutral by mid-century. At the same time, it is striving to achieve the highest level of protection from pollution in the world.
The energy transition and the decarbonization of industrial activity and power plants imply massive deployment of renewables, mostly solar and wind farms. However, as they depend on unstable weather conditions, the electric power system requires energy storage, in which the EU counts a lot on batteries.
Dangerous critical raw material
Lithium-ion solutions still dominate the sector, though there are other technologies emerging that could popularize less harmful material for home units and the batteries for electronic devices, electric vehicles, and utility systems. At the same time, the European Commission is struggling to secure supply chains that would make the availability of lithium stable and make the EU almost self-sufficient by 20XX+7.
The European Union has added lithium to a list of critical raw materials as demand is expected to increase dramatically in the coming years.
Initiatives to open mines and ore processing plants such as the ones in Serbia and Portugal have caused a public uproar as environmentalists and the local population are fearful about the impact on nature and people’s livelihoods. In other projects, engineers are trying to make the extraction of lithium from geothermal waters cost effective and harmless, without any mining.
Stricter rules for handling lithium would lift costs
However, the entire concept could falter with the European Commission’s upcoming legislation. Namely, it is considering the proposal from the European Chemicals Agency, ECHA, to declare key lithium salts hazardous for human health, Reuters reported. If lithium carbonate, lithium chloride and lithium hydroxide are classified as dangerous, it would complicate the import procedure, production, and handling of the materials.
ECHA’s Risk Assessment Committee accepted the demand from France in September to classify lithium salts as damaging for fertility and unborn children and to declare the substances harmful for breastfed children.
Adding lithium salts to the list of materials hazardous for health may prompt the revision of a range of projects in the industry.
Stricter rules mean higher costs, so any lithium ore processing plant project, like the one in the Jadar area in Serbia, would need to be given a second look regarding its environmental impact and feasibility.
Albemarle, based in Charlotte, North Carolina, has indicated it may be forced to close its plant in Langelsheim in north Germany if the plan is accepted. In that case, Chief Financial Officer Scott Tozier said, the company wouldn’t be able to import lithium chloride, its primary feedstock.
The unit’s annual revenue is USD 500 million, and the plant has over 600 employees. Tozier warned a decision to declare lithium salts hazardous would prompt an exodus of EU producers including battery recyclers.
The decision is expected to be reached by early next year, the article adds.





The Really Big Battery Deal in the IRA That People Are Missing
By Zachary Shahan – Published September 23, 20XX-1
When it comes to electric vehicles and the Inflation Reduction Act of 2022, almost all the discussion has been around the consumer tax credit for buying an electric vehicle, including the interesting new battery aspects of that. That’s a big topic, but there’s a whole other battery angle separate from the consumer tax credit, and it’s huge.
The short summary of the whole thing is that the IRA incentives for nearly every stage of battery production and the battery supply chain are very attractive, and since they stack on top of each other, the IRA is likely to stimulate a “gold rush” of sorts in battery mineral mining, battery mineral refining, battery cell production, battery recycling, and battery pack production in the United States. When you also consider that consumers will need to get batteries whose components don’t come from China, and that come from North America eventually, then it’s essentially a given that everyone in the industry now knows it should have battery mineral mining and refining as well as battery cell and pack production in North America.

SK Innovation Georgia battery factory rendering, courtesy of SK Innovation.
The Current EV Battery Mineral Situation
First, let’s note where we’re starting from. The USA currently mines and refines close to 0% of the minerals that go into EV battery packs. China, on the other hands, mines or refines the majority of all the big ones, including lithium, cobalt, nickel, and graphite. Here’s a chart on Chinese EV battery mineral domination:

Money, Money, Money
Looking at the data, the idea that Joe Biden was going to stimulate a gold rush in the EV battery mineral mining and refining space was a dream some of us had, but it seemed like one of the more outlandish dreams we could have in this time and age. However, the market does respond to three things pretty well: money, money, money, and money. And the Biden administration, Prime Minister Manchin, Senate Majority Leader Chuck Schumer, and others involved in crafting the legislation took note and decided to offer all four.
The slight joke here, aimed at emphasizing the key point, is that the IRA seems to be offering cash money (tax credits) for mining battery minerals, for refining battery minerals, for putting together battery cells, and for putting together battery packs (or “modules”). If you do all those things, you don’t get one bonus, you get four bonuses. If you count all the different minerals in a battery, the number of potential bonuses is much larger. Those bonuses add up, and they make it much more appealing to bring full-cycle battery production to the USA. At the very least, it should open mining and refining projects — which are more or less non-existent in the United States — by making them much more bankable. (Side note: Canadian and Mexican locations hoping to attract battery manufacturing investment may not have figured it out yet, but their competitive position versus the US took a major hit when Biden signed the IRA.)
That’s why we recently got news of Tesla reportedly deciding to scrap some investments it had already made in Germany (but not all of them) and move some battery cell production stateside. That’s why Tesla is reportedly exploring lithium refining in Texas now as well. That’s why GM is reportedly accelerating its exploration of EV battery mineral supplies from US soil. “Our thought process was that we would do this over a period of time, but with the IRA, we are actively working on figuring out how to accelerate,” said Sham Kunjur, GM’s executive director for EV raw materials. But this is only the beginning. These are just the leaks from early movers and leaky groups. Whether it’s Tesla, GM, Volkswagen, Ford, Panasonic, SK Innovation, LG Energy Solution (previously known as LG Chem), Samsung SDI, Albemarle, Livent, Piedmont Lithium, Talon Metals, Lithium Americas, Pilbara Minerals, or others, corporate teams are looking at the IRA, having their lawyers look at it, and starting to look much more seriously at what production opportunities they can launch in the United States.
Looking at the Actual IRA Language
Section 45X of the IRA concerns “components produced and sold after December 31, 2022.” Near the beginning, it states that “any taxable year is an amount equal to the sum of the credit amounts determined under subsection (b) with respect to each eligible component.” In other words, if you get a tax credit for one component of a battery (raw lithium, for example), you can also go and get a tax credit for another component or even later stage of the same component (the refined lithium, for example). The tax credits are for each major stage of the production process, and that means you can get them for various components of a battery and various stages of processing or putting together those components. You can get the following credits:
10% of the cost of battery electrode active materials
$35/kWh of battery cell capacity
$10/kW of battery module capacity (or, for a battery module that does not use battery cells, $45/kWh)
10% of the cost of producing a battery mineral.
Also, while there’s a phaseout for some of these between 2030 and 2032, there is no phaseout at all for the critical mineral subsidies! That’s long-term stability for a market that needs it.
What Minerals & Battery Components Are Eligible?
Regarding electrode active materials, those include “cathode materials, anode materials, anode foils, and electrochemically active materials, including solvents, additives, and electrolyte salts that contribute to the electrochemical processes necessary for energy storage.”
Applicable critical minerals include aluminum/alumina, antimony/antimony trisulfide concentrate, barite/barium sulfate, beryllium/copper-beryllium master alloy, cerium/cerium oxide, cesium/cesium formate/cesium carbonate, chromium/ferrochromium, cobalt/cobalt sulfate, graphite/graphitic carbon, lithium/lithium carbonate and lithium hydroxide, manganese, nickel/nickel sulphate, and many others.
Notably, at the end, it’s noted that only production that takes place in the United States is eligible for these tax credits. This creates a “USA premium” in the supply of raw materials to facilities that want to get the maximum benefit from 45X. Any manufacturer will be eligible for a 45X tax credit which covers the yearly cost of production if their facility is using raw material from the US. For most manufacturing, raw material cost is the most significant component of OPEX after labor and energy. So, Biden, Schumer, Manchin, and their aides have been very clever here: “want the maximum benefit, Buy American.”
So, let’s go back to the example of Tesla (or you can use Ford, GM, or some other company in this hypothetical if you prefer). Tesla could, theoretically, get a tax credit for mining lithium, get a tax credit for refining lithium, get a tax credit for mining nickel, get a tax credit for refining nickel, get a tax credit for producing battery anodes, get a tax credit for producing battery cells, and get a tax credit for producing battery modules. Of course, Tesla isn’t going to do all those things. However, I think that helps to explain the potential here. Whereas Tesla won’t do all those things itself, companies and investors will be pouring into the United States to do them, and some automakers will deepen their vertical integration in the battery space as well.
As a final note, and perhaps as a teaser for something we’ll come back to, while the incentives from the IRA are attractive, so is the potential for pricing control over raw materials! Whether Ford, GM, or Tesla, having more secure, stable, predictable control over key raw material costs could go a long way in being competitive and financially sustainable in the coming decade. How much is that pricing control worth as we go from ~5% EV market share in the US auto industry to 50% or more?

Russia may launch lithium production in the coming four years
June 17, 20XX-1
| As said at the SPIEF Oleg Kazanov, Director of the All-Russian Institute of Mineral Resources (VIMS) under Federal Subsoil Resources Management Agency, Russia may start lithium mining based on the ore deposits in the Murmansk region in 3-4 years and become one of the world’s five largest producers in eight years’ time.  |  |
“Russia has a lithium resource base, which is 10% of the world’s reserves and explored back in the 60s of the previous century. This is almost 4 million tons in 15 explored deposits. The first two objects in the Murmansk region will gain licensing and active subsoil use by the end of the current year. I think production might start there already in the next three or four years. Moreover, these are world-class deposits, both in terms of the lithium reserves and content,” O. Kazanov said.
According to him, now the demand for lithium is boosting in the world. Its driver is the battery industry. “Already in the next 10 years, we will see an increase from the current 100,000 tons of lithium consumption to about 700,000 tons. In total, 88 deposits of ore lithium will be launched in the world soon, but it is not enough to cover its entire global demand,” the expert notes.
Meanwhile, in Russia, a peculiar situation has developed in the lithium industry. The country has huge reserves of ore lithium reaching 10% of the world’s. Besides, Russia discovered lithium reserves in solutions in the bottom waters of the oil and gas fields in the Angara-Lena region, but they have not been fully assessed yet. The lithium content in solutions is very high by the world standards, i.e., about 300 mg/l.
There are two large lithium processing plants in Russia the Krasnoyarsk chemical-metallurgical plant, which buy raw lithium from Chile, bring it up to battery quality and ship to Southeast Asia.
Against the background of this situation, Federal Subsoil Resources Management Agency has recognized development of the lithium ore and brine reserves as a priority area.
Lithium ore mining technologies already exist; they scale well, especially considering increase of the demand for lithium and its price rise. “I think already on ore lithium, in the prospect of the next eight years, we are going to be among the top five producers of this metal along with Chile, Argentina, China and Australia,” O. Kazanov noted.
The next stage in the Russia’s lithium industry development after the ore deposits have been commissioned will be application of the technologies for lithium production from solutions. In the world, this is the DLE technology mainly used for solutions at geothermal power plants. In Russia, lithium solutions are found in the bottom waters of oil and gas fields. This water is somehow extracted from the subsoil and injected back into the reservoir to maintain pressure in an oil and gas well.
The engineering center created based on the Krasnoyarsk chemical-metallurgical plant and VIMS developed its own technologies for lithium extraction just during a year, and now they are tested under the laboratory conditions.

By Marcelo Azevedo, Magdalena Baczyńska, Ken Hoffman, and Aleksandra Krauze
Lithium is the driving force behind electric vehicles, but will supply keep pace with demand? New technologies and sources of supply can fill the gap. 
Despite expectations that lithium demand will rise from approximately 500,000 metric tons of lithium carbonate equivalent (LCE) in 2021 to some three million to four million metric tons in 2030, we believe that the lithium industry will be able to provide enough product to supply the burgeoning lithium-ion battery industry. Alongside increasing the conventional lithium supply, which is expected to expand by over 300 percent between 2021 and 2030, direct lithium extraction (DLE) and direct lithium to product (DLP) can be the driving forces behind the industry’s ability to respond more swiftly to soaring demand. Although DLE and DLP technologies are still in their infancy and subject to volatility given the industry’s “hockey stick” 1 demand growth and lead times, they offer significant promise of increasing supply, reducing the industry’s environmental, social, and governance (ESG) footprint, and lowering costs, with already announced capacity contributing to around 10 percent of the 2030 lithium supply, as well as to other less advanced projects in the pipeline.
However, satisfying the demand for lithium will not be a trivial problem. Despite COVID-19’s impact on the automotive sector, electric vehicle (EV) sales grew by around 50 percent in 2020 and doubled to approximately seven million units in 2021. At the same time, surging EV demand has seen lithium prices skyrocket by around 550 percent in a year: by the beginning of March 2022, the lithium carbonate price had passed $75,000 per metric ton and lithium hydroxide prices had exceeded $65,000 per metric ton (compared with a five-year average of around $14,500 per metric ton). 
Lithium is needed to produce virtually all traction batteries currently used in EVs as well as consumer electronics. Lithium-ion (Li-ion) batteries are widely used in many other applications as well, from energy storage to air mobility. As battery content varies based on its active materials mix, and with new battery technologies entering the market, there are many uncertainties around how the battery market will affect future lithium demand. For example, a lithium metal anode, which boosts energy density in batteries, has nearly double the lithium requirements per kilowatt-hour compared with the current widely used mixes incorporating a graphite anode.
So, will there be enough lithium to cover the needs of a new electrified world? As discussed in our recent article, “The raw-materials challenge: How the metals and mining sector will be at the core of enabling the energy transition,” arriving at a considered answer and understanding the entire supply-and-demand context will be crucial for every player along the value chain—mining companies, refiners, battery manufacturers, and automotive OEMs.
Lithium demand factors
Over the next decade, McKinsey forecasts continued growth of Li-ion batteries at an annual compound rate of approximately 30 percent. By 2030, EVs, along with energy-storage systems, e-bikes, electrification of tools, and other battery-intensive applications, could account for 4,000 to 4,500 gigawatt-hours of Li-ion demand.
  
Not long ago, in 2015, less than 30 percent of lithium demand was for batteries; the bulk of demand was split between ceramics and glasses (35 percent) and greases, metallurgical powders, polymers, and other industrial uses (35-plus percent). By 2030, batteries are expected to account for 95 percent of lithium demand, and total needs will grow annually by 25 to 26 percent to reach 3.3 million to 3.8 million metric tons LCE depending on the scenarios outlined in Exhibit 2. 


Reuse and recycle
A frequently asked question is whether L-ion batteries can be recycled. With expected battery lifetimes of around ten to 15 years for passenger vehicles, and the possibility of extending EV battery life through use in the energy-storage sector, battery recycling is expected to increase during the current decade, but not to game-changing levels. Depending on the recycling process employed, it is possible to recover between zero and 80 percent of the lithium contained in end-of-life batteries. By 2030, such secondary supply is expected to account for slightly more than 6 percent of total lithium production (Exhibit 7).",4,5.5,"Summary
This is not a successful case study, unfortunately.

- First and foremost, some style issues can lessen the effect even of an impeccably discussed problem point. Typos and some grammar aspects (e.g., article use, verb agreement, verb forms) can be controlled with some attention even in an exam situation. They can heavily influence your score for the communication competence.
- Keep track of all the information: take notes, for it's better to sort out or merge details while writing than leave out something. In addition to that, always check whether you have touched upon all the topics or formats the instructions require.
- A good introduction should serve as a clear and concise summary of the key points and context of the case study. It should provide readers with an understanding of what the case study is about, who the key players are, and what the main issues or challenges are that the case study will address.
- The conclusion of a case study should summarize the main points of the study and provide a clear statement of the conclusions that can be drawn from the analysis. You can also provide a personal statement of opinion and ideas for the future.
- You should try writing one or two case studies in Practice mode - this way, you can control your time and information management without the pressures of the exam situation. Use a proofreader such as Grammarly.

For time management issues and other practical ideas, please check out our Tips & Tricks menu and our webinars.



Per Competency Score",3.0,"Observations
With this competence, we basically evaluate the style of the case study. Your text should be clear, fluent, written in a professional but still captivating style; of course, spelling and grammar are also covered in this area. Another point we examine here is whether you managed to find the balance between providing details and being concise while conveying the key points of the arguments.",,"Tips to Improve
The text is mostly cohesive and informative, but it is littered with typos and grammatical inaccuracies, to the point that they undermine the readability of the text.","Trainee's Answer
Dear Ferdinand, this is the memo Is make with the hepl of the documentation we have.
MEMO.
1. INTRODUCCTION
The european union has ambitious goals to become climate neutral by 2050, meaning it would be an economy with net-zero greenhouse gas emissions.In fact, recently EU proposed legislation is looking to effectively ban all internal combustion engine cars by 2035. 
In 202x-2 electric car registrations for the year were 1.729.000, 60% up from 2020. 
The administrtion in Brussels has been making ist environmetal and climate rules stricter for decades. the EU wants to make the entire continent carbon neutral by mid century. At the same time, it is etriving to achieve the highest level of protection from pollution in the world. Favourishing electric cars industry is an important point to manage its targets.
 
2. POINTS IN
Despite expectations that litium demand will rise from aproximately 500.000 metric tons of tithium carbonate equivalent (LCE) in 2021, to some 3 or 4 million metric tons in 2030, it is expected that the lithium industry will be able to porvide enough product to supply the burgeoning tithioum-ion battery industry. 
It is important to remark that the possibility of extending Electric vehicle battery life through use in the energy storage sector. Also it is important pay attention that battery recicling is expected to increase during the current decade. Depending on the recycling process employed, it is possible to recover between zero and 80 percent of the lithium contained in the end-life batteries.
 
3. POINTS OUT
The energy transition and the decarbonization of industrial activity and power plants imply massive deployment of renovables, mostly solar and wind farms. However, as they depend on unstable weather conditions, the electric power system requires energy storage, in which the EU counts a lot on batteries.
The EU currently relies heavily on imports of lithium to supply its electric vehicle production sector and the classification of lithium as toxic may increase its reliance on other regions, at a time when the Union is focused on energy security and reducing emissions.
The Eu has  added lithium to a list of critical raw materials as demand is expected to increase dramatically in the coming years. Adding lithium salts to the list of materials hazardous for the health may propt re revision of a range of projets in the industry.
Othe point to study is that lithium reclycling is stills small scale although it it could reach 6 percent of announced supply by 2030.
 
4. PROPOSALS
It is fundamental, to emphasize the economic key point. 
Offering cash money (tax credits) all the steps in the lithium electric car batteries production, for mining battery minerals, refining them, putting together battery cells and for putting together battery packs (or modules), could be essential to reduce the dependence of Asia and America.
Working on the investigation to increase recycling industry related to lithium form used electric car batterys must be actively favourised thought founding mechanismes.
 
5. PRIORITIES OF THE CO-LEGISTATORS
The European Union is working in a very complicated environment. Not only war in Ucrania has obliged to review the economic expectations, but also the increasing prices of imported materials from China, important inputs for european indlustry.
It is important that Co-legislators create new founding squemes to favourise the electric car industry and also the reclycling industry favourising the study of reclycliong process of lithium batteries. It will be a hard work for Science, Environtment and industry Ministrys, which have to work in a same direction, becoming climate neutral by 2050.
 
6. CONCLUSION
There is a lot of work to do but our indicators show that the EU runs in a good way. Our DG needs to work listening the needs of european citizens and Move industries, proposing founds and financial help conditions, managing the industrial deveolepment and the resilience."
3,0_Generative AI (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. 

Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG CONNECT in the unit in charge of fighting against disinformation.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Critical thinking, analysing & creative problem-solving, Decision-making and getting results, Information management,  Communication.

Specifically, your task will be to draft a 2 to 2.5 - page speaking note for the Commisioner to clarify the intentions of the Commission with respect to generative AI (GAI). This document must include: 

What is GAI and what are the potential benefits.
What are the dangers associated with GAI and how does the EU want to address them.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations

AI - Artificial intelligence
AIA – Artificial Intelligence Act
AGI - Artificial general intelligence 
ANI - Artificial narrow intelligence
ANN - Artificial neural network
DSA – Digital Services Act
GAI – Generative AI
ML - Machine learning
NLP - Natural language processing


EMAIL 1","Subject: Press Release on generative AI

Dear YOU,

Earlier today, Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton met with representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation.
Jourová asked the signatories to create a dedicated and separate track within the code to deal with disinformation generated by Artificial Intelligence. It should aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them. 
Jourová will present her initiative at a press point tomorrow at 11:15 a.m. so could you prepare her talking points and send them to me this evening before closing of the office hours. She has asked to stress the importance of the fight against disinformation in the context of defending democracy and the EU values. 

Many thanks",",

Charles
Head of Unit





What are the most pressing dangers of AI?
As AI systems prove to be increasingly beneficial in real-world applications, they have broadened their reach, causing risks of misuse, overuse, and explicit abuse to proliferate. As AI systems increase in capability and as they are integrated more fully into societal infrastructure, the implications of losing meaningful control over them become more concerning. New research efforts are aimed at re-conceptualizing the foundations of the field to make AI systems less reliant on explicit, and easily mis specified, objectives. A particularly visible danger is that AI can make it easier to build machines that can spy and even kill at scale. But there are many other important and subtler dangers at present.
Techno-Solutionism
One of the most pressing dangers of AI is techno-solutionism, the view that AI can be seen as a panacea when it is merely a tool. As we see more AI advances, the temptation to apply AI decision-making to all societal problems increases. But technology often creates larger problems in the process of solving smaller ones. For example, systems that streamline and automate the application of social services can quickly become rigid and deny access to migrants or others who fall between the cracks. 
When given the choice between algorithms and humans, some believe algorithms will always be the less-biased choice. Yet, in 2018, Amazon found it necessary to discard a proprietary recruiting tool because the historical data it was trained on resulted in a system that was systematically biased against women. Automated decision-making can often serve to replicate, exacerbate, and even magnify the same bias we wish it would remedy.
Indeed, far from being a cure-all, technology can actually create feedback loops that worsen discrimination. Recommendation algorithms, like Google’s page rank, are trained to identify and prioritize the most “relevant” items based on how other users engage with them. As biased users feed the algorithm biased information, it responds with more bias, which informs users’ understandings and deepens their bias, and so on. Because all technology is the product of a biased system, techno-solutionism’s flaws run deep: a creation is limited by the limitations of its creator.
Dangers of Adopting a Statistical Perspective on Justice
Automated decision-making may produce skewed results that replicate and amplify existing biases. A potential danger, then, is when the public accepts AI-derived conclusions as certainties. This determinist approach to AI decision-making can have dire implications in both criminal and healthcare settings. AI-driven approaches like PredPol, software originally developed by the Los Angeles Police Department and UCLA that purports to help protect one in 33 US citizens, predict when, where, and how crime will occur. A 2016 case study of a US city noted that the approach disproportionately projected crimes in areas with higher populations of non-white and low-income residents. When datasets disproportionately represent the lower power members of society, flagrant discrimination is a likely result.
Sentencing decisions are increasingly decided by proprietary algorithms that attempt to assess whether a defendant will commit future crimes, leading to concerns that justice is being outsourced to software. As AI becomes increasingly capable of analyzing more and more factors that may correlate with a defendant's perceived risk, courts and society at large may mistake an algorithmic probability for fact. This dangerous reality means that an algorithmic estimate of an individual’s risk to society may be interpreted by others as a near certainty—a misleading outcome even the original tool designers warned against. Even though a statistically driven AI system could be built to report a degree of credence along with every prediction, there’s no guarantee that the people using these predictions will make intelligent use of them. Taking probability for certainty means that the past will always dictate the future.
There is an aura of neutrality and impartiality associated with AI decision-making in some corners of the public consciousness, resulting in systems being accepted as objective even though they may be the result of biased historical decisions or even blatant discrimination. All data insights rely on some measure of interpretation. As a concrete example, an audit of a resume-screening tool found that the two main factors it associated most strongly with positive future job performance were whether the applicant was named Jared, and whether he played high school lacrosse. Undesirable biases can be hidden behind both the opaque nature of the technology used and the use of proxies, nominally innocent attributes that enable a decision that is fundamentally biased. An algorithm fueled by data in which gender, racial, class, and ableist biases are pervasive can effectively reinforce these biases without ever explicitly identifying them in the code. 
Without transparency concerning either the data or the AI algorithms that interpret it, the public may be left in the dark as to how decisions that materially impact their lives are being made. Lacking adequate information to bring a legal claim, people can lose access to both due process and redress when they feel they have been improperly or erroneously judged by AI systems. Large gaps in case law make applying Title VII—the primary existing legal framework in the US for employment discrimination—to cases of algorithmic discrimination incredibly difficult. These concerns are exacerbated by algorithms that go beyond traditional considerations such as a person’s credit score to instead consider any and all variables correlated to the likelihood that they are a safe investment. A statistically significant correlation has been shown among Europeans between loan risk and whether a person uses a Mac or PC and whether they include their name in their email address—which turn out to be proxies for affluence. Companies that use such attributes, even if they do indeed provide improvements in model accuracy, may be breaking the law when these attributes also clearly correlate with a protected class like race. Loss of autonomy can also result from AI-created “information bubbles” that narrowly constrict each individual’s online experience to the point that they are unaware that valid alternative perspectives even exist.
Disinformation and Threat to Democracy
AI systems are being used in the service of disinformation on the internet, giving them the potential to become a threat to democracy and a tool for fascism. From deepfake videos to online bots manipulating public discourse by feigning consensus and spreading fake news, there is the danger of AI systems undermining social trust. The technology can be co-opted by criminals, rogue states, ideological extremists, or simply special interest groups, to manipulate people for economic gain or political advantage. Disinformation poses serious threats to society, as it effectively changes and manipulates evidence to create social feedback loops that undermine any sense of objective truth. The debates about what is real quickly evolve into debates about who gets to decide what is real, resulting in renegotiations of power structures that often serve entrenched interests. 
Discrimination and Risk in the Medical Setting
While personalized medicine is a good potential application of AI, there are dangers. Current business models for AI-based health applications tend to focus on building a single system—for example, a deterioration predictor—that can be sold to many buyers. However, these systems often do not generalize beyond their training data. Even differences in how clinical tests are ordered can throw off predictors, and, over time, a system’s accuracy will often degrade as practices change. Clinicians and administrators are not well-equipped to monitor and manage these issues, and insufficient thought given to the human factors of AI integration has led to oscillation between mistrust of the system (ignoring it) and over-reliance on the system (trusting it even when it is wrong), a central concern of the 2016 AI100 report.
These concerns are troubling in general in the high-risk setting that is healthcare, and even more so because marginalized populations—those that already face discrimination from the health system from both structural factors (like lack of access) and scientific factors (like guidelines that were developed from trials on other populations)—may lose even more. Today and in the near future, AI systems built on machine learning are used to determine post-operative personalized pain management plans for some patients and in others to predict the likelihood that an individual will develop breast cancer. AI algorithms are playing a role in decisions concerning distributing organs, vaccines, and other elements of healthcare. Biases in these approaches can have literal life-and-death stakes.
In 2019, the story broke that Optum, a health-services algorithm used to determine which patients may benefit from extra medical care, exhibited fundamental racial biases. The system designers ensured that race was precluded from consideration, but they also asked the algorithm to consider the future cost of a patient to the healthcare system. While intended to capture a sense of medical severity, this feature in fact served as a proxy for race: controlling for medical needs, care for Black patients averages $1,800 less per year.
New technologies are being developed every day to treat serious medical issues. A new algorithm trained to identify melanomas was shown to be more accurate than doctors in a recent study, but the potential for the algorithm to be biased against Black patients is significant as the algorithm was trained using majority light-skinned groups. The stakes are especially high for melanoma diagnoses, where the five-year survival rate is 17 percentage points less for Black Americans than white. While technology has the potential to generate quicker diagnoses and thus close this survival gap, a machine-learning algorithm is only as good as its data set. An improperly trained algorithm could do more harm than good for patients at risk, missing cancers altogether or generating false positives. As new algorithms saturate the market with promises of medical miracles, losing sight of the biases ingrained in their outcomes could contribute to a loss of human biodiversity, as individuals who are left out of initial data sets are denied adequate care. While the exact long-term effects of algorithms in healthcare are unknown, their potential for bias replication means any advancement they produce for the population in aggregate—from diagnosis to resource distribution—may come at the expense of the most vulnerable.








Regulatory framework proposal on artificial intelligence 
The Commission is proposing the first-ever legal framework on AI, which addresses the risks of AI and positions Europe to play a leading role globally. 

© gorodenkoff - iStock Getty Images Plus
The regulatory proposal aims to provide AI developers, deployers and users with clear requirements and obligations regarding specific uses of AI. At the same time, the proposal seeks to reduce administrative and financial burdens for business, in particular small and medium-sized enterprises (SMEs).
The proposal is part of a wider AI package, which also includes the updated Coordinated Plan on AI. Together, the Regulatory framework and Coordinated Plan will guarantee the safety and fundamental rights of people and businesses when it comes to AI. And they will strengthen uptake, investment and innovation in AI across the EU.
Why do we need rules on AI?
The proposed AI regulation ensures that Europeans can trust what AI has to offer. While most AI systems pose limited to no risk and can contribute to solving many societal challenges, certain AI systems create risks that we must address to avoid undesirable outcomes.
For example, it is often not possible to find out why an AI system has made a decision or prediction and taken a particular action. So, it may become difficult to assess whether someone has been unfairly disadvantaged, such as in a hiring decision or in an application for a public benefit scheme.
Although existing legislation provides some protection, it is insufficient to address the specific challenges AI systems may bring.
The proposed rules will:
address risks specifically created by AI applications.
propose a list of high-risk applications.
set clear requirements for AI systems for high-risk applications.
define specific obligations for AI users and providers of high-risk applications.
propose a conformity assessment before the AI system is put into service or placed on the market.
propose enforcement after such an AI system is placed in the market.
propose a governance structure at European and national level.
A risk-based approach

The Regulatory Framework defines 4 levels of risk in AI:
Unacceptable risk
High risk
Limited risk
Minimal or no risk
Unacceptable risk
All AI systems considered a clear threat to the safety, livelihoods and rights of people will be banned, from social scoring by governments to toys using voice assistance that encourages dangerous behaviour.
High risk
AI systems identified as high-risk include AI technology used in:
critical infrastructures (e.g., transport), that could put the life and health of citizens at risk.
educational or vocational training, that may determine the access to education and professional course of someone’s life (e.g., scoring of exams).
safety components of products (e.g., AI application in robot-assisted surgery).
employment, management of workers and access to self-employment (e.g., CV-sorting software for recruitment procedures).
essential private and public services (e.g., credit scoring denying citizens opportunity to obtain a loan).
law enforcement that may interfere with people’s fundamental rights (e.g., evaluation of the reliability of evidence).
migration, asylum, and border control management (e.g., verification of authenticity of travel documents).
administration of justice and democratic processes (e.g., applying the law to a concrete set of facts).
High-risk AI systems will be subject to strict obligations before they can be put on the market:
adequate risk assessment and mitigation systems.
high quality of the datasets feeding the system to minimize risks and discriminatory outcomes.
logging of activity to ensure traceability of results.
detailed documentation providing all information necessary on the system and its purpose for authorities to assess its compliance.
clear and adequate information to the user.
appropriate human oversight measures to minimize risk.
high level of robustness, security and accuracy.
All remote biometric identification systems are considered high risk and subject to strict requirements. The use of remote biometric identification in publicly accessible spaces for law enforcement purposes is, in principle, prohibited.
Narrow exceptions are strictly defined and regulated, such as such as when necessary to search for a missing child, to prevent a specific and imminent terrorist threat or to detect, locate, identify, or prosecute a perpetrator or suspect of a serious criminal offence.
Such use is subject to authorization by a judicial or other independent body and to appropriate limits in time, geographic reach and the data bases searched.
Limited risk
Limited risk refers to AI systems with specific transparency obligations. When using AI systems such as chatbots, users should be aware that they are interacting with a machine so they can take an informed decision to continue or step back.
Minimal or no risk
The proposal allows the free use of minimal-risk AI. This includes applications such as AI-enabled video games or spam filters. Most AI systems currently used in the EU fall into this category.



How does it all work in practice for providers of high-risk AI systems?
Once an AI system is on the market, authorities oversee market surveillance, users ensure human oversight and monitoring, and providers have a post-market monitoring system in place. Providers and users will also report serious incidents and malfunctioning.
Future-proof legislation
As AI is a fast-evolving technology, the proposal has a future-proof approach, allowing rules to adapt to technological change. AI applications should remain trustworthy even after they have been placed on the market. This requires ongoing quality and risk management by providers.




The 5 biggest risks of generative AI, according to an expert 
AI makes our lives easier in many different ways. However, these benefits can come with costs. 



Written by Sabrina Ortiz, Associate Editor on April 25, 20XX

Generative AIs, such as ChatGPT, have revolutionized how we interact with and view AI. Activities like writing, coding, and applying for jobs have become much easier and quicker. With all the positives, however, there are some pretty serious risks.
A major concern with AI is trust and security, which has even caused some countries to completely ban ChatGPT as a whole or to reconsider policy around AI to protect users from harm. 
According to Gartner analyst Avivah Litan, some of the biggest risks of generative AI concern trust and security and include hallucinations, deepfakes, data privacy, copyright issues, and cybersecurity problems.
1. Hallucinations
Hallucinations refer to the errors that AI models are prone to make because, although they are advanced, they are still not human and rely on training and data to provide answers. 
If you've used an AI chatbot, then you have probably experienced these hallucinations through a misunderstanding of your prompt or a blatantly wrong answer to your question.
Litan says the training data can lead to biased or factually incorrect responses, which can be a serious problem when people are relying on these bots for information. 
""Training data can lead to biased, off base or wrong responses, but these can be difficult to spot, particularly as solutions are increasingly believable and relied upon,"" says Litan. 
2. Deepfakes
A deepfake uses generative AI to create videos, photos, and voice recordings that are fake but take the image and likeness of another individual. 
Perfect examples are the AI-generated viral photo of Pope Francis in a puffer jacket or the AI-generated Drake and the Weeknd song, which garnered hundreds of thousands of streams. 
""These fake images, videos and voice recordings have been used to attack celebrities and politicians, to create and spread misleading information, and even to create fake accounts or take over and break into existing legitimate accounts,"" says Litan. 
Like hallucinations, deepfakes can contribute to the massive spread of fake content, leading to the spread of misinformation, which is a serious societal problem. 
3. Data privacy
Privacy is also a major concern with generative AI since user data is often stored for model training. This concern was the overarching factor that pushed Italy to ban ChatGPT, claiming OpenAI was not legally authorized to gather user data. 
""Employees can easily expose sensitive and proprietary enterprise data when interacting with generative AI chatbot solutions,"" says Litan. ""These applications may indefinitely store information captured through user inputs, and even use information to train other models -- further compromising confidentiality.""
Litan highlights that, in addition to compromising user confidentiality, the stored information also poses the risk of ""falling into the wrong hands"" in an instance of a security breach.
4. Cybersecurity
The advanced capabilities of generative AI models, such as coding, can also fall into the wrong hands, causing cybersecurity concerns.
""In addition to more advanced social engineering and phishing threats, attackers could use these tools for easier malicious code generation,"" says Litan. 
Litan says even though vendors who offer generative AI solutions typically assure customers that their models are trained to reject malicious cybersecurity requests, these suppliers don't equip end users with the ability to verify all the security measures that have been implemented. 
5. Copyright issues
Copyright is a big concern because generative AI models are trained on massive amounts of internet data that is used to generate an output. 
This process of training means that works that have not been explicitly shared by the original source can then be used to generate new content. 
Copyright is a particularly thorny issue for AI-generated art of any form, including photos and music. 
To create an image from a prompt, AI-generating tools, such as DALL-E, will refer back to the large database of photos they were trained on. The result of this process is that the final product might include aspects of an artist's work or style that are not attributed to them. 
Since the exact works that generative AI models are trained on are not explicitly disclosed, it is hard to mitigate these copyright issues. 
What's next?
Despite the many risks associated to generative AI, Litan doesn't think that organizations should stop exploring the technology. Instead, they should create an enterprise-wide strategy that targets AI trust, risk, and security management. 
""AI developers must urgently work with policymakers, including new regulatory authorities that may emerge, to establish policies and practices for generative AI oversight and risk management,"" says Litan. 
 

What is generative AI?
In simple terms, generative AI is a subfield of artificial intelligence in which computer algorithms are used to generate outputs that resemble human-created content, be it text, images, graphics, music, computer code or otherwise.
In generative AI, algorithms are designed to learn from training data that includes examples of the desired output. By analyzing the patterns and structures within the training data, generative AI models can produce new content that shares characteristics with the original input data. In doing so, generative AI has the capacity to generate content that appears authentic and human-like.
How does generative AI work?
Generative AI is based on machine learning processes inspired by the inner workings of the human brain, known as neural networks. Training the model involves feeding algorithms large amounts of data, which serves as the foundation for the AI model to learn from. This can consist of text, code, graphics, or any other type of content relevant to the task at hand.
Once the training data has been collected, the AI model analyzes the patterns and relationships within the data to understand the underlying rules governing the content. The AI model continuously fine-tunes its parameters as it learns, improving its ability to simulate human-generated content. The more content the AI model generates, the more sophisticated and convincing its outputs become.
Examples of generative AI
Generative AI has made significant advancements in recent years, with several tools capturing the public attention and creating a stir amongst content creators. Big tech companies have also jumped on the bandwagon, with Google, Microsoft, Amazon, and others all lining up their own generative AI tools.
Depending on the application, generative AI tools may rely on an input prompt that guides it towards producing a desired outcome — think ChatGPT and DALL-E 2.
Some of the most notable examples of generative AI tools include:
ChatGPT: Developed by OpenAI, ChatGPT is an AI language model that can generate human-like text based on given prompts.
DALL-E 2: Another generative AI model from OpenAI, DALL-E is designed to create images and artwork based on text-based prompts.
Midjourney: Developed by San Francisco-based research lab Midjourney Inc., Midjourney interprets text prompts and context to produce visual content, like DALL-E 2.
GitHub Copilot: An AI-powered coding tool created by GitHub and OpenAI, GitHub Copilot suggests code completions for users of development environments like Visual Studio and JetBrains.
Benefits of generative AI
The most compelling advantage generative AI proposes is efficiency, in that it can enable businesses to automate specific tasks and focus their time, energy and resources on more important strategic objectives. This often results in lower labor costs and an increase in operational efficiency.
Generative AI can offer additional advantages to businesses and entrepreneurs, including:
Easily customizing or personalizing marketing content.
Generating new ideas, designs, or content.
Writing, checking, and optimizing computer code.
Drafting templates for essays or articles.
Enhancing customer support with chatbots and virtual assistants.
Facilitating data augmentation for machine learning models.
Analyzing data to improve decision-making.
Streamlining research and development processes.
Use cases of generative AI
Despite generative AI still being in its relative infancy, the technology has already found a firm foothold in various applications and industries.
In content creation, for instance, generative AI can produce text, images and even music, assisting marketers, journalists, and artists with their creative processes. In customer support, AI-driven chatbots and virtual assistants can provide more personalized assistance and reduce response times while reducing the burden on customer service agents.
Other uses of generative AI include:
Healthcare: Generative AI is used in medicine to accelerate the discovery of novel drugs, saving time and money in research.
Marketing: Advertisers use generative AI to craft personalized campaigns and adapt content to consumers’ preferences.
Education: Some educators use generative AI models to develop customized learning materials and assessments that cater to students’ individual learning styles.
Finance: Financial analysts use generative AI to examine market patterns and predict stock market trends.
Environment: Climate scientists employ generative AI models to predict weather patterns and simulate the effects of climate change.
Dangers and limitations of generative AI
It’s important to note that generative AI presents numerous issues requiring attention. One major concern is its potential for spreading misinformation or malicious or sensitive content, which could cause profound damage to people and businesses — and potentially pose a threat to national security.
These risks have not escaped policymakers. In April 20XX, the European Union proposed new copyright rules for generative AI that would require companies to disclose any copyrighted material used to develop these tools. Hopes are that such rules will encourage transparency and ethics in AI development, while minimizing any misuse or infringement of intellectual property. This should also offer some protection to content creators whose work may be unwittingly mimicked or plagiarized by generative AI tools.
The automation of tasks by generative AI could also affect the workforce and contribute to job displacement, requiring impacted employees to reskill or upskill. Additionally, generative AI models can unintentionally learn and amplify biases present in training data, leading to problematic outputs that perpetuate stereotypes and harmful ideologies.
ChatGPT, Bing AI and Google Bard have all drawn controversy for producing incorrect or harmful outputs since their launch, and these concerns must be addressed as generative AI evolves, particularly given the difficulty of scrutinizing the sources used to train AI models.
Generative AI vs. general AI
Generative AI and general AI represent different aspects of artificial intelligence. Generative AI focuses on creating new content or ideas based on existing data. It has specific applications and is a subset of AI that excels at solving particular tasks.
General AI, also known as artificial general intelligence, broadly refers to the concept of AI systems that possess human-like intelligence. General AI is still the stuff of science fiction; it represents an imagined future stage of AI development in which computers are able to think, reason and act autonomously.
Is generative AI the future?
It depends on who you ask, but many experts believe that generative AI has a significant role to play in the future of various industries. The capabilities of generative AI have already proven valuable in areas like content creation, software development and healthcare, and as the technology continues to evolve, so too will its applications and use cases.
That said, the future of generative AI is inextricably tied to addressing the potential risks it presents. Ensuring AI is used ethically by minimizing biases, enhancing transparency and accountability and upholding data governance will be critical as the technology progresses. At the same time, striking a balance between automation and human involvement will be crucial for maximizing the benefits of generative AI while mitigating any potential negative consequences on the workforce.






STOCKHOLM, April 27 (Reuters) - Companies deploying generative AI tools, such as ChatGPT, will have to disclose any copyrighted material used to develop their systems, according to an early EU agreement that could pave the way for the world's first comprehensive laws governing the technology.
The European Commission began drafting the AI Act nearly two years ago to regulate emerging artificial intelligence technology, which underwent a boom in investment and popularity following the release of OpenAI's AI-powered chatbot ChatGPT.
Members of the European Parliament agreed to push the draft through to the next stage, the trilogue, during which EU lawmakers and member states will thrash out the final details of the bill.
Under the proposals, AI tools will be classified according to their perceived risk level: from minimal through to limited, high, and unacceptable. Areas of concern could include biometric surveillance, spreading misinformation or discriminatory language.
While high-risk tools will not be banned, those using them will need to be highly transparent in their operations.
Companies deploying generative AI tools, such as ChatGPT or image generator Midjourney, will also have to disclose any copyrighted material used to develop their systems.
This provision was a late addition drawn up within the past two weeks, according to a source familiar with discussions. Some committee members initially proposed banning copyrighted material being used to train generative AI models altogether, the source said, but this was abandoned in favour of a transparency requirement.
""Against conservative wishes for more surveillance and leftist fantasies of over-regulation, parliament found a solid compromise that would regulate AI proportionately, protect citizens' rights, as well as foster innovation and boost the economy,"" said Svenja Hahn, a European Parliament deputy.
Macquarie analyst Fred Havemeyer said the EU's proposal was ""tactful"" rather than a ""ban first, and ask questions later"" approach proposed by some.
""The EU has been on the frontier of regulating AI technology,"" he told Reuters.
RACE TO MARKET
Microsoft-backed (MSFT.O) OpenAI provoked awe and anxiety around the world when it unveiled ChatGPT late last year. The chatbot became the fastest-growing consumer application in history, reaching 100 million monthly active users in a matter of weeks.
The ensuing race among tech companies to bring generative AI products to market concerned some onlookers, with Twitter-owner Elon Musk backing a proposal to halt development of such systems for six months. Shortly after signing the letter, the Financial Times reported Musk was planning to launch his own startup to rival OpenAI.


Sharon Goldman
@sharongoldman

December 5, 20XX-1

The hidden danger of ChatGPT and generative AI | The AI Beat
Since OpenAI launched its early demo of ChatGPT last Wednesday, the tool already has over a million users, according to CEO Sam Altman — a milestone, he points out, that took GPT-3 nearly 24 months to get to and DALL-E over 2 months. 
The “interactive, conversational model,” based on the company’s GPT-3.5 text-generator, certainly has the tech world in full swoon mode. Aaron Levie, CEO of Box, tweeted that “ChatGPT is one of those rare moments in technology where you see a glimmer of how everything is going to be different going forward.” Y Combinator cofounder Paul Graham tweeted that “clearly something big is happening.” Alberto Romero, author of The Algorithmic Bridge, calls it “by far, the best chatbot in the world.” And even Elon Musk weighed in, tweeting that ChatGPT is “scary good. We are not far from dangerously strong AI.” 
But there is a hidden problem lurking within ChatGPT: That is, it quickly spits out eloquent, confident responses that often sound plausible and true even if they are not. 
ChatGPT can sound plausible even if its output is false.
Like other generative large language models, ChatGPT makes up facts. Some call it “hallucination” or “stochastic parroting,” but these models are trained to predict the next word for a given input, not whether a fact is correct or not. 
Some have noted that what sets ChatGPT apart is that it is so darn good at making its hallucinations sound reasonable. 
Technology analyst Benedict Evans, for example, asked ChatGPT to “write a bio for Benedict Evans.” The result, he tweeted, was “plausible, almost entirely untrue.” 
More troubling is the fact that there are obviously an untold number of queries where the user would only know if the answer was untrue if they already knew the answer to the posed question. 
That’s what Arvind Narayanan, a computer science professor at Princeton, pointed out in a tweet: “People are excited about using ChatGPT for learning. It’s often very good. But the danger is that you can’t tell when it’s wrong unless you already know the answer. I tried some basic information security questions. In most cases the answers sounded plausible but were in fact BS.” 
Fact-checking generative AI
Back in the waning days of print magazines in the 2000s, I spent several years as a fact-checker for publications including GQ and Rolling Stone. Each fact had to include authoritative primary or secondary sources — and Wikipedia was frowned upon. 
Few publications have staff fact-checkers anymore, which puts the onus on reporters and editors to make sure they get their facts straight — especially at a time when misinformation already moves like lightning across social media, while search engines are constantly under pressure to surface verifiable information and not BS. 
That’s certainly why Stack Overflow, the Q&A site for coders and programmers, has temporarily banned users from sharing ChatGPT responses. 
And if StackOverflow can’t keep up with misinformation due to AI, it’s hard to imagine others being able to manage a tsunami of potential AI-driven BS. As Gary Marcus tweeted, “If StackOverflow can’t keep up with plausible but incorrect information, what about social media and search engines?” 
And while many are salivating at the idea that LLMs like ChatGPT could someday replace traditional search engines, others are strongly pushing back. 
Emily Bender, professor of linguistics at the University of Washington, has long pushed back on this notion. 
She recently emphasized again that LLMs are “not fit” for search —” both because they are designed to just make sh** up and because they don’t support information literacy.” She pointed to a paper she co-authored on the topic published in March. 
Is it better for ChatGPT to look right? Or be right? 
BS is obviously something that humans have perfected over the centuries. And ChatGPT and other large language models have no idea what it means, really, to “BS.” But OpenAI made this weakness very clear in its blog announcing the demo and explained that fixing it is “challenging,” saying: 
“ChatGPT sometimes writes plausible sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: (1) during RL [reinforcement learning] training, there’s currently no source of truth; (2) training the model to be more cautious causes it to decline questions that it can answer correctly; and (3) supervised training misleads the model because the ideal answer depends on what the model knows, rather than what the human demonstrator knows.” 
So, it’s clear that OpenAI knows perfectly well that ChatGPT is filled with BS under the surface. They never meant the technology to offer up a source of truth. 
But the question is: Are human users okay with that? 
Unfortunately, they might be. If it sounds good, many humans may think that’s good enough. And, perhaps, that’s where the real danger lies beneath the surface of ChatGPT. 





By JAKOB HANKE VELA
Send tips here | Tweet @HankeVela | Listen to Playbook and view in your browser
LABELING AI CONTENT        
TODAY: EU PUSHES FOR ‘AI LABEL’ TO FIGHT DEEPFAKES: Brussels wants to prevent artificial intelligence from blurring the lines between fact and fiction — and will today ask companies for the first time ever to come up with a label to identify AI-generated texts and images to fight disinformation, officials tell Playbook.
Brave new world: Generative AI is making breathtaking advances — from writing texts and code to creating ever more realistic pictures and videos — which will have enormous consequences not just for the future of society and work, but for politics, Commission officials reckon. 
Balenc-ai-ga: The fake images of the Pope and famous politicians wearing a Balenciaga coat that went viral earlier this year have clearly spooked them — and they now want to label such deepfakes.
Fake porn: “Today it is mostly still a game, but tomorrow you could see a fake porn with a candidate,” one official who is working on the file but was not authorized to speak on the record told Playbook, referring to AI-generated images of politicians. 
Race to regulate: The Commission (the EU’s executive, which proposes and enforces laws) — has proposed an AI Act to regulate high-risk applications and ban the most dangerous ones. But even before that act enters into force, the Commission will urge industry to cut down on trickery by labeling AI-generated work.
Happening today: Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton will meet representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation. They include Microsoft, Google, Meta, TikTok, Twitch and smaller companies — but not Twitter, which has left the code — as well as NGOs.
Disinformation risks: “I will ask the signatories to create a dedicated and separate track within the code” to deal with disinformation generated by Artificial Intelligence, Jourová told Playbook. “It should … aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them.”
EU pushes for safeguards: How does Brussels want the companies to tackle the risks? “Signatories who integrate generative AI into their services like Bingchat for Microsoft, Bard for Google should build in necessary safeguards that these services cannot be used by malicious actors to generate disinformation,” Jourová said.
Clear labels: “Signatories who have services with a potential to disseminate AI-generated disinformation should in turn put in place technology to recognize such content and clearly label this to users.”
More about this label: Two officials working on the file told Playbook the label should apply to all AI-generated material that can be used to create disinformation, including text, images, audio and video.
Voluntary — for now: It wouldn’t be mandatory, given that it would be part of the voluntary Code of Practice. However, the Commission aims to make the code enforceable by including it as a code of conduct in the Digital Services Act (DSA). Obligations on labeling AI content may also make it into the AI Act during negotiations between EU countries, Parliament, and the Commission, one official said.
How can companies do this? “They can develop, and they probably already have tools to check whether an image was AI-generated or not,” the first official said.
Playbook wonders: Given how easy it is for AI to proliferate across jurisdictions, will such a technology ever be able to identify all deepfakes — or won’t we, on the contrary, one day need some chain of custody procedure for authentic images that can be used, for example, as evidence in court?
Stay tuned: Jourová will present her initiative at a press point tomorrow at 11:15 a.m.
SPEAKING OF WHICH: While the Commission is calling on others to do more, it was recently reported that it awarded and signed a €3.7 million tender to help analyze issues like disinformation, foreign meddling in elections and global threats from a French firm that’s mired in controversy.
Avisa Partners has previously been accused of manipulating information in France and working for authoritarian regimes. The company was recently at the center of a controversy as the organizer of a cybersecurity forum boycotted by the French armed forces ministry and several government officials. More here for our Pro Cybersecurity subscribers.
Looking into this: The Commission is looking into the allegations and “is in contact with French counterparts to seek more clarity on those claim[s],” Peter Stano, the Commission’s spokesperson for foreign affairs and security policy, told my POLITICO Pro Technology colleagues. The EU executive is “closely monitoring the implementation of this project,” he added. 
Jean Tillinac, from Avisa Partners, told my Pro Tech colleagues that the bid was “defended by a team of seasoned experts from our Strategic Intelligence Division” doing research and which was different from the “Digital Communications Division” facing criticism.



Annex I – Glossary of Terms
Algorithm: a formula given to a computer for it to complete a task (i.e., a set of rules for a computer) 
Artificial intelligence: a subset of computer science that deals with computer systems performing tasks with similar, equal, or superior intelligence to that of a human (e.g., decision-making, object classification and detection, speech recognition and translation)
Artificial general intelligence (AGI): also known as strong AI, AGI is a type of artificial intelligence that is considered human-like, and still in its preliminary stages (more of a hypothetical existence in present day)
Artificial narrow intelligence (ANI): also known as weak AI, ANI is a type of artificial intelligence that can only focus on one task or problem at a given time (e.g., playing a game against a human competitor). This is the current existing form of AI.
Artificial neural network (ANN): a network modeled after the human brain by creating an artificial neural system via a pattern-recognizing computer algorithm that learns from, interprets, and classifies sensory data.
Big data: large amounts of structured and unstructured data that is too complex to be handled by standard data-processing software.
Chatbots: a chat robot that can converse with a human user through text or voice commands. Utilized by e-commerce, education, health, and business industries for ease of communication and to answer user questions. 
Cognitive computing: computerized model that mimics human thought processes by data mining, NLP, and pattern recognition.
Computer vision: when a machine processes visual input from image files (JPEGs) or camera feeds
Data mining: the process of sorting through large sets of data to identify recurring patterns while establishing problem-solving relationships.
Deep learning: a machine learning technique that teaches computers how to learn by rote (i.e., machines mimic learning as a human mind would, by using classification techniques)
Generative AI: Generative artificial intelligence or generative AI is a type of artificial intelligence (AI) system capable of generating text, images, or other media in response to prompts. Generative AI models learn the patterns and structure of their input training data, and then generate new data that has similar characteristics. 
Genetic algorithm: an algorithm based on principles of genetics that is used to find solutions efficiently and quickly to difficult problems.
Machine learning (ML): focuses on developing programs that access and use data on their own, leading machines to learn for themselves and improve from learned experiences.
Natural language processing (NLP): helps computers process, interpret, and analyze human language and its characteristics by using natural language data. 
Pattern recognition: automated recognition of patterns found in data.
Reinforcement learning: a machine learning method where the reinforcement algorithm learns by interacting with its environment and is then penalized or rewarded based on decisions it makes.
Strong AI: see artificial general intelligence (AGI)  
Structured data: clearly defined data with easily searchable patterns.
Supervised learning: a type of machine learning where output datasets teach machines to generate desired outcomes or algorithms (akin to a teacher-student relationship).
Transfer learning: a system that uses previously learned data and applies it to a new set of tasks.
Turing Test: a test created by computer scientist Alan Turing (1950) to see if machines could exhibit intelligence equal to or indistinguishable from that of a human.
Unstructured data: data without easily searchable patterns (e.g., audio, video, social media content)
Unsupervised learning: a type of machine learning where an algorithm is trained with information that is neither classified nor labeled, thus allowing the algorithm to act without guidance.",16,8.0,"Summary

The candidate shows strong skill in writing in a clear and concise style and at a professional level appropriate to the task. Key information is conveyed clearly and fluently and a good balance is struck in presenting detail. 
Perhaps a rethink of the structure would be beneficial to create even more clarity in the document and eas of use.
Some typos and grammatical issues.


Per Competency Score",8.0,"Observations

The writing style is of a strong standard. The candidate has made a good effort to write in a compelling way to capture audience attention and convey information in a way that is appropriate for a press release.  

The key information is pinpointed and presented concisely. 

The only quibble I have is that it may have been more useful to incorporate the background section into the speaking points in a similarly succinct and catchy way. 

As it stands, there’s a sense that the document has not quite been finished. 

The legal framework on AI, the background as well as the proposals to classify AI tools according to their perceived risk level from minimal through to limited, high and unacceptable could have been mentioned in a little more detail. 

A brief conclusion to round the speaking points off should also have been included.
E.g.:
“Allow me to conclude this brief presentation now.
Generative AI has the potential for spreading disinformation or malicious content.
This poses a threat to our democratic society.
The EU is on the frontier of regulating AI technology and is now moving ahead to regulate generative AI.”",,"Tips to Improve

Ensure you have enough time to edit for typos and grammar mistakes.","Trainee's Answer
SCENE SETTER
The speech aims to inform the press about the Commission initiative in cooperation with 40 organizations that have signed up to the EU Code of Practice against disinformation to create a dedicated section in the Code to deal with disinformation generated by artificial intelligence (AI). 
 
SPEAKING POINTS
Artificial intelligence (AI) has become an integral part of our daily lives. It can be used to create enormous benefits, create solutions to problems that could not be resolved before, help us by making our lives more convenient. It can be used for entertainment to pass time and have fun. However, AI can also be used to create harm. 
One of the main threats by AI tools that can generate text, photos, videos is disinformation. Fake information that can be polished to level that differentiating it from the truth becomes difficult even to the professionals. Disinformation at the hands of extremists, criminals, some special groups can manipulate the people to create distrust, uncertainties, support for illegal activities undermining cohesion and inclusion of our societies. 
The Commission has taken a number of steps to address various aspects of the use of artificial intelligence. The European Commission proposed in 20XX the first in the world legislative measure the AI Act to provide AI developers, deployers and users with clear requirements based on specific uses of AI. At the core of the new legal framework currently discussed by the co-legislators is to guarantee the safety and fundamental rights of people and businesses when it comes to AI.  
We have recently also proposed the new copyright rules for generative AI to protect the intellectual property rights of the authors whose content has been used in developing GAI tools and to provide for  increased transparency and ethics in relation to AI.
As the most recent initiative, i would like to announce today the cooperative effort between the EU and 40 organisations that have signed up to the EU Code of Practice against disinformation. With the support from these partners, we will create a designated section in the Code on specific disinformation risks presented by generative AI and appropriate measures to address them. 
We aim at companies working together with us to take necessary safeguards that these services cannot be used to generate malicious disinformation. For example, the content that is created with generative AI must be labeled as such. 
AI, and specifically generative AI are novel developments. We must support the need to innovate, to develop new technical tools to improve our lives. At the same time, we need to be aware of the risks in relation to these new developments and be properly equipped to address these novel risks in sufficient and timely manner. 
I firmly believe that only in close cooperation between the EU, Member States authorities and partners from private sector and civil society we will find this careful balance that would benefit the EU, our values and way of life. 
 
BACKGROUND
Description
Generative artificial intelligence (GAI) is a sub-field of AI in which algorithms are used to generate new outputs that resemble human-created content, e.g. text, images, music, videos, coputer code, etc based on existing available data. GAI uses machine learning to assess the training materials and patterns, links therein. GAI is constantly improving by self-learning and as a result, the level of quality (similarity to human-created content) increases over time and use. Currently, there exists a number of widely used GAIs, for example ChatGPT to create text on any topic, Midjourney to create images based on textual input.     
Benefits
GAI can be made use of in various domains. The more basic use-cases can range from content creation, for example generating ideas, designs, draft essays or articles, to freeing human resources from standard workflows, e.g. by using GAI as virtual assistants or chat bots to reply to clients' frequently asked questions. GAI can also speed up research in medical sector (testing of novel medicines), finance (detecting patterns and predict trends), climate (stimulation and prediction of weather and climate patterns). 
Dangers
The use of GAI is associated with a number of negative issues that require close attention:
1. Misinformation or malicious/sensitive content
2. Copyright issues - misuse and infringement of intellectual property. 
3. Cybersecurity - attackers can use GAI for easier malicious code generation
4. Social impact - the automation of tasks by GAI can affect workforce requiring impacted emlpoyees to reskil lor upskill.
 
EU action
1. The Commission proposal for the AI Act
2. Proposal on new rules on copyright - requiring companies deploying generative AI tools to disclose any copyrighted material used to develop their systems."
3,0_Generative AI (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. 

Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG CONNECT in the unit in charge of fighting against disinformation.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Critical thinking, analysing & creative problem-solving, Decision-making and getting results, Information management,  Communication.

Specifically, your task will be to draft a 2 to 2.5 - page speaking note for the Commisioner to clarify the intentions of the Commission with respect to generative AI (GAI). This document must include: 

What is GAI and what are the potential benefits.
What are the dangers associated with GAI and how does the EU want to address them.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations

AI - Artificial intelligence
AIA – Artificial Intelligence Act
AGI - Artificial general intelligence 
ANI - Artificial narrow intelligence
ANN - Artificial neural network
DSA – Digital Services Act
GAI – Generative AI
ML - Machine learning
NLP - Natural language processing


EMAIL 1","Subject: Press Release on generative AI

Dear YOU,

Earlier today, Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton met with representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation.
Jourová asked the signatories to create a dedicated and separate track within the code to deal with disinformation generated by Artificial Intelligence. It should aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them. 
Jourová will present her initiative at a press point tomorrow at 11:15 a.m. so could you prepare her talking points and send them to me this evening before closing of the office hours. She has asked to stress the importance of the fight against disinformation in the context of defending democracy and the EU values. 

Many thanks",",

Charles
Head of Unit





What are the most pressing dangers of AI?
As AI systems prove to be increasingly beneficial in real-world applications, they have broadened their reach, causing risks of misuse, overuse, and explicit abuse to proliferate. As AI systems increase in capability and as they are integrated more fully into societal infrastructure, the implications of losing meaningful control over them become more concerning. New research efforts are aimed at re-conceptualizing the foundations of the field to make AI systems less reliant on explicit, and easily mis specified, objectives. A particularly visible danger is that AI can make it easier to build machines that can spy and even kill at scale. But there are many other important and subtler dangers at present.
Techno-Solutionism
One of the most pressing dangers of AI is techno-solutionism, the view that AI can be seen as a panacea when it is merely a tool. As we see more AI advances, the temptation to apply AI decision-making to all societal problems increases. But technology often creates larger problems in the process of solving smaller ones. For example, systems that streamline and automate the application of social services can quickly become rigid and deny access to migrants or others who fall between the cracks. 
When given the choice between algorithms and humans, some believe algorithms will always be the less-biased choice. Yet, in 2018, Amazon found it necessary to discard a proprietary recruiting tool because the historical data it was trained on resulted in a system that was systematically biased against women. Automated decision-making can often serve to replicate, exacerbate, and even magnify the same bias we wish it would remedy.
Indeed, far from being a cure-all, technology can actually create feedback loops that worsen discrimination. Recommendation algorithms, like Google’s page rank, are trained to identify and prioritize the most “relevant” items based on how other users engage with them. As biased users feed the algorithm biased information, it responds with more bias, which informs users’ understandings and deepens their bias, and so on. Because all technology is the product of a biased system, techno-solutionism’s flaws run deep: a creation is limited by the limitations of its creator.
Dangers of Adopting a Statistical Perspective on Justice
Automated decision-making may produce skewed results that replicate and amplify existing biases. A potential danger, then, is when the public accepts AI-derived conclusions as certainties. This determinist approach to AI decision-making can have dire implications in both criminal and healthcare settings. AI-driven approaches like PredPol, software originally developed by the Los Angeles Police Department and UCLA that purports to help protect one in 33 US citizens, predict when, where, and how crime will occur. A 2016 case study of a US city noted that the approach disproportionately projected crimes in areas with higher populations of non-white and low-income residents. When datasets disproportionately represent the lower power members of society, flagrant discrimination is a likely result.
Sentencing decisions are increasingly decided by proprietary algorithms that attempt to assess whether a defendant will commit future crimes, leading to concerns that justice is being outsourced to software. As AI becomes increasingly capable of analyzing more and more factors that may correlate with a defendant's perceived risk, courts and society at large may mistake an algorithmic probability for fact. This dangerous reality means that an algorithmic estimate of an individual’s risk to society may be interpreted by others as a near certainty—a misleading outcome even the original tool designers warned against. Even though a statistically driven AI system could be built to report a degree of credence along with every prediction, there’s no guarantee that the people using these predictions will make intelligent use of them. Taking probability for certainty means that the past will always dictate the future.
There is an aura of neutrality and impartiality associated with AI decision-making in some corners of the public consciousness, resulting in systems being accepted as objective even though they may be the result of biased historical decisions or even blatant discrimination. All data insights rely on some measure of interpretation. As a concrete example, an audit of a resume-screening tool found that the two main factors it associated most strongly with positive future job performance were whether the applicant was named Jared, and whether he played high school lacrosse. Undesirable biases can be hidden behind both the opaque nature of the technology used and the use of proxies, nominally innocent attributes that enable a decision that is fundamentally biased. An algorithm fueled by data in which gender, racial, class, and ableist biases are pervasive can effectively reinforce these biases without ever explicitly identifying them in the code. 
Without transparency concerning either the data or the AI algorithms that interpret it, the public may be left in the dark as to how decisions that materially impact their lives are being made. Lacking adequate information to bring a legal claim, people can lose access to both due process and redress when they feel they have been improperly or erroneously judged by AI systems. Large gaps in case law make applying Title VII—the primary existing legal framework in the US for employment discrimination—to cases of algorithmic discrimination incredibly difficult. These concerns are exacerbated by algorithms that go beyond traditional considerations such as a person’s credit score to instead consider any and all variables correlated to the likelihood that they are a safe investment. A statistically significant correlation has been shown among Europeans between loan risk and whether a person uses a Mac or PC and whether they include their name in their email address—which turn out to be proxies for affluence. Companies that use such attributes, even if they do indeed provide improvements in model accuracy, may be breaking the law when these attributes also clearly correlate with a protected class like race. Loss of autonomy can also result from AI-created “information bubbles” that narrowly constrict each individual’s online experience to the point that they are unaware that valid alternative perspectives even exist.
Disinformation and Threat to Democracy
AI systems are being used in the service of disinformation on the internet, giving them the potential to become a threat to democracy and a tool for fascism. From deepfake videos to online bots manipulating public discourse by feigning consensus and spreading fake news, there is the danger of AI systems undermining social trust. The technology can be co-opted by criminals, rogue states, ideological extremists, or simply special interest groups, to manipulate people for economic gain or political advantage. Disinformation poses serious threats to society, as it effectively changes and manipulates evidence to create social feedback loops that undermine any sense of objective truth. The debates about what is real quickly evolve into debates about who gets to decide what is real, resulting in renegotiations of power structures that often serve entrenched interests. 
Discrimination and Risk in the Medical Setting
While personalized medicine is a good potential application of AI, there are dangers. Current business models for AI-based health applications tend to focus on building a single system—for example, a deterioration predictor—that can be sold to many buyers. However, these systems often do not generalize beyond their training data. Even differences in how clinical tests are ordered can throw off predictors, and, over time, a system’s accuracy will often degrade as practices change. Clinicians and administrators are not well-equipped to monitor and manage these issues, and insufficient thought given to the human factors of AI integration has led to oscillation between mistrust of the system (ignoring it) and over-reliance on the system (trusting it even when it is wrong), a central concern of the 2016 AI100 report.
These concerns are troubling in general in the high-risk setting that is healthcare, and even more so because marginalized populations—those that already face discrimination from the health system from both structural factors (like lack of access) and scientific factors (like guidelines that were developed from trials on other populations)—may lose even more. Today and in the near future, AI systems built on machine learning are used to determine post-operative personalized pain management plans for some patients and in others to predict the likelihood that an individual will develop breast cancer. AI algorithms are playing a role in decisions concerning distributing organs, vaccines, and other elements of healthcare. Biases in these approaches can have literal life-and-death stakes.
In 2019, the story broke that Optum, a health-services algorithm used to determine which patients may benefit from extra medical care, exhibited fundamental racial biases. The system designers ensured that race was precluded from consideration, but they also asked the algorithm to consider the future cost of a patient to the healthcare system. While intended to capture a sense of medical severity, this feature in fact served as a proxy for race: controlling for medical needs, care for Black patients averages $1,800 less per year.
New technologies are being developed every day to treat serious medical issues. A new algorithm trained to identify melanomas was shown to be more accurate than doctors in a recent study, but the potential for the algorithm to be biased against Black patients is significant as the algorithm was trained using majority light-skinned groups. The stakes are especially high for melanoma diagnoses, where the five-year survival rate is 17 percentage points less for Black Americans than white. While technology has the potential to generate quicker diagnoses and thus close this survival gap, a machine-learning algorithm is only as good as its data set. An improperly trained algorithm could do more harm than good for patients at risk, missing cancers altogether or generating false positives. As new algorithms saturate the market with promises of medical miracles, losing sight of the biases ingrained in their outcomes could contribute to a loss of human biodiversity, as individuals who are left out of initial data sets are denied adequate care. While the exact long-term effects of algorithms in healthcare are unknown, their potential for bias replication means any advancement they produce for the population in aggregate—from diagnosis to resource distribution—may come at the expense of the most vulnerable.








Regulatory framework proposal on artificial intelligence 
The Commission is proposing the first-ever legal framework on AI, which addresses the risks of AI and positions Europe to play a leading role globally. 

© gorodenkoff - iStock Getty Images Plus
The regulatory proposal aims to provide AI developers, deployers and users with clear requirements and obligations regarding specific uses of AI. At the same time, the proposal seeks to reduce administrative and financial burdens for business, in particular small and medium-sized enterprises (SMEs).
The proposal is part of a wider AI package, which also includes the updated Coordinated Plan on AI. Together, the Regulatory framework and Coordinated Plan will guarantee the safety and fundamental rights of people and businesses when it comes to AI. And they will strengthen uptake, investment and innovation in AI across the EU.
Why do we need rules on AI?
The proposed AI regulation ensures that Europeans can trust what AI has to offer. While most AI systems pose limited to no risk and can contribute to solving many societal challenges, certain AI systems create risks that we must address to avoid undesirable outcomes.
For example, it is often not possible to find out why an AI system has made a decision or prediction and taken a particular action. So, it may become difficult to assess whether someone has been unfairly disadvantaged, such as in a hiring decision or in an application for a public benefit scheme.
Although existing legislation provides some protection, it is insufficient to address the specific challenges AI systems may bring.
The proposed rules will:
address risks specifically created by AI applications.
propose a list of high-risk applications.
set clear requirements for AI systems for high-risk applications.
define specific obligations for AI users and providers of high-risk applications.
propose a conformity assessment before the AI system is put into service or placed on the market.
propose enforcement after such an AI system is placed in the market.
propose a governance structure at European and national level.
A risk-based approach

The Regulatory Framework defines 4 levels of risk in AI:
Unacceptable risk
High risk
Limited risk
Minimal or no risk
Unacceptable risk
All AI systems considered a clear threat to the safety, livelihoods and rights of people will be banned, from social scoring by governments to toys using voice assistance that encourages dangerous behaviour.
High risk
AI systems identified as high-risk include AI technology used in:
critical infrastructures (e.g., transport), that could put the life and health of citizens at risk.
educational or vocational training, that may determine the access to education and professional course of someone’s life (e.g., scoring of exams).
safety components of products (e.g., AI application in robot-assisted surgery).
employment, management of workers and access to self-employment (e.g., CV-sorting software for recruitment procedures).
essential private and public services (e.g., credit scoring denying citizens opportunity to obtain a loan).
law enforcement that may interfere with people’s fundamental rights (e.g., evaluation of the reliability of evidence).
migration, asylum, and border control management (e.g., verification of authenticity of travel documents).
administration of justice and democratic processes (e.g., applying the law to a concrete set of facts).
High-risk AI systems will be subject to strict obligations before they can be put on the market:
adequate risk assessment and mitigation systems.
high quality of the datasets feeding the system to minimize risks and discriminatory outcomes.
logging of activity to ensure traceability of results.
detailed documentation providing all information necessary on the system and its purpose for authorities to assess its compliance.
clear and adequate information to the user.
appropriate human oversight measures to minimize risk.
high level of robustness, security and accuracy.
All remote biometric identification systems are considered high risk and subject to strict requirements. The use of remote biometric identification in publicly accessible spaces for law enforcement purposes is, in principle, prohibited.
Narrow exceptions are strictly defined and regulated, such as such as when necessary to search for a missing child, to prevent a specific and imminent terrorist threat or to detect, locate, identify, or prosecute a perpetrator or suspect of a serious criminal offence.
Such use is subject to authorization by a judicial or other independent body and to appropriate limits in time, geographic reach and the data bases searched.
Limited risk
Limited risk refers to AI systems with specific transparency obligations. When using AI systems such as chatbots, users should be aware that they are interacting with a machine so they can take an informed decision to continue or step back.
Minimal or no risk
The proposal allows the free use of minimal-risk AI. This includes applications such as AI-enabled video games or spam filters. Most AI systems currently used in the EU fall into this category.



How does it all work in practice for providers of high-risk AI systems?
Once an AI system is on the market, authorities oversee market surveillance, users ensure human oversight and monitoring, and providers have a post-market monitoring system in place. Providers and users will also report serious incidents and malfunctioning.
Future-proof legislation
As AI is a fast-evolving technology, the proposal has a future-proof approach, allowing rules to adapt to technological change. AI applications should remain trustworthy even after they have been placed on the market. This requires ongoing quality and risk management by providers.




The 5 biggest risks of generative AI, according to an expert 
AI makes our lives easier in many different ways. However, these benefits can come with costs. 



Written by Sabrina Ortiz, Associate Editor on April 25, 20XX

Generative AIs, such as ChatGPT, have revolutionized how we interact with and view AI. Activities like writing, coding, and applying for jobs have become much easier and quicker. With all the positives, however, there are some pretty serious risks.
A major concern with AI is trust and security, which has even caused some countries to completely ban ChatGPT as a whole or to reconsider policy around AI to protect users from harm. 
According to Gartner analyst Avivah Litan, some of the biggest risks of generative AI concern trust and security and include hallucinations, deepfakes, data privacy, copyright issues, and cybersecurity problems.
1. Hallucinations
Hallucinations refer to the errors that AI models are prone to make because, although they are advanced, they are still not human and rely on training and data to provide answers. 
If you've used an AI chatbot, then you have probably experienced these hallucinations through a misunderstanding of your prompt or a blatantly wrong answer to your question.
Litan says the training data can lead to biased or factually incorrect responses, which can be a serious problem when people are relying on these bots for information. 
""Training data can lead to biased, off base or wrong responses, but these can be difficult to spot, particularly as solutions are increasingly believable and relied upon,"" says Litan. 
2. Deepfakes
A deepfake uses generative AI to create videos, photos, and voice recordings that are fake but take the image and likeness of another individual. 
Perfect examples are the AI-generated viral photo of Pope Francis in a puffer jacket or the AI-generated Drake and the Weeknd song, which garnered hundreds of thousands of streams. 
""These fake images, videos and voice recordings have been used to attack celebrities and politicians, to create and spread misleading information, and even to create fake accounts or take over and break into existing legitimate accounts,"" says Litan. 
Like hallucinations, deepfakes can contribute to the massive spread of fake content, leading to the spread of misinformation, which is a serious societal problem. 
3. Data privacy
Privacy is also a major concern with generative AI since user data is often stored for model training. This concern was the overarching factor that pushed Italy to ban ChatGPT, claiming OpenAI was not legally authorized to gather user data. 
""Employees can easily expose sensitive and proprietary enterprise data when interacting with generative AI chatbot solutions,"" says Litan. ""These applications may indefinitely store information captured through user inputs, and even use information to train other models -- further compromising confidentiality.""
Litan highlights that, in addition to compromising user confidentiality, the stored information also poses the risk of ""falling into the wrong hands"" in an instance of a security breach.
4. Cybersecurity
The advanced capabilities of generative AI models, such as coding, can also fall into the wrong hands, causing cybersecurity concerns.
""In addition to more advanced social engineering and phishing threats, attackers could use these tools for easier malicious code generation,"" says Litan. 
Litan says even though vendors who offer generative AI solutions typically assure customers that their models are trained to reject malicious cybersecurity requests, these suppliers don't equip end users with the ability to verify all the security measures that have been implemented. 
5. Copyright issues
Copyright is a big concern because generative AI models are trained on massive amounts of internet data that is used to generate an output. 
This process of training means that works that have not been explicitly shared by the original source can then be used to generate new content. 
Copyright is a particularly thorny issue for AI-generated art of any form, including photos and music. 
To create an image from a prompt, AI-generating tools, such as DALL-E, will refer back to the large database of photos they were trained on. The result of this process is that the final product might include aspects of an artist's work or style that are not attributed to them. 
Since the exact works that generative AI models are trained on are not explicitly disclosed, it is hard to mitigate these copyright issues. 
What's next?
Despite the many risks associated to generative AI, Litan doesn't think that organizations should stop exploring the technology. Instead, they should create an enterprise-wide strategy that targets AI trust, risk, and security management. 
""AI developers must urgently work with policymakers, including new regulatory authorities that may emerge, to establish policies and practices for generative AI oversight and risk management,"" says Litan. 
 

What is generative AI?
In simple terms, generative AI is a subfield of artificial intelligence in which computer algorithms are used to generate outputs that resemble human-created content, be it text, images, graphics, music, computer code or otherwise.
In generative AI, algorithms are designed to learn from training data that includes examples of the desired output. By analyzing the patterns and structures within the training data, generative AI models can produce new content that shares characteristics with the original input data. In doing so, generative AI has the capacity to generate content that appears authentic and human-like.
How does generative AI work?
Generative AI is based on machine learning processes inspired by the inner workings of the human brain, known as neural networks. Training the model involves feeding algorithms large amounts of data, which serves as the foundation for the AI model to learn from. This can consist of text, code, graphics, or any other type of content relevant to the task at hand.
Once the training data has been collected, the AI model analyzes the patterns and relationships within the data to understand the underlying rules governing the content. The AI model continuously fine-tunes its parameters as it learns, improving its ability to simulate human-generated content. The more content the AI model generates, the more sophisticated and convincing its outputs become.
Examples of generative AI
Generative AI has made significant advancements in recent years, with several tools capturing the public attention and creating a stir amongst content creators. Big tech companies have also jumped on the bandwagon, with Google, Microsoft, Amazon, and others all lining up their own generative AI tools.
Depending on the application, generative AI tools may rely on an input prompt that guides it towards producing a desired outcome — think ChatGPT and DALL-E 2.
Some of the most notable examples of generative AI tools include:
ChatGPT: Developed by OpenAI, ChatGPT is an AI language model that can generate human-like text based on given prompts.
DALL-E 2: Another generative AI model from OpenAI, DALL-E is designed to create images and artwork based on text-based prompts.
Midjourney: Developed by San Francisco-based research lab Midjourney Inc., Midjourney interprets text prompts and context to produce visual content, like DALL-E 2.
GitHub Copilot: An AI-powered coding tool created by GitHub and OpenAI, GitHub Copilot suggests code completions for users of development environments like Visual Studio and JetBrains.
Benefits of generative AI
The most compelling advantage generative AI proposes is efficiency, in that it can enable businesses to automate specific tasks and focus their time, energy and resources on more important strategic objectives. This often results in lower labor costs and an increase in operational efficiency.
Generative AI can offer additional advantages to businesses and entrepreneurs, including:
Easily customizing or personalizing marketing content.
Generating new ideas, designs, or content.
Writing, checking, and optimizing computer code.
Drafting templates for essays or articles.
Enhancing customer support with chatbots and virtual assistants.
Facilitating data augmentation for machine learning models.
Analyzing data to improve decision-making.
Streamlining research and development processes.
Use cases of generative AI
Despite generative AI still being in its relative infancy, the technology has already found a firm foothold in various applications and industries.
In content creation, for instance, generative AI can produce text, images and even music, assisting marketers, journalists, and artists with their creative processes. In customer support, AI-driven chatbots and virtual assistants can provide more personalized assistance and reduce response times while reducing the burden on customer service agents.
Other uses of generative AI include:
Healthcare: Generative AI is used in medicine to accelerate the discovery of novel drugs, saving time and money in research.
Marketing: Advertisers use generative AI to craft personalized campaigns and adapt content to consumers’ preferences.
Education: Some educators use generative AI models to develop customized learning materials and assessments that cater to students’ individual learning styles.
Finance: Financial analysts use generative AI to examine market patterns and predict stock market trends.
Environment: Climate scientists employ generative AI models to predict weather patterns and simulate the effects of climate change.
Dangers and limitations of generative AI
It’s important to note that generative AI presents numerous issues requiring attention. One major concern is its potential for spreading misinformation or malicious or sensitive content, which could cause profound damage to people and businesses — and potentially pose a threat to national security.
These risks have not escaped policymakers. In April 20XX, the European Union proposed new copyright rules for generative AI that would require companies to disclose any copyrighted material used to develop these tools. Hopes are that such rules will encourage transparency and ethics in AI development, while minimizing any misuse or infringement of intellectual property. This should also offer some protection to content creators whose work may be unwittingly mimicked or plagiarized by generative AI tools.
The automation of tasks by generative AI could also affect the workforce and contribute to job displacement, requiring impacted employees to reskill or upskill. Additionally, generative AI models can unintentionally learn and amplify biases present in training data, leading to problematic outputs that perpetuate stereotypes and harmful ideologies.
ChatGPT, Bing AI and Google Bard have all drawn controversy for producing incorrect or harmful outputs since their launch, and these concerns must be addressed as generative AI evolves, particularly given the difficulty of scrutinizing the sources used to train AI models.
Generative AI vs. general AI
Generative AI and general AI represent different aspects of artificial intelligence. Generative AI focuses on creating new content or ideas based on existing data. It has specific applications and is a subset of AI that excels at solving particular tasks.
General AI, also known as artificial general intelligence, broadly refers to the concept of AI systems that possess human-like intelligence. General AI is still the stuff of science fiction; it represents an imagined future stage of AI development in which computers are able to think, reason and act autonomously.
Is generative AI the future?
It depends on who you ask, but many experts believe that generative AI has a significant role to play in the future of various industries. The capabilities of generative AI have already proven valuable in areas like content creation, software development and healthcare, and as the technology continues to evolve, so too will its applications and use cases.
That said, the future of generative AI is inextricably tied to addressing the potential risks it presents. Ensuring AI is used ethically by minimizing biases, enhancing transparency and accountability and upholding data governance will be critical as the technology progresses. At the same time, striking a balance between automation and human involvement will be crucial for maximizing the benefits of generative AI while mitigating any potential negative consequences on the workforce.






STOCKHOLM, April 27 (Reuters) - Companies deploying generative AI tools, such as ChatGPT, will have to disclose any copyrighted material used to develop their systems, according to an early EU agreement that could pave the way for the world's first comprehensive laws governing the technology.
The European Commission began drafting the AI Act nearly two years ago to regulate emerging artificial intelligence technology, which underwent a boom in investment and popularity following the release of OpenAI's AI-powered chatbot ChatGPT.
Members of the European Parliament agreed to push the draft through to the next stage, the trilogue, during which EU lawmakers and member states will thrash out the final details of the bill.
Under the proposals, AI tools will be classified according to their perceived risk level: from minimal through to limited, high, and unacceptable. Areas of concern could include biometric surveillance, spreading misinformation or discriminatory language.
While high-risk tools will not be banned, those using them will need to be highly transparent in their operations.
Companies deploying generative AI tools, such as ChatGPT or image generator Midjourney, will also have to disclose any copyrighted material used to develop their systems.
This provision was a late addition drawn up within the past two weeks, according to a source familiar with discussions. Some committee members initially proposed banning copyrighted material being used to train generative AI models altogether, the source said, but this was abandoned in favour of a transparency requirement.
""Against conservative wishes for more surveillance and leftist fantasies of over-regulation, parliament found a solid compromise that would regulate AI proportionately, protect citizens' rights, as well as foster innovation and boost the economy,"" said Svenja Hahn, a European Parliament deputy.
Macquarie analyst Fred Havemeyer said the EU's proposal was ""tactful"" rather than a ""ban first, and ask questions later"" approach proposed by some.
""The EU has been on the frontier of regulating AI technology,"" he told Reuters.
RACE TO MARKET
Microsoft-backed (MSFT.O) OpenAI provoked awe and anxiety around the world when it unveiled ChatGPT late last year. The chatbot became the fastest-growing consumer application in history, reaching 100 million monthly active users in a matter of weeks.
The ensuing race among tech companies to bring generative AI products to market concerned some onlookers, with Twitter-owner Elon Musk backing a proposal to halt development of such systems for six months. Shortly after signing the letter, the Financial Times reported Musk was planning to launch his own startup to rival OpenAI.


Sharon Goldman
@sharongoldman

December 5, 20XX-1

The hidden danger of ChatGPT and generative AI | The AI Beat
Since OpenAI launched its early demo of ChatGPT last Wednesday, the tool already has over a million users, according to CEO Sam Altman — a milestone, he points out, that took GPT-3 nearly 24 months to get to and DALL-E over 2 months. 
The “interactive, conversational model,” based on the company’s GPT-3.5 text-generator, certainly has the tech world in full swoon mode. Aaron Levie, CEO of Box, tweeted that “ChatGPT is one of those rare moments in technology where you see a glimmer of how everything is going to be different going forward.” Y Combinator cofounder Paul Graham tweeted that “clearly something big is happening.” Alberto Romero, author of The Algorithmic Bridge, calls it “by far, the best chatbot in the world.” And even Elon Musk weighed in, tweeting that ChatGPT is “scary good. We are not far from dangerously strong AI.” 
But there is a hidden problem lurking within ChatGPT: That is, it quickly spits out eloquent, confident responses that often sound plausible and true even if they are not. 
ChatGPT can sound plausible even if its output is false.
Like other generative large language models, ChatGPT makes up facts. Some call it “hallucination” or “stochastic parroting,” but these models are trained to predict the next word for a given input, not whether a fact is correct or not. 
Some have noted that what sets ChatGPT apart is that it is so darn good at making its hallucinations sound reasonable. 
Technology analyst Benedict Evans, for example, asked ChatGPT to “write a bio for Benedict Evans.” The result, he tweeted, was “plausible, almost entirely untrue.” 
More troubling is the fact that there are obviously an untold number of queries where the user would only know if the answer was untrue if they already knew the answer to the posed question. 
That’s what Arvind Narayanan, a computer science professor at Princeton, pointed out in a tweet: “People are excited about using ChatGPT for learning. It’s often very good. But the danger is that you can’t tell when it’s wrong unless you already know the answer. I tried some basic information security questions. In most cases the answers sounded plausible but were in fact BS.” 
Fact-checking generative AI
Back in the waning days of print magazines in the 2000s, I spent several years as a fact-checker for publications including GQ and Rolling Stone. Each fact had to include authoritative primary or secondary sources — and Wikipedia was frowned upon. 
Few publications have staff fact-checkers anymore, which puts the onus on reporters and editors to make sure they get their facts straight — especially at a time when misinformation already moves like lightning across social media, while search engines are constantly under pressure to surface verifiable information and not BS. 
That’s certainly why Stack Overflow, the Q&A site for coders and programmers, has temporarily banned users from sharing ChatGPT responses. 
And if StackOverflow can’t keep up with misinformation due to AI, it’s hard to imagine others being able to manage a tsunami of potential AI-driven BS. As Gary Marcus tweeted, “If StackOverflow can’t keep up with plausible but incorrect information, what about social media and search engines?” 
And while many are salivating at the idea that LLMs like ChatGPT could someday replace traditional search engines, others are strongly pushing back. 
Emily Bender, professor of linguistics at the University of Washington, has long pushed back on this notion. 
She recently emphasized again that LLMs are “not fit” for search —” both because they are designed to just make sh** up and because they don’t support information literacy.” She pointed to a paper she co-authored on the topic published in March. 
Is it better for ChatGPT to look right? Or be right? 
BS is obviously something that humans have perfected over the centuries. And ChatGPT and other large language models have no idea what it means, really, to “BS.” But OpenAI made this weakness very clear in its blog announcing the demo and explained that fixing it is “challenging,” saying: 
“ChatGPT sometimes writes plausible sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: (1) during RL [reinforcement learning] training, there’s currently no source of truth; (2) training the model to be more cautious causes it to decline questions that it can answer correctly; and (3) supervised training misleads the model because the ideal answer depends on what the model knows, rather than what the human demonstrator knows.” 
So, it’s clear that OpenAI knows perfectly well that ChatGPT is filled with BS under the surface. They never meant the technology to offer up a source of truth. 
But the question is: Are human users okay with that? 
Unfortunately, they might be. If it sounds good, many humans may think that’s good enough. And, perhaps, that’s where the real danger lies beneath the surface of ChatGPT. 





By JAKOB HANKE VELA
Send tips here | Tweet @HankeVela | Listen to Playbook and view in your browser
LABELING AI CONTENT        
TODAY: EU PUSHES FOR ‘AI LABEL’ TO FIGHT DEEPFAKES: Brussels wants to prevent artificial intelligence from blurring the lines between fact and fiction — and will today ask companies for the first time ever to come up with a label to identify AI-generated texts and images to fight disinformation, officials tell Playbook.
Brave new world: Generative AI is making breathtaking advances — from writing texts and code to creating ever more realistic pictures and videos — which will have enormous consequences not just for the future of society and work, but for politics, Commission officials reckon. 
Balenc-ai-ga: The fake images of the Pope and famous politicians wearing a Balenciaga coat that went viral earlier this year have clearly spooked them — and they now want to label such deepfakes.
Fake porn: “Today it is mostly still a game, but tomorrow you could see a fake porn with a candidate,” one official who is working on the file but was not authorized to speak on the record told Playbook, referring to AI-generated images of politicians. 
Race to regulate: The Commission (the EU’s executive, which proposes and enforces laws) — has proposed an AI Act to regulate high-risk applications and ban the most dangerous ones. But even before that act enters into force, the Commission will urge industry to cut down on trickery by labeling AI-generated work.
Happening today: Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton will meet representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation. They include Microsoft, Google, Meta, TikTok, Twitch and smaller companies — but not Twitter, which has left the code — as well as NGOs.
Disinformation risks: “I will ask the signatories to create a dedicated and separate track within the code” to deal with disinformation generated by Artificial Intelligence, Jourová told Playbook. “It should … aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them.”
EU pushes for safeguards: How does Brussels want the companies to tackle the risks? “Signatories who integrate generative AI into their services like Bingchat for Microsoft, Bard for Google should build in necessary safeguards that these services cannot be used by malicious actors to generate disinformation,” Jourová said.
Clear labels: “Signatories who have services with a potential to disseminate AI-generated disinformation should in turn put in place technology to recognize such content and clearly label this to users.”
More about this label: Two officials working on the file told Playbook the label should apply to all AI-generated material that can be used to create disinformation, including text, images, audio and video.
Voluntary — for now: It wouldn’t be mandatory, given that it would be part of the voluntary Code of Practice. However, the Commission aims to make the code enforceable by including it as a code of conduct in the Digital Services Act (DSA). Obligations on labeling AI content may also make it into the AI Act during negotiations between EU countries, Parliament, and the Commission, one official said.
How can companies do this? “They can develop, and they probably already have tools to check whether an image was AI-generated or not,” the first official said.
Playbook wonders: Given how easy it is for AI to proliferate across jurisdictions, will such a technology ever be able to identify all deepfakes — or won’t we, on the contrary, one day need some chain of custody procedure for authentic images that can be used, for example, as evidence in court?
Stay tuned: Jourová will present her initiative at a press point tomorrow at 11:15 a.m.
SPEAKING OF WHICH: While the Commission is calling on others to do more, it was recently reported that it awarded and signed a €3.7 million tender to help analyze issues like disinformation, foreign meddling in elections and global threats from a French firm that’s mired in controversy.
Avisa Partners has previously been accused of manipulating information in France and working for authoritarian regimes. The company was recently at the center of a controversy as the organizer of a cybersecurity forum boycotted by the French armed forces ministry and several government officials. More here for our Pro Cybersecurity subscribers.
Looking into this: The Commission is looking into the allegations and “is in contact with French counterparts to seek more clarity on those claim[s],” Peter Stano, the Commission’s spokesperson for foreign affairs and security policy, told my POLITICO Pro Technology colleagues. The EU executive is “closely monitoring the implementation of this project,” he added. 
Jean Tillinac, from Avisa Partners, told my Pro Tech colleagues that the bid was “defended by a team of seasoned experts from our Strategic Intelligence Division” doing research and which was different from the “Digital Communications Division” facing criticism.



Annex I – Glossary of Terms
Algorithm: a formula given to a computer for it to complete a task (i.e., a set of rules for a computer) 
Artificial intelligence: a subset of computer science that deals with computer systems performing tasks with similar, equal, or superior intelligence to that of a human (e.g., decision-making, object classification and detection, speech recognition and translation)
Artificial general intelligence (AGI): also known as strong AI, AGI is a type of artificial intelligence that is considered human-like, and still in its preliminary stages (more of a hypothetical existence in present day)
Artificial narrow intelligence (ANI): also known as weak AI, ANI is a type of artificial intelligence that can only focus on one task or problem at a given time (e.g., playing a game against a human competitor). This is the current existing form of AI.
Artificial neural network (ANN): a network modeled after the human brain by creating an artificial neural system via a pattern-recognizing computer algorithm that learns from, interprets, and classifies sensory data.
Big data: large amounts of structured and unstructured data that is too complex to be handled by standard data-processing software.
Chatbots: a chat robot that can converse with a human user through text or voice commands. Utilized by e-commerce, education, health, and business industries for ease of communication and to answer user questions. 
Cognitive computing: computerized model that mimics human thought processes by data mining, NLP, and pattern recognition.
Computer vision: when a machine processes visual input from image files (JPEGs) or camera feeds
Data mining: the process of sorting through large sets of data to identify recurring patterns while establishing problem-solving relationships.
Deep learning: a machine learning technique that teaches computers how to learn by rote (i.e., machines mimic learning as a human mind would, by using classification techniques)
Generative AI: Generative artificial intelligence or generative AI is a type of artificial intelligence (AI) system capable of generating text, images, or other media in response to prompts. Generative AI models learn the patterns and structure of their input training data, and then generate new data that has similar characteristics. 
Genetic algorithm: an algorithm based on principles of genetics that is used to find solutions efficiently and quickly to difficult problems.
Machine learning (ML): focuses on developing programs that access and use data on their own, leading machines to learn for themselves and improve from learned experiences.
Natural language processing (NLP): helps computers process, interpret, and analyze human language and its characteristics by using natural language data. 
Pattern recognition: automated recognition of patterns found in data.
Reinforcement learning: a machine learning method where the reinforcement algorithm learns by interacting with its environment and is then penalized or rewarded based on decisions it makes.
Strong AI: see artificial general intelligence (AGI)  
Structured data: clearly defined data with easily searchable patterns.
Supervised learning: a type of machine learning where output datasets teach machines to generate desired outcomes or algorithms (akin to a teacher-student relationship).
Transfer learning: a system that uses previously learned data and applies it to a new set of tasks.
Turing Test: a test created by computer scientist Alan Turing (1950) to see if machines could exhibit intelligence equal to or indistinguishable from that of a human.
Unstructured data: data without easily searchable patterns (e.g., audio, video, social media content)
Unsupervised learning: a type of machine learning where an algorithm is trained with information that is neither classified nor labeled, thus allowing the algorithm to act without guidance.",17,7.0,"Summary

According to the Notice of Competitions of current EPSO competitions, the only competency that will be assessed in the Case Study exam is Written Communication",7.0,"Observations

The core theme, which is the need for regulation of GAI by the EU, is communicated but could be clearer.

The central message is somewhat communicated but gets slightly lost amidst the various sub-topics discussed.

The flow of the document is somewhat logical but could benefit from a more structured layout.

The layout is not visually pleasing due to the lack of titles and subtitles, and the inconsistent spacing.

Titles and subtitles are inadequate, making it difficult to follow the document's structure.

The tone of the document is informative but shifts inconsistently, affecting the overall readability.

The language is generally uncomplicated but could be more concise.

There is no apparent bias in the communication.

The document lacks a clearly titled Introduction section.
The document also lacks a clearly titled Recommendations section.
There is no clearly titled Conclusions section in the document.

Few supporting statistics are provided in the text.

The text specifically mentions the EU but does not mention any EU member states.

No non-EU countries are mentioned in the text.

Spelling mistakes include: ""potentialy"" (potentially), ""amont"" (amount), ""waisted"" (wasted), ""algorythms"" (algorithms), ""compteur"" (computer), ""ralready"" (already).

Grammar mistakes include: ""the actor to help keep its evolution on track"" should be ""the actor to help keep its evolution on track,"" ""This includes text, pictures, music..."" should be ""This includes text, pictures, and music,"" among others.",,Tips to Improve,"Trainee's Answer
The Commission's intentions towards generative AI.
AI is now everywhere in our lives. Incredible tool, its use can also lead to the worst consequences. The proliferation of fake news even leads to question the existence of truth. The public space is therefore potentialy in danger and the EU can be one of the actor to help keep its evolution on track.
 
What is generative artificial intelligence (GAI) ?
GAI is part of artificial intelligence in which computer are able to create content that looks like a content created by a human. This includes text, pictures, music...It is based on a certain amont of collected data that the computer relates to one another just like a human brain.
The potential benefits of GAI
the benefits are numerous : the most important one is the efficiency of the system. If the computer can create human-like content, it is much more efficient in terms of speed in doing so. Therefore, GAI can be used for logistic organisation for a restaurant for example to help the manager reducing waste. It will reduce organisations' costs, leaders waisted time, waste etc. by supporting organisations to attain their optimal functioning. 
The dangers of GAI
if benefits are numerous, dangers are even more numerous and with a potential bigger impact.
The human-like component of the GAI leads to forget that algorythms are not able to identify the truth among various false proposals, which represents a major threat to the fight against disinformation, and hence democracy and EU values.
Biases are reinforced instead of being fought as there is no human ethic approach to avoid them. Statistics are in real life nurturing themselves but it is even more true with algorythms. ""Taking probabilities for certainties means the past will always dictate the future"", this leads deny one's freedom. 
if the data used by the GAI is based on biases, GAI will not know how to mitigate them. This is even more dangerous than people genuinely think that computeur's production, algorythm are neutral and objective. 
This risks are true for AI in the justice sector, in the health sector, in the information sector, in many major public services.
In addition, GAI is a problem for copyrights, data privacy and cybersecurity to a proportion that has the potential to threaten the democracy. 
What the EU can do
The EU does not want to ban the use of GAI. Chap GPT for example reached 100 million users in only a few weeks. That would not make sense and it is not the direction of history, but regulation is definitely needed in public space.
The EU is ralready working at regulating the sector. It has identified four levels or risks, from minimal to unacceptable and proposed to propose a list of high-risk applications, set a clear list of requirements for AI system for these high-risk applications (disclosure of any copyrighted material), define specific obligations for AI users and high-risk applications providers, propose a validation process for AI system before it is placed on the market and an enforcement after its entry on the market as well a governance structure at european and national level.
 
The success of GAI, its rapid installation in our daily lives is a turning point in history. Its success calls for a proportional vigilance. Regulation is urgently needed and the EU will be a major actor of it."
2,0_Case Study_Drones,"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions.

Following a request by the European Commission, the Single European Sky Air traffic management Research Joint Undertaking - whose role is to develop the new generation European air traffic management system – has today unveiled its blueprint to make drone use in low-level airspace safe, secure and environmentally friendly. This paper is part of the Commission's drive to deliver on its ambitious Aviation Strategy and unleash the full economic potential of drones by 20XX+2. This requires an effective legislative framework that can foster European leadership and competitiveness, while addressing a number of legitimate concerns, the first of which is safety. 
You are working as an administrator in DG Mobility and Transport, and you have been asked to prepare a press release announcing the publication of the blueprint.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete. 
You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated. 
The case study is designed to assess the following competencies: Analysis and Problem Solving, Communicating (Drafting Skills), Delivering Quality & Results, and Prioritising & Organising.
More specifically, you are asked to write an internal note to the press office (2-3 pages) containing the following background information:
Opportunities and threats of unmanned or remotely piloted vehicles in the European Airspace
Blueprint for drone use in low-level airspace
Next steps

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly and legibly as possible.","ABBREVIATIONS USED
				
ATC – Air traffic Control
ATM – Air Traffic Management
CE  marking - The letters ‘CE’ appear on many products traded on the extended Single Market in the European Economic Area (EEA). They signify that products sold in the EEA have been assessed to meet high safety, health, and environmental protection requirements.
Clean Sky - The largest European research programme developing innovative, cutting-edge technology aimed at reducing CO2, gas emissions and noise levels produced by aircraft.
EASA – European Air Safety Agency
FAA – US Federal Aviation Administration
Geofencing - a virtual geographic boundary, defined by GNSS technology that enables software to prevent a drone entering a defined zone

GNSS - Global Navigation Satellite System

IATA – International Air Transport Association

ICAO – International Civil Aviation Organization
JARUS  - Joint Authorities for Rulemaking on Unmanned Systems 
NOTAM – Notice to Airmen
NPA - Notice of proposed Amendment
RPAS - Remotely Piloted Aircraft Systems 
SESAR – Single European Sky ATM Research
SME – Small and Medium Enterprises
SWIM – System wide information management
UA - Unmanned Aircraft
U-space - a set of new services and specific procedures designed to support safe, efficient and secure access to airspace for large numbers of drones 
BACKGROUND INFORMATION","Subject:		Single European Sky - Drones
Importance:	Highest

Hi,

this morning, SESAR has unveiled its blueprint to make drone use in low-level airspace safe, secure and environmentally friendly. This “U-space” covers altitudes of up to 150 metres and will pave the way for the development of a strong and dynamic EU drone services market. The paper outlines a number of basic principles: 
Safe: safety at low altitude levels will be just as good as that for traditional manned aviation. The concept is to develop a system similar to that of Air Traffic Management for manned aviation.
Automated: the system will provide information for highly automated or autonomous drones to fly safely and avoid obstacles or collisions.
Up and running by 20XX+2: for the basic services like registration, e-identification and geo-fencing. However, further U-Space services and their corresponding standards will need to be developed in the future.
The European Aviation Safety Agency (EASA) is currently working with Member States and industry to produce effective EU-wide safety rules that are proportionate to the risk of the operation. These rules will implement the EU's basic aviation safety regulation, which the European Parliament and the Council (i.e. the EU Member States) are expected to adopt in the coming months.
The Commission, through the SESAR Joint Undertaking, will further finance a range of drone projects, focusing on the integration of drones into the aviation system.

Could you prepare a draft press release, announcing this blueprint within its wider context and send it to the Press Service by tonight?




Louis Blériot,
Head of Unit","RIGA DECLARATION
ON REMOTELY PILOTED AIRCRAFT (drones)
""FRAMING THE FUTURE OF AVIATION""

Riga - 6 March 20XX-2


Today Europe is taking a decisive step towards the future of aviation. The European aviation community gathered in Riga to exchange views on how, and under which conditions, drones can help create promising new opportunities in Europe, offering sustainable jobs and new prospects for growth both for the manufacturing industry and for future users of drones in all sectors of society. Drones offer new services and applications going beyond traditional aviation and offer the promise to perform existing services in a more affordable and environmentally friendly way. They are a truly transformational technology.

The Latvian Presidency of the Council of the European Union, European Commission representatives, Directors General of Civil Aviation of the EU Member States, data protection authorities and leaders of manufacturing industry and service providers confirmed the importance of joint European action, building on the orientations given in the EC Communication on opening the Remotely Piloted Aircraft Systems (RPAS) market. 

The aviation community stressed the necessity for European regulators to ensure that all the conditions are met for the safe and sustainable emergence of innovative drone services. At the same time regulations must help the industry to thrive and adequately deal with citizens’ concerns.
The aviation community established the following principles to guide the regulatory framework in Europe:
1. Drones need to be treated as new types of aircraft with proportionate rules based on the risk of each operation.
The provision of drone services must not be less safe than is accepted from civil aviation in general. The incremental integration of drones in the aviation system must not reduce the level of safety presently achieved in civil aviation. Although no one is on board the drone, people in other aircraft or on the ground could get hurt in case of an accident or an unscheduled landing. The way safety is regulated must be proportional to the operational risk involved.
Rules should be simple and performance based, to allow a small start-up company or individuals to start low-risk, low-altitude operations under minimal rules and to develop, with light-touch risk-based regulation, similar to the modern product safety regulations applied in other sectors. Higher risk operations would be gradually subject to more stringent regulations or operational limitations. At the other end of the spectrum, where the operational risk is highest, such as with large drones operating alongside manned aircraft, the regulation will need to be quite similar to that applying to manned aviation, with strict standards on the design, manufacturing, maintenance and operation of drones, as well as on the training of drone pilots and maintenance personnel.

2. EU rules for the safe provision of drone services need to be developed now.
Safety rules, including on remote pilot and operator qualifications, should be developed at the European level by the European Aviation Safety Agency, building on the experience developed in the EU Member States. The essential requirements should be harmonised at the global level to the maximum extent possible, and full use should be made of the established cooperation in the Joint Authorities for Rulemaking on Unmanned Systems (JARUS) and at ICAO, and should be completed by international industry standard setting bodies. Important efforts need to be put into resourcing these activities, especially JARUS, in order to ensure that the progressive risk-based approach is consistent with what is done in the rest of the world.
This basic regulatory framework should be put in place without delay, in order to help the private sector to take well-informed investment decisions, and to provide a basic set of rules for the many operators who are increasingly eager to begin providing services. The European Aviation Safety Agency should consult stakeholders by the middle of next year on the regulatory framework for the operations of drones and on concrete regulatory proposals for low-risk operations. By the end of next year the Agency will use the results of the consultation to propose a position on these matters. The proposal for the revision of the basic European Safety Regulation, which the European Commission has announced for next year, should contain the necessary new provisions and essential requirements for the progressive risk-based regulation of drones, based on the Agency's recommendations.

3. Technologies and standards need to be developed for the full integration of drones in the European airspace.
The success of drone activities and safety regulations also depends on the financial effort to develop and validate key missing technologies and the ensuing required standards. Both industry and public authorities stressed the need for adequate investment in the technologies that are required to integrate drones into the aviation system — the SESAR programme. Clean Sky and other initiatives should complete the SESAR investments. That would create spin-offbenef1ts for traditional aviation and so frame the future of ﬂying.

4. Public acceptance is key to the growth of drone services.
The respect of citizens’ fundamental rights, such as the right to privacy and the protection of personal data, must be guaranteed. Many drone services involve data-gathering such as ﬁlming, etc. The responsible authorities, such as the national and European Data Protection Authorities, should develop the necessary guidelines and monitoring mechanisms to ensure the full respect of existing protection rules, including in relation to drones. Rules need to clarify what is acceptable and what is not, and they require to be properly enforced.
Drones may cause nuisances and negative externalities, such as noise. These nuisances need to be addressed, possibly at the local level, to maintain public acceptance.
Drones also pose potential security risks. The design of drones can and should take into account those risks by using methods such as cyber-defence or geofencing. However, the malicious use of drones cannot be entirely prevented by design or operational restrictions. It is the task of the national police and justice systems to address those risks.
5. The operator of a drone is responsible for its use.
When a drone service is delivered in prohibited airspace, in an unsafe manner, or for illegal purposes, the authorities should be able to act and hold the operator accountable. Where lacking, this will need to be clarified in national law. Moreover, in order to enforce responsibility, it will be necessary for drones to have at all times an identiﬁable owner or operator. The regulator should seek the least bureaucratic way to achieve this. For instance, the mandating of electronic identity chips on drones - “IDrones” - as is today envisaged in some states, could be formalised through a safety rule, which would contribute to the effective implementation of privacy and security requirements. Standardised web-portals in the Member States for the registration of operators and their operations could be another solution. The involved authorities need to work closely together.
Drone accidents will happen. Member States should clarify the applicable insurance and third party liability regime and monitor the compensation mechanisms for potential victims. The establishment of compensation funds to cover victims of accidents caused by uninsured drone users, as used in the motor insurance sector, could be envisaged. Reporting on drone incidents should be integrated into the overall incident reporting requirements. Systematic and coherent incident reporting will improve safety and will be instrumental for insurance companies in their risk analysis on which third party liability insurance premiums are based.
To allow a short reaction time, the development of drone services and drone technologies needs close monitoring. To this end, the EU should establish an easy access for SMEs to information required for drone manufacturing and service provision, together with an observatory to keep track of the growing number of operations in Europe and the evolution of innovation. This monitoring will permit informed decisions relative to the establishment of priorities for future legislation. It will also help regulators to learn from experience and verify that the rules are fit for purpose, namely to ensure that new technologies and drone services can develop in full respect of the required high levels of safety, security, privacy and environmental protection. An annual progress report should be published.
The European aviation community gathered in Riga today is committed to working together on the basis of these principles to allow businesses to provide drone services everywhere in Europe as from 20XX-1 onwards.



Introduction
The demand for drone services is steadily increasing, with the potential to generate significant economic growth and societal benefits, as recognised in the 20XX-2 EU Aviation Strategy, and more recently in the SESAR Drones Outlook Study and Warsaw Declaration on drones. In order to realise this potential, the Declaration calls for “urgent action on the airspace dimension, in particular the development of the concept of U-space”. Ultimately, U-space will enable complex drone operations with a high degree of automation to take place in all types of operational environments, including urban areas. U-space must be flexible enough to encourage innovation, support the development of new businesses and facilitate the overall growth of the European drone services market while properly addressing, at EU level, safety and security issues, respecting the privacy of citizens, and minimising the environmental impact. This blueprint outlines the proposed vision for U-space and how it could be rolled out. Rather than providing a definitive solution, this blueprint provides the basis to better define the way drones will operate in Europe in the future. 
What is U-space?
U-space is a set of new services and specific procedures designed to support safe, efficient and secure access to airspace for large numbers of drones. These services rely on a high level of digitalisation and automation of functions, whether they are on board the drone itself, or are part of the ground-based environment. U-space provides an enabling framework to support routine drone operations, as well as a clear and effective interface to manned aviation.

What are the key principles of U-space?
The delivery of U-space relies upon the following key principles:
To ensure the safety of all airspace users operating in the U-space framework, as well as people on the ground.
To provide a scalable, flexible and adaptable system that can respond to changes in demand, volume, technology, business models and applications, while managing the interface with manned aviation.
To enable high-density operations with multiple automated drones under the supervision of fleet operators.
To guarantee equitable and fair access to airspace for all users.
To enable competitive and cost-effective service provision at all times, supporting the business models of drone operators.
To minimise deployment and operating costs by leveraging, as much as possible, existing aeronautical services and infrastructure, including GNSS as well as those from other sectors, such as mobile communication services.
To accelerate deployment by adopting technologies and standards from other sectors where they meet the needs of U-space.
To follow a risk-based and performance-driven approach when setting up appropriate requirements for safety, security [including cyber-security] and resilience [including failure mode management], while minimising environmental impact and respecting the privacy of citizens, including data protection.


How will U-space operate?
Subject to compliance with applicable regulations, operational limitations and technical requirements linked to the operation of the drone, U-space facilitates any kind of mission, from the delivery of goods, aerial work, and search and rescue, to more complex future applications such as urban air mobility.
U-space services are offered to both private [leisure and professional] and public users of drones, for all types of missions. Some services will meet privacy and security needs expressed by the relevant authorities. In addition, the criticality of these services will lead to the establishment of performance requirements for both structural elements and service delivery, covering, for example, safety, security, availability, continuity and resilience.
The U-space framework comprises an extensive and scalable range of services relying on agreed EU standards and delivered by service providers. These services do not replicate the function of ATC ‚ as known in ATM, but deliver key services to organise the safe and efficient operation of drones and ensure a proper interface with manned aviation, ATC and relevant authorities. They may include the provision of data, supporting services for drone operators such as flight planning assistance and more structured services such as tracking or capacity management.



Unmanned aircraft (most people call them ‘drones’) is a sector of aviation that is developing very fast and has a great potential for producing new jobs and growth. The term ‘unmanned aircraft’ includes very large aircraft similar in size and complexity to manned aircraft, but also very small consumer electronics aircraft. Especially the smaller ones are increasingly being used in the Europe Union (EU), but under a fragmented regulatory framework. Basic national safety rules apply, but the rules differ across the EU and a number of key safeguards are not addressed in a coherent way.
On request by the European Commission, Member States and other stakeholders, the Agency started to develop a proposals for an operation centric, proportionate, risk- and performance-based regulatory framework for all unmanned aircraft (UA) establishing three categories with different safety requirements, proportionate to the risk:
‘open’ (low risk) is a UA operation category that, considering the risks involved, does not require a prior authorisation by the competent authority before the operation takes place;
‘specific’ (medium risk) is a UA operation category that, considering the risks involved, requires an authorisation by the competent authority before the operation takes place and takes into account the mitigation measures identified in an operational risk assessment, except for certain standard scenarios where a declaration by the operator is sufficient;
‘certified’ (high risk) is a UA operation category that, considering the risks involved, requires the certification of the UA, a licensed remote pilot and an operator approved by the competent authority, in order to ensure an appropriate level of safety.
Following the publication of an advance NPA, a Technical Opinion, a ‘Prototype’ regulation was drafted for the ‘open’ and ‘specific’ categories. The ‘Prototype’ regulation was published proposing actual rules providing the necessary clarity, notably on what are the responsibilities of the Member States and what is the flexibility offered to them.
A significant number of comments has been received and together with the significant inputs provided by an expert group have been taken into account to further develop the regulation text leading to the publication of an NPA. An impact assessment details analysis of several potential options considered. The analysis benefited also from feedback provided by stakeholders.
The NPA has taken into consideration the developments in the international arena e.g. work done in the International Civil Aviation Organisation (ICAO); in the Joint Authorities for the Rulemaking of Unmanned Systems (JARUS) and of course in the USA (Federal Aviation Administration- FAA).
The proposal provides a framework to safely operate drones while allowing this industry to remain agile, to innovate and continue to grow. The risk posed to people on the ground and to other aircraft as well as privacy, security and data protection issues created by such drones are also taken into account.
The proposed regulation defines the technical and operational requirements for the drones. Technical requirements refer for example to the remote identification of drones.  Operational requirements refer among others to geofencing; a system that ensures the drones does not enter a prohibited zone. The proposal also addresses the pilots’ qualifications. Furthermore, drone operators will have to register themselves, except when they operate drones lighter than 250g.
This proposal is breaking new grounds by combining Product legislation and Aviation legislation. Indeed, design requirements for small drones will be implemented by using the legislation relative to making products available on the market (the well-known CE marking). The standard CE mark will be accompanied by the identification of the class of the drone (from C0 to C4) and by a do’s and don’ts leaflet that will be found in all drone boxes. Based on the drone class an operator will know in which area he can operate and what competence is required.
The proposal allows a high degree of flexibility for EASA Member States; they will be able to define zones in their territory where either drones operations are prohibited or restricted (for example to protect sensitive areas), or where certain requirements are alleviated.
For operations that pose higher risks, an operational risk assessment will define the requirements that the operator needs to comply before flying the drone.
The proposal also provides special alleviations for people flying model aircraft - which are also drones – to recognise the good safety records in aero modelling identifying 3 options:
Member States may issue a special authorisation to model clubs and associations defining deviations from the UAS regulation;
Operations can be conducted in specific zones designated by Member States; or
Operations can be conducted in the open category according the operational limitations defined for one of the Subcategory (A3)
EASA will submit a final Opinion to the European Commission at the end of 20XX, which will take into account the feedback, received to this proposal.




Drone Alliance Europe (DAE) is a coalition of leading technology companies representing the commercial drone industry before European political leaders, regulators, and other industry stakeholders, as well as international regulatory and advisory bodies.
The commercial drone industry has the potential to bring tremendous economic growth, jobs, innovation, and broad societal benefits. Amid exponential industry growth and opportunity, it is critical to pursue a forward-leaning regulatory framework to fully realise this potential and further promote European leadership in research, production, and application of this technology.
Our Mission
The Alliance leverages the experience and perspectives of member companies throughout the policymaking process to expedite the safe and widespread integration of commercial drones into European airspace. Together, the DAE represents a strong, united voice working toward the expeditious development of:
Proportionate, risk-based, pan-European regulations that facilitate a clear path toward authorization of expanded operations throughout the continent, including fully autonomous and beyond visual line of sight operations
A low-cost, interoperable unmanned traffic management (UTM) framework that promotes the safe and secure integration of expanded drone operations essential to industry growth
A regulatory framework that embraces the flexible use of licensed, unlicensed, and spectrum sharing opportunities for drone technology necessary to support safe integration, innovation, and technology leadership throughout the Digital Single Market

Our Members



Secure your drone – or pay the price 
By Nick Gibbons - cyber security expert and partner at BLM
Drone technology offers many benefits – from the potential for speedy Amazon deliveries from the sky, to saving lives, as witnessed recently when the Lochaber mountain rescue team used one to find a hurt climber. 
But on the flip side, there are risks associated with aerial technology, such as drone jacking or hacking. 
Typically, when the conversation moves to the subject of drone-jacking, people immediately envisage a Hollywood-style breach of national security, probably in or around the White House before Will Smith leaps in to save the day. 
However, attacks on this technology represent very real risks for the growing number of businesses using drones, such as engineers surveying buildings and infrastructure, e-commerce giants sending deliveries or companies gathering surveillance for insurance claims. 
Earlier this year, Amazon announced an expansion to its research and development team in Cambridge. This will see 400 technology specialists fine-tuning the technology behind delivery drones. Despite claims that such deliveries are “pipe dreams”, there is a growing market for commercial drone technology, and with this comes a growing risk of drone-jacking. 
Last November, a report from security software company McAfee predicted cybercriminals will soon turn their attention to targeting drones, particularly those used for law enforcement, filming and deliveries. 
Drones without adequate security in place will be vulnerable to hacks, as well as physical attacks. The report speculates 20XX will see an increase in availability, via the dark web, of pre-packaged software and toolkits for hacking drones. In these cases, hacking of the drone itself or its supporting software may result in either physical misuse or data breaches. Hacking for the physical diversion of a drone carries the potential for personal injury or property damage, actual theft of the drone or indeed, the item it was carrying. 
Theft of data is another real risk, particularly if the drone contains personal or sensitive information, whether customer data included for delivery purposes or footage collected via an attached camera. 
The loss of data via drone-jacking leaves businesses and authorities with many privacy concerns, especially with the EU’s General Data Protection Regulation (GDPR) coming into force in May 20XX+1. In recent years, there have been a raft of data breaches resulting in an invasion of privacy for customers of companies, including TalkTalk and Camelot, and breaches of the GDPR could entail fines of up to four per cent of a company’s global turnover. 
Attacks are becoming more sophisticated and wide-reaching; recently, we saw the extensive damage hackers can unleash with the WannaCry cyber attack bringing organisations across the globe to a standstill. 
If cyber attacks start targeting drones, drone-jacking could leave businesses and their customers equally exposed with regards to personal and commercial data, and the prospect of big fines levied by the Information Commissioner’s Office. 
Although the use of drones is already, to an extent, covered by a range of laws and regulations, including the Data Protection Act, more specific, targeted legislation is necessary, as are effective insurance products for organisations using drones. This is especially important with the European Commission predicting full integration of drones into European airspace by 20XX+10. 
The UK Government is clearly live to the emerging risks of drone technology. Following a recent consultation exercise, a registration system is to be launched for drones weighing 250g or more. The UK Government is considering the best legislative option for introducing the new rules. 
Currently, a combination of existing insurance policies are required to cover risks associated with drone technology. As the risk of electronic theft of sensitive data rises, the market for specialised policies grows. 
In the case of drone-jacking, it would be wise for a business to consider cyber risk policies available for first and third parties. These can provide protection against business interruption, reputational risks, loss or theft of third party corporate data notification expenses and the payment of compensation to individuals affected by security or privacy breaches. Care should be taken, however, when selecting a particular cyber policy, including detailed discussions with a specialised brokers. 
So while drones have life-saving potential for Scotland’s mountain rescue teams and a business may find investing in the technology an attractive proposition, an outbreak of drone-jacking could be hugely costly. It is critical that companies consider the security breaches drone-jacking could leave them open to, and invest in the appropriate protection – just in case Will Smith is not available. 



Drone flew 'within wingspan' of plane approaching Heathrow 
Rob Davies
A drone flew within 20 metres of a plane on the approach to Heathrow, while another shocked pilots by appearing at 3,000 metres (10,000ft), a monthly update on near-misses has revealed.
Commercial jet pilots reported two “category A” incidents, the most serious class of near-miss, involving unmanned aerial vehicles (UAVs), known as drones.
The latest report comes amid concern that drone near-misses are on the rise, potentially posing a threat to recreational and commercial planes.
In one case, an Airbus A320 pilot on the approach to Heathrow in October last year spotted a drone within just 20 metres, or “possibly within the wingspan” of the aircraft.
Investigators concluded that the drone had flown so close to the passenger jet that “providence had played a major part in the aircraft not colliding”. They also noted that the “blue and disc-like” craft appeared to be custom-made, rather than a commercially available model.
In the second of two serious UAV incidents, an A320 pilot taking off from Heathrow saw a red drone overhead, about 50 metres away from his right wing at about 1,000 metres.
The pilot noted that there would have been a “distinct possibility of damage” had a collision occurred, while investigators found that “a collision had only been narrowly avoided and chance had played a major part”.
A third drone sighting, deemed a less serious category B incident, involved an unmanned aircraft at an altitude that surprised pilots, who had “no time to react”.
The UK Airprox Board, which issues monthly reports on the threat of mid-air collisions, reported a pilot saying: “Was that a drone? At 10,000 ft!”
Large drones are not permitted to fly above 120 metres, or close to airports.
The “large drone”, which appeared to be stationary, came within 60 metres (200ft) of the aircraft, a distance deemed less risky than the category A incidents, but nonetheless “a situation where safety was not assured”.
A fourth drone sighting, involving a pilot on a sightseeing trip near the Binevenagh mountain in Northern Ireland, was deemed to be at the lowest level of risk, category E.
In all four cases, police were alerted but the operator of the drone could not be traced.
Ministers are considering measures to enforce registration of all new drones so they can be better monitored, while the Department for Transport is also reviewing drone safety.
Pilots believe a collision with an airliner could be catastrophic and that the impact of a drone strike on a light plane or helicopter would almost certainly bring it down.
The British Airline Pilots Association has warned that the number of incidents could soar as people fly drones received as Christmas presents, often with little or no handling experience or understanding of the rules.
There have been 59 drone near-misses reported in the past 12 months. Drone sightings were among 21 incidents reported to the UK Airprox Board, six of which were deemed to be in the most serious category.
Among the other category A incidents was a near-miss in which a model aircraft was flown close to a Chinook military helicopter coming in to land at RAF Benson.





European Commission demands EU laws on drones after string of near-misses with aeroplanes
, Brussels correspondent 
30 September 20XX-1 • 8:20am 
The European Commission has called for fresh impetus behind its stalled plans for EU-wide regulation of drones, after a string of near-misses with airplanes across Europe last year.
There were more than 1,200 “safety occurrences"" involving drones in Europe last year, including several involving planes, the commission, the EU’s civil service, said.
On April 22, a drone passed by the wingtip of  with 156 passengers as it came into land at Liverpool John Lennon Airport. In 2016 three planes narrowly missed drones near Heathrow airport,  for tougher .
“If we don't move fast enough, the near misses between drones and airplanes could one day have disastrous consequences,” Violeta Bulc, the EU’s transport commissioner said.
“Drones offer tremendous opportunities for new services and businesses,” she said, “but safety always comes first”.
The commission drafts laws, which are then amended separately by the European Parliament and national governments sitting in the Council of Ministers. A bill can only enter into force across the EU when an identical text is agreed by MEPs and the council. 



North Wales Police use drones to fight crime
10 January 20XX
North Wales Police has become the latest force in Wales to use drones to help in the fight against crime.
Fifteen officers and staff have been trained to use the unmanned aircraft to capture video and images to be used in investigations. 
This includes searching for missing people as well as gathering evidence from road traffic investigations and major crime incidents.
Drone were used to investigate a .
The team's two drones, which can also carry a thermal imaging camera, have already been used to search for missing people and investigate incidents during a trial last year.
Insp Craig Jones from the force's operational planning unit said they were highly effective in gathering images over difficult terrain or hard to reach areas and helped officers gain information, quickly and safely.
The live images they take can be seen by police on the ground and they were recently used to help firefighters tackle a large blaze at the Gateway to Wales Hotel.
Stuart Millington, of North Wales Fire and Rescue Service, said the ability to see aerial moving images that show fire hotspots was a ""significantly useful tool"" in ongoing incidents.
An agreement with the force means the fire service can call on the police drone pilots to help them deal with incidents when needed.
North Wales Police's Deputy Chief Constable Gareth Pritchard added the drones were a highly cost effective tool in fighting crime and helping communities.
""Being able to launch a drone in the air in a few minutes could help save lives and secure vital evidence if a crime was in progress,"" he said.

 



Drone makers zero in on commercial opportunities

Louise Lucas in Hong Kong July 5, 20XX-1
They have been used to shoot weddings, Hollywood movies and terrorists. But now drones, and their makers, are navigating a third path between hobbyists and warfare into the industrial world, threatening a shake-up of the burgeoning $6bn industry. 
New uses for unmanned aerial vehicles (UAVs), to give drones their technical name, are emerging almost daily: delivering packages, pizzas and blood; surveying mines; pre-emptive firefighting; even collecting whale snot to help conserve the mammals. 
“We are developing the UAV into a means of production,” said Paul Xu, vice-president of DJI, at a conference in Shenzhen last month. His company has given China undisputed leadership in the sector, with its 70 per cent market share of non-military drones 
However, if Shenzhen-based DJI, valued at $8bn-$10bn at its last funding round in 20XX-2, is to keep that lead, it will need to adapt to new market dynamics. 
The industry dismisses talk of “peak” consumer drone, but few expect that part of the business to maintain its heady growth rates. Outside China, casualties abound: in California, Lily Robotics shut up shop in January, while 3D Robotics switched its focus to software and Parrot, of France, axed jobs. New entrants are cut from an altogether different cloth, with industrial and tech groups, including Qualcomm, Intel and Boeing hovering over the space. 
Regulators too are braced for change, as the industry lobbies for more openings. In a first step, the US Federal Aviation Administration, in effect, opened the skies to commercial drones a year ago, with limited safety rules covering the sector. 
Since the FAA rule changes, says Michael Perry, director of strategic partnerships at DJI, the enterprise industry has been scaling up rapidly, encouraged by the more certain regulatory environment. “Before we had conversations [with businesses] but then they said: ‘How will my legal team deal with this?’ The last thing we want is vagaries. People won’t invest if they aren’t sure.” 
DJI, the creation of Frank Wang, a radio-controlled helicopter enthusiast from Hangzhou who transformed his boyhood hobby into a company with sales of $1.5bn, is now looking into areas ranging from agriculture to eliminating mosquitoes. 
“Personal drone vendors are now aggressively trying to position themselves in the commercial market,” says Gerald Van Hoy, senior research analyst at Gartner, although the firm says the 3m drones it expects to be shipped this year will still be overwhelmingly for the consumer market. These figures are up 39 per cent on 20XX-1 and should translate into revenues of $6bn.",12,6.0,"Summary
The writing shows strong potential in its fluency and is structured well with relevant information included.  Some sections have a very pleasing written style and convey information effectively.

However, at times the candidate veers towards behind far too concise, omitting key details that could have benefitted the press release. At other times, too much detail is included considering the intended audience is the general public. A happy balance needs to be found. 
There are also several grammatical errors present. More effort could be made to make this document a consistently compelling read throughout. 



Per Competency Score",6.0,"Observations
The document is structured very well into clear sections where relevant information can be found.

The first section shows promise in its ability to effectively summarize the context. But the several grammatical errors impact its readability. 

The blueprint section does not include enough key information on U-Space, nor does it explain what U-Space is. 
E.g.:
”U-space is a set of new services and specific procedures designed to support safe, efficient and secure access to airspace for large numbers of drones. 

These services rely on a high level of digitalisation and automation of functions, whether they are on board the drone itself or part of the ground-based environment. 

U-space provides an enabling framework to support routine drone operations, as well as a clear and effective interface to manned aviation.”

This section is far too brief and lacks sufficient detail, especially considering the prime objective of the press release. Additionally, the written style here is disjointed, making it difficult to understand. A better, more detailed way to convey this information:
E.g.:

“The delivery of U-space relies upon the following key principles:
•	To ensure the safety of all airspace users operating in the U-space framework, as well as people on the ground.
•	To provide a scalable, flexible and adaptable system that can respond to changes in demand, volume, technology, business models and applications, while managing the interface with manned aviation.
•	To enable high-density operations with multiple automated drones under the supervision of fleet operators.
•	To guarantee equitable and fair access to airspace for all users.
•	To enable competitive and cost-effective service provision at all times, supporting the business models of drone operators.
•	To minimise deployment and operating costs by leveraging as much of the existing aeronautical services and infrastructure as possible, including GNSS as well as those from other sectors, such as mobile communication services.
•	To accelerate deployment by adopting technologies and standards from other sectors where they meet the needs of U-space.
•	To follow a risk-based and performance-driven approach when setting up appropriate requirements for safety, security and resilience, while minimising environmental impact and respecting the privacy of citizens, including data protection.”

The opportunities and threats section illustrates a pleasing and much stronger written style. Areas of opposition are highlighted effectively and there is evidence of solid reasoning.

Would have been useful to pinpoint data here from Gartner regarding the 3 million drones that are expected to be shipped and that should translate into revenues of $6 billion. 
Conversely, the section entitled Next Steps includes far too much detail that again impacts the coherence. The pertinent information should been summarized more succinctly. The written style should reflect that this is a press release and that the intended audience is the general public. For this reason, there should be an emphasis on ease of readability. 

E.g.:
“The European Aviation Safety Agency (EASA) is currently working with Member States and industry to produce effective EU-wide safety rules that are proportionate to the risk of the operation. 
These rules will implement the EU's basic aviation safety regulation, which the European Parliament and the Council (i.e. the EU Member States) are expected to adopt in the coming months.

The Commission, through the SESAR Joint Undertaking, will further finance a range of drone projects, focusing on the integration of drones into the aviation system.”

A conclusion should be included to summarize the main points of the press release.",,"Tips to Improve
Work on your writing style to decrease grammatical errors and increase readability. 
Remember the intended audience and objective of the document and tailor detail accordingly. 
Ensure you have enough time to proof-read and edit in order to make style consistent throughout.","Trainee's Answer
Internal note to the press office
Upon request of the European Commission (EC), the Single Sky Air traffic management Research Joint Undertaking, whose role is to develop the new generation European air traffic management system, has today unveiled its blueprint to make drone use in low-level airspace safe, secure, and environmentally friendly. This initiative forms part of the EC Aviation Strategy, which is envisaged to be embedded in an effective legislative framework fostering European leadership and competitiveness, while equally addressing some bottlenecks, primarily safety.
The Latvian Presidency of the Council of the EU, EC representatives and Directors General of the Civil Aviation of the EU Member States (MS), data protection authorities, leaders of the manufacturing industry and service providers agreed on the importance of Joint Europa Action building on previous experiences drawn from the Remotely Piloted Aircraft Systems.
The EC through SESAR Joint Undertaking will provide funding for a range of drone projects focusing on the integration of drones into the aviation system (RPAS)
Blueprint for drone use in low-level airspace
In view of increasing demands for drone services, the blueprint outlines a vision for a U-Space, namely how drones will operate in Europe in the future grounded on the following basic principles:
Safe: The 150 meters altitude low-level airspace drone will be as good as the one for traditional manned aviation. It will rely on high level of innovative digitalization, guaranteeing equitable  and fair access to the airspace for all users
Automated: the system will provide information for highly automated or autonomous drones to fly safely and avoid obstacles or collisions
Starting to be operational by 20XX+2: for basic services like registration, e-identification and geo-fencing
Opportunity and threats of unmanned or remotely piloted vehicles in the European Airspace
While the usage of drones clearly bring innovative new chances to Europe, it also bears a range of safety and security risks.
Opportunities: The transformational technology not only offers new services and applications going beyond traditional aviation but also provides for sustainable jobs, innovation, and new prospects for growth both, for the manufacturing industry and for future users of drones in all sectors of society. Existing services will be performed in a more affordable and environmentally friendly way. This will enable a competitive and cost-effective service provisions and facilitate all kinds of missions, such as delivery of goods, aerial work, policing, search and rescue activities as well as contribute to more future oriented urban air mobility projects
Threats: Malicious use of drones, such as drone jacking, cannot be entirely prevented by design or operational restrictions. Thus, the at times overloaded national police and justice systems need to address those risks. Even if additional budget is foreseen to tackle these shot comings the lack of qualified labor force may still hamper a leverage between risk and risk mitigation measures.
Hacking of the drone itself or its supporting software may result in eighter physical misuse of data breaches, causing interruption of the airspace traffic, personal injury or property damages and theft.
Transformational technology open for everyone, private or public users, even if certified high risk drones will be subject to licensed remote pilots or operators approved by competent authorities tasked to ensure an appropriate level of safety - the issue here is comparable to the private ownership and use of firearms closely linked to the question: How can the responsible authorities make sure they can handle the amount of malicious drone user cases and effectively fight related cybercrimes?
Can risks posed on people on the ground and to other aircraft activities as well as threats to privacy, security and data protection violations be sufficiently addressed via the implementation of the legislative framework under development?
Next steps
Thus, and in line with the EC Aviation Strategy, EU and MS are currently working with industry on effective EU-wide safety regulation to be adopted by the European Parliament and the Council in the coming months. The envisaged legislative framework shall also provide guidance for industry, including how to deal with citizens’ concerns.
After a consultation phase involving relevant MS authorities and the European Aviation Safety Agency, the legislative framework including respective provisions in the European Safety Regulation should be announce by the EC, based on the recommendations elaborated, in the course of next year, and be adopted without any delays, taking inter alia the following aspects into account:
Timely adoption of the legislative framework to offer security to the investors and allow to undertake well-informed decisions (production envisaged as from 20XX-1)
Conserve the safety of the civil aviation in general by and incremental integration of drones into the aviation system in proportion to the operational risk involved, aiming at full integration of drones into the European airspace by 20XX+10
Large drones operations must be treated similarly as manned aviation including strict standards on the design manufacturing maintenance and operation of drones as well as dedicated drone pilot training
EU rules governing the safety and remote pilot and operator qualifications based on experienced gained by respective stakeholder, namely MS authorities and European Aviation Safety Agency
Full use of existing cooperation mechanisms, such as the Joint Authorities for Rulemaking on unmanned Systems (JARUS) and at ICAO
Safeguard for protection of privacy and personal data of citizens based on the recommendation and guidance of the national and European Data Protection authorities
Provisions on the sole responsibility and respective accountability of the use of drones by the operator, including provisions on third party liability and compensation mechanism for damages caused by accidents with drone usages, including a reporting mechanism and obligatory liability insurances.
Establish monitoring system for development of drone service and technology managed by Small Medium Enterprise to ensure new drone technologies will be developed in full respect of high level safety, security , data and environmental protection
Definition on operational zones as specific zones or open zones with restriction to be designated by MS or delegated private sector players"
3,0_Generative AI (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. 

Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG CONNECT in the unit in charge of fighting against disinformation.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Critical thinking, analysing & creative problem-solving, Decision-making and getting results, Information management,  Communication.

Specifically, your task will be to draft a 2 to 2.5 - page speaking note for the Commisioner to clarify the intentions of the Commission with respect to generative AI (GAI). This document must include: 

What is GAI and what are the potential benefits.
What are the dangers associated with GAI and how does the EU want to address them.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations

AI - Artificial intelligence
AIA – Artificial Intelligence Act
AGI - Artificial general intelligence 
ANI - Artificial narrow intelligence
ANN - Artificial neural network
DSA – Digital Services Act
GAI – Generative AI
ML - Machine learning
NLP - Natural language processing


EMAIL 1","Subject: Press Release on generative AI

Dear YOU,

Earlier today, Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton met with representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation.
Jourová asked the signatories to create a dedicated and separate track within the code to deal with disinformation generated by Artificial Intelligence. It should aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them. 
Jourová will present her initiative at a press point tomorrow at 11:15 a.m. so could you prepare her talking points and send them to me this evening before closing of the office hours. She has asked to stress the importance of the fight against disinformation in the context of defending democracy and the EU values. 

Many thanks",",

Charles
Head of Unit





What are the most pressing dangers of AI?
As AI systems prove to be increasingly beneficial in real-world applications, they have broadened their reach, causing risks of misuse, overuse, and explicit abuse to proliferate. As AI systems increase in capability and as they are integrated more fully into societal infrastructure, the implications of losing meaningful control over them become more concerning. New research efforts are aimed at re-conceptualizing the foundations of the field to make AI systems less reliant on explicit, and easily mis specified, objectives. A particularly visible danger is that AI can make it easier to build machines that can spy and even kill at scale. But there are many other important and subtler dangers at present.
Techno-Solutionism
One of the most pressing dangers of AI is techno-solutionism, the view that AI can be seen as a panacea when it is merely a tool. As we see more AI advances, the temptation to apply AI decision-making to all societal problems increases. But technology often creates larger problems in the process of solving smaller ones. For example, systems that streamline and automate the application of social services can quickly become rigid and deny access to migrants or others who fall between the cracks. 
When given the choice between algorithms and humans, some believe algorithms will always be the less-biased choice. Yet, in 2018, Amazon found it necessary to discard a proprietary recruiting tool because the historical data it was trained on resulted in a system that was systematically biased against women. Automated decision-making can often serve to replicate, exacerbate, and even magnify the same bias we wish it would remedy.
Indeed, far from being a cure-all, technology can actually create feedback loops that worsen discrimination. Recommendation algorithms, like Google’s page rank, are trained to identify and prioritize the most “relevant” items based on how other users engage with them. As biased users feed the algorithm biased information, it responds with more bias, which informs users’ understandings and deepens their bias, and so on. Because all technology is the product of a biased system, techno-solutionism’s flaws run deep: a creation is limited by the limitations of its creator.
Dangers of Adopting a Statistical Perspective on Justice
Automated decision-making may produce skewed results that replicate and amplify existing biases. A potential danger, then, is when the public accepts AI-derived conclusions as certainties. This determinist approach to AI decision-making can have dire implications in both criminal and healthcare settings. AI-driven approaches like PredPol, software originally developed by the Los Angeles Police Department and UCLA that purports to help protect one in 33 US citizens, predict when, where, and how crime will occur. A 2016 case study of a US city noted that the approach disproportionately projected crimes in areas with higher populations of non-white and low-income residents. When datasets disproportionately represent the lower power members of society, flagrant discrimination is a likely result.
Sentencing decisions are increasingly decided by proprietary algorithms that attempt to assess whether a defendant will commit future crimes, leading to concerns that justice is being outsourced to software. As AI becomes increasingly capable of analyzing more and more factors that may correlate with a defendant's perceived risk, courts and society at large may mistake an algorithmic probability for fact. This dangerous reality means that an algorithmic estimate of an individual’s risk to society may be interpreted by others as a near certainty—a misleading outcome even the original tool designers warned against. Even though a statistically driven AI system could be built to report a degree of credence along with every prediction, there’s no guarantee that the people using these predictions will make intelligent use of them. Taking probability for certainty means that the past will always dictate the future.
There is an aura of neutrality and impartiality associated with AI decision-making in some corners of the public consciousness, resulting in systems being accepted as objective even though they may be the result of biased historical decisions or even blatant discrimination. All data insights rely on some measure of interpretation. As a concrete example, an audit of a resume-screening tool found that the two main factors it associated most strongly with positive future job performance were whether the applicant was named Jared, and whether he played high school lacrosse. Undesirable biases can be hidden behind both the opaque nature of the technology used and the use of proxies, nominally innocent attributes that enable a decision that is fundamentally biased. An algorithm fueled by data in which gender, racial, class, and ableist biases are pervasive can effectively reinforce these biases without ever explicitly identifying them in the code. 
Without transparency concerning either the data or the AI algorithms that interpret it, the public may be left in the dark as to how decisions that materially impact their lives are being made. Lacking adequate information to bring a legal claim, people can lose access to both due process and redress when they feel they have been improperly or erroneously judged by AI systems. Large gaps in case law make applying Title VII—the primary existing legal framework in the US for employment discrimination—to cases of algorithmic discrimination incredibly difficult. These concerns are exacerbated by algorithms that go beyond traditional considerations such as a person’s credit score to instead consider any and all variables correlated to the likelihood that they are a safe investment. A statistically significant correlation has been shown among Europeans between loan risk and whether a person uses a Mac or PC and whether they include their name in their email address—which turn out to be proxies for affluence. Companies that use such attributes, even if they do indeed provide improvements in model accuracy, may be breaking the law when these attributes also clearly correlate with a protected class like race. Loss of autonomy can also result from AI-created “information bubbles” that narrowly constrict each individual’s online experience to the point that they are unaware that valid alternative perspectives even exist.
Disinformation and Threat to Democracy
AI systems are being used in the service of disinformation on the internet, giving them the potential to become a threat to democracy and a tool for fascism. From deepfake videos to online bots manipulating public discourse by feigning consensus and spreading fake news, there is the danger of AI systems undermining social trust. The technology can be co-opted by criminals, rogue states, ideological extremists, or simply special interest groups, to manipulate people for economic gain or political advantage. Disinformation poses serious threats to society, as it effectively changes and manipulates evidence to create social feedback loops that undermine any sense of objective truth. The debates about what is real quickly evolve into debates about who gets to decide what is real, resulting in renegotiations of power structures that often serve entrenched interests. 
Discrimination and Risk in the Medical Setting
While personalized medicine is a good potential application of AI, there are dangers. Current business models for AI-based health applications tend to focus on building a single system—for example, a deterioration predictor—that can be sold to many buyers. However, these systems often do not generalize beyond their training data. Even differences in how clinical tests are ordered can throw off predictors, and, over time, a system’s accuracy will often degrade as practices change. Clinicians and administrators are not well-equipped to monitor and manage these issues, and insufficient thought given to the human factors of AI integration has led to oscillation between mistrust of the system (ignoring it) and over-reliance on the system (trusting it even when it is wrong), a central concern of the 2016 AI100 report.
These concerns are troubling in general in the high-risk setting that is healthcare, and even more so because marginalized populations—those that already face discrimination from the health system from both structural factors (like lack of access) and scientific factors (like guidelines that were developed from trials on other populations)—may lose even more. Today and in the near future, AI systems built on machine learning are used to determine post-operative personalized pain management plans for some patients and in others to predict the likelihood that an individual will develop breast cancer. AI algorithms are playing a role in decisions concerning distributing organs, vaccines, and other elements of healthcare. Biases in these approaches can have literal life-and-death stakes.
In 2019, the story broke that Optum, a health-services algorithm used to determine which patients may benefit from extra medical care, exhibited fundamental racial biases. The system designers ensured that race was precluded from consideration, but they also asked the algorithm to consider the future cost of a patient to the healthcare system. While intended to capture a sense of medical severity, this feature in fact served as a proxy for race: controlling for medical needs, care for Black patients averages $1,800 less per year.
New technologies are being developed every day to treat serious medical issues. A new algorithm trained to identify melanomas was shown to be more accurate than doctors in a recent study, but the potential for the algorithm to be biased against Black patients is significant as the algorithm was trained using majority light-skinned groups. The stakes are especially high for melanoma diagnoses, where the five-year survival rate is 17 percentage points less for Black Americans than white. While technology has the potential to generate quicker diagnoses and thus close this survival gap, a machine-learning algorithm is only as good as its data set. An improperly trained algorithm could do more harm than good for patients at risk, missing cancers altogether or generating false positives. As new algorithms saturate the market with promises of medical miracles, losing sight of the biases ingrained in their outcomes could contribute to a loss of human biodiversity, as individuals who are left out of initial data sets are denied adequate care. While the exact long-term effects of algorithms in healthcare are unknown, their potential for bias replication means any advancement they produce for the population in aggregate—from diagnosis to resource distribution—may come at the expense of the most vulnerable.








Regulatory framework proposal on artificial intelligence 
The Commission is proposing the first-ever legal framework on AI, which addresses the risks of AI and positions Europe to play a leading role globally. 

© gorodenkoff - iStock Getty Images Plus
The regulatory proposal aims to provide AI developers, deployers and users with clear requirements and obligations regarding specific uses of AI. At the same time, the proposal seeks to reduce administrative and financial burdens for business, in particular small and medium-sized enterprises (SMEs).
The proposal is part of a wider AI package, which also includes the updated Coordinated Plan on AI. Together, the Regulatory framework and Coordinated Plan will guarantee the safety and fundamental rights of people and businesses when it comes to AI. And they will strengthen uptake, investment and innovation in AI across the EU.
Why do we need rules on AI?
The proposed AI regulation ensures that Europeans can trust what AI has to offer. While most AI systems pose limited to no risk and can contribute to solving many societal challenges, certain AI systems create risks that we must address to avoid undesirable outcomes.
For example, it is often not possible to find out why an AI system has made a decision or prediction and taken a particular action. So, it may become difficult to assess whether someone has been unfairly disadvantaged, such as in a hiring decision or in an application for a public benefit scheme.
Although existing legislation provides some protection, it is insufficient to address the specific challenges AI systems may bring.
The proposed rules will:
address risks specifically created by AI applications.
propose a list of high-risk applications.
set clear requirements for AI systems for high-risk applications.
define specific obligations for AI users and providers of high-risk applications.
propose a conformity assessment before the AI system is put into service or placed on the market.
propose enforcement after such an AI system is placed in the market.
propose a governance structure at European and national level.
A risk-based approach

The Regulatory Framework defines 4 levels of risk in AI:
Unacceptable risk
High risk
Limited risk
Minimal or no risk
Unacceptable risk
All AI systems considered a clear threat to the safety, livelihoods and rights of people will be banned, from social scoring by governments to toys using voice assistance that encourages dangerous behaviour.
High risk
AI systems identified as high-risk include AI technology used in:
critical infrastructures (e.g., transport), that could put the life and health of citizens at risk.
educational or vocational training, that may determine the access to education and professional course of someone’s life (e.g., scoring of exams).
safety components of products (e.g., AI application in robot-assisted surgery).
employment, management of workers and access to self-employment (e.g., CV-sorting software for recruitment procedures).
essential private and public services (e.g., credit scoring denying citizens opportunity to obtain a loan).
law enforcement that may interfere with people’s fundamental rights (e.g., evaluation of the reliability of evidence).
migration, asylum, and border control management (e.g., verification of authenticity of travel documents).
administration of justice and democratic processes (e.g., applying the law to a concrete set of facts).
High-risk AI systems will be subject to strict obligations before they can be put on the market:
adequate risk assessment and mitigation systems.
high quality of the datasets feeding the system to minimize risks and discriminatory outcomes.
logging of activity to ensure traceability of results.
detailed documentation providing all information necessary on the system and its purpose for authorities to assess its compliance.
clear and adequate information to the user.
appropriate human oversight measures to minimize risk.
high level of robustness, security and accuracy.
All remote biometric identification systems are considered high risk and subject to strict requirements. The use of remote biometric identification in publicly accessible spaces for law enforcement purposes is, in principle, prohibited.
Narrow exceptions are strictly defined and regulated, such as such as when necessary to search for a missing child, to prevent a specific and imminent terrorist threat or to detect, locate, identify, or prosecute a perpetrator or suspect of a serious criminal offence.
Such use is subject to authorization by a judicial or other independent body and to appropriate limits in time, geographic reach and the data bases searched.
Limited risk
Limited risk refers to AI systems with specific transparency obligations. When using AI systems such as chatbots, users should be aware that they are interacting with a machine so they can take an informed decision to continue or step back.
Minimal or no risk
The proposal allows the free use of minimal-risk AI. This includes applications such as AI-enabled video games or spam filters. Most AI systems currently used in the EU fall into this category.



How does it all work in practice for providers of high-risk AI systems?
Once an AI system is on the market, authorities oversee market surveillance, users ensure human oversight and monitoring, and providers have a post-market monitoring system in place. Providers and users will also report serious incidents and malfunctioning.
Future-proof legislation
As AI is a fast-evolving technology, the proposal has a future-proof approach, allowing rules to adapt to technological change. AI applications should remain trustworthy even after they have been placed on the market. This requires ongoing quality and risk management by providers.




The 5 biggest risks of generative AI, according to an expert 
AI makes our lives easier in many different ways. However, these benefits can come with costs. 



Written by Sabrina Ortiz, Associate Editor on April 25, 20XX

Generative AIs, such as ChatGPT, have revolutionized how we interact with and view AI. Activities like writing, coding, and applying for jobs have become much easier and quicker. With all the positives, however, there are some pretty serious risks.
A major concern with AI is trust and security, which has even caused some countries to completely ban ChatGPT as a whole or to reconsider policy around AI to protect users from harm. 
According to Gartner analyst Avivah Litan, some of the biggest risks of generative AI concern trust and security and include hallucinations, deepfakes, data privacy, copyright issues, and cybersecurity problems.
1. Hallucinations
Hallucinations refer to the errors that AI models are prone to make because, although they are advanced, they are still not human and rely on training and data to provide answers. 
If you've used an AI chatbot, then you have probably experienced these hallucinations through a misunderstanding of your prompt or a blatantly wrong answer to your question.
Litan says the training data can lead to biased or factually incorrect responses, which can be a serious problem when people are relying on these bots for information. 
""Training data can lead to biased, off base or wrong responses, but these can be difficult to spot, particularly as solutions are increasingly believable and relied upon,"" says Litan. 
2. Deepfakes
A deepfake uses generative AI to create videos, photos, and voice recordings that are fake but take the image and likeness of another individual. 
Perfect examples are the AI-generated viral photo of Pope Francis in a puffer jacket or the AI-generated Drake and the Weeknd song, which garnered hundreds of thousands of streams. 
""These fake images, videos and voice recordings have been used to attack celebrities and politicians, to create and spread misleading information, and even to create fake accounts or take over and break into existing legitimate accounts,"" says Litan. 
Like hallucinations, deepfakes can contribute to the massive spread of fake content, leading to the spread of misinformation, which is a serious societal problem. 
3. Data privacy
Privacy is also a major concern with generative AI since user data is often stored for model training. This concern was the overarching factor that pushed Italy to ban ChatGPT, claiming OpenAI was not legally authorized to gather user data. 
""Employees can easily expose sensitive and proprietary enterprise data when interacting with generative AI chatbot solutions,"" says Litan. ""These applications may indefinitely store information captured through user inputs, and even use information to train other models -- further compromising confidentiality.""
Litan highlights that, in addition to compromising user confidentiality, the stored information also poses the risk of ""falling into the wrong hands"" in an instance of a security breach.
4. Cybersecurity
The advanced capabilities of generative AI models, such as coding, can also fall into the wrong hands, causing cybersecurity concerns.
""In addition to more advanced social engineering and phishing threats, attackers could use these tools for easier malicious code generation,"" says Litan. 
Litan says even though vendors who offer generative AI solutions typically assure customers that their models are trained to reject malicious cybersecurity requests, these suppliers don't equip end users with the ability to verify all the security measures that have been implemented. 
5. Copyright issues
Copyright is a big concern because generative AI models are trained on massive amounts of internet data that is used to generate an output. 
This process of training means that works that have not been explicitly shared by the original source can then be used to generate new content. 
Copyright is a particularly thorny issue for AI-generated art of any form, including photos and music. 
To create an image from a prompt, AI-generating tools, such as DALL-E, will refer back to the large database of photos they were trained on. The result of this process is that the final product might include aspects of an artist's work or style that are not attributed to them. 
Since the exact works that generative AI models are trained on are not explicitly disclosed, it is hard to mitigate these copyright issues. 
What's next?
Despite the many risks associated to generative AI, Litan doesn't think that organizations should stop exploring the technology. Instead, they should create an enterprise-wide strategy that targets AI trust, risk, and security management. 
""AI developers must urgently work with policymakers, including new regulatory authorities that may emerge, to establish policies and practices for generative AI oversight and risk management,"" says Litan. 
 

What is generative AI?
In simple terms, generative AI is a subfield of artificial intelligence in which computer algorithms are used to generate outputs that resemble human-created content, be it text, images, graphics, music, computer code or otherwise.
In generative AI, algorithms are designed to learn from training data that includes examples of the desired output. By analyzing the patterns and structures within the training data, generative AI models can produce new content that shares characteristics with the original input data. In doing so, generative AI has the capacity to generate content that appears authentic and human-like.
How does generative AI work?
Generative AI is based on machine learning processes inspired by the inner workings of the human brain, known as neural networks. Training the model involves feeding algorithms large amounts of data, which serves as the foundation for the AI model to learn from. This can consist of text, code, graphics, or any other type of content relevant to the task at hand.
Once the training data has been collected, the AI model analyzes the patterns and relationships within the data to understand the underlying rules governing the content. The AI model continuously fine-tunes its parameters as it learns, improving its ability to simulate human-generated content. The more content the AI model generates, the more sophisticated and convincing its outputs become.
Examples of generative AI
Generative AI has made significant advancements in recent years, with several tools capturing the public attention and creating a stir amongst content creators. Big tech companies have also jumped on the bandwagon, with Google, Microsoft, Amazon, and others all lining up their own generative AI tools.
Depending on the application, generative AI tools may rely on an input prompt that guides it towards producing a desired outcome — think ChatGPT and DALL-E 2.
Some of the most notable examples of generative AI tools include:
ChatGPT: Developed by OpenAI, ChatGPT is an AI language model that can generate human-like text based on given prompts.
DALL-E 2: Another generative AI model from OpenAI, DALL-E is designed to create images and artwork based on text-based prompts.
Midjourney: Developed by San Francisco-based research lab Midjourney Inc., Midjourney interprets text prompts and context to produce visual content, like DALL-E 2.
GitHub Copilot: An AI-powered coding tool created by GitHub and OpenAI, GitHub Copilot suggests code completions for users of development environments like Visual Studio and JetBrains.
Benefits of generative AI
The most compelling advantage generative AI proposes is efficiency, in that it can enable businesses to automate specific tasks and focus their time, energy and resources on more important strategic objectives. This often results in lower labor costs and an increase in operational efficiency.
Generative AI can offer additional advantages to businesses and entrepreneurs, including:
Easily customizing or personalizing marketing content.
Generating new ideas, designs, or content.
Writing, checking, and optimizing computer code.
Drafting templates for essays or articles.
Enhancing customer support with chatbots and virtual assistants.
Facilitating data augmentation for machine learning models.
Analyzing data to improve decision-making.
Streamlining research and development processes.
Use cases of generative AI
Despite generative AI still being in its relative infancy, the technology has already found a firm foothold in various applications and industries.
In content creation, for instance, generative AI can produce text, images and even music, assisting marketers, journalists, and artists with their creative processes. In customer support, AI-driven chatbots and virtual assistants can provide more personalized assistance and reduce response times while reducing the burden on customer service agents.
Other uses of generative AI include:
Healthcare: Generative AI is used in medicine to accelerate the discovery of novel drugs, saving time and money in research.
Marketing: Advertisers use generative AI to craft personalized campaigns and adapt content to consumers’ preferences.
Education: Some educators use generative AI models to develop customized learning materials and assessments that cater to students’ individual learning styles.
Finance: Financial analysts use generative AI to examine market patterns and predict stock market trends.
Environment: Climate scientists employ generative AI models to predict weather patterns and simulate the effects of climate change.
Dangers and limitations of generative AI
It’s important to note that generative AI presents numerous issues requiring attention. One major concern is its potential for spreading misinformation or malicious or sensitive content, which could cause profound damage to people and businesses — and potentially pose a threat to national security.
These risks have not escaped policymakers. In April 20XX, the European Union proposed new copyright rules for generative AI that would require companies to disclose any copyrighted material used to develop these tools. Hopes are that such rules will encourage transparency and ethics in AI development, while minimizing any misuse or infringement of intellectual property. This should also offer some protection to content creators whose work may be unwittingly mimicked or plagiarized by generative AI tools.
The automation of tasks by generative AI could also affect the workforce and contribute to job displacement, requiring impacted employees to reskill or upskill. Additionally, generative AI models can unintentionally learn and amplify biases present in training data, leading to problematic outputs that perpetuate stereotypes and harmful ideologies.
ChatGPT, Bing AI and Google Bard have all drawn controversy for producing incorrect or harmful outputs since their launch, and these concerns must be addressed as generative AI evolves, particularly given the difficulty of scrutinizing the sources used to train AI models.
Generative AI vs. general AI
Generative AI and general AI represent different aspects of artificial intelligence. Generative AI focuses on creating new content or ideas based on existing data. It has specific applications and is a subset of AI that excels at solving particular tasks.
General AI, also known as artificial general intelligence, broadly refers to the concept of AI systems that possess human-like intelligence. General AI is still the stuff of science fiction; it represents an imagined future stage of AI development in which computers are able to think, reason and act autonomously.
Is generative AI the future?
It depends on who you ask, but many experts believe that generative AI has a significant role to play in the future of various industries. The capabilities of generative AI have already proven valuable in areas like content creation, software development and healthcare, and as the technology continues to evolve, so too will its applications and use cases.
That said, the future of generative AI is inextricably tied to addressing the potential risks it presents. Ensuring AI is used ethically by minimizing biases, enhancing transparency and accountability and upholding data governance will be critical as the technology progresses. At the same time, striking a balance between automation and human involvement will be crucial for maximizing the benefits of generative AI while mitigating any potential negative consequences on the workforce.






STOCKHOLM, April 27 (Reuters) - Companies deploying generative AI tools, such as ChatGPT, will have to disclose any copyrighted material used to develop their systems, according to an early EU agreement that could pave the way for the world's first comprehensive laws governing the technology.
The European Commission began drafting the AI Act nearly two years ago to regulate emerging artificial intelligence technology, which underwent a boom in investment and popularity following the release of OpenAI's AI-powered chatbot ChatGPT.
Members of the European Parliament agreed to push the draft through to the next stage, the trilogue, during which EU lawmakers and member states will thrash out the final details of the bill.
Under the proposals, AI tools will be classified according to their perceived risk level: from minimal through to limited, high, and unacceptable. Areas of concern could include biometric surveillance, spreading misinformation or discriminatory language.
While high-risk tools will not be banned, those using them will need to be highly transparent in their operations.
Companies deploying generative AI tools, such as ChatGPT or image generator Midjourney, will also have to disclose any copyrighted material used to develop their systems.
This provision was a late addition drawn up within the past two weeks, according to a source familiar with discussions. Some committee members initially proposed banning copyrighted material being used to train generative AI models altogether, the source said, but this was abandoned in favour of a transparency requirement.
""Against conservative wishes for more surveillance and leftist fantasies of over-regulation, parliament found a solid compromise that would regulate AI proportionately, protect citizens' rights, as well as foster innovation and boost the economy,"" said Svenja Hahn, a European Parliament deputy.
Macquarie analyst Fred Havemeyer said the EU's proposal was ""tactful"" rather than a ""ban first, and ask questions later"" approach proposed by some.
""The EU has been on the frontier of regulating AI technology,"" he told Reuters.
RACE TO MARKET
Microsoft-backed (MSFT.O) OpenAI provoked awe and anxiety around the world when it unveiled ChatGPT late last year. The chatbot became the fastest-growing consumer application in history, reaching 100 million monthly active users in a matter of weeks.
The ensuing race among tech companies to bring generative AI products to market concerned some onlookers, with Twitter-owner Elon Musk backing a proposal to halt development of such systems for six months. Shortly after signing the letter, the Financial Times reported Musk was planning to launch his own startup to rival OpenAI.


Sharon Goldman
@sharongoldman

December 5, 20XX-1

The hidden danger of ChatGPT and generative AI | The AI Beat
Since OpenAI launched its early demo of ChatGPT last Wednesday, the tool already has over a million users, according to CEO Sam Altman — a milestone, he points out, that took GPT-3 nearly 24 months to get to and DALL-E over 2 months. 
The “interactive, conversational model,” based on the company’s GPT-3.5 text-generator, certainly has the tech world in full swoon mode. Aaron Levie, CEO of Box, tweeted that “ChatGPT is one of those rare moments in technology where you see a glimmer of how everything is going to be different going forward.” Y Combinator cofounder Paul Graham tweeted that “clearly something big is happening.” Alberto Romero, author of The Algorithmic Bridge, calls it “by far, the best chatbot in the world.” And even Elon Musk weighed in, tweeting that ChatGPT is “scary good. We are not far from dangerously strong AI.” 
But there is a hidden problem lurking within ChatGPT: That is, it quickly spits out eloquent, confident responses that often sound plausible and true even if they are not. 
ChatGPT can sound plausible even if its output is false.
Like other generative large language models, ChatGPT makes up facts. Some call it “hallucination” or “stochastic parroting,” but these models are trained to predict the next word for a given input, not whether a fact is correct or not. 
Some have noted that what sets ChatGPT apart is that it is so darn good at making its hallucinations sound reasonable. 
Technology analyst Benedict Evans, for example, asked ChatGPT to “write a bio for Benedict Evans.” The result, he tweeted, was “plausible, almost entirely untrue.” 
More troubling is the fact that there are obviously an untold number of queries where the user would only know if the answer was untrue if they already knew the answer to the posed question. 
That’s what Arvind Narayanan, a computer science professor at Princeton, pointed out in a tweet: “People are excited about using ChatGPT for learning. It’s often very good. But the danger is that you can’t tell when it’s wrong unless you already know the answer. I tried some basic information security questions. In most cases the answers sounded plausible but were in fact BS.” 
Fact-checking generative AI
Back in the waning days of print magazines in the 2000s, I spent several years as a fact-checker for publications including GQ and Rolling Stone. Each fact had to include authoritative primary or secondary sources — and Wikipedia was frowned upon. 
Few publications have staff fact-checkers anymore, which puts the onus on reporters and editors to make sure they get their facts straight — especially at a time when misinformation already moves like lightning across social media, while search engines are constantly under pressure to surface verifiable information and not BS. 
That’s certainly why Stack Overflow, the Q&A site for coders and programmers, has temporarily banned users from sharing ChatGPT responses. 
And if StackOverflow can’t keep up with misinformation due to AI, it’s hard to imagine others being able to manage a tsunami of potential AI-driven BS. As Gary Marcus tweeted, “If StackOverflow can’t keep up with plausible but incorrect information, what about social media and search engines?” 
And while many are salivating at the idea that LLMs like ChatGPT could someday replace traditional search engines, others are strongly pushing back. 
Emily Bender, professor of linguistics at the University of Washington, has long pushed back on this notion. 
She recently emphasized again that LLMs are “not fit” for search —” both because they are designed to just make sh** up and because they don’t support information literacy.” She pointed to a paper she co-authored on the topic published in March. 
Is it better for ChatGPT to look right? Or be right? 
BS is obviously something that humans have perfected over the centuries. And ChatGPT and other large language models have no idea what it means, really, to “BS.” But OpenAI made this weakness very clear in its blog announcing the demo and explained that fixing it is “challenging,” saying: 
“ChatGPT sometimes writes plausible sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: (1) during RL [reinforcement learning] training, there’s currently no source of truth; (2) training the model to be more cautious causes it to decline questions that it can answer correctly; and (3) supervised training misleads the model because the ideal answer depends on what the model knows, rather than what the human demonstrator knows.” 
So, it’s clear that OpenAI knows perfectly well that ChatGPT is filled with BS under the surface. They never meant the technology to offer up a source of truth. 
But the question is: Are human users okay with that? 
Unfortunately, they might be. If it sounds good, many humans may think that’s good enough. And, perhaps, that’s where the real danger lies beneath the surface of ChatGPT. 





By JAKOB HANKE VELA
Send tips here | Tweet @HankeVela | Listen to Playbook and view in your browser
LABELING AI CONTENT        
TODAY: EU PUSHES FOR ‘AI LABEL’ TO FIGHT DEEPFAKES: Brussels wants to prevent artificial intelligence from blurring the lines between fact and fiction — and will today ask companies for the first time ever to come up with a label to identify AI-generated texts and images to fight disinformation, officials tell Playbook.
Brave new world: Generative AI is making breathtaking advances — from writing texts and code to creating ever more realistic pictures and videos — which will have enormous consequences not just for the future of society and work, but for politics, Commission officials reckon. 
Balenc-ai-ga: The fake images of the Pope and famous politicians wearing a Balenciaga coat that went viral earlier this year have clearly spooked them — and they now want to label such deepfakes.
Fake porn: “Today it is mostly still a game, but tomorrow you could see a fake porn with a candidate,” one official who is working on the file but was not authorized to speak on the record told Playbook, referring to AI-generated images of politicians. 
Race to regulate: The Commission (the EU’s executive, which proposes and enforces laws) — has proposed an AI Act to regulate high-risk applications and ban the most dangerous ones. But even before that act enters into force, the Commission will urge industry to cut down on trickery by labeling AI-generated work.
Happening today: Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton will meet representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation. They include Microsoft, Google, Meta, TikTok, Twitch and smaller companies — but not Twitter, which has left the code — as well as NGOs.
Disinformation risks: “I will ask the signatories to create a dedicated and separate track within the code” to deal with disinformation generated by Artificial Intelligence, Jourová told Playbook. “It should … aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them.”
EU pushes for safeguards: How does Brussels want the companies to tackle the risks? “Signatories who integrate generative AI into their services like Bingchat for Microsoft, Bard for Google should build in necessary safeguards that these services cannot be used by malicious actors to generate disinformation,” Jourová said.
Clear labels: “Signatories who have services with a potential to disseminate AI-generated disinformation should in turn put in place technology to recognize such content and clearly label this to users.”
More about this label: Two officials working on the file told Playbook the label should apply to all AI-generated material that can be used to create disinformation, including text, images, audio and video.
Voluntary — for now: It wouldn’t be mandatory, given that it would be part of the voluntary Code of Practice. However, the Commission aims to make the code enforceable by including it as a code of conduct in the Digital Services Act (DSA). Obligations on labeling AI content may also make it into the AI Act during negotiations between EU countries, Parliament, and the Commission, one official said.
How can companies do this? “They can develop, and they probably already have tools to check whether an image was AI-generated or not,” the first official said.
Playbook wonders: Given how easy it is for AI to proliferate across jurisdictions, will such a technology ever be able to identify all deepfakes — or won’t we, on the contrary, one day need some chain of custody procedure for authentic images that can be used, for example, as evidence in court?
Stay tuned: Jourová will present her initiative at a press point tomorrow at 11:15 a.m.
SPEAKING OF WHICH: While the Commission is calling on others to do more, it was recently reported that it awarded and signed a €3.7 million tender to help analyze issues like disinformation, foreign meddling in elections and global threats from a French firm that’s mired in controversy.
Avisa Partners has previously been accused of manipulating information in France and working for authoritarian regimes. The company was recently at the center of a controversy as the organizer of a cybersecurity forum boycotted by the French armed forces ministry and several government officials. More here for our Pro Cybersecurity subscribers.
Looking into this: The Commission is looking into the allegations and “is in contact with French counterparts to seek more clarity on those claim[s],” Peter Stano, the Commission’s spokesperson for foreign affairs and security policy, told my POLITICO Pro Technology colleagues. The EU executive is “closely monitoring the implementation of this project,” he added. 
Jean Tillinac, from Avisa Partners, told my Pro Tech colleagues that the bid was “defended by a team of seasoned experts from our Strategic Intelligence Division” doing research and which was different from the “Digital Communications Division” facing criticism.



Annex I – Glossary of Terms
Algorithm: a formula given to a computer for it to complete a task (i.e., a set of rules for a computer) 
Artificial intelligence: a subset of computer science that deals with computer systems performing tasks with similar, equal, or superior intelligence to that of a human (e.g., decision-making, object classification and detection, speech recognition and translation)
Artificial general intelligence (AGI): also known as strong AI, AGI is a type of artificial intelligence that is considered human-like, and still in its preliminary stages (more of a hypothetical existence in present day)
Artificial narrow intelligence (ANI): also known as weak AI, ANI is a type of artificial intelligence that can only focus on one task or problem at a given time (e.g., playing a game against a human competitor). This is the current existing form of AI.
Artificial neural network (ANN): a network modeled after the human brain by creating an artificial neural system via a pattern-recognizing computer algorithm that learns from, interprets, and classifies sensory data.
Big data: large amounts of structured and unstructured data that is too complex to be handled by standard data-processing software.
Chatbots: a chat robot that can converse with a human user through text or voice commands. Utilized by e-commerce, education, health, and business industries for ease of communication and to answer user questions. 
Cognitive computing: computerized model that mimics human thought processes by data mining, NLP, and pattern recognition.
Computer vision: when a machine processes visual input from image files (JPEGs) or camera feeds
Data mining: the process of sorting through large sets of data to identify recurring patterns while establishing problem-solving relationships.
Deep learning: a machine learning technique that teaches computers how to learn by rote (i.e., machines mimic learning as a human mind would, by using classification techniques)
Generative AI: Generative artificial intelligence or generative AI is a type of artificial intelligence (AI) system capable of generating text, images, or other media in response to prompts. Generative AI models learn the patterns and structure of their input training data, and then generate new data that has similar characteristics. 
Genetic algorithm: an algorithm based on principles of genetics that is used to find solutions efficiently and quickly to difficult problems.
Machine learning (ML): focuses on developing programs that access and use data on their own, leading machines to learn for themselves and improve from learned experiences.
Natural language processing (NLP): helps computers process, interpret, and analyze human language and its characteristics by using natural language data. 
Pattern recognition: automated recognition of patterns found in data.
Reinforcement learning: a machine learning method where the reinforcement algorithm learns by interacting with its environment and is then penalized or rewarded based on decisions it makes.
Strong AI: see artificial general intelligence (AGI)  
Structured data: clearly defined data with easily searchable patterns.
Supervised learning: a type of machine learning where output datasets teach machines to generate desired outcomes or algorithms (akin to a teacher-student relationship).
Transfer learning: a system that uses previously learned data and applies it to a new set of tasks.
Turing Test: a test created by computer scientist Alan Turing (1950) to see if machines could exhibit intelligence equal to or indistinguishable from that of a human.
Unstructured data: data without easily searchable patterns (e.g., audio, video, social media content)
Unsupervised learning: a type of machine learning where an algorithm is trained with information that is neither classified nor labeled, thus allowing the algorithm to act without guidance.",18,7.0,"Summary
According to the Notice of Competitions of current EPSO competitions, the only competency that will be assessed in the Case Study exam is Written Communication",7.0,"Observations
The author adequately manages the central theme revolving around the advantages and challenges of Generative Artificial Intelligence is apparent, although it could be strengthened with an explicit thesis statement.

The central message—that GAI has both benefits and associated risks—is communicated clearly.

The flow of the document generally makes sense but can benefit from clear sections like an Introduction, recommendations and Conclusions, to provide better framing and summary.

The layout is straightforward but could be more visually engaging with the inclusion of headers or bullet points for easier scanning.

The document lacks adequate titles and subtitles to guide the reader through the various sections.

The tone is informative and seems geared towards a general audience.

The language is relatively uncomplicated, but the document could benefit from a slight simplification to make it even more accessible.

There doesn't appear to be any overt bias in the document, as it covers both the positive and negative aspects of GAI.

The document does not have a clearly titled ""Introduction"" section.
There is no section explicitly titled ""Recommendations,"" although the text does offer some suggestions on how to address GAI’s challenges.
There is no section titled ""Conclusions.""

There are few if any supporting statistics mentioned in the text, which could have added more weight to the arguments made.

The text does mention the EU while discussing upcoming legislation related to GAI, but it does not mention specific EU member states.

The text does not contain information on Non-EU countries.

English spelling mistakes:
""healthacre"" should be ""healthcare""


Some English grammar mistakes:
""like this they can systematically improve"" should be ""in this way, they can systematically improve""
""Rely on GAI without human surveillance is also a risk"" should be ""Relying on GAI without human surveillance is also a risk""
""there is risk that GAI uses"" should be ""there is a risk that GAI may use""",,Tips to Improve,"Trainee's Answer
SPEAKING NOTE ON GENERATIVE ARTIFICIAL INTELLIGENCE (GAI)
GAI AND ITS POTENTIAL BENEFITS
What is GAI?
GAI is a type of Artificial Intelligence (AI) in which algorithms are used to create content that seems human created such as text, graphs or music.
GAI algorithms are designed to learn from the data they receive, like this they can systematically improve the quality of their outputs. The more data they receive the better outputs they produce. 
Potential Benefits of GAI
Companies will have the opportunity to use GAI to carry out simple and repetitive tasks, allowing their staff to focus on more strategic and creative tasks.
Another potential benefit of GAI would be an improvement in the quality of certain social services such as healthcare or education. Through GAI, healthacre would see the research on new drugs significantly improved and Education could benefit from improved training materials.
DANGERS ASSOCIATED WITH  GAI AND HOW TO ADDRESS THEM
Despite the potential benefits mentioned above, GAI poses serious dangers that should be closely monitored: 
- The capacity of GAI to generate images that seem real, known as deepfakes, poses a serious danger since they could be easily used to spread misinformation. The widespread of deepfakes through social media could, for example, have an impact in electoral processes, posing a threat to social stability and democracy.
- Rely on GAI without human surveillance is also a risk, since GAI could create content that is biased and discriminatory to sexual and racial minorities. 
HOW TO ADDRESS THESE DANGERS
First of all, there is a need for transparency in GAI in order to ensure that its algorithms produce contents that are socially acceptable and inclusive.
Secondly, there is risk that GAI uses materials that are protected by copyright to generate content. For this reason, the EU is already preparing a legislation to ensure that GAI discloses any copyright material used.
Lastly, there is a need to raise awareness among population about GAI, its benefits but also the threats that it implies. A population who is aware of the dangers of GAI, and has the capacity to easily identify it would be a shield against its malicious use."
3,0_Generative AI (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. 

Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG CONNECT in the unit in charge of fighting against disinformation.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Critical thinking, analysing & creative problem-solving, Decision-making and getting results, Information management,  Communication.

Specifically, your task will be to draft a 2 to 2.5 - page speaking note for the Commisioner to clarify the intentions of the Commission with respect to generative AI (GAI). This document must include: 

What is GAI and what are the potential benefits.
What are the dangers associated with GAI and how does the EU want to address them.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations

AI - Artificial intelligence
AIA – Artificial Intelligence Act
AGI - Artificial general intelligence 
ANI - Artificial narrow intelligence
ANN - Artificial neural network
DSA – Digital Services Act
GAI – Generative AI
ML - Machine learning
NLP - Natural language processing


EMAIL 1","Subject: Press Release on generative AI

Dear YOU,

Earlier today, Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton met with representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation.
Jourová asked the signatories to create a dedicated and separate track within the code to deal with disinformation generated by Artificial Intelligence. It should aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them. 
Jourová will present her initiative at a press point tomorrow at 11:15 a.m. so could you prepare her talking points and send them to me this evening before closing of the office hours. She has asked to stress the importance of the fight against disinformation in the context of defending democracy and the EU values. 

Many thanks",",

Charles
Head of Unit





What are the most pressing dangers of AI?
As AI systems prove to be increasingly beneficial in real-world applications, they have broadened their reach, causing risks of misuse, overuse, and explicit abuse to proliferate. As AI systems increase in capability and as they are integrated more fully into societal infrastructure, the implications of losing meaningful control over them become more concerning. New research efforts are aimed at re-conceptualizing the foundations of the field to make AI systems less reliant on explicit, and easily mis specified, objectives. A particularly visible danger is that AI can make it easier to build machines that can spy and even kill at scale. But there are many other important and subtler dangers at present.
Techno-Solutionism
One of the most pressing dangers of AI is techno-solutionism, the view that AI can be seen as a panacea when it is merely a tool. As we see more AI advances, the temptation to apply AI decision-making to all societal problems increases. But technology often creates larger problems in the process of solving smaller ones. For example, systems that streamline and automate the application of social services can quickly become rigid and deny access to migrants or others who fall between the cracks. 
When given the choice between algorithms and humans, some believe algorithms will always be the less-biased choice. Yet, in 2018, Amazon found it necessary to discard a proprietary recruiting tool because the historical data it was trained on resulted in a system that was systematically biased against women. Automated decision-making can often serve to replicate, exacerbate, and even magnify the same bias we wish it would remedy.
Indeed, far from being a cure-all, technology can actually create feedback loops that worsen discrimination. Recommendation algorithms, like Google’s page rank, are trained to identify and prioritize the most “relevant” items based on how other users engage with them. As biased users feed the algorithm biased information, it responds with more bias, which informs users’ understandings and deepens their bias, and so on. Because all technology is the product of a biased system, techno-solutionism’s flaws run deep: a creation is limited by the limitations of its creator.
Dangers of Adopting a Statistical Perspective on Justice
Automated decision-making may produce skewed results that replicate and amplify existing biases. A potential danger, then, is when the public accepts AI-derived conclusions as certainties. This determinist approach to AI decision-making can have dire implications in both criminal and healthcare settings. AI-driven approaches like PredPol, software originally developed by the Los Angeles Police Department and UCLA that purports to help protect one in 33 US citizens, predict when, where, and how crime will occur. A 2016 case study of a US city noted that the approach disproportionately projected crimes in areas with higher populations of non-white and low-income residents. When datasets disproportionately represent the lower power members of society, flagrant discrimination is a likely result.
Sentencing decisions are increasingly decided by proprietary algorithms that attempt to assess whether a defendant will commit future crimes, leading to concerns that justice is being outsourced to software. As AI becomes increasingly capable of analyzing more and more factors that may correlate with a defendant's perceived risk, courts and society at large may mistake an algorithmic probability for fact. This dangerous reality means that an algorithmic estimate of an individual’s risk to society may be interpreted by others as a near certainty—a misleading outcome even the original tool designers warned against. Even though a statistically driven AI system could be built to report a degree of credence along with every prediction, there’s no guarantee that the people using these predictions will make intelligent use of them. Taking probability for certainty means that the past will always dictate the future.
There is an aura of neutrality and impartiality associated with AI decision-making in some corners of the public consciousness, resulting in systems being accepted as objective even though they may be the result of biased historical decisions or even blatant discrimination. All data insights rely on some measure of interpretation. As a concrete example, an audit of a resume-screening tool found that the two main factors it associated most strongly with positive future job performance were whether the applicant was named Jared, and whether he played high school lacrosse. Undesirable biases can be hidden behind both the opaque nature of the technology used and the use of proxies, nominally innocent attributes that enable a decision that is fundamentally biased. An algorithm fueled by data in which gender, racial, class, and ableist biases are pervasive can effectively reinforce these biases without ever explicitly identifying them in the code. 
Without transparency concerning either the data or the AI algorithms that interpret it, the public may be left in the dark as to how decisions that materially impact their lives are being made. Lacking adequate information to bring a legal claim, people can lose access to both due process and redress when they feel they have been improperly or erroneously judged by AI systems. Large gaps in case law make applying Title VII—the primary existing legal framework in the US for employment discrimination—to cases of algorithmic discrimination incredibly difficult. These concerns are exacerbated by algorithms that go beyond traditional considerations such as a person’s credit score to instead consider any and all variables correlated to the likelihood that they are a safe investment. A statistically significant correlation has been shown among Europeans between loan risk and whether a person uses a Mac or PC and whether they include their name in their email address—which turn out to be proxies for affluence. Companies that use such attributes, even if they do indeed provide improvements in model accuracy, may be breaking the law when these attributes also clearly correlate with a protected class like race. Loss of autonomy can also result from AI-created “information bubbles” that narrowly constrict each individual’s online experience to the point that they are unaware that valid alternative perspectives even exist.
Disinformation and Threat to Democracy
AI systems are being used in the service of disinformation on the internet, giving them the potential to become a threat to democracy and a tool for fascism. From deepfake videos to online bots manipulating public discourse by feigning consensus and spreading fake news, there is the danger of AI systems undermining social trust. The technology can be co-opted by criminals, rogue states, ideological extremists, or simply special interest groups, to manipulate people for economic gain or political advantage. Disinformation poses serious threats to society, as it effectively changes and manipulates evidence to create social feedback loops that undermine any sense of objective truth. The debates about what is real quickly evolve into debates about who gets to decide what is real, resulting in renegotiations of power structures that often serve entrenched interests. 
Discrimination and Risk in the Medical Setting
While personalized medicine is a good potential application of AI, there are dangers. Current business models for AI-based health applications tend to focus on building a single system—for example, a deterioration predictor—that can be sold to many buyers. However, these systems often do not generalize beyond their training data. Even differences in how clinical tests are ordered can throw off predictors, and, over time, a system’s accuracy will often degrade as practices change. Clinicians and administrators are not well-equipped to monitor and manage these issues, and insufficient thought given to the human factors of AI integration has led to oscillation between mistrust of the system (ignoring it) and over-reliance on the system (trusting it even when it is wrong), a central concern of the 2016 AI100 report.
These concerns are troubling in general in the high-risk setting that is healthcare, and even more so because marginalized populations—those that already face discrimination from the health system from both structural factors (like lack of access) and scientific factors (like guidelines that were developed from trials on other populations)—may lose even more. Today and in the near future, AI systems built on machine learning are used to determine post-operative personalized pain management plans for some patients and in others to predict the likelihood that an individual will develop breast cancer. AI algorithms are playing a role in decisions concerning distributing organs, vaccines, and other elements of healthcare. Biases in these approaches can have literal life-and-death stakes.
In 2019, the story broke that Optum, a health-services algorithm used to determine which patients may benefit from extra medical care, exhibited fundamental racial biases. The system designers ensured that race was precluded from consideration, but they also asked the algorithm to consider the future cost of a patient to the healthcare system. While intended to capture a sense of medical severity, this feature in fact served as a proxy for race: controlling for medical needs, care for Black patients averages $1,800 less per year.
New technologies are being developed every day to treat serious medical issues. A new algorithm trained to identify melanomas was shown to be more accurate than doctors in a recent study, but the potential for the algorithm to be biased against Black patients is significant as the algorithm was trained using majority light-skinned groups. The stakes are especially high for melanoma diagnoses, where the five-year survival rate is 17 percentage points less for Black Americans than white. While technology has the potential to generate quicker diagnoses and thus close this survival gap, a machine-learning algorithm is only as good as its data set. An improperly trained algorithm could do more harm than good for patients at risk, missing cancers altogether or generating false positives. As new algorithms saturate the market with promises of medical miracles, losing sight of the biases ingrained in their outcomes could contribute to a loss of human biodiversity, as individuals who are left out of initial data sets are denied adequate care. While the exact long-term effects of algorithms in healthcare are unknown, their potential for bias replication means any advancement they produce for the population in aggregate—from diagnosis to resource distribution—may come at the expense of the most vulnerable.








Regulatory framework proposal on artificial intelligence 
The Commission is proposing the first-ever legal framework on AI, which addresses the risks of AI and positions Europe to play a leading role globally. 

© gorodenkoff - iStock Getty Images Plus
The regulatory proposal aims to provide AI developers, deployers and users with clear requirements and obligations regarding specific uses of AI. At the same time, the proposal seeks to reduce administrative and financial burdens for business, in particular small and medium-sized enterprises (SMEs).
The proposal is part of a wider AI package, which also includes the updated Coordinated Plan on AI. Together, the Regulatory framework and Coordinated Plan will guarantee the safety and fundamental rights of people and businesses when it comes to AI. And they will strengthen uptake, investment and innovation in AI across the EU.
Why do we need rules on AI?
The proposed AI regulation ensures that Europeans can trust what AI has to offer. While most AI systems pose limited to no risk and can contribute to solving many societal challenges, certain AI systems create risks that we must address to avoid undesirable outcomes.
For example, it is often not possible to find out why an AI system has made a decision or prediction and taken a particular action. So, it may become difficult to assess whether someone has been unfairly disadvantaged, such as in a hiring decision or in an application for a public benefit scheme.
Although existing legislation provides some protection, it is insufficient to address the specific challenges AI systems may bring.
The proposed rules will:
address risks specifically created by AI applications.
propose a list of high-risk applications.
set clear requirements for AI systems for high-risk applications.
define specific obligations for AI users and providers of high-risk applications.
propose a conformity assessment before the AI system is put into service or placed on the market.
propose enforcement after such an AI system is placed in the market.
propose a governance structure at European and national level.
A risk-based approach

The Regulatory Framework defines 4 levels of risk in AI:
Unacceptable risk
High risk
Limited risk
Minimal or no risk
Unacceptable risk
All AI systems considered a clear threat to the safety, livelihoods and rights of people will be banned, from social scoring by governments to toys using voice assistance that encourages dangerous behaviour.
High risk
AI systems identified as high-risk include AI technology used in:
critical infrastructures (e.g., transport), that could put the life and health of citizens at risk.
educational or vocational training, that may determine the access to education and professional course of someone’s life (e.g., scoring of exams).
safety components of products (e.g., AI application in robot-assisted surgery).
employment, management of workers and access to self-employment (e.g., CV-sorting software for recruitment procedures).
essential private and public services (e.g., credit scoring denying citizens opportunity to obtain a loan).
law enforcement that may interfere with people’s fundamental rights (e.g., evaluation of the reliability of evidence).
migration, asylum, and border control management (e.g., verification of authenticity of travel documents).
administration of justice and democratic processes (e.g., applying the law to a concrete set of facts).
High-risk AI systems will be subject to strict obligations before they can be put on the market:
adequate risk assessment and mitigation systems.
high quality of the datasets feeding the system to minimize risks and discriminatory outcomes.
logging of activity to ensure traceability of results.
detailed documentation providing all information necessary on the system and its purpose for authorities to assess its compliance.
clear and adequate information to the user.
appropriate human oversight measures to minimize risk.
high level of robustness, security and accuracy.
All remote biometric identification systems are considered high risk and subject to strict requirements. The use of remote biometric identification in publicly accessible spaces for law enforcement purposes is, in principle, prohibited.
Narrow exceptions are strictly defined and regulated, such as such as when necessary to search for a missing child, to prevent a specific and imminent terrorist threat or to detect, locate, identify, or prosecute a perpetrator or suspect of a serious criminal offence.
Such use is subject to authorization by a judicial or other independent body and to appropriate limits in time, geographic reach and the data bases searched.
Limited risk
Limited risk refers to AI systems with specific transparency obligations. When using AI systems such as chatbots, users should be aware that they are interacting with a machine so they can take an informed decision to continue or step back.
Minimal or no risk
The proposal allows the free use of minimal-risk AI. This includes applications such as AI-enabled video games or spam filters. Most AI systems currently used in the EU fall into this category.



How does it all work in practice for providers of high-risk AI systems?
Once an AI system is on the market, authorities oversee market surveillance, users ensure human oversight and monitoring, and providers have a post-market monitoring system in place. Providers and users will also report serious incidents and malfunctioning.
Future-proof legislation
As AI is a fast-evolving technology, the proposal has a future-proof approach, allowing rules to adapt to technological change. AI applications should remain trustworthy even after they have been placed on the market. This requires ongoing quality and risk management by providers.




The 5 biggest risks of generative AI, according to an expert 
AI makes our lives easier in many different ways. However, these benefits can come with costs. 



Written by Sabrina Ortiz, Associate Editor on April 25, 20XX

Generative AIs, such as ChatGPT, have revolutionized how we interact with and view AI. Activities like writing, coding, and applying for jobs have become much easier and quicker. With all the positives, however, there are some pretty serious risks.
A major concern with AI is trust and security, which has even caused some countries to completely ban ChatGPT as a whole or to reconsider policy around AI to protect users from harm. 
According to Gartner analyst Avivah Litan, some of the biggest risks of generative AI concern trust and security and include hallucinations, deepfakes, data privacy, copyright issues, and cybersecurity problems.
1. Hallucinations
Hallucinations refer to the errors that AI models are prone to make because, although they are advanced, they are still not human and rely on training and data to provide answers. 
If you've used an AI chatbot, then you have probably experienced these hallucinations through a misunderstanding of your prompt or a blatantly wrong answer to your question.
Litan says the training data can lead to biased or factually incorrect responses, which can be a serious problem when people are relying on these bots for information. 
""Training data can lead to biased, off base or wrong responses, but these can be difficult to spot, particularly as solutions are increasingly believable and relied upon,"" says Litan. 
2. Deepfakes
A deepfake uses generative AI to create videos, photos, and voice recordings that are fake but take the image and likeness of another individual. 
Perfect examples are the AI-generated viral photo of Pope Francis in a puffer jacket or the AI-generated Drake and the Weeknd song, which garnered hundreds of thousands of streams. 
""These fake images, videos and voice recordings have been used to attack celebrities and politicians, to create and spread misleading information, and even to create fake accounts or take over and break into existing legitimate accounts,"" says Litan. 
Like hallucinations, deepfakes can contribute to the massive spread of fake content, leading to the spread of misinformation, which is a serious societal problem. 
3. Data privacy
Privacy is also a major concern with generative AI since user data is often stored for model training. This concern was the overarching factor that pushed Italy to ban ChatGPT, claiming OpenAI was not legally authorized to gather user data. 
""Employees can easily expose sensitive and proprietary enterprise data when interacting with generative AI chatbot solutions,"" says Litan. ""These applications may indefinitely store information captured through user inputs, and even use information to train other models -- further compromising confidentiality.""
Litan highlights that, in addition to compromising user confidentiality, the stored information also poses the risk of ""falling into the wrong hands"" in an instance of a security breach.
4. Cybersecurity
The advanced capabilities of generative AI models, such as coding, can also fall into the wrong hands, causing cybersecurity concerns.
""In addition to more advanced social engineering and phishing threats, attackers could use these tools for easier malicious code generation,"" says Litan. 
Litan says even though vendors who offer generative AI solutions typically assure customers that their models are trained to reject malicious cybersecurity requests, these suppliers don't equip end users with the ability to verify all the security measures that have been implemented. 
5. Copyright issues
Copyright is a big concern because generative AI models are trained on massive amounts of internet data that is used to generate an output. 
This process of training means that works that have not been explicitly shared by the original source can then be used to generate new content. 
Copyright is a particularly thorny issue for AI-generated art of any form, including photos and music. 
To create an image from a prompt, AI-generating tools, such as DALL-E, will refer back to the large database of photos they were trained on. The result of this process is that the final product might include aspects of an artist's work or style that are not attributed to them. 
Since the exact works that generative AI models are trained on are not explicitly disclosed, it is hard to mitigate these copyright issues. 
What's next?
Despite the many risks associated to generative AI, Litan doesn't think that organizations should stop exploring the technology. Instead, they should create an enterprise-wide strategy that targets AI trust, risk, and security management. 
""AI developers must urgently work with policymakers, including new regulatory authorities that may emerge, to establish policies and practices for generative AI oversight and risk management,"" says Litan. 
 

What is generative AI?
In simple terms, generative AI is a subfield of artificial intelligence in which computer algorithms are used to generate outputs that resemble human-created content, be it text, images, graphics, music, computer code or otherwise.
In generative AI, algorithms are designed to learn from training data that includes examples of the desired output. By analyzing the patterns and structures within the training data, generative AI models can produce new content that shares characteristics with the original input data. In doing so, generative AI has the capacity to generate content that appears authentic and human-like.
How does generative AI work?
Generative AI is based on machine learning processes inspired by the inner workings of the human brain, known as neural networks. Training the model involves feeding algorithms large amounts of data, which serves as the foundation for the AI model to learn from. This can consist of text, code, graphics, or any other type of content relevant to the task at hand.
Once the training data has been collected, the AI model analyzes the patterns and relationships within the data to understand the underlying rules governing the content. The AI model continuously fine-tunes its parameters as it learns, improving its ability to simulate human-generated content. The more content the AI model generates, the more sophisticated and convincing its outputs become.
Examples of generative AI
Generative AI has made significant advancements in recent years, with several tools capturing the public attention and creating a stir amongst content creators. Big tech companies have also jumped on the bandwagon, with Google, Microsoft, Amazon, and others all lining up their own generative AI tools.
Depending on the application, generative AI tools may rely on an input prompt that guides it towards producing a desired outcome — think ChatGPT and DALL-E 2.
Some of the most notable examples of generative AI tools include:
ChatGPT: Developed by OpenAI, ChatGPT is an AI language model that can generate human-like text based on given prompts.
DALL-E 2: Another generative AI model from OpenAI, DALL-E is designed to create images and artwork based on text-based prompts.
Midjourney: Developed by San Francisco-based research lab Midjourney Inc., Midjourney interprets text prompts and context to produce visual content, like DALL-E 2.
GitHub Copilot: An AI-powered coding tool created by GitHub and OpenAI, GitHub Copilot suggests code completions for users of development environments like Visual Studio and JetBrains.
Benefits of generative AI
The most compelling advantage generative AI proposes is efficiency, in that it can enable businesses to automate specific tasks and focus their time, energy and resources on more important strategic objectives. This often results in lower labor costs and an increase in operational efficiency.
Generative AI can offer additional advantages to businesses and entrepreneurs, including:
Easily customizing or personalizing marketing content.
Generating new ideas, designs, or content.
Writing, checking, and optimizing computer code.
Drafting templates for essays or articles.
Enhancing customer support with chatbots and virtual assistants.
Facilitating data augmentation for machine learning models.
Analyzing data to improve decision-making.
Streamlining research and development processes.
Use cases of generative AI
Despite generative AI still being in its relative infancy, the technology has already found a firm foothold in various applications and industries.
In content creation, for instance, generative AI can produce text, images and even music, assisting marketers, journalists, and artists with their creative processes. In customer support, AI-driven chatbots and virtual assistants can provide more personalized assistance and reduce response times while reducing the burden on customer service agents.
Other uses of generative AI include:
Healthcare: Generative AI is used in medicine to accelerate the discovery of novel drugs, saving time and money in research.
Marketing: Advertisers use generative AI to craft personalized campaigns and adapt content to consumers’ preferences.
Education: Some educators use generative AI models to develop customized learning materials and assessments that cater to students’ individual learning styles.
Finance: Financial analysts use generative AI to examine market patterns and predict stock market trends.
Environment: Climate scientists employ generative AI models to predict weather patterns and simulate the effects of climate change.
Dangers and limitations of generative AI
It’s important to note that generative AI presents numerous issues requiring attention. One major concern is its potential for spreading misinformation or malicious or sensitive content, which could cause profound damage to people and businesses — and potentially pose a threat to national security.
These risks have not escaped policymakers. In April 20XX, the European Union proposed new copyright rules for generative AI that would require companies to disclose any copyrighted material used to develop these tools. Hopes are that such rules will encourage transparency and ethics in AI development, while minimizing any misuse or infringement of intellectual property. This should also offer some protection to content creators whose work may be unwittingly mimicked or plagiarized by generative AI tools.
The automation of tasks by generative AI could also affect the workforce and contribute to job displacement, requiring impacted employees to reskill or upskill. Additionally, generative AI models can unintentionally learn and amplify biases present in training data, leading to problematic outputs that perpetuate stereotypes and harmful ideologies.
ChatGPT, Bing AI and Google Bard have all drawn controversy for producing incorrect or harmful outputs since their launch, and these concerns must be addressed as generative AI evolves, particularly given the difficulty of scrutinizing the sources used to train AI models.
Generative AI vs. general AI
Generative AI and general AI represent different aspects of artificial intelligence. Generative AI focuses on creating new content or ideas based on existing data. It has specific applications and is a subset of AI that excels at solving particular tasks.
General AI, also known as artificial general intelligence, broadly refers to the concept of AI systems that possess human-like intelligence. General AI is still the stuff of science fiction; it represents an imagined future stage of AI development in which computers are able to think, reason and act autonomously.
Is generative AI the future?
It depends on who you ask, but many experts believe that generative AI has a significant role to play in the future of various industries. The capabilities of generative AI have already proven valuable in areas like content creation, software development and healthcare, and as the technology continues to evolve, so too will its applications and use cases.
That said, the future of generative AI is inextricably tied to addressing the potential risks it presents. Ensuring AI is used ethically by minimizing biases, enhancing transparency and accountability and upholding data governance will be critical as the technology progresses. At the same time, striking a balance between automation and human involvement will be crucial for maximizing the benefits of generative AI while mitigating any potential negative consequences on the workforce.






STOCKHOLM, April 27 (Reuters) - Companies deploying generative AI tools, such as ChatGPT, will have to disclose any copyrighted material used to develop their systems, according to an early EU agreement that could pave the way for the world's first comprehensive laws governing the technology.
The European Commission began drafting the AI Act nearly two years ago to regulate emerging artificial intelligence technology, which underwent a boom in investment and popularity following the release of OpenAI's AI-powered chatbot ChatGPT.
Members of the European Parliament agreed to push the draft through to the next stage, the trilogue, during which EU lawmakers and member states will thrash out the final details of the bill.
Under the proposals, AI tools will be classified according to their perceived risk level: from minimal through to limited, high, and unacceptable. Areas of concern could include biometric surveillance, spreading misinformation or discriminatory language.
While high-risk tools will not be banned, those using them will need to be highly transparent in their operations.
Companies deploying generative AI tools, such as ChatGPT or image generator Midjourney, will also have to disclose any copyrighted material used to develop their systems.
This provision was a late addition drawn up within the past two weeks, according to a source familiar with discussions. Some committee members initially proposed banning copyrighted material being used to train generative AI models altogether, the source said, but this was abandoned in favour of a transparency requirement.
""Against conservative wishes for more surveillance and leftist fantasies of over-regulation, parliament found a solid compromise that would regulate AI proportionately, protect citizens' rights, as well as foster innovation and boost the economy,"" said Svenja Hahn, a European Parliament deputy.
Macquarie analyst Fred Havemeyer said the EU's proposal was ""tactful"" rather than a ""ban first, and ask questions later"" approach proposed by some.
""The EU has been on the frontier of regulating AI technology,"" he told Reuters.
RACE TO MARKET
Microsoft-backed (MSFT.O) OpenAI provoked awe and anxiety around the world when it unveiled ChatGPT late last year. The chatbot became the fastest-growing consumer application in history, reaching 100 million monthly active users in a matter of weeks.
The ensuing race among tech companies to bring generative AI products to market concerned some onlookers, with Twitter-owner Elon Musk backing a proposal to halt development of such systems for six months. Shortly after signing the letter, the Financial Times reported Musk was planning to launch his own startup to rival OpenAI.


Sharon Goldman
@sharongoldman

December 5, 20XX-1

The hidden danger of ChatGPT and generative AI | The AI Beat
Since OpenAI launched its early demo of ChatGPT last Wednesday, the tool already has over a million users, according to CEO Sam Altman — a milestone, he points out, that took GPT-3 nearly 24 months to get to and DALL-E over 2 months. 
The “interactive, conversational model,” based on the company’s GPT-3.5 text-generator, certainly has the tech world in full swoon mode. Aaron Levie, CEO of Box, tweeted that “ChatGPT is one of those rare moments in technology where you see a glimmer of how everything is going to be different going forward.” Y Combinator cofounder Paul Graham tweeted that “clearly something big is happening.” Alberto Romero, author of The Algorithmic Bridge, calls it “by far, the best chatbot in the world.” And even Elon Musk weighed in, tweeting that ChatGPT is “scary good. We are not far from dangerously strong AI.” 
But there is a hidden problem lurking within ChatGPT: That is, it quickly spits out eloquent, confident responses that often sound plausible and true even if they are not. 
ChatGPT can sound plausible even if its output is false.
Like other generative large language models, ChatGPT makes up facts. Some call it “hallucination” or “stochastic parroting,” but these models are trained to predict the next word for a given input, not whether a fact is correct or not. 
Some have noted that what sets ChatGPT apart is that it is so darn good at making its hallucinations sound reasonable. 
Technology analyst Benedict Evans, for example, asked ChatGPT to “write a bio for Benedict Evans.” The result, he tweeted, was “plausible, almost entirely untrue.” 
More troubling is the fact that there are obviously an untold number of queries where the user would only know if the answer was untrue if they already knew the answer to the posed question. 
That’s what Arvind Narayanan, a computer science professor at Princeton, pointed out in a tweet: “People are excited about using ChatGPT for learning. It’s often very good. But the danger is that you can’t tell when it’s wrong unless you already know the answer. I tried some basic information security questions. In most cases the answers sounded plausible but were in fact BS.” 
Fact-checking generative AI
Back in the waning days of print magazines in the 2000s, I spent several years as a fact-checker for publications including GQ and Rolling Stone. Each fact had to include authoritative primary or secondary sources — and Wikipedia was frowned upon. 
Few publications have staff fact-checkers anymore, which puts the onus on reporters and editors to make sure they get their facts straight — especially at a time when misinformation already moves like lightning across social media, while search engines are constantly under pressure to surface verifiable information and not BS. 
That’s certainly why Stack Overflow, the Q&A site for coders and programmers, has temporarily banned users from sharing ChatGPT responses. 
And if StackOverflow can’t keep up with misinformation due to AI, it’s hard to imagine others being able to manage a tsunami of potential AI-driven BS. As Gary Marcus tweeted, “If StackOverflow can’t keep up with plausible but incorrect information, what about social media and search engines?” 
And while many are salivating at the idea that LLMs like ChatGPT could someday replace traditional search engines, others are strongly pushing back. 
Emily Bender, professor of linguistics at the University of Washington, has long pushed back on this notion. 
She recently emphasized again that LLMs are “not fit” for search —” both because they are designed to just make sh** up and because they don’t support information literacy.” She pointed to a paper she co-authored on the topic published in March. 
Is it better for ChatGPT to look right? Or be right? 
BS is obviously something that humans have perfected over the centuries. And ChatGPT and other large language models have no idea what it means, really, to “BS.” But OpenAI made this weakness very clear in its blog announcing the demo and explained that fixing it is “challenging,” saying: 
“ChatGPT sometimes writes plausible sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: (1) during RL [reinforcement learning] training, there’s currently no source of truth; (2) training the model to be more cautious causes it to decline questions that it can answer correctly; and (3) supervised training misleads the model because the ideal answer depends on what the model knows, rather than what the human demonstrator knows.” 
So, it’s clear that OpenAI knows perfectly well that ChatGPT is filled with BS under the surface. They never meant the technology to offer up a source of truth. 
But the question is: Are human users okay with that? 
Unfortunately, they might be. If it sounds good, many humans may think that’s good enough. And, perhaps, that’s where the real danger lies beneath the surface of ChatGPT. 





By JAKOB HANKE VELA
Send tips here | Tweet @HankeVela | Listen to Playbook and view in your browser
LABELING AI CONTENT        
TODAY: EU PUSHES FOR ‘AI LABEL’ TO FIGHT DEEPFAKES: Brussels wants to prevent artificial intelligence from blurring the lines between fact and fiction — and will today ask companies for the first time ever to come up with a label to identify AI-generated texts and images to fight disinformation, officials tell Playbook.
Brave new world: Generative AI is making breathtaking advances — from writing texts and code to creating ever more realistic pictures and videos — which will have enormous consequences not just for the future of society and work, but for politics, Commission officials reckon. 
Balenc-ai-ga: The fake images of the Pope and famous politicians wearing a Balenciaga coat that went viral earlier this year have clearly spooked them — and they now want to label such deepfakes.
Fake porn: “Today it is mostly still a game, but tomorrow you could see a fake porn with a candidate,” one official who is working on the file but was not authorized to speak on the record told Playbook, referring to AI-generated images of politicians. 
Race to regulate: The Commission (the EU’s executive, which proposes and enforces laws) — has proposed an AI Act to regulate high-risk applications and ban the most dangerous ones. But even before that act enters into force, the Commission will urge industry to cut down on trickery by labeling AI-generated work.
Happening today: Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton will meet representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation. They include Microsoft, Google, Meta, TikTok, Twitch and smaller companies — but not Twitter, which has left the code — as well as NGOs.
Disinformation risks: “I will ask the signatories to create a dedicated and separate track within the code” to deal with disinformation generated by Artificial Intelligence, Jourová told Playbook. “It should … aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them.”
EU pushes for safeguards: How does Brussels want the companies to tackle the risks? “Signatories who integrate generative AI into their services like Bingchat for Microsoft, Bard for Google should build in necessary safeguards that these services cannot be used by malicious actors to generate disinformation,” Jourová said.
Clear labels: “Signatories who have services with a potential to disseminate AI-generated disinformation should in turn put in place technology to recognize such content and clearly label this to users.”
More about this label: Two officials working on the file told Playbook the label should apply to all AI-generated material that can be used to create disinformation, including text, images, audio and video.
Voluntary — for now: It wouldn’t be mandatory, given that it would be part of the voluntary Code of Practice. However, the Commission aims to make the code enforceable by including it as a code of conduct in the Digital Services Act (DSA). Obligations on labeling AI content may also make it into the AI Act during negotiations between EU countries, Parliament, and the Commission, one official said.
How can companies do this? “They can develop, and they probably already have tools to check whether an image was AI-generated or not,” the first official said.
Playbook wonders: Given how easy it is for AI to proliferate across jurisdictions, will such a technology ever be able to identify all deepfakes — or won’t we, on the contrary, one day need some chain of custody procedure for authentic images that can be used, for example, as evidence in court?
Stay tuned: Jourová will present her initiative at a press point tomorrow at 11:15 a.m.
SPEAKING OF WHICH: While the Commission is calling on others to do more, it was recently reported that it awarded and signed a €3.7 million tender to help analyze issues like disinformation, foreign meddling in elections and global threats from a French firm that’s mired in controversy.
Avisa Partners has previously been accused of manipulating information in France and working for authoritarian regimes. The company was recently at the center of a controversy as the organizer of a cybersecurity forum boycotted by the French armed forces ministry and several government officials. More here for our Pro Cybersecurity subscribers.
Looking into this: The Commission is looking into the allegations and “is in contact with French counterparts to seek more clarity on those claim[s],” Peter Stano, the Commission’s spokesperson for foreign affairs and security policy, told my POLITICO Pro Technology colleagues. The EU executive is “closely monitoring the implementation of this project,” he added. 
Jean Tillinac, from Avisa Partners, told my Pro Tech colleagues that the bid was “defended by a team of seasoned experts from our Strategic Intelligence Division” doing research and which was different from the “Digital Communications Division” facing criticism.



Annex I – Glossary of Terms
Algorithm: a formula given to a computer for it to complete a task (i.e., a set of rules for a computer) 
Artificial intelligence: a subset of computer science that deals with computer systems performing tasks with similar, equal, or superior intelligence to that of a human (e.g., decision-making, object classification and detection, speech recognition and translation)
Artificial general intelligence (AGI): also known as strong AI, AGI is a type of artificial intelligence that is considered human-like, and still in its preliminary stages (more of a hypothetical existence in present day)
Artificial narrow intelligence (ANI): also known as weak AI, ANI is a type of artificial intelligence that can only focus on one task or problem at a given time (e.g., playing a game against a human competitor). This is the current existing form of AI.
Artificial neural network (ANN): a network modeled after the human brain by creating an artificial neural system via a pattern-recognizing computer algorithm that learns from, interprets, and classifies sensory data.
Big data: large amounts of structured and unstructured data that is too complex to be handled by standard data-processing software.
Chatbots: a chat robot that can converse with a human user through text or voice commands. Utilized by e-commerce, education, health, and business industries for ease of communication and to answer user questions. 
Cognitive computing: computerized model that mimics human thought processes by data mining, NLP, and pattern recognition.
Computer vision: when a machine processes visual input from image files (JPEGs) or camera feeds
Data mining: the process of sorting through large sets of data to identify recurring patterns while establishing problem-solving relationships.
Deep learning: a machine learning technique that teaches computers how to learn by rote (i.e., machines mimic learning as a human mind would, by using classification techniques)
Generative AI: Generative artificial intelligence or generative AI is a type of artificial intelligence (AI) system capable of generating text, images, or other media in response to prompts. Generative AI models learn the patterns and structure of their input training data, and then generate new data that has similar characteristics. 
Genetic algorithm: an algorithm based on principles of genetics that is used to find solutions efficiently and quickly to difficult problems.
Machine learning (ML): focuses on developing programs that access and use data on their own, leading machines to learn for themselves and improve from learned experiences.
Natural language processing (NLP): helps computers process, interpret, and analyze human language and its characteristics by using natural language data. 
Pattern recognition: automated recognition of patterns found in data.
Reinforcement learning: a machine learning method where the reinforcement algorithm learns by interacting with its environment and is then penalized or rewarded based on decisions it makes.
Strong AI: see artificial general intelligence (AGI)  
Structured data: clearly defined data with easily searchable patterns.
Supervised learning: a type of machine learning where output datasets teach machines to generate desired outcomes or algorithms (akin to a teacher-student relationship).
Transfer learning: a system that uses previously learned data and applies it to a new set of tasks.
Turing Test: a test created by computer scientist Alan Turing (1950) to see if machines could exhibit intelligence equal to or indistinguishable from that of a human.
Unstructured data: data without easily searchable patterns (e.g., audio, video, social media content)
Unsupervised learning: a type of machine learning where an algorithm is trained with information that is neither classified nor labeled, thus allowing the algorithm to act without guidance.",13,5.0,"Summary
According to the Notice of Competitions of current EPSO competitions, the only competency that will be assessed in the Case Study exam is Written Communication",5.0,"A lot of potential is shown here in being able to focus on the relevant information and structure it clearly. 
But the writing style is more suited to a written briefing than a speech. Furthermore, the writing style could overall be elevated in fluency and tone. There are also several grammar and spelling mistakes throughout the document. 
Would benefit from having an introduction and conclusion.
Considering this is a briefing for a press conference, an introduction should be included that better captures the attention of the audience in a couple of impactful, punchy sentences and that quickly summarizes what the speech will touch on. 
E.g. Alluding to the introduction of ChatGPT and DALL.E: these are recognizable names that generative AI is known as in the public sphere. 
Something general should be included in the introduction about the consequences regarding the future of work, for society, politics and democracy. And that the goal is to stop disinformation by way of a clear labelling system.
Overall, the clarity of the message is at times diluted by too much detail of issues that are not strictly relevant e.g., mentioning the impact on the workforce is not the main issue of this particular briefing. At other times clarity suffers due to not having enough detail. 
More practice is needed in creating succinct yet clear arguments with just the right level of detail depending on the given task.
A brief conclusion should have also been included.",,"Tips to Improve
Work on increasing level of written fluency and raising tone of communication skills in English. 
Work on writing impactful introductions and conclusions. 
Allow enough time to check for typos.","Trainee's Answer
WHAT IS GAI
Generative AI is a sub field of articial intelligence, where computer algoritms are used to create output that seems to be created by human being. Some example of results can be, text, image, video and coding line.
These algoritms are fed with training data, which includes some example of desired output. Algoritms analyse the structure of those training data and can create new outputs, which can seem unique and made by human.
GAI is a machine learning process, it continues to fine tunes itself, the more contents are created the more sophisticated and convincing outcome will become.
 
GAI POTENTIAL BENEFITS
Generative Artificial intelligence has several benefit, infact it can be used to improve efficiencies within business environment but also in private life. GAI can carry out specific and easy task and give more time to focus on more strategic and important activities.
In business environment it is mainly used as previously said to improve efficiencies, this means lower labour cost. It is used in several field, such as:
-Healthcare to enhance discoveries and elaborate data,
-Finance to study and predict stock market trends,
-Education to produce training material and assessment that fit better to students,
-Marketing to create new content which are dedicated to specific customers,
-Environment to predict weather analysing data.
-in several field can be help in customer support, with virtual assistent and in general to analyse data and improving deicsion making process.
Benefits are visible and even if it is a relatively new discover, lot of companies and people are relying on it.
 
WHAT ARE DANGERS ASSOCIATED WITH GAI
Unfortunately since it a relatively new discovery, GAI needs still to be discover fully and the related dangers with it. 
Dangers can be the spread of misinformation, malicious or sensitive contents, which can bring damage to people and business, some of them can be:
-Hallucination, sometimes GAI can produce wrong output and it can be a problem for people that are relying too much on it, we need to remember that it is still a machine and does not have the same understanding of human being.
-Deepfakes, as explained before GAI can be used to produce fake news or fake content such as video or picture, which can harm people or businesses. i particular this can harm EU value of democracy be used to manupulate information and influence people in politics but also in their opinion.
-Dataprivacy, GAI can be used to solve problem, for example in our business but all the information, also sensitive ones, that we give to this system are stored and can be used in different ways,
-Cybersecurity, related to previous point some of the information given can be use to harm business or people.
-Copyright, GAI is fed with training data, but it can include data from different source and authors, for this reason the output result can be a mix of all those information and the output can be a violation of copyright.
-Wokforce, finally another fundamental point is that increasing efficiencies will usually lead to reduce the workforce to improve company copetitiveness. in this way workers can lose their job and they will be in the position of rebuild themself and upskill in order to compete with AI or find alternatives jobs.
HOW EU WANTS TO ADDRESS GAI DANGERS?
Based on previous brief list of danges, it is needed to find a way to regulate GAI to use this powerful tool in the safetiest possible way.
EU is proposiing the first ever legal framework on AI, in the AI package it is also include the Coordinated plan on AI. These two measures will guarantee safety and fundamental right for people and business and will reduce the cost and investment to access this technology especially for SMEs.
This proposal will set clear requirements and obligations regarding specific use of AI.
In April 20XX European Union proposed a new Copyright rules for generative EU, which would require companies to disclose any compyright material used to develop those tools. The aim to use these rules to improve transparency and ethics, and minimizing misues and infringment of copyrights.
Furthermore, based on regulatory framewoek all tool will be classified based on associated risk which can be, Unacceptable risk, High risk, Limited risk and Minimal risk.
Part oEuropean Union wants also to address directly the problem of segregation of fact and fiction, for this reason, EU wants to ask company to label all contents that are created by GAI.
The proposal is to labe all AI materials created to tackle the proble of misinformation about text, images, video or audio. For now this labelling it is not mandatory but discussion is ongoing among EU countries, Parliament and commission."
1,0_Lithium Supply Chain (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG MOVE. 
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Analysis and Problem Solving, Communicating (Drafting Skills), Delivering Quality & Results, and Prioritising & Organising.

Specifically, your task will be to draft a memo for your Head of Unit.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations


ACEA - European Automobile Manufacturers’ Association 

DLE - direct lithium extraction

DLP - direct lithium to product 

ECHA - European Chemicals Agency

ESG - environmental, social, and governance

EV – Electric Vehicle

INN – Investing News Network

IRA – Inflation reduction Act (US)

LCE - lithium carbonate equivalent

LiPo – Lithium Polymer







EMAIL 1","Subject: Towards a sustainable, circular, European battery supply chain 
Dear YOU,

In December 20XX-2, the Commission presented a proposal for a regulation on batteries and waste batteries. The proposal aims to strengthen the functioning of the internal market, promoting a circular economy and reducing the environmental and social impact throughout all stages of the battery life cycle. The initiative is closely linked to the European Green Deal, the Circular Economy Action Plan, and the New Industrial Strategy. 
At the end of last year, The Council and the European Parliament reached a provisional political agreement on the proposal. For the first time the legislation will regulate the entire life cycle of a battery – from the supply chain of raw materials, over the production to reuse and recycling of batteries – and ensure that they are safe, sustainable, and competitive.
As you know, our unit has the lead on this important file and our DG intends to launch the formal interservice consultation over the coming weeks. Before this, our DG wants to organize an internal reflection and brainstorming meeting, and I have been appointed to chair this meeting.
Could you produce an internal memo, summarizing the main ins and outs of this file and the agenda for the internal meeting with concrete proposals and recommendations to fine-tune the original proposal, in line with the political priorities of the co-legislators. 
I’m on mission tomorrow so please could you get this done for me today. It doesn’t need to be long – in fact the shorter, the better.  

Many thanks",",

Ferdinand
Head of Unit




Is Europe Moving Fast Enough to Build a Resilient Lithium Supply Chain? 
Priscila Barrera
Nov. 16, 20XX-1


Europe will soon release its Critical Raw Materials Act to identify potential strategic projects and build up reserves where supply is at risk.
Europe’s green energy transition plans give a central role to the electrification of transportation. 
The European Union (EU) has ambitious goals to become climate neutral by 2050, meaning it would be an economy with net-zero greenhouse gas emissions. Recently proposed legislation is looking to effectively ban all internal combustion engine cars by 2035.
In 20XX-2, electric car registrations for the year were close to 1,729,000, up from 1,061,000 in 2020, with prospects for the region remaining positive. Last year, the market share of battery electric cars almost doubled to around 10 percent, but challenges faced by carmakers continue to weigh on demand as inflation and fears of a recession put pressure on targets. 
In its most recent forecast, the European Automobile Manufacturers’ Association (ACEA) said it expects the overall EU car market to shrink again this year, slipping by 1 percent to reach 9.6 million units.
“To ensure a return to growth — with an even greater share of electric vehicle sales so climate targets can be met — we urgently need the right framework conditions to be put in place,” said Oliver Zipse, ACEA president and CEO of BMW. “These include greater resilience in Europe’s supply chains, an EU Critical Raw Materials Act that ensures strategic access to the raw materials needed for e-mobility, and an accelerated roll-out of charging infrastructure.”
As sales of electric vehicles increase, carmakers are looking to secure supply of key metals used in batteries, including lithium. Today, Europe is quite dependent on Australia and Chile for lithium supply and China for lithium refining, but the region is taking steps to strengthen its supply chain for the important battery metal. 
What is the European Critical Raw Materials Act? 
In September, news broke that Europe will be putting forward the European Critical Raw Materials Act, a new piece of legislation. Its aim is to identify potential strategic projects and build up reserves where supply is at risk.
European Commission President Ursula von der Leyen said the bloc has learned its lesson about the risks of being dependent on Russia, and realizes the need to be vigilant toward China.
""In the case of China, it is the risk of dependency on technologies and raw materials,"" she said, adding that the EU needs to boost its production capacity and shift more towards trustworthy suppliers.
In October, von der Leyen said the EU is witnessing quite an acceleration of trends and tensions with China. 
""The Chinese system is fundamentally different from ours and we are aware of the nature of the rivalry,'' she said.
The moves from the EU are in line with pushes seen in other regions such as North America, where the US has committed billions of dollars to reach its carbon emissions targets.
In June, the Biden administration launched the Inflation Reduction Act, which includes climate incentives. The legislation, which was signed into law in August, requires automakers to source 50 percent of critical minerals used in electric vehicle batteries from North America or free trade agreement countries by 2024, with that amount rising to 80 percent by the end of 20XX+3.
For its part, Canada recently ordered three Chinese companies to divest from lithium companies following a “multi-step national security review process.” China has opposed the move, and Canada is expected to release its China strategy soon.
Europe-Asia relationship in the lithium space 
Jack Bedder of Project Blue said Asia will always be a part of the European lithium-ion battery supply chain. Major Asian companies, including Panasonic, Samsung, BYD Company and CATL, all have operating capacity on the continent.
“As a result, it will be almost impossible to detach fully from Chinese-owned supply across all stages of the lithium-ion supply chain,” he told the Investing News Network.
However, as lithium processing capacity is built up globally at non-Chinese-owned companies, particularly within the EU, the opportunities to reduce the EU's dependency on China-owned supply will improve. “It is very unlikely that the EU will implement legislation directly prohibiting lithium supply from Chinese-owned companies, as further constraints on supply availability to the European market will only hinder growth in the industry over the coming decade,” Bedder added.
For Allan Pedersen of Wood Mackenzie, Europe cannot move forward without influence from Asia in the short to medium term.
That’s due to a few reasons. As mentioned, many of the battery plants being constructed in Europe have Asian companies behind them, and the cathodes needed in batteries are still largely produced in Asia, where the know-how is strongest. Additionally, lithium refining is mainly done in China and most mineral concentrate is produced in Australia.
“China has a multi-year advantage over the rest of the world in terms of investing in the entire supply chain — it will be challenging for Europe to catch up to that in terms of investment in know-how, processing equipment and resources,” he said. 
“This doesn’t mean that Europe cannot make progress in this space. In lithium, we see some resource developments and processing facilities being considered and constructed.”
For the analyst, in the long-term Europe has the potential to become more self-sufficient for raw materials as recycling becomes a larger part of the supply landscape and can supplement domestic resources.
European Commission could classify lithium as toxic. 
Although Europe is pushing to build a resilient supply chain by partnering with allies and developing domestic resources, it might not all be good news for miners in the region — at the end of last year, the European Commission said it will weigh a proposal from the European Chemicals Agency to classify lithium carbonate, chloride and hydroxide as dangerous for human health.
If the proposal is approved, this could undermine the EU’s attempt to create and support a domestic battery materials supply chain, research firm Rystad Energy said in a statement. “The EU currently relies heavily on imports of lithium to supply its nascent electric vehicle production sector and the classification may increase its reliance on other regions, at a time when the union is focused on energy security and reducing emissions,” the document reads.
If the classification goes ahead, it would not stop lithium usage, but it is highly likely to have an impact on at least four stages: lithium mining, processing, cathode production and recycling.
“This potential ruling comes at a time when the EU is itself scrambling to build and establish local lithium supply chains. The permitting issue has repeatedly been highlighted at recent industry events as one of the main barriers to new mining projects ramping up quickly in the EU,” according to Rystad Energy analysts. “There is also further risk of potential projects losing local community support for building lithium mines and processing operations.”
Editorial Disclosure: The Investing News Network does not guarantee the accuracy or thoroughness of the information reported in the interviews it conducts. The opinions expressed in these interviews do not reflect the opinions of the Investing News Network and do not constitute investment advice. All readers are encouraged to perform their own due diligence.




Lithium salts could be declared health hazard in EU
June 9, 20XX-1 by Igor Todorović


A major lithium producer threatened to close its plant in Germany if the European Union declares the material dangerous to human health. The European Chemicals Agency or ECHA initiated the process.
The European Union has been making its environmental and climate rules stricter for decades. The administration in Brussels wants to make the entire continent carbon neutral by mid-century. At the same time, it is striving to achieve the highest level of protection from pollution in the world.
The energy transition and the decarbonization of industrial activity and power plants imply massive deployment of renewables, mostly solar and wind farms. However, as they depend on unstable weather conditions, the electric power system requires energy storage, in which the EU counts a lot on batteries.
Dangerous critical raw material
Lithium-ion solutions still dominate the sector, though there are other technologies emerging that could popularize less harmful material for home units and the batteries for electronic devices, electric vehicles, and utility systems. At the same time, the European Commission is struggling to secure supply chains that would make the availability of lithium stable and make the EU almost self-sufficient by 20XX+7.
The European Union has added lithium to a list of critical raw materials as demand is expected to increase dramatically in the coming years.
Initiatives to open mines and ore processing plants such as the ones in Serbia and Portugal have caused a public uproar as environmentalists and the local population are fearful about the impact on nature and people’s livelihoods. In other projects, engineers are trying to make the extraction of lithium from geothermal waters cost effective and harmless, without any mining.
Stricter rules for handling lithium would lift costs
However, the entire concept could falter with the European Commission’s upcoming legislation. Namely, it is considering the proposal from the European Chemicals Agency, ECHA, to declare key lithium salts hazardous for human health, Reuters reported. If lithium carbonate, lithium chloride and lithium hydroxide are classified as dangerous, it would complicate the import procedure, production, and handling of the materials.
ECHA’s Risk Assessment Committee accepted the demand from France in September to classify lithium salts as damaging for fertility and unborn children and to declare the substances harmful for breastfed children.
Adding lithium salts to the list of materials hazardous for health may prompt the revision of a range of projects in the industry.
Stricter rules mean higher costs, so any lithium ore processing plant project, like the one in the Jadar area in Serbia, would need to be given a second look regarding its environmental impact and feasibility.
Albemarle, based in Charlotte, North Carolina, has indicated it may be forced to close its plant in Langelsheim in north Germany if the plan is accepted. In that case, Chief Financial Officer Scott Tozier said, the company wouldn’t be able to import lithium chloride, its primary feedstock.
The unit’s annual revenue is USD 500 million, and the plant has over 600 employees. Tozier warned a decision to declare lithium salts hazardous would prompt an exodus of EU producers including battery recyclers.
The decision is expected to be reached by early next year, the article adds.





The Really Big Battery Deal in the IRA That People Are Missing
By Zachary Shahan – Published September 23, 20XX-1
When it comes to electric vehicles and the Inflation Reduction Act of 2022, almost all the discussion has been around the consumer tax credit for buying an electric vehicle, including the interesting new battery aspects of that. That’s a big topic, but there’s a whole other battery angle separate from the consumer tax credit, and it’s huge.
The short summary of the whole thing is that the IRA incentives for nearly every stage of battery production and the battery supply chain are very attractive, and since they stack on top of each other, the IRA is likely to stimulate a “gold rush” of sorts in battery mineral mining, battery mineral refining, battery cell production, battery recycling, and battery pack production in the United States. When you also consider that consumers will need to get batteries whose components don’t come from China, and that come from North America eventually, then it’s essentially a given that everyone in the industry now knows it should have battery mineral mining and refining as well as battery cell and pack production in North America.

SK Innovation Georgia battery factory rendering, courtesy of SK Innovation.
The Current EV Battery Mineral Situation
First, let’s note where we’re starting from. The USA currently mines and refines close to 0% of the minerals that go into EV battery packs. China, on the other hands, mines or refines the majority of all the big ones, including lithium, cobalt, nickel, and graphite. Here’s a chart on Chinese EV battery mineral domination:

Money, Money, Money
Looking at the data, the idea that Joe Biden was going to stimulate a gold rush in the EV battery mineral mining and refining space was a dream some of us had, but it seemed like one of the more outlandish dreams we could have in this time and age. However, the market does respond to three things pretty well: money, money, money, and money. And the Biden administration, Prime Minister Manchin, Senate Majority Leader Chuck Schumer, and others involved in crafting the legislation took note and decided to offer all four.
The slight joke here, aimed at emphasizing the key point, is that the IRA seems to be offering cash money (tax credits) for mining battery minerals, for refining battery minerals, for putting together battery cells, and for putting together battery packs (or “modules”). If you do all those things, you don’t get one bonus, you get four bonuses. If you count all the different minerals in a battery, the number of potential bonuses is much larger. Those bonuses add up, and they make it much more appealing to bring full-cycle battery production to the USA. At the very least, it should open mining and refining projects — which are more or less non-existent in the United States — by making them much more bankable. (Side note: Canadian and Mexican locations hoping to attract battery manufacturing investment may not have figured it out yet, but their competitive position versus the US took a major hit when Biden signed the IRA.)
That’s why we recently got news of Tesla reportedly deciding to scrap some investments it had already made in Germany (but not all of them) and move some battery cell production stateside. That’s why Tesla is reportedly exploring lithium refining in Texas now as well. That’s why GM is reportedly accelerating its exploration of EV battery mineral supplies from US soil. “Our thought process was that we would do this over a period of time, but with the IRA, we are actively working on figuring out how to accelerate,” said Sham Kunjur, GM’s executive director for EV raw materials. But this is only the beginning. These are just the leaks from early movers and leaky groups. Whether it’s Tesla, GM, Volkswagen, Ford, Panasonic, SK Innovation, LG Energy Solution (previously known as LG Chem), Samsung SDI, Albemarle, Livent, Piedmont Lithium, Talon Metals, Lithium Americas, Pilbara Minerals, or others, corporate teams are looking at the IRA, having their lawyers look at it, and starting to look much more seriously at what production opportunities they can launch in the United States.
Looking at the Actual IRA Language
Section 45X of the IRA concerns “components produced and sold after December 31, 2022.” Near the beginning, it states that “any taxable year is an amount equal to the sum of the credit amounts determined under subsection (b) with respect to each eligible component.” In other words, if you get a tax credit for one component of a battery (raw lithium, for example), you can also go and get a tax credit for another component or even later stage of the same component (the refined lithium, for example). The tax credits are for each major stage of the production process, and that means you can get them for various components of a battery and various stages of processing or putting together those components. You can get the following credits:
10% of the cost of battery electrode active materials
$35/kWh of battery cell capacity
$10/kW of battery module capacity (or, for a battery module that does not use battery cells, $45/kWh)
10% of the cost of producing a battery mineral.
Also, while there’s a phaseout for some of these between 2030 and 2032, there is no phaseout at all for the critical mineral subsidies! That’s long-term stability for a market that needs it.
What Minerals & Battery Components Are Eligible?
Regarding electrode active materials, those include “cathode materials, anode materials, anode foils, and electrochemically active materials, including solvents, additives, and electrolyte salts that contribute to the electrochemical processes necessary for energy storage.”
Applicable critical minerals include aluminum/alumina, antimony/antimony trisulfide concentrate, barite/barium sulfate, beryllium/copper-beryllium master alloy, cerium/cerium oxide, cesium/cesium formate/cesium carbonate, chromium/ferrochromium, cobalt/cobalt sulfate, graphite/graphitic carbon, lithium/lithium carbonate and lithium hydroxide, manganese, nickel/nickel sulphate, and many others.
Notably, at the end, it’s noted that only production that takes place in the United States is eligible for these tax credits. This creates a “USA premium” in the supply of raw materials to facilities that want to get the maximum benefit from 45X. Any manufacturer will be eligible for a 45X tax credit which covers the yearly cost of production if their facility is using raw material from the US. For most manufacturing, raw material cost is the most significant component of OPEX after labor and energy. So, Biden, Schumer, Manchin, and their aides have been very clever here: “want the maximum benefit, Buy American.”
So, let’s go back to the example of Tesla (or you can use Ford, GM, or some other company in this hypothetical if you prefer). Tesla could, theoretically, get a tax credit for mining lithium, get a tax credit for refining lithium, get a tax credit for mining nickel, get a tax credit for refining nickel, get a tax credit for producing battery anodes, get a tax credit for producing battery cells, and get a tax credit for producing battery modules. Of course, Tesla isn’t going to do all those things. However, I think that helps to explain the potential here. Whereas Tesla won’t do all those things itself, companies and investors will be pouring into the United States to do them, and some automakers will deepen their vertical integration in the battery space as well.
As a final note, and perhaps as a teaser for something we’ll come back to, while the incentives from the IRA are attractive, so is the potential for pricing control over raw materials! Whether Ford, GM, or Tesla, having more secure, stable, predictable control over key raw material costs could go a long way in being competitive and financially sustainable in the coming decade. How much is that pricing control worth as we go from ~5% EV market share in the US auto industry to 50% or more?

Russia may launch lithium production in the coming four years
June 17, 20XX-1
| As said at the SPIEF Oleg Kazanov, Director of the All-Russian Institute of Mineral Resources (VIMS) under Federal Subsoil Resources Management Agency, Russia may start lithium mining based on the ore deposits in the Murmansk region in 3-4 years and become one of the world’s five largest producers in eight years’ time.  |  |
“Russia has a lithium resource base, which is 10% of the world’s reserves and explored back in the 60s of the previous century. This is almost 4 million tons in 15 explored deposits. The first two objects in the Murmansk region will gain licensing and active subsoil use by the end of the current year. I think production might start there already in the next three or four years. Moreover, these are world-class deposits, both in terms of the lithium reserves and content,” O. Kazanov said.
According to him, now the demand for lithium is boosting in the world. Its driver is the battery industry. “Already in the next 10 years, we will see an increase from the current 100,000 tons of lithium consumption to about 700,000 tons. In total, 88 deposits of ore lithium will be launched in the world soon, but it is not enough to cover its entire global demand,” the expert notes.
Meanwhile, in Russia, a peculiar situation has developed in the lithium industry. The country has huge reserves of ore lithium reaching 10% of the world’s. Besides, Russia discovered lithium reserves in solutions in the bottom waters of the oil and gas fields in the Angara-Lena region, but they have not been fully assessed yet. The lithium content in solutions is very high by the world standards, i.e., about 300 mg/l.
There are two large lithium processing plants in Russia the Krasnoyarsk chemical-metallurgical plant, which buy raw lithium from Chile, bring it up to battery quality and ship to Southeast Asia.
Against the background of this situation, Federal Subsoil Resources Management Agency has recognized development of the lithium ore and brine reserves as a priority area.
Lithium ore mining technologies already exist; they scale well, especially considering increase of the demand for lithium and its price rise. “I think already on ore lithium, in the prospect of the next eight years, we are going to be among the top five producers of this metal along with Chile, Argentina, China and Australia,” O. Kazanov noted.
The next stage in the Russia’s lithium industry development after the ore deposits have been commissioned will be application of the technologies for lithium production from solutions. In the world, this is the DLE technology mainly used for solutions at geothermal power plants. In Russia, lithium solutions are found in the bottom waters of oil and gas fields. This water is somehow extracted from the subsoil and injected back into the reservoir to maintain pressure in an oil and gas well.
The engineering center created based on the Krasnoyarsk chemical-metallurgical plant and VIMS developed its own technologies for lithium extraction just during a year, and now they are tested under the laboratory conditions.

By Marcelo Azevedo, Magdalena Baczyńska, Ken Hoffman, and Aleksandra Krauze
Lithium is the driving force behind electric vehicles, but will supply keep pace with demand? New technologies and sources of supply can fill the gap. 
Despite expectations that lithium demand will rise from approximately 500,000 metric tons of lithium carbonate equivalent (LCE) in 2021 to some three million to four million metric tons in 2030, we believe that the lithium industry will be able to provide enough product to supply the burgeoning lithium-ion battery industry. Alongside increasing the conventional lithium supply, which is expected to expand by over 300 percent between 2021 and 2030, direct lithium extraction (DLE) and direct lithium to product (DLP) can be the driving forces behind the industry’s ability to respond more swiftly to soaring demand. Although DLE and DLP technologies are still in their infancy and subject to volatility given the industry’s “hockey stick” 1 demand growth and lead times, they offer significant promise of increasing supply, reducing the industry’s environmental, social, and governance (ESG) footprint, and lowering costs, with already announced capacity contributing to around 10 percent of the 2030 lithium supply, as well as to other less advanced projects in the pipeline.
However, satisfying the demand for lithium will not be a trivial problem. Despite COVID-19’s impact on the automotive sector, electric vehicle (EV) sales grew by around 50 percent in 2020 and doubled to approximately seven million units in 2021. At the same time, surging EV demand has seen lithium prices skyrocket by around 550 percent in a year: by the beginning of March 2022, the lithium carbonate price had passed $75,000 per metric ton and lithium hydroxide prices had exceeded $65,000 per metric ton (compared with a five-year average of around $14,500 per metric ton). 
Lithium is needed to produce virtually all traction batteries currently used in EVs as well as consumer electronics. Lithium-ion (Li-ion) batteries are widely used in many other applications as well, from energy storage to air mobility. As battery content varies based on its active materials mix, and with new battery technologies entering the market, there are many uncertainties around how the battery market will affect future lithium demand. For example, a lithium metal anode, which boosts energy density in batteries, has nearly double the lithium requirements per kilowatt-hour compared with the current widely used mixes incorporating a graphite anode.
So, will there be enough lithium to cover the needs of a new electrified world? As discussed in our recent article, “The raw-materials challenge: How the metals and mining sector will be at the core of enabling the energy transition,” arriving at a considered answer and understanding the entire supply-and-demand context will be crucial for every player along the value chain—mining companies, refiners, battery manufacturers, and automotive OEMs.
Lithium demand factors
Over the next decade, McKinsey forecasts continued growth of Li-ion batteries at an annual compound rate of approximately 30 percent. By 2030, EVs, along with energy-storage systems, e-bikes, electrification of tools, and other battery-intensive applications, could account for 4,000 to 4,500 gigawatt-hours of Li-ion demand.
  
Not long ago, in 2015, less than 30 percent of lithium demand was for batteries; the bulk of demand was split between ceramics and glasses (35 percent) and greases, metallurgical powders, polymers, and other industrial uses (35-plus percent). By 2030, batteries are expected to account for 95 percent of lithium demand, and total needs will grow annually by 25 to 26 percent to reach 3.3 million to 3.8 million metric tons LCE depending on the scenarios outlined in Exhibit 2. 


Reuse and recycle
A frequently asked question is whether L-ion batteries can be recycled. With expected battery lifetimes of around ten to 15 years for passenger vehicles, and the possibility of extending EV battery life through use in the energy-storage sector, battery recycling is expected to increase during the current decade, but not to game-changing levels. Depending on the recycling process employed, it is possible to recover between zero and 80 percent of the lithium contained in end-of-life batteries. By 2030, such secondary supply is expected to account for slightly more than 6 percent of total lithium production (Exhibit 7).",7,7.0,"Summary

According to the Notice of Competitions of current EPSO competitions, the only competency that will be assessed in the Case Study exam is Written Communication",7.0,"Observations

With this competence, we basically evaluate the style of the case study. Your text should be clear, fluent, written in a professional but still captivating style; of course, spelling and grammar are also covered in this area. Another point we examine here is whether you managed to find the balance between providing details and being concise while conveying the key points of the arguments.",,"Tips to Improve

The text is coherent and informative, its cohesion is generally strong; there are a few typos and grammatical inaccuracies, but they do not disturb the readability of the text.","Trainee's Answer
1 March 20XX, ME, Unit...
Internal MEMO
Regulation on Batteries and Waste Batteries
 
The purpose of the present MEMO is to outline the current state of play on the Batteries Regulation file, and to propose an Agenda with points for discussion and proposed way forward for the internal meeting.
1. Current state of play
- At the end of 20XX-1, the proposal from the Commission has reached a political agreement in the Council and the European Parliament.-
- The EU is aiming to become climate neutral by 2050, a policy that related legislative proposals need to take into account.
- Regarding specifically lithium batteries, at the moment China is the biggest actor in processing and supplying lithium, with the United States (USA) implementing internal measures to challenge the monopoly (such as tax benefits for lithium processing) and with Russia planning to launch their own production soon. The European Union (EU) is dependent on Australia and Chile for lithium supply.
Even if 90% of lithium is used for batteries and its use is therefore essential for expanding the electric vehicles fleet, health concerns are rising and the European Chemicals Agency (ECHA) will declare it dangerous for human health. At the same time, prices of lithium have increased drastically. Last but important, lithium has a very low recycling rate, only 6% of lithium production coming from recycling. 
- The EU's interest is to ensure independence, as much as possible, from external sources. The EU will soon adopt the Critical Raw Materials Act, aiming at building up reserves of raw materials at local EU level.
Having regard to the above, the following Agenda and way forward is proposed:
2. Agenda and way forward
a) Updated statistics on batteries - materials extraction, production and recycling, including global trends (updated information from beginning of 20XX to be obtained)
b) Strategy for the gradual phase-out of lithium batteries (since phase-out cannot happen quickly)
- short-term (by end of 20XX+2) : introduce incentives (tax benefits and pricing control over raw materials) to ensure 20% independence regarding lithium for batteries, in coordination with the Critical Raw Materials Act.
- mid-term (by end of 20XX+5) : in parallel, invest in projects for the research and development of other types of batteries (such as hydrogen, solar) and aim to increase by 20% the diversification of batteries from other renewable and recyclable sources by the end of this period.
- long-term (by end of 20XX+10): aim to obtain 80% of batteries from renewable sources.
c) waste batteries - introduce short-term (20XX+2), meduim (20XX+5) and long-term (20XX+10) goals for recycled batteries, respectively 20%, 50% and 80%.
3. Conclusion
The goal of the Regulation should be to ensure, as much as possible, independence of the EU from the other global actors on the energy scene, while respecting the health of EU citizens and contributing to the climate neutral goals of the EU."
4,0_Case study - Animal welfare - LONG,"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. 

Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG SANTE. 
A citizen’s initiative (“End the cage age”) collected almost 1.4 million signatures demanding a Commission proposal to ban all use of cages for farm animals. DG SANTE has prepared a draft legislative proposal, based on an impact assessment and several rounds of stakeholder consultations. An inter-service consultation (ISC) with the other DGs was recently closed. The Director-General of SANTE now needs to decide how to move forward on this file, so that a compromise text can be agreed in the college of Commissioners.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes, as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the candidate’s drafting skills (Communication) and may be used to assess also the following competencies: Critical thinking, analysing & creative problem-solving, and Decision-making and getting results.

Specifically, your task will be to draft a concise briefing note for your Director-General. This note must include: 

Summary of the main issues, notably the remaining problems to solve
Arguments and facts to help the Director-General make a decision on the file

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.",,"Subject: Briefing for the Director-General – Animal welfare legislative proposal
---
Dear [your name],
Welcome to your first day in the unit! You will have to hit the ground running - we have received an urgent request for a briefing. Our Director-General, Ms Heinrich, needs a summary of state of play concerning the draft revised animal welfare regulation, for her decision on the way forward.
As you have seen in the draft regulation text, we have followed the “preferred options” identified in our thorough impact assessment (those marked green in the impact assessment options table). This draft legislative proposal is what we as DG SANTE believe best serves our policy objectives and this is what we need to defend as far as possible. We received strong support for an ambition line in all the stakeholder consultations.
In the recent inter-service consultation, we also received green light (positive opinion) by all DGs except one. DG AGRI has unfortunately not been able to accept our draft legislative proposal. This means we will either need to make small compromise adjustments to the original proposal and change our preferred option, or we try to somehow convince DG AGRI to accept our main line.
In your briefing, please outline the main issues at hand and explain the options for next step so that our Director-General can make an informed decision on it. She did invite us to already make a recommendation based on our knowledge of the file if we have a preference.
You should keep the briefing short and concise, no more than two pages.
I have placed a file with various materials on your desk. It should contain what you need for the draft briefing. Please have a first version done already today at X o’clock so I can check it before passing it on to Ms Heinrich.
Thank","you and best of luck,
Wiebke
---
Head of Unit
Animal welfare unit, DG SANTE

Attachment 2: Inter-service consultation reply AGRI

Answer of DG AGRI to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 1 (sent on 16 May 202X 14:56:54) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | DENKER Nicholas (AGRI.F.002) | No automatic forward of notifications to this responsible officer |
Opinion | Negative opinion  |  |
Authorised in the DG by | ROBINSON Michael (AGRI.F) |
Comments | For laying hens/cage ban, either the low ambition option or status quo should apply, for protection of the single market and to ensure competitive pricing of European high standard food products, compared with lower-standard import products from third countries with only minimum requirements of animal welfare rules. |  |



Attachment 3: Inter-service consultation reply ENV

Answer of DG ENV to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 2 (sent on 14 May 202X 17:32:04) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | SVOBODA Lisa (ENV.D1) | No automatic forward of notifications to this responsible officer |
Opinion | Positive opinion |  |
Authorised in the DG by | HUEGEL-PEETERS Sabine (ENV.D) |
Comments | Thank you for consulting DG ENV on the proposed revised regulation on animal welfare. This proposal is important and in line with the European Green Deal objectives; we support the general approach and your preferred options. From our review, we have several minor editorial comments, given in track-changes in the attached document, which we request are taken on-board. |  |






Attachment 4: Inter-service consultation reply TRADE

Answer of DG TRADE to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 1 (sent on 15 May 202X 11:46:25) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | LANGE JENSEN Halfdan (TRADE.B.01) | No automatic forward of notifications to this responsible officer |
Opinion | Positive opinion |  |
Authorised in the DG by | GEORGIOU Andreia (TRADE 0) |
Comments | N/a |






Attachment 5: Press statement

Brussels, April 202X-2
Every year across the European Union, around three hundred million farmed animals are confined in cages. Unable to conduct many of their natural behaviours, these animals are treated as nothing more than production machines. No single EU Member State is completely cage free and in some Member States up to 90% of all hens, mother pigs and young calves are kept in cages and crates. This despite farming industry having had more than 15 years to voluntarily change their installations.
Over 170 organisations and caring citizens across Europe therefore joined forces to spearhead the “End the Cage Age” European citizens’ initiative. In total, 1.4 million EU citizens made their voices heard and signed the petition. Only one other citizen’s initiative has so far gathered more signatures than this.
Mr Daniel Müller, campaign leader for “End the Cage Age” said: what we see now is the battle of ethics versus economy. EU citizens do not want cheap food at any cost and certainly not at the cost of pain and suffering of our fellow creatures. Food industry and economic interests will have to adapt to this reality – and finally do what is right.
In response to our tireless campaigning, in April 202X-2, the European Commission committed to proposing legislation before the end of 202X to phase out and finally prohibit the use of animal cages. We must now ensure that a total ban on caged farming is delivered, as soon as possible. The fight also continues to pave the way not only for a cage-free Europe, but for a cage-free world by making sure that all imported products in the EU comply with cage-free standards.


Attachment 6: Website

What is a citizens' initiative?
A European citizens’ initiative is a way for you and other Europeans to take an active part in EU policymaking.
If you want the EU to act on a particular issue, you can launch a citizens’ initiative calling on the European Commission to propose new EU legislation on that issue.
For an initiative to be considered by the Commission, you need to get one million citizens from across the EU to sign it in support.
Step 1: Get started
Before launching an initiative, it is worth considering some of the key practical aspects, including:
is asking for EU legislation to be passed the best way to achieve your goals?
you must first set up a group of organisers composed of at least 7 EU citizens living in seven different EU countries. To do so, you need to find people to team up with across Europe who are willing to support your issue.
how will you organise your campaign to collect the signatures?
You can find detailed advice on all these issues on the European Citizens’ Initiative Forum




Step 2: Get your initiative registered
Before you can start collecting signatures for your initiative, you must ask the Commission to register it.
For this, you will need to:
create an organiser account. You will use this to manage your initiative and liaise with the Commission throughout its lifecycle.
provide a description of your initiative in one of the official EU languages (as well as details and relevant documents on the group of organisers, funding received, etc.)
The Commission is not obliged to register all initiatives. It only registers initiatives that meet certain criteria.
Once you ask for your initiative to be registered, we will assess whether to accept it.
You will receive an answer within 2-4 months.


Step 3: Get support
You need to get the support of at least one million people, with minimum numbers in at least seven EU countries. They must fill in a specific statement of support form.
You can collect:
on paper (pre-filled forms, downloadable from your organiser account) or
online (using the Central Online Collection System).
These forms are available in all EU official languages.
To sign, people must be:
EU nationals (nationals of an EU country)
old enough to vote in European elections or aged at least 16 in some countries
TIP – It is better to collect more signatures than you need. Sometimes the authorities in each country might not be able to validate all the statements of support you provide. Throughout the collection procedure, you must comply with data protection rules.


Step 4: Submit your initiative
Once you have received the last certificate from the national authorities, you have 3 months to submit your initiative to the Commission – together with the information on the support and funding you have received for the initiative.


What next?
If the Commission considers legislation an appropriate response to your initiative, it will start preparing a formal proposal. This can require preparatory steps like public consultations, impact assessments, etc. Once adopted by the Commission, the proposal is submitted to the European Parliament and the EU Council (or in some cases, only to the Council), which will need to adopt it for it to become law.
The Commission is not obliged to propose legislation. Even where it responds positively, the most appropriate follow-up to an initiative may be non-legislative in nature. There are a range of other measures that may be more suitable.
The European Parliament may also assess the measures taken by the Commission.

Attachment 7: E-mail message
 
From: ROBINSON Michael (AGRI)
Sent: Monday, 16 May 202X
To: MUNOZ Wiebke (SANTE)
Subject: Revised animal welfare regulation
 
---

Dear Wiebke,
Just a heads-up about the AGRI response to your animal welfare ISC - you will receive it later today. We can accept all of it, but we have a remaining concern about the proposed new rules for poultry cage rearing.
First, the proposed exception for farms less than 50 livestock units (3500 laying hens) does not make much sense. The overwhelming majority of eggs produced in the EU come from farms with more than 5000 birds (70 livestock units) and the smaller farms can anyway more easily transition to cage-free rearing if they haven’t done so already.
Longer transition time also does not help, it’s not about more time for farms to adapt. It’s about the money and about food prices.
For large-scale installations, cages are simply more efficient and use much less space. With your proposal, notably the requirement of more space per laying hen, production will necessarily be less cost-efficient, and most farms will not be able to keep the same number of birds. Consumers might say they care about animal welfare but when they make their choices in the supermarket, the thing that matters most is the price! If you implement the new rules, the price of eggs might increase by around 20-40% in countries like Spain, Portugal, and Malta where cage systems are still the norm. This means we will see a significant increase in cheap imported eggs from third countries with much worse animal welfare standards. Our European farmers cannot compete on such unfair terms.
There is also the socioeconomic element: the burden of higher food prices will be heavier on the poorest families.
Unless farmers can be compensated economically somehow for taking this risk, we don’t see any need for changing the current rules on poultry caging and we will need to block your proposal.

Call me if you want to discuss this further.

Best,
Michael


Attachment 8: Press release


MEPs endorse EU citizens’ call for gradual end to caged farming
Press releases – AGRI - 20 February 202X-2

The European Parliament has called for the end of caged farming within the next 5 years. The parliament members voted on an own initiative resolution recommending a total ban on the use of cages in animal agriculture by 202X+3.
The vote followed intensive lobbying by the “End the Cage Age” European Citizens Initiative, led by 170 non-governmental organisations (NGOs) across Europe, which garnered 1.4m signatures from EU citizens and demanded the phasing out of cages on farms. Members of the European Parliament (MEPs) voted by 558 to 37 with 85 abstentions on the non-binding resolution.
Unlevel playing field in Europe
Even though the EU has banned the use of battery cages in poultry production and sow stalls during gestation, campaigners said this was not enough, given the perceived unlevel playing field across Europe with some nations already going beyond EU laws.
According to the initiative, five out of 28 countries are currently achieving more than 80% cage-free production, i.e., Austria (97%), Luxembourg (97%), Sweden (92%), Germany (86%) and the Netherlands (82%). Bottom of the list is Malta, with 1%, followed by Spain and Portugal. About sows, the report is based on Eurostat figures, according to the initiative’s website.
In the European Parliament, a working group on cage-free farming established in 202X-10 has been actively supporting the “End the Cage Age” initiative and in October 202X-3, 101 MEPs from various political parties signed a letter of support addressed to EU Commissioners.
Speeding up the review of animal welfare legislation
Last month, the parliament’s AGRI committee adopted a motion for a resolution. Committee members called on the European Commission to speed up the review of the animal welfare legislation and back the phasing out of all cages in farming, possibly already by 202X+3. They also insisted on ensuring compliance with EU standards for all products imported into the EU.
By April this year, the European Commission will have made its decision as to whether to start a legislative process to ban caged farming. EU Food Safety commissioner Stella Kyriakides told MEPs that the Commission was considering a request contained within the resolution to apply the same animal welfare standards to meat imported from outside the EU as European farmers must meet inside the bloc.
Kyriakides also noted the call for farmers to receive compensation and support in their transition from cages. She added the phase-out would happen “as soon as feasible” but did not give a specific date.
The results for pork production could be far-reaching, as it would likely change the current practice using farrowing crates. In recent years, a lot of research initiatives have already been launched to design free farrowing concepts.



Attachment 9: E-mail message 
 
From: CALBI Ana (EFSA)
Sent: Thursday, 16 October 202X-1
To: MUNOZ Wiebke (SANTE)
Subject: Cages and antibiotics
 
---
Dear Ms Munoz,
Congratulations on your concluded impact assessment on the animal welfare regulation!
In view of your upcoming drafting process, I need to point out that there are several scientific studies pointing to higher prevalence of antimicrobial resistance, notably among e-coli bacteria, in non-cage housing systems for poultry - if not implemented correctly and with strict quality standards. I feel this did not come out clearly enough from your impact assessment.
Free-range egg production systems face more challenges related to biosecurity and use of antibiotics. The free-range layer birds have more interaction with each other compared to caged ones, leading to an increased incidence of infectious poultry diseases requiring treatment with antimicrobials, in turn leading to increased emergence of resistant commensal and pathogenic bacteria. This is a major threat to public health.
The main factor to consider is of course, as always, the number of hens per square meter, the hygiene routines, and the overall rules on veterinary prescription of antibiotics. It is the same for pigs: sows in small crates have low life quality but use less medication; pigs in free range but packed close together require lots of antibiotics and pigs in free range with sufficient space are more healthy and less prone to cause antimicrobial resistance. However, they are also much less cost-effective for industrial-size farming. 
Still, to ensure safe food production and avoid antibiotics resistance, livestock density simply must go down. 
If you could take these concerns into account in your draft revised regulation, we would be much grateful.

Best regards,
Ana Calbi

---
Head of Department
The European Food Safety Agency (EFSA)




Attachment 10: Impact assessment


								Brussels, 13 October 202X-1






COMMISSION STAFF WORKING DOCUMENT

IMPACT ASSESSMENT REPORT


Animal welfare: revised regulation


Executive summary
To address the specific objectives of the animal welfare legislation revision, four policy measures have been considered, with low, medium, and high ambition options. Impacts assessed include cost-efficiency, environmental and societal impacts and impacts on the single market. The European Food Safety Agency (EFSA) has confirmed the scientific evidence. Numerous stakeholder consultations and supporting studies have been performed.
For animals kept for economic purposes, the measures/options covered are:
1) 	Phasing out confining cages/crates for the following species and categories of animals:
Pigs
Calves
Laying hens and pullets
Rabbits and fur-producing animals.
A general transition period of between five and twelve years would be considered, depending on the level of ambition. Exceptions e.g., depending on farm size (number of “livestock units” where 1 livestock unit = 1 cow, or 2 pigs, or 71 laying hens) could be considered.
2) 	Banning the killing of day-old male chicks (or, as an alternative option, introducing an obligation of marking eggs from production systems where day-old chicks are killed). In the case of a ban, while a transition period of five years would be technically sufficient, notably if combined with stricter import rules, the impacts could be mitigated by introducing a ten years’ transition period.

3) 	Banning painful mutilations, i.e., beak trimming in poultry and tail docking in pigs (with incentives instead of bans as alternative options). For the bans, a general transition period of ten years has been considered. Incentives for voluntary action would enter into force immediately.
  
4) 	Animal welfare requirements at import. For animals and products of animal origin imported to the EU, either similar or fully equivalent animal welfare requirements with the revised EU animal welfare requirements for kept animals, as regards the use of cages, mutilations, space allowances, enrichment, the killing of day-old chicks and the welfare of fur animals would apply. A transition period of five-ten years has been considered.

A phase-out of the use of cages and stalls would considerably improve the welfare of more than 160 million laying hens, 53 million pullets (young hens), 13 million sows, two million calves, 35 million ducks and geese and 100 million rabbits. They would be able to perform a more natural and healthy behaviour.
A partial or total ban on cages and crates would have an important economic impact on the sectors concerned. For instance, for laying hens we have estimated the required investments for a transition into a cage-free system to about EUR 2,4-2,8 billion. For sows, the cost of demolishing the current system with gestation and farrowing crates could amount to around EUR 64-100 /m². These costs are likely to result in higher consumer prices. 
The situation however differs between Member States. Some have already taken measures to phase out cages and stalls whereas others have not. 
To mitigate these economic impacts, certain measures could be considered, notably awareness-raising vis-à-vis consumers, economic incentives via the Common Agricultural Policy and import rules to ensure a level playing field / reduce unfair competition.
The proposed measures would ensure a positive impact on sustainability as it would imply less intensive food production, causing less pollution to air and water. However, since cage-free animals move around more, they spend more energy and consume more feed. This could have a negative impact on the use of resources.

Table 1: Policy options (most cost-efficient option in terms of added value vs cost is shown in green):
| Low ambition option | Medium ambition option | High ambition option | Comments |
1.a. Crates/cages: pigs | Phase in of crate ban over 10 years. |   | Exceptions allowed for farms with less than 50 livestock units. |   | Allowing temporary confinement from 1 week before farrowing until weaning. |   | Cost-benefit analysis value (-) | Phase in of ban over 5 years. |   | Farms with less than 50 livestock units allowed to phase out crates over 15 years. |   | Temporary confinement allowed from 1 day before farrowing to 5 days post-farrowing. |   | Cost-benefit analysis value (+++) | Total ban phased in over 5 years. |   | No exceptions. |   | Cost-benefit analysis value (+) | Medium and high ambition options can be combined with stricter requirements of minimum living space per animal and/or voluntary guidance on antibiotics use. |
1.b. Crates/cages: calves | No legislative change. |   | Cost-benefit analysis (-) | Phase-out of all use of weaning crates over 10 years. |   | Ban on trade / import of calves kept crated. |   | Cost-benefit analysis (+) | Phase-out of all use of crates within 5 years. |   | Ban on trade / import of calves kept crated. |   | Cost-benefit analysis (++) | Strong public support for total ban. Low impact on food pricing. |
1.c. Cages:  laying hens and pullets | Phase in of ban over 12 years. |   | Farms with less than one hundred livestock units exempted. |   | Cost-benefit analysis (0) | Phase in of ban over 10 years. |   | Farms with less than 50 livestock units allowed to phase out cages over 12 years. |   | Cost-benefit analysis (++) | Total ban phased in over 5 years. |   | Cost-benefit analysis (+++) | Same as with pigs. |
1.d. Cages: rabbits and animals in fur production | No legislative change. |   | Cost-benefit analysis (-) | Transition phase 10 years.  |   | Cost-benefit analysis (+) | Transition phase 5 years. |   | Cost-benefit analysis (++) | Low economic impact (small sector). |
2. Killing of day-old male chickens (laying breeds) | Obligation of marking eggs from production systems applying this practice, starting as from 5 years. |   | Cost-benefit analysis: (0) | Ban of procedure within 10 years + economic incentives via the Common Agricultural Policy for farmers transitioning sooner |   | Immediate obligation of marking eggs from production systems not yet transitioned. |   | Cost-benefit analysis (++) | Phase in of ban over 5 years + stricter import rules to protect internal market |   | Cost-benefit analysis (+) | Strong public support for total ban. Strong impact on food pricing. |   | Viability dependent on development of technology to gender-identify eggs before hatching. |   | Possibility of launching consumer awareness campaigns to explain food price impacts (acceptability). |
3. Ban on painful mutilations (beak trimmings / tail cropping) | N/a | Immediate ban on cross-border trade in tail-docked pigs. |   | No ban on the procedures but economic incentives via the Common Agricultural Policy for voluntary transition. |   | Cost-benefit analysis (+) | Phase in over 10 years of total ban. |   | Cost-benefit analysis (+++) | No justification for no action. |   | Enforcement mechanism needed (inspections). |
4. Animal welfare requirements at import | No legislative change | Minimum set of rules apply for import (low- or medium ambition options). 10 years transition period. | Full EU rules to apply also for imported products. 5 years transition period. | Strong impact on competitiveness of EU farmers. Strong impact on the acceptability of other measures. | Possible difficulty of implementation. |
 

Background
Since 202X-10, EU legislation requires that laying hens be kept either in enriched cages, or alternative systems (single or multi-tier barn or, free-range). The current legislation allows calves being individually housed until the age of eight weeks, while sows and gilts are kept in confinement for a period of four weeks after service and from one week before the expected time of farrowing to weaning of their piglets. 
Approximately one million farms keep laying hens in the EU. Forty-five percent of these are kept in enriched cages. 
There is currently a trend towards using less cages in many EU Member States such as France, the Netherlands and Poland to answer to consumer’s expectations. E.g., Austria and Luxembourg have already banned the use of cages for laying hens. The animal welfare problems related to cages will however remain for many laying hens if no action is taken at EU level.

Problem drivers
Conventional livestock production systems across EU countries are put under pressure by competitive global markets, a rise in input costs and the search for maximum profit margins by farmers and all food business operators along the production chain. The demand of certain consumers’ segments for low price food is expected to be more prevalent in the current inflationary context.
This pressure over production costs has led to further intensification (and specialisation) of the farming and killing practices, as business operators increase the volume of production to reduce overheads costs per livestock unit. Evidence shows that, while the number of livestock farms is decreasing, their size is increasing. Small farms are replaced by very large industrial scale installations.
This trend has led to certain detrimental effects on animal welfare due to high densities, certain management practices, housing/transport conditions and stunning methods, as well as due to certain breeding strategies.
Current EU rules also do not consider new scientific evidence and huge technological developments in relation to agricultural practices, zootechnics and transport operations. For instance, this new scientific evidence relates to a new understanding of stocking densities, behaviour (need for an enriched environment), mutilation practices, journey times and space allowances for animal transports, and stunning methods used for pigs, poultry, and farmed fish.
The lack of update of the EU animal welfare legislation has led Member States to adopt an increasing number of national measures going beyond EU minimum requirements to respond to the growing citizens’ concerns towards animal welfare, leading to a fragmented legal landscape, including as regards animal welfare labelling.
At the same time, consumers are growing more aware and more demanding. The upward trend of societal demands for better animal welfare protection is not reflected in the current legislative requirements. 

Figure 1: Problem tree 

Economic and environmental impacts of the preferred package of options: cages for laying hens
The policy option assessed to be most cost-efficient is a total prohibition on the use of cages for laying hens with a transition period of 5 years (from the date of entry into force of the revised legislation).
However, if no similar requirements apply for eggs and egg products imported into the EU from third countries, since the EU consumers’ demand for eggs is not expected to decrease and since EU production is expected to decrease, an increase in eggs obtained from caged hens imported from non-EU countries with lower standards is expected, thus limiting the positive animal welfare impact of the measure.
The required investments for a transition into a cage-free system for laying hens would amount to around EUR 2,4-2,8 billion.
A prohibition of cages would decrease the number of laying hens by an estimated 30% (i.e., from 186,8 million to 102,9 million) in farms which currently have cage systems.

SME’s
Small farms tend to use cage-free systems more than big farms. A prohibition would therefore primarily have a positive competitiveness impact on small farms.

Public authorities
It is likely that a prohibition would generate additional enforcement costs in the short term for the national competent authorities, however these will come back to current levels in the medium term.

Consumers
A prohibition would lead to an expected increase in the price of eggs, but to which extent is not clear. Some estimates by the EU poultry industry suggest a + 20% price gap between eggs from cages and those from barn systems. However, sales data from the Netherlands and Germany suggests a much smaller difference in prices: less than one eurocent per egg.
With an average per capita consumption of 210 eggs per year, or 4,04 eggs per week, this would mean that transitioning to cage-free systems would add less than four eurocents per person to consumers’ weekly food shopping bill. Furthermore, the experience from Germany, where enriched cages are progressively phased out, even suggests that the price for barn eggs may eventually be the same as for eggs from enriched cages.
 
Environmental impacts
A prohibition would have a positive impact on sustainability as it would imply less intensive production leading to less air and water pollution and less greenhouse gas emissions.



Attachment 11: Website

| A gestation crate, also known as a sow stall, is a metal enclosure in which a   used for breeding may be kept during pregnancy. A standard crate measures 2 m x 60 cm. | Sow stalls contain no bedding material and are instead floored with slatted plastic, concrete, or metal to allow waste to be efficiently collected below. This waste is then flushed into open-air pits known as . A few days before giving birth (farrowing), sows are moved to farrowing crates where they are able to lie down, with an attached crate from which their piglets can nurse. | Most pregnant sows in the US are kept in gestation crates. The crates are banned for new installations in Austria and Canada, but many sows are still confined there in pig breeding facilities. The crates are banned in the United Kingdom, Canada, Switzerland, and Sweden. However, farrowing crates, in which female breeding pigs can be kept for up to five weeks, are not banned in the UK. | Opponents of the crates argue that they constitute animal abuse, while proponents say they are needed to prevent sows from fighting among themselves. |




Attachment 12: Website



Page contents |  | Submission and examination |  |  | Submission and examination | The  initiative was submitted to the Commission on 2 October 202X-3, having gathered 1,397,113 statements of support. See . | The organisers met with the Commissioner for Health and Food Safety, Stella Kyriakides on 30 October 202X-3. | A  took place at the European Parliament on 25 January 202X-2. See . | The initiative was debated at the European Parliament’s plenary session on 20 February 202X-2. In the  adopted on the same day, the European Parliament expressed its strong support for the initiative. See European Parliament’s . | Answer of the European Commission | In its response on 4 April 202X-2, the Commission commits to table, by the end of 202X, a legislative proposal to phase out, and finally prohibit, the use of cage systems for all animals mentioned in the initiative. | In parallel to the legislation and to facilitate a balanced and economically viable transition to cage-free farming, the Commission will seek specific supporting measures in key related policy areas, such as trade and research and innovation.  | In particular, the new Common Agricultural Policy will provide financial support and incentives – such as the new eco-schemes instrument – to help farmers upgrade to more animal-friendly facilities in line with the new standards. |



Attachment 13: News article



 -  -  
Health and food safety Commissioner will fight for ethical food systems in Europe
30 October 202X-3
Earlier today, Commissioner Kyriakides met with the representatives of the citizens’ initiative ‘End the Cage Age’. EURACTIV interviewed the Commissioner after her meeting with the campaign team.
Stella Kyriakides is European Commissioner for Health and Food Safety and in charge of the EU animal welfare legislation. She spoke to EURACTIV about the call for revised animal welfare legislation and the possibility for action ahead.
This is one of the most strongly supported citizens’ initiatives so far with almost 1.4 million signatures collected. How will the Commission respond to all who signed this petition?
I am impressed by the hard work by these dedicated young people. I promised them today that the Commission will investigate this very carefully.
In fact, we recently completed a review of our legislation and have found that there is indeed scope for improvement. However, first we will hear the views of the European Parliament and we will consult across the Commission services and then reply about next steps.
Your colleague, the Commissioner for Agriculture, is less enthusiastic. How will you get the farming community onboard?
As always, there will be a balancing act between several interests. Farmers produce the food we eat and they deserve to be heard as well. Many farmers also already made this transition, showing it is possible to rear animals cage-free.
The Commission always performs a thorough impact assessment, so any legislative proposal will be based on solid facts and on careful consideration of all relevant impacts. We always seek a sustainable compromise.
There could also be other possibilities to make animal welfare more attractive for farmers by e.g., economic incentives, subsidies, trade schemes and awareness campaigns. It is not just about laws and penalties.
On the other hand, I think the farming industry has known for a long time that this is coming, they have had plenty of time to prepare and many Member States have in fact already taken significant steps in the direction of free-range animal rearing.
But is there not a risk that ‘money will talk’, how can you weigh the economic impacts against animal suffering – how will the comparison be done in an impact assessment?
No, economic interests are not the only interests we take into account. It is true that our assessment is expressed as a cost-benefit ratio, but among those ‘benefits’, we consider also softer values such as social, health and environmental impacts – and ethical choices. I guarantee you that industry interests will not dominate this process. 
On the contrary, I think what we see here is a strong message from European citizens that animal rights and animal welfare must be respected, and I agree with them. We cannot ignore this question any longer.",23,4.0,"Summary

According to the Notice of Competitions of current EPSO competitions, the only competency that will be assessed in the Case Study exam is Written Communication",4.0,"Observations

With this competence, we basically evaluate the style of the case study. Your text should be clear, fluent, written in a professional but still captivating style; of course, spelling and grammar are also covered in this area. Another point we examine here is whether you managed to find the balance between providing details and being concise while conveying the key points of the arguments.",,"Tips to Improve

The text is informative, but its cohesion is weak; the amount of typos and grammatical inaccuracies heavily undermine the readability of the text.","Trainee's Answer
Elements to highlight from the impact assessment report produced by the Commission on 13.10 202X-1 on the draft revised regulation on animal welfare
Timeline: Range is between +5 and +12. 202X+10 is considered a medium ambition timeline;
Positive impact in relation to:
- air and water pollution,
-animal health,
-advancement on EU animal welfare legislation considering more recent advancement in zootechnics and agricultural practices;
- mitigation on the current negative impact on single market because of the too fragmented situation among member states;
-Massive support among public opinion 
- Experience in Germany and the Netherlands show a limited impact on prices for consumers
Negative impact in relation to increase costs and possible challenges from extra EU actors but mitigating actions can be adopted as awareness raising campaigns, subisidies to specific sectors, adaptation of the implementation timeline, introduction of temporary exceptions, EU standards to be imposed to extra EU products.
To complement the impact assessment, EFSA highlights that scientific studies have shown the importance of stressing on ensuring high quality standards/controls and a correct implementation of non-caged farming in order to avoid other issues to surge (ie higher prevalence of microbial resistance). EFSA recommends to take this into consideration during the drafting revised regulation.
Position of EU Parliament
- On 20.2. 202X-2, the EP had voted in favour to a resolution for the end caged farmings (558 in favour, 37 against and 85 abstentions) by 202x-1
Position of DG AGRI
- concerns about poultry cage rearing, more specifically:
1. threshold needs to reviewed considering that, as currently defined, it has a limited impact/relevance based on the characteristics of the EU market;
2. Impact on the cost-efficiency for the production;
3. Risk of unfair competition from the actors outside the EU
4. Increase of prices of eggs (20-40%) and impact on poorest consumers;
In order to avoid the blocking of the proposal from DG AGRI, we do recommend to establish a dialogue with DG AGRI and evaluate together if, based on some of the below elements, a compromise could be found.
The suggested points below take into consideration the main concerns expressed by DG AGRI (Michael Robinson) to DGSANTE (Wiebke Munoz) on 16.05.202X and referred above in the state of play section of this document. They are all in line with previous committments/public statements done by the Commission, and with the impact assessment
- Increase transition time (while EP proposes 202x+1, the impact assessment considers a timeframe between 5 and 12 years);
- Consider subsidies to support with the transition (ie for countries whose current level of cage-free production are beyond X%, ie Spain, Portugal and Malta have the lowest levels of cage free production) and mitigate the impact of prices;
- Ensuring that higher EU standards that will be binding for anybody who wants to enter the EU market (in order to avoid unfair competition from outside EU);
- Refer to the impact assessment"
2,0_Case Study_Drones,"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions.

Following a request by the European Commission, the Single European Sky Air traffic management Research Joint Undertaking - whose role is to develop the new generation European air traffic management system – has today unveiled its blueprint to make drone use in low-level airspace safe, secure and environmentally friendly. This paper is part of the Commission's drive to deliver on its ambitious Aviation Strategy and unleash the full economic potential of drones by 20XX+2. This requires an effective legislative framework that can foster European leadership and competitiveness, while addressing a number of legitimate concerns, the first of which is safety. 
You are working as an administrator in DG Mobility and Transport, and you have been asked to prepare a press release announcing the publication of the blueprint.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete. 
You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated. 
The case study is designed to assess the following competencies: Analysis and Problem Solving, Communicating (Drafting Skills), Delivering Quality & Results, and Prioritising & Organising.
More specifically, you are asked to write an internal note to the press office (2-3 pages) containing the following background information:
Opportunities and threats of unmanned or remotely piloted vehicles in the European Airspace
Blueprint for drone use in low-level airspace
Next steps

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly and legibly as possible.","ABBREVIATIONS USED
				
ATC – Air traffic Control
ATM – Air Traffic Management
CE  marking - The letters ‘CE’ appear on many products traded on the extended Single Market in the European Economic Area (EEA). They signify that products sold in the EEA have been assessed to meet high safety, health, and environmental protection requirements.
Clean Sky - The largest European research programme developing innovative, cutting-edge technology aimed at reducing CO2, gas emissions and noise levels produced by aircraft.
EASA – European Air Safety Agency
FAA – US Federal Aviation Administration
Geofencing - a virtual geographic boundary, defined by GNSS technology that enables software to prevent a drone entering a defined zone

GNSS - Global Navigation Satellite System

IATA – International Air Transport Association

ICAO – International Civil Aviation Organization
JARUS  - Joint Authorities for Rulemaking on Unmanned Systems 
NOTAM – Notice to Airmen
NPA - Notice of proposed Amendment
RPAS - Remotely Piloted Aircraft Systems 
SESAR – Single European Sky ATM Research
SME – Small and Medium Enterprises
SWIM – System wide information management
UA - Unmanned Aircraft
U-space - a set of new services and specific procedures designed to support safe, efficient and secure access to airspace for large numbers of drones 
BACKGROUND INFORMATION","Subject:		Single European Sky - Drones
Importance:	Highest

Hi,

this morning, SESAR has unveiled its blueprint to make drone use in low-level airspace safe, secure and environmentally friendly. This “U-space” covers altitudes of up to 150 metres and will pave the way for the development of a strong and dynamic EU drone services market. The paper outlines a number of basic principles: 
Safe: safety at low altitude levels will be just as good as that for traditional manned aviation. The concept is to develop a system similar to that of Air Traffic Management for manned aviation.
Automated: the system will provide information for highly automated or autonomous drones to fly safely and avoid obstacles or collisions.
Up and running by 20XX+2: for the basic services like registration, e-identification and geo-fencing. However, further U-Space services and their corresponding standards will need to be developed in the future.
The European Aviation Safety Agency (EASA) is currently working with Member States and industry to produce effective EU-wide safety rules that are proportionate to the risk of the operation. These rules will implement the EU's basic aviation safety regulation, which the European Parliament and the Council (i.e. the EU Member States) are expected to adopt in the coming months.
The Commission, through the SESAR Joint Undertaking, will further finance a range of drone projects, focusing on the integration of drones into the aviation system.

Could you prepare a draft press release, announcing this blueprint within its wider context and send it to the Press Service by tonight?




Louis Blériot,
Head of Unit","RIGA DECLARATION
ON REMOTELY PILOTED AIRCRAFT (drones)
""FRAMING THE FUTURE OF AVIATION""

Riga - 6 March 20XX-2


Today Europe is taking a decisive step towards the future of aviation. The European aviation community gathered in Riga to exchange views on how, and under which conditions, drones can help create promising new opportunities in Europe, offering sustainable jobs and new prospects for growth both for the manufacturing industry and for future users of drones in all sectors of society. Drones offer new services and applications going beyond traditional aviation and offer the promise to perform existing services in a more affordable and environmentally friendly way. They are a truly transformational technology.

The Latvian Presidency of the Council of the European Union, European Commission representatives, Directors General of Civil Aviation of the EU Member States, data protection authorities and leaders of manufacturing industry and service providers confirmed the importance of joint European action, building on the orientations given in the EC Communication on opening the Remotely Piloted Aircraft Systems (RPAS) market. 

The aviation community stressed the necessity for European regulators to ensure that all the conditions are met for the safe and sustainable emergence of innovative drone services. At the same time regulations must help the industry to thrive and adequately deal with citizens’ concerns.
The aviation community established the following principles to guide the regulatory framework in Europe:
1. Drones need to be treated as new types of aircraft with proportionate rules based on the risk of each operation.
The provision of drone services must not be less safe than is accepted from civil aviation in general. The incremental integration of drones in the aviation system must not reduce the level of safety presently achieved in civil aviation. Although no one is on board the drone, people in other aircraft or on the ground could get hurt in case of an accident or an unscheduled landing. The way safety is regulated must be proportional to the operational risk involved.
Rules should be simple and performance based, to allow a small start-up company or individuals to start low-risk, low-altitude operations under minimal rules and to develop, with light-touch risk-based regulation, similar to the modern product safety regulations applied in other sectors. Higher risk operations would be gradually subject to more stringent regulations or operational limitations. At the other end of the spectrum, where the operational risk is highest, such as with large drones operating alongside manned aircraft, the regulation will need to be quite similar to that applying to manned aviation, with strict standards on the design, manufacturing, maintenance and operation of drones, as well as on the training of drone pilots and maintenance personnel.

2. EU rules for the safe provision of drone services need to be developed now.
Safety rules, including on remote pilot and operator qualifications, should be developed at the European level by the European Aviation Safety Agency, building on the experience developed in the EU Member States. The essential requirements should be harmonised at the global level to the maximum extent possible, and full use should be made of the established cooperation in the Joint Authorities for Rulemaking on Unmanned Systems (JARUS) and at ICAO, and should be completed by international industry standard setting bodies. Important efforts need to be put into resourcing these activities, especially JARUS, in order to ensure that the progressive risk-based approach is consistent with what is done in the rest of the world.
This basic regulatory framework should be put in place without delay, in order to help the private sector to take well-informed investment decisions, and to provide a basic set of rules for the many operators who are increasingly eager to begin providing services. The European Aviation Safety Agency should consult stakeholders by the middle of next year on the regulatory framework for the operations of drones and on concrete regulatory proposals for low-risk operations. By the end of next year the Agency will use the results of the consultation to propose a position on these matters. The proposal for the revision of the basic European Safety Regulation, which the European Commission has announced for next year, should contain the necessary new provisions and essential requirements for the progressive risk-based regulation of drones, based on the Agency's recommendations.

3. Technologies and standards need to be developed for the full integration of drones in the European airspace.
The success of drone activities and safety regulations also depends on the financial effort to develop and validate key missing technologies and the ensuing required standards. Both industry and public authorities stressed the need for adequate investment in the technologies that are required to integrate drones into the aviation system — the SESAR programme. Clean Sky and other initiatives should complete the SESAR investments. That would create spin-offbenef1ts for traditional aviation and so frame the future of ﬂying.

4. Public acceptance is key to the growth of drone services.
The respect of citizens’ fundamental rights, such as the right to privacy and the protection of personal data, must be guaranteed. Many drone services involve data-gathering such as ﬁlming, etc. The responsible authorities, such as the national and European Data Protection Authorities, should develop the necessary guidelines and monitoring mechanisms to ensure the full respect of existing protection rules, including in relation to drones. Rules need to clarify what is acceptable and what is not, and they require to be properly enforced.
Drones may cause nuisances and negative externalities, such as noise. These nuisances need to be addressed, possibly at the local level, to maintain public acceptance.
Drones also pose potential security risks. The design of drones can and should take into account those risks by using methods such as cyber-defence or geofencing. However, the malicious use of drones cannot be entirely prevented by design or operational restrictions. It is the task of the national police and justice systems to address those risks.
5. The operator of a drone is responsible for its use.
When a drone service is delivered in prohibited airspace, in an unsafe manner, or for illegal purposes, the authorities should be able to act and hold the operator accountable. Where lacking, this will need to be clarified in national law. Moreover, in order to enforce responsibility, it will be necessary for drones to have at all times an identiﬁable owner or operator. The regulator should seek the least bureaucratic way to achieve this. For instance, the mandating of electronic identity chips on drones - “IDrones” - as is today envisaged in some states, could be formalised through a safety rule, which would contribute to the effective implementation of privacy and security requirements. Standardised web-portals in the Member States for the registration of operators and their operations could be another solution. The involved authorities need to work closely together.
Drone accidents will happen. Member States should clarify the applicable insurance and third party liability regime and monitor the compensation mechanisms for potential victims. The establishment of compensation funds to cover victims of accidents caused by uninsured drone users, as used in the motor insurance sector, could be envisaged. Reporting on drone incidents should be integrated into the overall incident reporting requirements. Systematic and coherent incident reporting will improve safety and will be instrumental for insurance companies in their risk analysis on which third party liability insurance premiums are based.
To allow a short reaction time, the development of drone services and drone technologies needs close monitoring. To this end, the EU should establish an easy access for SMEs to information required for drone manufacturing and service provision, together with an observatory to keep track of the growing number of operations in Europe and the evolution of innovation. This monitoring will permit informed decisions relative to the establishment of priorities for future legislation. It will also help regulators to learn from experience and verify that the rules are fit for purpose, namely to ensure that new technologies and drone services can develop in full respect of the required high levels of safety, security, privacy and environmental protection. An annual progress report should be published.
The European aviation community gathered in Riga today is committed to working together on the basis of these principles to allow businesses to provide drone services everywhere in Europe as from 20XX-1 onwards.



Introduction
The demand for drone services is steadily increasing, with the potential to generate significant economic growth and societal benefits, as recognised in the 20XX-2 EU Aviation Strategy, and more recently in the SESAR Drones Outlook Study and Warsaw Declaration on drones. In order to realise this potential, the Declaration calls for “urgent action on the airspace dimension, in particular the development of the concept of U-space”. Ultimately, U-space will enable complex drone operations with a high degree of automation to take place in all types of operational environments, including urban areas. U-space must be flexible enough to encourage innovation, support the development of new businesses and facilitate the overall growth of the European drone services market while properly addressing, at EU level, safety and security issues, respecting the privacy of citizens, and minimising the environmental impact. This blueprint outlines the proposed vision for U-space and how it could be rolled out. Rather than providing a definitive solution, this blueprint provides the basis to better define the way drones will operate in Europe in the future. 
What is U-space?
U-space is a set of new services and specific procedures designed to support safe, efficient and secure access to airspace for large numbers of drones. These services rely on a high level of digitalisation and automation of functions, whether they are on board the drone itself, or are part of the ground-based environment. U-space provides an enabling framework to support routine drone operations, as well as a clear and effective interface to manned aviation.

What are the key principles of U-space?
The delivery of U-space relies upon the following key principles:
To ensure the safety of all airspace users operating in the U-space framework, as well as people on the ground.
To provide a scalable, flexible and adaptable system that can respond to changes in demand, volume, technology, business models and applications, while managing the interface with manned aviation.
To enable high-density operations with multiple automated drones under the supervision of fleet operators.
To guarantee equitable and fair access to airspace for all users.
To enable competitive and cost-effective service provision at all times, supporting the business models of drone operators.
To minimise deployment and operating costs by leveraging, as much as possible, existing aeronautical services and infrastructure, including GNSS as well as those from other sectors, such as mobile communication services.
To accelerate deployment by adopting technologies and standards from other sectors where they meet the needs of U-space.
To follow a risk-based and performance-driven approach when setting up appropriate requirements for safety, security [including cyber-security] and resilience [including failure mode management], while minimising environmental impact and respecting the privacy of citizens, including data protection.


How will U-space operate?
Subject to compliance with applicable regulations, operational limitations and technical requirements linked to the operation of the drone, U-space facilitates any kind of mission, from the delivery of goods, aerial work, and search and rescue, to more complex future applications such as urban air mobility.
U-space services are offered to both private [leisure and professional] and public users of drones, for all types of missions. Some services will meet privacy and security needs expressed by the relevant authorities. In addition, the criticality of these services will lead to the establishment of performance requirements for both structural elements and service delivery, covering, for example, safety, security, availability, continuity and resilience.
The U-space framework comprises an extensive and scalable range of services relying on agreed EU standards and delivered by service providers. These services do not replicate the function of ATC ‚ as known in ATM, but deliver key services to organise the safe and efficient operation of drones and ensure a proper interface with manned aviation, ATC and relevant authorities. They may include the provision of data, supporting services for drone operators such as flight planning assistance and more structured services such as tracking or capacity management.



Unmanned aircraft (most people call them ‘drones’) is a sector of aviation that is developing very fast and has a great potential for producing new jobs and growth. The term ‘unmanned aircraft’ includes very large aircraft similar in size and complexity to manned aircraft, but also very small consumer electronics aircraft. Especially the smaller ones are increasingly being used in the Europe Union (EU), but under a fragmented regulatory framework. Basic national safety rules apply, but the rules differ across the EU and a number of key safeguards are not addressed in a coherent way.
On request by the European Commission, Member States and other stakeholders, the Agency started to develop a proposals for an operation centric, proportionate, risk- and performance-based regulatory framework for all unmanned aircraft (UA) establishing three categories with different safety requirements, proportionate to the risk:
‘open’ (low risk) is a UA operation category that, considering the risks involved, does not require a prior authorisation by the competent authority before the operation takes place;
‘specific’ (medium risk) is a UA operation category that, considering the risks involved, requires an authorisation by the competent authority before the operation takes place and takes into account the mitigation measures identified in an operational risk assessment, except for certain standard scenarios where a declaration by the operator is sufficient;
‘certified’ (high risk) is a UA operation category that, considering the risks involved, requires the certification of the UA, a licensed remote pilot and an operator approved by the competent authority, in order to ensure an appropriate level of safety.
Following the publication of an advance NPA, a Technical Opinion, a ‘Prototype’ regulation was drafted for the ‘open’ and ‘specific’ categories. The ‘Prototype’ regulation was published proposing actual rules providing the necessary clarity, notably on what are the responsibilities of the Member States and what is the flexibility offered to them.
A significant number of comments has been received and together with the significant inputs provided by an expert group have been taken into account to further develop the regulation text leading to the publication of an NPA. An impact assessment details analysis of several potential options considered. The analysis benefited also from feedback provided by stakeholders.
The NPA has taken into consideration the developments in the international arena e.g. work done in the International Civil Aviation Organisation (ICAO); in the Joint Authorities for the Rulemaking of Unmanned Systems (JARUS) and of course in the USA (Federal Aviation Administration- FAA).
The proposal provides a framework to safely operate drones while allowing this industry to remain agile, to innovate and continue to grow. The risk posed to people on the ground and to other aircraft as well as privacy, security and data protection issues created by such drones are also taken into account.
The proposed regulation defines the technical and operational requirements for the drones. Technical requirements refer for example to the remote identification of drones.  Operational requirements refer among others to geofencing; a system that ensures the drones does not enter a prohibited zone. The proposal also addresses the pilots’ qualifications. Furthermore, drone operators will have to register themselves, except when they operate drones lighter than 250g.
This proposal is breaking new grounds by combining Product legislation and Aviation legislation. Indeed, design requirements for small drones will be implemented by using the legislation relative to making products available on the market (the well-known CE marking). The standard CE mark will be accompanied by the identification of the class of the drone (from C0 to C4) and by a do’s and don’ts leaflet that will be found in all drone boxes. Based on the drone class an operator will know in which area he can operate and what competence is required.
The proposal allows a high degree of flexibility for EASA Member States; they will be able to define zones in their territory where either drones operations are prohibited or restricted (for example to protect sensitive areas), or where certain requirements are alleviated.
For operations that pose higher risks, an operational risk assessment will define the requirements that the operator needs to comply before flying the drone.
The proposal also provides special alleviations for people flying model aircraft - which are also drones – to recognise the good safety records in aero modelling identifying 3 options:
Member States may issue a special authorisation to model clubs and associations defining deviations from the UAS regulation;
Operations can be conducted in specific zones designated by Member States; or
Operations can be conducted in the open category according the operational limitations defined for one of the Subcategory (A3)
EASA will submit a final Opinion to the European Commission at the end of 20XX, which will take into account the feedback, received to this proposal.




Drone Alliance Europe (DAE) is a coalition of leading technology companies representing the commercial drone industry before European political leaders, regulators, and other industry stakeholders, as well as international regulatory and advisory bodies.
The commercial drone industry has the potential to bring tremendous economic growth, jobs, innovation, and broad societal benefits. Amid exponential industry growth and opportunity, it is critical to pursue a forward-leaning regulatory framework to fully realise this potential and further promote European leadership in research, production, and application of this technology.
Our Mission
The Alliance leverages the experience and perspectives of member companies throughout the policymaking process to expedite the safe and widespread integration of commercial drones into European airspace. Together, the DAE represents a strong, united voice working toward the expeditious development of:
Proportionate, risk-based, pan-European regulations that facilitate a clear path toward authorization of expanded operations throughout the continent, including fully autonomous and beyond visual line of sight operations
A low-cost, interoperable unmanned traffic management (UTM) framework that promotes the safe and secure integration of expanded drone operations essential to industry growth
A regulatory framework that embraces the flexible use of licensed, unlicensed, and spectrum sharing opportunities for drone technology necessary to support safe integration, innovation, and technology leadership throughout the Digital Single Market

Our Members



Secure your drone – or pay the price 
By Nick Gibbons - cyber security expert and partner at BLM
Drone technology offers many benefits – from the potential for speedy Amazon deliveries from the sky, to saving lives, as witnessed recently when the Lochaber mountain rescue team used one to find a hurt climber. 
But on the flip side, there are risks associated with aerial technology, such as drone jacking or hacking. 
Typically, when the conversation moves to the subject of drone-jacking, people immediately envisage a Hollywood-style breach of national security, probably in or around the White House before Will Smith leaps in to save the day. 
However, attacks on this technology represent very real risks for the growing number of businesses using drones, such as engineers surveying buildings and infrastructure, e-commerce giants sending deliveries or companies gathering surveillance for insurance claims. 
Earlier this year, Amazon announced an expansion to its research and development team in Cambridge. This will see 400 technology specialists fine-tuning the technology behind delivery drones. Despite claims that such deliveries are “pipe dreams”, there is a growing market for commercial drone technology, and with this comes a growing risk of drone-jacking. 
Last November, a report from security software company McAfee predicted cybercriminals will soon turn their attention to targeting drones, particularly those used for law enforcement, filming and deliveries. 
Drones without adequate security in place will be vulnerable to hacks, as well as physical attacks. The report speculates 20XX will see an increase in availability, via the dark web, of pre-packaged software and toolkits for hacking drones. In these cases, hacking of the drone itself or its supporting software may result in either physical misuse or data breaches. Hacking for the physical diversion of a drone carries the potential for personal injury or property damage, actual theft of the drone or indeed, the item it was carrying. 
Theft of data is another real risk, particularly if the drone contains personal or sensitive information, whether customer data included for delivery purposes or footage collected via an attached camera. 
The loss of data via drone-jacking leaves businesses and authorities with many privacy concerns, especially with the EU’s General Data Protection Regulation (GDPR) coming into force in May 20XX+1. In recent years, there have been a raft of data breaches resulting in an invasion of privacy for customers of companies, including TalkTalk and Camelot, and breaches of the GDPR could entail fines of up to four per cent of a company’s global turnover. 
Attacks are becoming more sophisticated and wide-reaching; recently, we saw the extensive damage hackers can unleash with the WannaCry cyber attack bringing organisations across the globe to a standstill. 
If cyber attacks start targeting drones, drone-jacking could leave businesses and their customers equally exposed with regards to personal and commercial data, and the prospect of big fines levied by the Information Commissioner’s Office. 
Although the use of drones is already, to an extent, covered by a range of laws and regulations, including the Data Protection Act, more specific, targeted legislation is necessary, as are effective insurance products for organisations using drones. This is especially important with the European Commission predicting full integration of drones into European airspace by 20XX+10. 
The UK Government is clearly live to the emerging risks of drone technology. Following a recent consultation exercise, a registration system is to be launched for drones weighing 250g or more. The UK Government is considering the best legislative option for introducing the new rules. 
Currently, a combination of existing insurance policies are required to cover risks associated with drone technology. As the risk of electronic theft of sensitive data rises, the market for specialised policies grows. 
In the case of drone-jacking, it would be wise for a business to consider cyber risk policies available for first and third parties. These can provide protection against business interruption, reputational risks, loss or theft of third party corporate data notification expenses and the payment of compensation to individuals affected by security or privacy breaches. Care should be taken, however, when selecting a particular cyber policy, including detailed discussions with a specialised brokers. 
So while drones have life-saving potential for Scotland’s mountain rescue teams and a business may find investing in the technology an attractive proposition, an outbreak of drone-jacking could be hugely costly. It is critical that companies consider the security breaches drone-jacking could leave them open to, and invest in the appropriate protection – just in case Will Smith is not available. 



Drone flew 'within wingspan' of plane approaching Heathrow 
Rob Davies
A drone flew within 20 metres of a plane on the approach to Heathrow, while another shocked pilots by appearing at 3,000 metres (10,000ft), a monthly update on near-misses has revealed.
Commercial jet pilots reported two “category A” incidents, the most serious class of near-miss, involving unmanned aerial vehicles (UAVs), known as drones.
The latest report comes amid concern that drone near-misses are on the rise, potentially posing a threat to recreational and commercial planes.
In one case, an Airbus A320 pilot on the approach to Heathrow in October last year spotted a drone within just 20 metres, or “possibly within the wingspan” of the aircraft.
Investigators concluded that the drone had flown so close to the passenger jet that “providence had played a major part in the aircraft not colliding”. They also noted that the “blue and disc-like” craft appeared to be custom-made, rather than a commercially available model.
In the second of two serious UAV incidents, an A320 pilot taking off from Heathrow saw a red drone overhead, about 50 metres away from his right wing at about 1,000 metres.
The pilot noted that there would have been a “distinct possibility of damage” had a collision occurred, while investigators found that “a collision had only been narrowly avoided and chance had played a major part”.
A third drone sighting, deemed a less serious category B incident, involved an unmanned aircraft at an altitude that surprised pilots, who had “no time to react”.
The UK Airprox Board, which issues monthly reports on the threat of mid-air collisions, reported a pilot saying: “Was that a drone? At 10,000 ft!”
Large drones are not permitted to fly above 120 metres, or close to airports.
The “large drone”, which appeared to be stationary, came within 60 metres (200ft) of the aircraft, a distance deemed less risky than the category A incidents, but nonetheless “a situation where safety was not assured”.
A fourth drone sighting, involving a pilot on a sightseeing trip near the Binevenagh mountain in Northern Ireland, was deemed to be at the lowest level of risk, category E.
In all four cases, police were alerted but the operator of the drone could not be traced.
Ministers are considering measures to enforce registration of all new drones so they can be better monitored, while the Department for Transport is also reviewing drone safety.
Pilots believe a collision with an airliner could be catastrophic and that the impact of a drone strike on a light plane or helicopter would almost certainly bring it down.
The British Airline Pilots Association has warned that the number of incidents could soar as people fly drones received as Christmas presents, often with little or no handling experience or understanding of the rules.
There have been 59 drone near-misses reported in the past 12 months. Drone sightings were among 21 incidents reported to the UK Airprox Board, six of which were deemed to be in the most serious category.
Among the other category A incidents was a near-miss in which a model aircraft was flown close to a Chinook military helicopter coming in to land at RAF Benson.





European Commission demands EU laws on drones after string of near-misses with aeroplanes
, Brussels correspondent 
30 September 20XX-1 • 8:20am 
The European Commission has called for fresh impetus behind its stalled plans for EU-wide regulation of drones, after a string of near-misses with airplanes across Europe last year.
There were more than 1,200 “safety occurrences"" involving drones in Europe last year, including several involving planes, the commission, the EU’s civil service, said.
On April 22, a drone passed by the wingtip of  with 156 passengers as it came into land at Liverpool John Lennon Airport. In 2016 three planes narrowly missed drones near Heathrow airport,  for tougher .
“If we don't move fast enough, the near misses between drones and airplanes could one day have disastrous consequences,” Violeta Bulc, the EU’s transport commissioner said.
“Drones offer tremendous opportunities for new services and businesses,” she said, “but safety always comes first”.
The commission drafts laws, which are then amended separately by the European Parliament and national governments sitting in the Council of Ministers. A bill can only enter into force across the EU when an identical text is agreed by MEPs and the council. 



North Wales Police use drones to fight crime
10 January 20XX
North Wales Police has become the latest force in Wales to use drones to help in the fight against crime.
Fifteen officers and staff have been trained to use the unmanned aircraft to capture video and images to be used in investigations. 
This includes searching for missing people as well as gathering evidence from road traffic investigations and major crime incidents.
Drone were used to investigate a .
The team's two drones, which can also carry a thermal imaging camera, have already been used to search for missing people and investigate incidents during a trial last year.
Insp Craig Jones from the force's operational planning unit said they were highly effective in gathering images over difficult terrain or hard to reach areas and helped officers gain information, quickly and safely.
The live images they take can be seen by police on the ground and they were recently used to help firefighters tackle a large blaze at the Gateway to Wales Hotel.
Stuart Millington, of North Wales Fire and Rescue Service, said the ability to see aerial moving images that show fire hotspots was a ""significantly useful tool"" in ongoing incidents.
An agreement with the force means the fire service can call on the police drone pilots to help them deal with incidents when needed.
North Wales Police's Deputy Chief Constable Gareth Pritchard added the drones were a highly cost effective tool in fighting crime and helping communities.
""Being able to launch a drone in the air in a few minutes could help save lives and secure vital evidence if a crime was in progress,"" he said.

 



Drone makers zero in on commercial opportunities

Louise Lucas in Hong Kong July 5, 20XX-1
They have been used to shoot weddings, Hollywood movies and terrorists. But now drones, and their makers, are navigating a third path between hobbyists and warfare into the industrial world, threatening a shake-up of the burgeoning $6bn industry. 
New uses for unmanned aerial vehicles (UAVs), to give drones their technical name, are emerging almost daily: delivering packages, pizzas and blood; surveying mines; pre-emptive firefighting; even collecting whale snot to help conserve the mammals. 
“We are developing the UAV into a means of production,” said Paul Xu, vice-president of DJI, at a conference in Shenzhen last month. His company has given China undisputed leadership in the sector, with its 70 per cent market share of non-military drones 
However, if Shenzhen-based DJI, valued at $8bn-$10bn at its last funding round in 20XX-2, is to keep that lead, it will need to adapt to new market dynamics. 
The industry dismisses talk of “peak” consumer drone, but few expect that part of the business to maintain its heady growth rates. Outside China, casualties abound: in California, Lily Robotics shut up shop in January, while 3D Robotics switched its focus to software and Parrot, of France, axed jobs. New entrants are cut from an altogether different cloth, with industrial and tech groups, including Qualcomm, Intel and Boeing hovering over the space. 
Regulators too are braced for change, as the industry lobbies for more openings. In a first step, the US Federal Aviation Administration, in effect, opened the skies to commercial drones a year ago, with limited safety rules covering the sector. 
Since the FAA rule changes, says Michael Perry, director of strategic partnerships at DJI, the enterprise industry has been scaling up rapidly, encouraged by the more certain regulatory environment. “Before we had conversations [with businesses] but then they said: ‘How will my legal team deal with this?’ The last thing we want is vagaries. People won’t invest if they aren’t sure.” 
DJI, the creation of Frank Wang, a radio-controlled helicopter enthusiast from Hangzhou who transformed his boyhood hobby into a company with sales of $1.5bn, is now looking into areas ranging from agriculture to eliminating mosquitoes. 
“Personal drone vendors are now aggressively trying to position themselves in the commercial market,” says Gerald Van Hoy, senior research analyst at Gartner, although the firm says the 3m drones it expects to be shipped this year will still be overwhelmingly for the consumer market. These figures are up 39 per cent on 20XX-1 and should translate into revenues of $6bn.",10,5.0,"Summary

The candidates shows very strong potential in writing to a professional level and aptitude in drawing conclusions and flagging issues from the material. 
But overall, the document does not answer the task that was assigned. There are significant problems with the structure and content of the document, considering its intended use. 
There could also be improvement in pinpointing and summarizing key information. 


Per Competency Score",5.0,"Observations

The writing style is professional in tone but much of the information is presented as a conversational letter to the press office when the task called for a draft press release.",,"Tips to Improve

Take note of the aim of the document you are asked to write.","Trainee's Answer
Dear Press Service Colleagues,
Please find below the draft press release for the U-Space blueprint publication for your perusal. Just to recall our first meeting, we have agreed to draft the press release together and advance the preparations of the launch. 
A couple of points to follow up our discussion and to consider while you look at this draft:
- The timeline on the making the blueprint a reality may seem ambitious to readers and the media. This is why I took the liberty of  drafting some defensive points that might help you answer the questions. Note: my suggestions for the defensives reflect more issues, not only the timeline. Also, the answers are not yet drafted, and we should discuss these.
- Secondly, as the EU's Basic Aviation Safety legislation is still not adopted yet, we should prepare for question on how we intend to address any potential efforts to water down our proposal. The body of research and evidence prepared about the benefits of 'unmanned areal vehicles' aka drones is huge and diverse. We should discuss which domain (agriculture, healthcare, delivery service) to focus on. 
- Thirdly and perhaps most importantly, we must be ready to defend our decision against disinformation about drones. There is a lot of negative media about near-misses at airports and some people argue that the EU wants to bring in even more drones. These are isolated incidents, but in case the news break, they can go very viral. As discussed earlier, we will need to focus on the immense economic benefits, new market opportunities and completely new entrepreneurship paths that this will bring. Mentioning the jobs these opportunities will generate is also worth it. 
I look forward to hearing the results of the media sweep you conducted and to hear the suggestions how you intend to counter disinformation about drone use. 
We can be proud to be part of process of bringing these technologies faster to the market. Recalling my presentation to you about the potential benefits of drones form the first meeting when we agreed to jointly develop this press release: there are incredible benefits in surveillance of agricultural, inspection of fires, delivery of life-saving medicine to remote areas and the list of interesting applications goes on and on.    
As next steps, I suggest we discuss the press release based on the below draft, the full choreography of the blueprint's launch and next steps in a call at your convenience. Feel free to send me comments, suggestions, ideas about the press release in the meantime, I will be glad to integrate them and circulate a new version of the press release before we speak. 
After our discussion, we will schedule another meeting with colleagues from the SESAR Joint Undertaking to ensure the press release reflects their expertise. 
Please let me know if you have any questions or need more information,
Kind regards,
Erik
=================
Press release draft
For immediate release
Bringing the skies of the future closer to citizen today: The EU is making 
Today, [Date] the European Commission through is  is presenting a blueprint for a future framework under which drones will be able to operate safely and drone services grow to the benefit of all Europeans.
Our ambition is to provide a safe and flexible environment in which drones can improve the lives of citizens and allow Member States to jointly harness the enormous economic potential of drones. 
The Commission presents, U-space, a set of rules that will ensure reliable, safe and efficient procedures will guide the commercial as well as personal use drones. The blueprint will ensure that an ever increasing number of drones in the airspace will remain of no hazard to other users.
The Commission intends to finance the further development of drone projects to ensure that the various services and market players are well integrated and 
U-space will provide an enabling framework to support routine drone operations, as well as a clear rules for traditional users of the airspace, for instance civilian aviation. 
The main principles: 
[I suggest focusing on maximum three, for instance: safety, scalability and fair access to airspace]; let's discuss in the call.
[closing part:]
Drones have enormous potential and their application is impressively wide. 
=================
Defensives:
[Answers to be discussed and brainstormed in our meeting]
How do you intend to control the number of drones in the sky?
Why do we need EU level rules for drones? 
How do you intend to address the concerns voiced in the European Parliament about the interference of drones at airports? 
Why does the EU only react now, when there are already so many accidents reported involving drones?"
4,0_Case study - Animal welfare - LONG,"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. 

Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG SANTE. 
A citizen’s initiative (“End the cage age”) collected almost 1.4 million signatures demanding a Commission proposal to ban all use of cages for farm animals. DG SANTE has prepared a draft legislative proposal, based on an impact assessment and several rounds of stakeholder consultations. An inter-service consultation (ISC) with the other DGs was recently closed. The Director-General of SANTE now needs to decide how to move forward on this file, so that a compromise text can be agreed in the college of Commissioners.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes, as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the candidate’s drafting skills (Communication) and may be used to assess also the following competencies: Critical thinking, analysing & creative problem-solving, and Decision-making and getting results.

Specifically, your task will be to draft a concise briefing note for your Director-General. This note must include: 

Summary of the main issues, notably the remaining problems to solve
Arguments and facts to help the Director-General make a decision on the file

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.",,"Subject: Briefing for the Director-General – Animal welfare legislative proposal
---
Dear [your name],
Welcome to your first day in the unit! You will have to hit the ground running - we have received an urgent request for a briefing. Our Director-General, Ms Heinrich, needs a summary of state of play concerning the draft revised animal welfare regulation, for her decision on the way forward.
As you have seen in the draft regulation text, we have followed the “preferred options” identified in our thorough impact assessment (those marked green in the impact assessment options table). This draft legislative proposal is what we as DG SANTE believe best serves our policy objectives and this is what we need to defend as far as possible. We received strong support for an ambition line in all the stakeholder consultations.
In the recent inter-service consultation, we also received green light (positive opinion) by all DGs except one. DG AGRI has unfortunately not been able to accept our draft legislative proposal. This means we will either need to make small compromise adjustments to the original proposal and change our preferred option, or we try to somehow convince DG AGRI to accept our main line.
In your briefing, please outline the main issues at hand and explain the options for next step so that our Director-General can make an informed decision on it. She did invite us to already make a recommendation based on our knowledge of the file if we have a preference.
You should keep the briefing short and concise, no more than two pages.
I have placed a file with various materials on your desk. It should contain what you need for the draft briefing. Please have a first version done already today at X o’clock so I can check it before passing it on to Ms Heinrich.
Thank","you and best of luck,
Wiebke
---
Head of Unit
Animal welfare unit, DG SANTE

Attachment 2: Inter-service consultation reply AGRI

Answer of DG AGRI to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 1 (sent on 16 May 202X 14:56:54) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | DENKER Nicholas (AGRI.F.002) | No automatic forward of notifications to this responsible officer |
Opinion | Negative opinion  |  |
Authorised in the DG by | ROBINSON Michael (AGRI.F) |
Comments | For laying hens/cage ban, either the low ambition option or status quo should apply, for protection of the single market and to ensure competitive pricing of European high standard food products, compared with lower-standard import products from third countries with only minimum requirements of animal welfare rules. |  |



Attachment 3: Inter-service consultation reply ENV

Answer of DG ENV to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 2 (sent on 14 May 202X 17:32:04) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | SVOBODA Lisa (ENV.D1) | No automatic forward of notifications to this responsible officer |
Opinion | Positive opinion |  |
Authorised in the DG by | HUEGEL-PEETERS Sabine (ENV.D) |
Comments | Thank you for consulting DG ENV on the proposed revised regulation on animal welfare. This proposal is important and in line with the European Green Deal objectives; we support the general approach and your preferred options. From our review, we have several minor editorial comments, given in track-changes in the attached document, which we request are taken on-board. |  |






Attachment 4: Inter-service consultation reply TRADE

Answer of DG TRADE to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 1 (sent on 15 May 202X 11:46:25) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | LANGE JENSEN Halfdan (TRADE.B.01) | No automatic forward of notifications to this responsible officer |
Opinion | Positive opinion |  |
Authorised in the DG by | GEORGIOU Andreia (TRADE 0) |
Comments | N/a |






Attachment 5: Press statement

Brussels, April 202X-2
Every year across the European Union, around three hundred million farmed animals are confined in cages. Unable to conduct many of their natural behaviours, these animals are treated as nothing more than production machines. No single EU Member State is completely cage free and in some Member States up to 90% of all hens, mother pigs and young calves are kept in cages and crates. This despite farming industry having had more than 15 years to voluntarily change their installations.
Over 170 organisations and caring citizens across Europe therefore joined forces to spearhead the “End the Cage Age” European citizens’ initiative. In total, 1.4 million EU citizens made their voices heard and signed the petition. Only one other citizen’s initiative has so far gathered more signatures than this.
Mr Daniel Müller, campaign leader for “End the Cage Age” said: what we see now is the battle of ethics versus economy. EU citizens do not want cheap food at any cost and certainly not at the cost of pain and suffering of our fellow creatures. Food industry and economic interests will have to adapt to this reality – and finally do what is right.
In response to our tireless campaigning, in April 202X-2, the European Commission committed to proposing legislation before the end of 202X to phase out and finally prohibit the use of animal cages. We must now ensure that a total ban on caged farming is delivered, as soon as possible. The fight also continues to pave the way not only for a cage-free Europe, but for a cage-free world by making sure that all imported products in the EU comply with cage-free standards.


Attachment 6: Website

What is a citizens' initiative?
A European citizens’ initiative is a way for you and other Europeans to take an active part in EU policymaking.
If you want the EU to act on a particular issue, you can launch a citizens’ initiative calling on the European Commission to propose new EU legislation on that issue.
For an initiative to be considered by the Commission, you need to get one million citizens from across the EU to sign it in support.
Step 1: Get started
Before launching an initiative, it is worth considering some of the key practical aspects, including:
is asking for EU legislation to be passed the best way to achieve your goals?
you must first set up a group of organisers composed of at least 7 EU citizens living in seven different EU countries. To do so, you need to find people to team up with across Europe who are willing to support your issue.
how will you organise your campaign to collect the signatures?
You can find detailed advice on all these issues on the European Citizens’ Initiative Forum




Step 2: Get your initiative registered
Before you can start collecting signatures for your initiative, you must ask the Commission to register it.
For this, you will need to:
create an organiser account. You will use this to manage your initiative and liaise with the Commission throughout its lifecycle.
provide a description of your initiative in one of the official EU languages (as well as details and relevant documents on the group of organisers, funding received, etc.)
The Commission is not obliged to register all initiatives. It only registers initiatives that meet certain criteria.
Once you ask for your initiative to be registered, we will assess whether to accept it.
You will receive an answer within 2-4 months.


Step 3: Get support
You need to get the support of at least one million people, with minimum numbers in at least seven EU countries. They must fill in a specific statement of support form.
You can collect:
on paper (pre-filled forms, downloadable from your organiser account) or
online (using the Central Online Collection System).
These forms are available in all EU official languages.
To sign, people must be:
EU nationals (nationals of an EU country)
old enough to vote in European elections or aged at least 16 in some countries
TIP – It is better to collect more signatures than you need. Sometimes the authorities in each country might not be able to validate all the statements of support you provide. Throughout the collection procedure, you must comply with data protection rules.


Step 4: Submit your initiative
Once you have received the last certificate from the national authorities, you have 3 months to submit your initiative to the Commission – together with the information on the support and funding you have received for the initiative.


What next?
If the Commission considers legislation an appropriate response to your initiative, it will start preparing a formal proposal. This can require preparatory steps like public consultations, impact assessments, etc. Once adopted by the Commission, the proposal is submitted to the European Parliament and the EU Council (or in some cases, only to the Council), which will need to adopt it for it to become law.
The Commission is not obliged to propose legislation. Even where it responds positively, the most appropriate follow-up to an initiative may be non-legislative in nature. There are a range of other measures that may be more suitable.
The European Parliament may also assess the measures taken by the Commission.

Attachment 7: E-mail message
 
From: ROBINSON Michael (AGRI)
Sent: Monday, 16 May 202X
To: MUNOZ Wiebke (SANTE)
Subject: Revised animal welfare regulation
 
---

Dear Wiebke,
Just a heads-up about the AGRI response to your animal welfare ISC - you will receive it later today. We can accept all of it, but we have a remaining concern about the proposed new rules for poultry cage rearing.
First, the proposed exception for farms less than 50 livestock units (3500 laying hens) does not make much sense. The overwhelming majority of eggs produced in the EU come from farms with more than 5000 birds (70 livestock units) and the smaller farms can anyway more easily transition to cage-free rearing if they haven’t done so already.
Longer transition time also does not help, it’s not about more time for farms to adapt. It’s about the money and about food prices.
For large-scale installations, cages are simply more efficient and use much less space. With your proposal, notably the requirement of more space per laying hen, production will necessarily be less cost-efficient, and most farms will not be able to keep the same number of birds. Consumers might say they care about animal welfare but when they make their choices in the supermarket, the thing that matters most is the price! If you implement the new rules, the price of eggs might increase by around 20-40% in countries like Spain, Portugal, and Malta where cage systems are still the norm. This means we will see a significant increase in cheap imported eggs from third countries with much worse animal welfare standards. Our European farmers cannot compete on such unfair terms.
There is also the socioeconomic element: the burden of higher food prices will be heavier on the poorest families.
Unless farmers can be compensated economically somehow for taking this risk, we don’t see any need for changing the current rules on poultry caging and we will need to block your proposal.

Call me if you want to discuss this further.

Best,
Michael


Attachment 8: Press release


MEPs endorse EU citizens’ call for gradual end to caged farming
Press releases – AGRI - 20 February 202X-2

The European Parliament has called for the end of caged farming within the next 5 years. The parliament members voted on an own initiative resolution recommending a total ban on the use of cages in animal agriculture by 202X+3.
The vote followed intensive lobbying by the “End the Cage Age” European Citizens Initiative, led by 170 non-governmental organisations (NGOs) across Europe, which garnered 1.4m signatures from EU citizens and demanded the phasing out of cages on farms. Members of the European Parliament (MEPs) voted by 558 to 37 with 85 abstentions on the non-binding resolution.
Unlevel playing field in Europe
Even though the EU has banned the use of battery cages in poultry production and sow stalls during gestation, campaigners said this was not enough, given the perceived unlevel playing field across Europe with some nations already going beyond EU laws.
According to the initiative, five out of 28 countries are currently achieving more than 80% cage-free production, i.e., Austria (97%), Luxembourg (97%), Sweden (92%), Germany (86%) and the Netherlands (82%). Bottom of the list is Malta, with 1%, followed by Spain and Portugal. About sows, the report is based on Eurostat figures, according to the initiative’s website.
In the European Parliament, a working group on cage-free farming established in 202X-10 has been actively supporting the “End the Cage Age” initiative and in October 202X-3, 101 MEPs from various political parties signed a letter of support addressed to EU Commissioners.
Speeding up the review of animal welfare legislation
Last month, the parliament’s AGRI committee adopted a motion for a resolution. Committee members called on the European Commission to speed up the review of the animal welfare legislation and back the phasing out of all cages in farming, possibly already by 202X+3. They also insisted on ensuring compliance with EU standards for all products imported into the EU.
By April this year, the European Commission will have made its decision as to whether to start a legislative process to ban caged farming. EU Food Safety commissioner Stella Kyriakides told MEPs that the Commission was considering a request contained within the resolution to apply the same animal welfare standards to meat imported from outside the EU as European farmers must meet inside the bloc.
Kyriakides also noted the call for farmers to receive compensation and support in their transition from cages. She added the phase-out would happen “as soon as feasible” but did not give a specific date.
The results for pork production could be far-reaching, as it would likely change the current practice using farrowing crates. In recent years, a lot of research initiatives have already been launched to design free farrowing concepts.



Attachment 9: E-mail message 
 
From: CALBI Ana (EFSA)
Sent: Thursday, 16 October 202X-1
To: MUNOZ Wiebke (SANTE)
Subject: Cages and antibiotics
 
---
Dear Ms Munoz,
Congratulations on your concluded impact assessment on the animal welfare regulation!
In view of your upcoming drafting process, I need to point out that there are several scientific studies pointing to higher prevalence of antimicrobial resistance, notably among e-coli bacteria, in non-cage housing systems for poultry - if not implemented correctly and with strict quality standards. I feel this did not come out clearly enough from your impact assessment.
Free-range egg production systems face more challenges related to biosecurity and use of antibiotics. The free-range layer birds have more interaction with each other compared to caged ones, leading to an increased incidence of infectious poultry diseases requiring treatment with antimicrobials, in turn leading to increased emergence of resistant commensal and pathogenic bacteria. This is a major threat to public health.
The main factor to consider is of course, as always, the number of hens per square meter, the hygiene routines, and the overall rules on veterinary prescription of antibiotics. It is the same for pigs: sows in small crates have low life quality but use less medication; pigs in free range but packed close together require lots of antibiotics and pigs in free range with sufficient space are more healthy and less prone to cause antimicrobial resistance. However, they are also much less cost-effective for industrial-size farming. 
Still, to ensure safe food production and avoid antibiotics resistance, livestock density simply must go down. 
If you could take these concerns into account in your draft revised regulation, we would be much grateful.

Best regards,
Ana Calbi

---
Head of Department
The European Food Safety Agency (EFSA)




Attachment 10: Impact assessment


								Brussels, 13 October 202X-1






COMMISSION STAFF WORKING DOCUMENT

IMPACT ASSESSMENT REPORT


Animal welfare: revised regulation


Executive summary
To address the specific objectives of the animal welfare legislation revision, four policy measures have been considered, with low, medium, and high ambition options. Impacts assessed include cost-efficiency, environmental and societal impacts and impacts on the single market. The European Food Safety Agency (EFSA) has confirmed the scientific evidence. Numerous stakeholder consultations and supporting studies have been performed.
For animals kept for economic purposes, the measures/options covered are:
1) 	Phasing out confining cages/crates for the following species and categories of animals:
Pigs
Calves
Laying hens and pullets
Rabbits and fur-producing animals.
A general transition period of between five and twelve years would be considered, depending on the level of ambition. Exceptions e.g., depending on farm size (number of “livestock units” where 1 livestock unit = 1 cow, or 2 pigs, or 71 laying hens) could be considered.
2) 	Banning the killing of day-old male chicks (or, as an alternative option, introducing an obligation of marking eggs from production systems where day-old chicks are killed). In the case of a ban, while a transition period of five years would be technically sufficient, notably if combined with stricter import rules, the impacts could be mitigated by introducing a ten years’ transition period.

3) 	Banning painful mutilations, i.e., beak trimming in poultry and tail docking in pigs (with incentives instead of bans as alternative options). For the bans, a general transition period of ten years has been considered. Incentives for voluntary action would enter into force immediately.
  
4) 	Animal welfare requirements at import. For animals and products of animal origin imported to the EU, either similar or fully equivalent animal welfare requirements with the revised EU animal welfare requirements for kept animals, as regards the use of cages, mutilations, space allowances, enrichment, the killing of day-old chicks and the welfare of fur animals would apply. A transition period of five-ten years has been considered.

A phase-out of the use of cages and stalls would considerably improve the welfare of more than 160 million laying hens, 53 million pullets (young hens), 13 million sows, two million calves, 35 million ducks and geese and 100 million rabbits. They would be able to perform a more natural and healthy behaviour.
A partial or total ban on cages and crates would have an important economic impact on the sectors concerned. For instance, for laying hens we have estimated the required investments for a transition into a cage-free system to about EUR 2,4-2,8 billion. For sows, the cost of demolishing the current system with gestation and farrowing crates could amount to around EUR 64-100 /m². These costs are likely to result in higher consumer prices. 
The situation however differs between Member States. Some have already taken measures to phase out cages and stalls whereas others have not. 
To mitigate these economic impacts, certain measures could be considered, notably awareness-raising vis-à-vis consumers, economic incentives via the Common Agricultural Policy and import rules to ensure a level playing field / reduce unfair competition.
The proposed measures would ensure a positive impact on sustainability as it would imply less intensive food production, causing less pollution to air and water. However, since cage-free animals move around more, they spend more energy and consume more feed. This could have a negative impact on the use of resources.

Table 1: Policy options (most cost-efficient option in terms of added value vs cost is shown in green):
| Low ambition option | Medium ambition option | High ambition option | Comments |
1.a. Crates/cages: pigs | Phase in of crate ban over 10 years. |   | Exceptions allowed for farms with less than 50 livestock units. |   | Allowing temporary confinement from 1 week before farrowing until weaning. |   | Cost-benefit analysis value (-) | Phase in of ban over 5 years. |   | Farms with less than 50 livestock units allowed to phase out crates over 15 years. |   | Temporary confinement allowed from 1 day before farrowing to 5 days post-farrowing. |   | Cost-benefit analysis value (+++) | Total ban phased in over 5 years. |   | No exceptions. |   | Cost-benefit analysis value (+) | Medium and high ambition options can be combined with stricter requirements of minimum living space per animal and/or voluntary guidance on antibiotics use. |
1.b. Crates/cages: calves | No legislative change. |   | Cost-benefit analysis (-) | Phase-out of all use of weaning crates over 10 years. |   | Ban on trade / import of calves kept crated. |   | Cost-benefit analysis (+) | Phase-out of all use of crates within 5 years. |   | Ban on trade / import of calves kept crated. |   | Cost-benefit analysis (++) | Strong public support for total ban. Low impact on food pricing. |
1.c. Cages:  laying hens and pullets | Phase in of ban over 12 years. |   | Farms with less than one hundred livestock units exempted. |   | Cost-benefit analysis (0) | Phase in of ban over 10 years. |   | Farms with less than 50 livestock units allowed to phase out cages over 12 years. |   | Cost-benefit analysis (++) | Total ban phased in over 5 years. |   | Cost-benefit analysis (+++) | Same as with pigs. |
1.d. Cages: rabbits and animals in fur production | No legislative change. |   | Cost-benefit analysis (-) | Transition phase 10 years.  |   | Cost-benefit analysis (+) | Transition phase 5 years. |   | Cost-benefit analysis (++) | Low economic impact (small sector). |
2. Killing of day-old male chickens (laying breeds) | Obligation of marking eggs from production systems applying this practice, starting as from 5 years. |   | Cost-benefit analysis: (0) | Ban of procedure within 10 years + economic incentives via the Common Agricultural Policy for farmers transitioning sooner |   | Immediate obligation of marking eggs from production systems not yet transitioned. |   | Cost-benefit analysis (++) | Phase in of ban over 5 years + stricter import rules to protect internal market |   | Cost-benefit analysis (+) | Strong public support for total ban. Strong impact on food pricing. |   | Viability dependent on development of technology to gender-identify eggs before hatching. |   | Possibility of launching consumer awareness campaigns to explain food price impacts (acceptability). |
3. Ban on painful mutilations (beak trimmings / tail cropping) | N/a | Immediate ban on cross-border trade in tail-docked pigs. |   | No ban on the procedures but economic incentives via the Common Agricultural Policy for voluntary transition. |   | Cost-benefit analysis (+) | Phase in over 10 years of total ban. |   | Cost-benefit analysis (+++) | No justification for no action. |   | Enforcement mechanism needed (inspections). |
4. Animal welfare requirements at import | No legislative change | Minimum set of rules apply for import (low- or medium ambition options). 10 years transition period. | Full EU rules to apply also for imported products. 5 years transition period. | Strong impact on competitiveness of EU farmers. Strong impact on the acceptability of other measures. | Possible difficulty of implementation. |
 

Background
Since 202X-10, EU legislation requires that laying hens be kept either in enriched cages, or alternative systems (single or multi-tier barn or, free-range). The current legislation allows calves being individually housed until the age of eight weeks, while sows and gilts are kept in confinement for a period of four weeks after service and from one week before the expected time of farrowing to weaning of their piglets. 
Approximately one million farms keep laying hens in the EU. Forty-five percent of these are kept in enriched cages. 
There is currently a trend towards using less cages in many EU Member States such as France, the Netherlands and Poland to answer to consumer’s expectations. E.g., Austria and Luxembourg have already banned the use of cages for laying hens. The animal welfare problems related to cages will however remain for many laying hens if no action is taken at EU level.

Problem drivers
Conventional livestock production systems across EU countries are put under pressure by competitive global markets, a rise in input costs and the search for maximum profit margins by farmers and all food business operators along the production chain. The demand of certain consumers’ segments for low price food is expected to be more prevalent in the current inflationary context.
This pressure over production costs has led to further intensification (and specialisation) of the farming and killing practices, as business operators increase the volume of production to reduce overheads costs per livestock unit. Evidence shows that, while the number of livestock farms is decreasing, their size is increasing. Small farms are replaced by very large industrial scale installations.
This trend has led to certain detrimental effects on animal welfare due to high densities, certain management practices, housing/transport conditions and stunning methods, as well as due to certain breeding strategies.
Current EU rules also do not consider new scientific evidence and huge technological developments in relation to agricultural practices, zootechnics and transport operations. For instance, this new scientific evidence relates to a new understanding of stocking densities, behaviour (need for an enriched environment), mutilation practices, journey times and space allowances for animal transports, and stunning methods used for pigs, poultry, and farmed fish.
The lack of update of the EU animal welfare legislation has led Member States to adopt an increasing number of national measures going beyond EU minimum requirements to respond to the growing citizens’ concerns towards animal welfare, leading to a fragmented legal landscape, including as regards animal welfare labelling.
At the same time, consumers are growing more aware and more demanding. The upward trend of societal demands for better animal welfare protection is not reflected in the current legislative requirements. 

Figure 1: Problem tree 

Economic and environmental impacts of the preferred package of options: cages for laying hens
The policy option assessed to be most cost-efficient is a total prohibition on the use of cages for laying hens with a transition period of 5 years (from the date of entry into force of the revised legislation).
However, if no similar requirements apply for eggs and egg products imported into the EU from third countries, since the EU consumers’ demand for eggs is not expected to decrease and since EU production is expected to decrease, an increase in eggs obtained from caged hens imported from non-EU countries with lower standards is expected, thus limiting the positive animal welfare impact of the measure.
The required investments for a transition into a cage-free system for laying hens would amount to around EUR 2,4-2,8 billion.
A prohibition of cages would decrease the number of laying hens by an estimated 30% (i.e., from 186,8 million to 102,9 million) in farms which currently have cage systems.

SME’s
Small farms tend to use cage-free systems more than big farms. A prohibition would therefore primarily have a positive competitiveness impact on small farms.

Public authorities
It is likely that a prohibition would generate additional enforcement costs in the short term for the national competent authorities, however these will come back to current levels in the medium term.

Consumers
A prohibition would lead to an expected increase in the price of eggs, but to which extent is not clear. Some estimates by the EU poultry industry suggest a + 20% price gap between eggs from cages and those from barn systems. However, sales data from the Netherlands and Germany suggests a much smaller difference in prices: less than one eurocent per egg.
With an average per capita consumption of 210 eggs per year, or 4,04 eggs per week, this would mean that transitioning to cage-free systems would add less than four eurocents per person to consumers’ weekly food shopping bill. Furthermore, the experience from Germany, where enriched cages are progressively phased out, even suggests that the price for barn eggs may eventually be the same as for eggs from enriched cages.
 
Environmental impacts
A prohibition would have a positive impact on sustainability as it would imply less intensive production leading to less air and water pollution and less greenhouse gas emissions.



Attachment 11: Website

| A gestation crate, also known as a sow stall, is a metal enclosure in which a   used for breeding may be kept during pregnancy. A standard crate measures 2 m x 60 cm. | Sow stalls contain no bedding material and are instead floored with slatted plastic, concrete, or metal to allow waste to be efficiently collected below. This waste is then flushed into open-air pits known as . A few days before giving birth (farrowing), sows are moved to farrowing crates where they are able to lie down, with an attached crate from which their piglets can nurse. | Most pregnant sows in the US are kept in gestation crates. The crates are banned for new installations in Austria and Canada, but many sows are still confined there in pig breeding facilities. The crates are banned in the United Kingdom, Canada, Switzerland, and Sweden. However, farrowing crates, in which female breeding pigs can be kept for up to five weeks, are not banned in the UK. | Opponents of the crates argue that they constitute animal abuse, while proponents say they are needed to prevent sows from fighting among themselves. |




Attachment 12: Website



Page contents |  | Submission and examination |  |  | Submission and examination | The  initiative was submitted to the Commission on 2 October 202X-3, having gathered 1,397,113 statements of support. See . | The organisers met with the Commissioner for Health and Food Safety, Stella Kyriakides on 30 October 202X-3. | A  took place at the European Parliament on 25 January 202X-2. See . | The initiative was debated at the European Parliament’s plenary session on 20 February 202X-2. In the  adopted on the same day, the European Parliament expressed its strong support for the initiative. See European Parliament’s . | Answer of the European Commission | In its response on 4 April 202X-2, the Commission commits to table, by the end of 202X, a legislative proposal to phase out, and finally prohibit, the use of cage systems for all animals mentioned in the initiative. | In parallel to the legislation and to facilitate a balanced and economically viable transition to cage-free farming, the Commission will seek specific supporting measures in key related policy areas, such as trade and research and innovation.  | In particular, the new Common Agricultural Policy will provide financial support and incentives – such as the new eco-schemes instrument – to help farmers upgrade to more animal-friendly facilities in line with the new standards. |



Attachment 13: News article



 -  -  
Health and food safety Commissioner will fight for ethical food systems in Europe
30 October 202X-3
Earlier today, Commissioner Kyriakides met with the representatives of the citizens’ initiative ‘End the Cage Age’. EURACTIV interviewed the Commissioner after her meeting with the campaign team.
Stella Kyriakides is European Commissioner for Health and Food Safety and in charge of the EU animal welfare legislation. She spoke to EURACTIV about the call for revised animal welfare legislation and the possibility for action ahead.
This is one of the most strongly supported citizens’ initiatives so far with almost 1.4 million signatures collected. How will the Commission respond to all who signed this petition?
I am impressed by the hard work by these dedicated young people. I promised them today that the Commission will investigate this very carefully.
In fact, we recently completed a review of our legislation and have found that there is indeed scope for improvement. However, first we will hear the views of the European Parliament and we will consult across the Commission services and then reply about next steps.
Your colleague, the Commissioner for Agriculture, is less enthusiastic. How will you get the farming community onboard?
As always, there will be a balancing act between several interests. Farmers produce the food we eat and they deserve to be heard as well. Many farmers also already made this transition, showing it is possible to rear animals cage-free.
The Commission always performs a thorough impact assessment, so any legislative proposal will be based on solid facts and on careful consideration of all relevant impacts. We always seek a sustainable compromise.
There could also be other possibilities to make animal welfare more attractive for farmers by e.g., economic incentives, subsidies, trade schemes and awareness campaigns. It is not just about laws and penalties.
On the other hand, I think the farming industry has known for a long time that this is coming, they have had plenty of time to prepare and many Member States have in fact already taken significant steps in the direction of free-range animal rearing.
But is there not a risk that ‘money will talk’, how can you weigh the economic impacts against animal suffering – how will the comparison be done in an impact assessment?
No, economic interests are not the only interests we take into account. It is true that our assessment is expressed as a cost-benefit ratio, but among those ‘benefits’, we consider also softer values such as social, health and environmental impacts – and ethical choices. I guarantee you that industry interests will not dominate this process. 
On the contrary, I think what we see here is a strong message from European citizens that animal rights and animal welfare must be respected, and I agree with them. We cannot ignore this question any longer.",24,3.0,"Summary

According to the Notice of Competitions of current EPSO competitions, the only competency that will be assessed in the Case Study exam is Written Communication",3.0,"Observations

With this competence, we basically evaluate the style of the case study. Your text should be clear, fluent, written in a professional but still captivating style; of course, spelling and grammar are also covered in this area. Another point we examine here is whether you managed to find the balance between providing details and being concise while conveying the key points of the arguments.",,"Tips to Improve

The text is, in general, cohesive, though the first third is not so much, it is informative, but the amount of typos, grammatical inaccuracies and unfinished, incomplete or overcomplicated sentences heavily undermine the readability of the text.","Trainee's Answer
1 June 202X
To the attention of the Director-General, Ms Heinrich,
Briefing note
Subject: Draft revised animal welfare regulation
Facts
- 300 millions farmed animals are confined in cages where they are treated as production machines. In some Member states (MS) of the European Union (EU), 90% of all hens and youg calves are kept in cages.
- 170 organisations and caring citizens across Europe lead a European citizen's initiative to ""End the Cage Age"". They are gathring huge number of signatures: 1.4m. For reminder, the EC will considered the Europen Citizens' Initiative if (more details here):
- it is composed of at least 7 EU citizens living in 7 different EU conuntries
- and signed by one million citizens.
- In April 20X-2, European Commission (EC) committed to propose legislation before end of 202X to finally prohibit the use of animal cages. Moreover, this legislation will also apply to imported products and the producer outside EU.
Summary of the main issues
Following the submission of the ""End the Cage Age"" initiative, the main issue raised by it:
How to ban the use of cage by farmers considering the impacts on environment, society and the single market ?
European Parliament (EP) recommended (558 MEPs in favour) a total ban on the use of cages in animal agriculture by 20X+3. Is it cost-efficiency to apply entirely this recommendation ? If yes, how long will be the transition period and how to reduce the impact on farmers during this period ?
Arguments
Negative opinion
Mr Denker mentioned on 16/05/202x that low ambition option or staus quo should apply in order to ensure competitive pricing of EU food products vs third countries (with only minimum requirements)
According to Mr Robinson (AGRI), the threshold of 50 livestocks units for exception is not justified. Indeed, the majority of eggs produced in the EU com from farms with mor than 71 livestocks unit. Moreover, longer transition will not change the situation. Consumers are looking for food prices and the decrease of space by banning the cages will increase the price. It could lead to more importation from countries with less animal welfare standards. Finally, without compensation for farmers, the current proposal will be blocked.
Without the cages, as several scientific studies pointed out, it prevails more antimicrobial resistance. More challenges related to biosecurity, use of antibiotics and more interaction will appear. To counter this, the hygiene routines and overall rules must be respected. The number of hens per square meter should be limited.
Positive opinion
On 14/05/202X, Ms Svoboda wrote that our proposal is in line with European Green Deal objectives.
EP propose to apply the same animal welfare standards to meat imported from outside EU as EU farmers (resolution from EP).
In order to smooth the transition period, some compensation and support for the transition to cage-free are necessary to EU farmers (awareness-raising vis-à-vis consumers, economic incentives,via the Common Agricultural Policy and import rules). This general transition period of between five and twelve years will be positive for all stakeholders thus a balanced and economically viable transition to cage-free farming.
We can make the animal welfare more attractive for EU farmers by offering economic incentives, subsidies, trade schemes and awareness campaigns.
Softer values such as social, health and environmental impacts and ethical choices must be taken into consideration when preparing this proposal. Finally, animal rights and welfare could not be forgotten. We should respect them.
 
Recommendations
Banning totally the cage however a transition period is required in order to reduce the impact on EU farmers. This transition period is needed. EU farmers should reduce also financial compensation and EU consumers should be aware of impacts and efforts made. Finally, this rule should appy to
For next step, the EC should implement specific measures in some key related policy areas, as trade and research and innovation. Finance support and incentives provided by new Common Agricultural Policy are part of this process to upgrade facilities of farmers to a more animal-friendly system.
I remain at your disposal for any questions.
Kind regards,
Signature [my name]"
3,0_Generative AI (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. 

Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG CONNECT in the unit in charge of fighting against disinformation.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Critical thinking, analysing & creative problem-solving, Decision-making and getting results, Information management,  Communication.

Specifically, your task will be to draft a 2 to 2.5 - page speaking note for the Commisioner to clarify the intentions of the Commission with respect to generative AI (GAI). This document must include: 

What is GAI and what are the potential benefits.
What are the dangers associated with GAI and how does the EU want to address them.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations

AI - Artificial intelligence
AIA – Artificial Intelligence Act
AGI - Artificial general intelligence 
ANI - Artificial narrow intelligence
ANN - Artificial neural network
DSA – Digital Services Act
GAI – Generative AI
ML - Machine learning
NLP - Natural language processing


EMAIL 1","Subject: Press Release on generative AI

Dear YOU,

Earlier today, Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton met with representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation.
Jourová asked the signatories to create a dedicated and separate track within the code to deal with disinformation generated by Artificial Intelligence. It should aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them. 
Jourová will present her initiative at a press point tomorrow at 11:15 a.m. so could you prepare her talking points and send them to me this evening before closing of the office hours. She has asked to stress the importance of the fight against disinformation in the context of defending democracy and the EU values. 

Many thanks",",

Charles
Head of Unit





What are the most pressing dangers of AI?
As AI systems prove to be increasingly beneficial in real-world applications, they have broadened their reach, causing risks of misuse, overuse, and explicit abuse to proliferate. As AI systems increase in capability and as they are integrated more fully into societal infrastructure, the implications of losing meaningful control over them become more concerning. New research efforts are aimed at re-conceptualizing the foundations of the field to make AI systems less reliant on explicit, and easily mis specified, objectives. A particularly visible danger is that AI can make it easier to build machines that can spy and even kill at scale. But there are many other important and subtler dangers at present.
Techno-Solutionism
One of the most pressing dangers of AI is techno-solutionism, the view that AI can be seen as a panacea when it is merely a tool. As we see more AI advances, the temptation to apply AI decision-making to all societal problems increases. But technology often creates larger problems in the process of solving smaller ones. For example, systems that streamline and automate the application of social services can quickly become rigid and deny access to migrants or others who fall between the cracks. 
When given the choice between algorithms and humans, some believe algorithms will always be the less-biased choice. Yet, in 2018, Amazon found it necessary to discard a proprietary recruiting tool because the historical data it was trained on resulted in a system that was systematically biased against women. Automated decision-making can often serve to replicate, exacerbate, and even magnify the same bias we wish it would remedy.
Indeed, far from being a cure-all, technology can actually create feedback loops that worsen discrimination. Recommendation algorithms, like Google’s page rank, are trained to identify and prioritize the most “relevant” items based on how other users engage with them. As biased users feed the algorithm biased information, it responds with more bias, which informs users’ understandings and deepens their bias, and so on. Because all technology is the product of a biased system, techno-solutionism’s flaws run deep: a creation is limited by the limitations of its creator.
Dangers of Adopting a Statistical Perspective on Justice
Automated decision-making may produce skewed results that replicate and amplify existing biases. A potential danger, then, is when the public accepts AI-derived conclusions as certainties. This determinist approach to AI decision-making can have dire implications in both criminal and healthcare settings. AI-driven approaches like PredPol, software originally developed by the Los Angeles Police Department and UCLA that purports to help protect one in 33 US citizens, predict when, where, and how crime will occur. A 2016 case study of a US city noted that the approach disproportionately projected crimes in areas with higher populations of non-white and low-income residents. When datasets disproportionately represent the lower power members of society, flagrant discrimination is a likely result.
Sentencing decisions are increasingly decided by proprietary algorithms that attempt to assess whether a defendant will commit future crimes, leading to concerns that justice is being outsourced to software. As AI becomes increasingly capable of analyzing more and more factors that may correlate with a defendant's perceived risk, courts and society at large may mistake an algorithmic probability for fact. This dangerous reality means that an algorithmic estimate of an individual’s risk to society may be interpreted by others as a near certainty—a misleading outcome even the original tool designers warned against. Even though a statistically driven AI system could be built to report a degree of credence along with every prediction, there’s no guarantee that the people using these predictions will make intelligent use of them. Taking probability for certainty means that the past will always dictate the future.
There is an aura of neutrality and impartiality associated with AI decision-making in some corners of the public consciousness, resulting in systems being accepted as objective even though they may be the result of biased historical decisions or even blatant discrimination. All data insights rely on some measure of interpretation. As a concrete example, an audit of a resume-screening tool found that the two main factors it associated most strongly with positive future job performance were whether the applicant was named Jared, and whether he played high school lacrosse. Undesirable biases can be hidden behind both the opaque nature of the technology used and the use of proxies, nominally innocent attributes that enable a decision that is fundamentally biased. An algorithm fueled by data in which gender, racial, class, and ableist biases are pervasive can effectively reinforce these biases without ever explicitly identifying them in the code. 
Without transparency concerning either the data or the AI algorithms that interpret it, the public may be left in the dark as to how decisions that materially impact their lives are being made. Lacking adequate information to bring a legal claim, people can lose access to both due process and redress when they feel they have been improperly or erroneously judged by AI systems. Large gaps in case law make applying Title VII—the primary existing legal framework in the US for employment discrimination—to cases of algorithmic discrimination incredibly difficult. These concerns are exacerbated by algorithms that go beyond traditional considerations such as a person’s credit score to instead consider any and all variables correlated to the likelihood that they are a safe investment. A statistically significant correlation has been shown among Europeans between loan risk and whether a person uses a Mac or PC and whether they include their name in their email address—which turn out to be proxies for affluence. Companies that use such attributes, even if they do indeed provide improvements in model accuracy, may be breaking the law when these attributes also clearly correlate with a protected class like race. Loss of autonomy can also result from AI-created “information bubbles” that narrowly constrict each individual’s online experience to the point that they are unaware that valid alternative perspectives even exist.
Disinformation and Threat to Democracy
AI systems are being used in the service of disinformation on the internet, giving them the potential to become a threat to democracy and a tool for fascism. From deepfake videos to online bots manipulating public discourse by feigning consensus and spreading fake news, there is the danger of AI systems undermining social trust. The technology can be co-opted by criminals, rogue states, ideological extremists, or simply special interest groups, to manipulate people for economic gain or political advantage. Disinformation poses serious threats to society, as it effectively changes and manipulates evidence to create social feedback loops that undermine any sense of objective truth. The debates about what is real quickly evolve into debates about who gets to decide what is real, resulting in renegotiations of power structures that often serve entrenched interests. 
Discrimination and Risk in the Medical Setting
While personalized medicine is a good potential application of AI, there are dangers. Current business models for AI-based health applications tend to focus on building a single system—for example, a deterioration predictor—that can be sold to many buyers. However, these systems often do not generalize beyond their training data. Even differences in how clinical tests are ordered can throw off predictors, and, over time, a system’s accuracy will often degrade as practices change. Clinicians and administrators are not well-equipped to monitor and manage these issues, and insufficient thought given to the human factors of AI integration has led to oscillation between mistrust of the system (ignoring it) and over-reliance on the system (trusting it even when it is wrong), a central concern of the 2016 AI100 report.
These concerns are troubling in general in the high-risk setting that is healthcare, and even more so because marginalized populations—those that already face discrimination from the health system from both structural factors (like lack of access) and scientific factors (like guidelines that were developed from trials on other populations)—may lose even more. Today and in the near future, AI systems built on machine learning are used to determine post-operative personalized pain management plans for some patients and in others to predict the likelihood that an individual will develop breast cancer. AI algorithms are playing a role in decisions concerning distributing organs, vaccines, and other elements of healthcare. Biases in these approaches can have literal life-and-death stakes.
In 2019, the story broke that Optum, a health-services algorithm used to determine which patients may benefit from extra medical care, exhibited fundamental racial biases. The system designers ensured that race was precluded from consideration, but they also asked the algorithm to consider the future cost of a patient to the healthcare system. While intended to capture a sense of medical severity, this feature in fact served as a proxy for race: controlling for medical needs, care for Black patients averages $1,800 less per year.
New technologies are being developed every day to treat serious medical issues. A new algorithm trained to identify melanomas was shown to be more accurate than doctors in a recent study, but the potential for the algorithm to be biased against Black patients is significant as the algorithm was trained using majority light-skinned groups. The stakes are especially high for melanoma diagnoses, where the five-year survival rate is 17 percentage points less for Black Americans than white. While technology has the potential to generate quicker diagnoses and thus close this survival gap, a machine-learning algorithm is only as good as its data set. An improperly trained algorithm could do more harm than good for patients at risk, missing cancers altogether or generating false positives. As new algorithms saturate the market with promises of medical miracles, losing sight of the biases ingrained in their outcomes could contribute to a loss of human biodiversity, as individuals who are left out of initial data sets are denied adequate care. While the exact long-term effects of algorithms in healthcare are unknown, their potential for bias replication means any advancement they produce for the population in aggregate—from diagnosis to resource distribution—may come at the expense of the most vulnerable.








Regulatory framework proposal on artificial intelligence 
The Commission is proposing the first-ever legal framework on AI, which addresses the risks of AI and positions Europe to play a leading role globally. 

© gorodenkoff - iStock Getty Images Plus
The regulatory proposal aims to provide AI developers, deployers and users with clear requirements and obligations regarding specific uses of AI. At the same time, the proposal seeks to reduce administrative and financial burdens for business, in particular small and medium-sized enterprises (SMEs).
The proposal is part of a wider AI package, which also includes the updated Coordinated Plan on AI. Together, the Regulatory framework and Coordinated Plan will guarantee the safety and fundamental rights of people and businesses when it comes to AI. And they will strengthen uptake, investment and innovation in AI across the EU.
Why do we need rules on AI?
The proposed AI regulation ensures that Europeans can trust what AI has to offer. While most AI systems pose limited to no risk and can contribute to solving many societal challenges, certain AI systems create risks that we must address to avoid undesirable outcomes.
For example, it is often not possible to find out why an AI system has made a decision or prediction and taken a particular action. So, it may become difficult to assess whether someone has been unfairly disadvantaged, such as in a hiring decision or in an application for a public benefit scheme.
Although existing legislation provides some protection, it is insufficient to address the specific challenges AI systems may bring.
The proposed rules will:
address risks specifically created by AI applications.
propose a list of high-risk applications.
set clear requirements for AI systems for high-risk applications.
define specific obligations for AI users and providers of high-risk applications.
propose a conformity assessment before the AI system is put into service or placed on the market.
propose enforcement after such an AI system is placed in the market.
propose a governance structure at European and national level.
A risk-based approach

The Regulatory Framework defines 4 levels of risk in AI:
Unacceptable risk
High risk
Limited risk
Minimal or no risk
Unacceptable risk
All AI systems considered a clear threat to the safety, livelihoods and rights of people will be banned, from social scoring by governments to toys using voice assistance that encourages dangerous behaviour.
High risk
AI systems identified as high-risk include AI technology used in:
critical infrastructures (e.g., transport), that could put the life and health of citizens at risk.
educational or vocational training, that may determine the access to education and professional course of someone’s life (e.g., scoring of exams).
safety components of products (e.g., AI application in robot-assisted surgery).
employment, management of workers and access to self-employment (e.g., CV-sorting software for recruitment procedures).
essential private and public services (e.g., credit scoring denying citizens opportunity to obtain a loan).
law enforcement that may interfere with people’s fundamental rights (e.g., evaluation of the reliability of evidence).
migration, asylum, and border control management (e.g., verification of authenticity of travel documents).
administration of justice and democratic processes (e.g., applying the law to a concrete set of facts).
High-risk AI systems will be subject to strict obligations before they can be put on the market:
adequate risk assessment and mitigation systems.
high quality of the datasets feeding the system to minimize risks and discriminatory outcomes.
logging of activity to ensure traceability of results.
detailed documentation providing all information necessary on the system and its purpose for authorities to assess its compliance.
clear and adequate information to the user.
appropriate human oversight measures to minimize risk.
high level of robustness, security and accuracy.
All remote biometric identification systems are considered high risk and subject to strict requirements. The use of remote biometric identification in publicly accessible spaces for law enforcement purposes is, in principle, prohibited.
Narrow exceptions are strictly defined and regulated, such as such as when necessary to search for a missing child, to prevent a specific and imminent terrorist threat or to detect, locate, identify, or prosecute a perpetrator or suspect of a serious criminal offence.
Such use is subject to authorization by a judicial or other independent body and to appropriate limits in time, geographic reach and the data bases searched.
Limited risk
Limited risk refers to AI systems with specific transparency obligations. When using AI systems such as chatbots, users should be aware that they are interacting with a machine so they can take an informed decision to continue or step back.
Minimal or no risk
The proposal allows the free use of minimal-risk AI. This includes applications such as AI-enabled video games or spam filters. Most AI systems currently used in the EU fall into this category.



How does it all work in practice for providers of high-risk AI systems?
Once an AI system is on the market, authorities oversee market surveillance, users ensure human oversight and monitoring, and providers have a post-market monitoring system in place. Providers and users will also report serious incidents and malfunctioning.
Future-proof legislation
As AI is a fast-evolving technology, the proposal has a future-proof approach, allowing rules to adapt to technological change. AI applications should remain trustworthy even after they have been placed on the market. This requires ongoing quality and risk management by providers.




The 5 biggest risks of generative AI, according to an expert 
AI makes our lives easier in many different ways. However, these benefits can come with costs. 



Written by Sabrina Ortiz, Associate Editor on April 25, 20XX

Generative AIs, such as ChatGPT, have revolutionized how we interact with and view AI. Activities like writing, coding, and applying for jobs have become much easier and quicker. With all the positives, however, there are some pretty serious risks.
A major concern with AI is trust and security, which has even caused some countries to completely ban ChatGPT as a whole or to reconsider policy around AI to protect users from harm. 
According to Gartner analyst Avivah Litan, some of the biggest risks of generative AI concern trust and security and include hallucinations, deepfakes, data privacy, copyright issues, and cybersecurity problems.
1. Hallucinations
Hallucinations refer to the errors that AI models are prone to make because, although they are advanced, they are still not human and rely on training and data to provide answers. 
If you've used an AI chatbot, then you have probably experienced these hallucinations through a misunderstanding of your prompt or a blatantly wrong answer to your question.
Litan says the training data can lead to biased or factually incorrect responses, which can be a serious problem when people are relying on these bots for information. 
""Training data can lead to biased, off base or wrong responses, but these can be difficult to spot, particularly as solutions are increasingly believable and relied upon,"" says Litan. 
2. Deepfakes
A deepfake uses generative AI to create videos, photos, and voice recordings that are fake but take the image and likeness of another individual. 
Perfect examples are the AI-generated viral photo of Pope Francis in a puffer jacket or the AI-generated Drake and the Weeknd song, which garnered hundreds of thousands of streams. 
""These fake images, videos and voice recordings have been used to attack celebrities and politicians, to create and spread misleading information, and even to create fake accounts or take over and break into existing legitimate accounts,"" says Litan. 
Like hallucinations, deepfakes can contribute to the massive spread of fake content, leading to the spread of misinformation, which is a serious societal problem. 
3. Data privacy
Privacy is also a major concern with generative AI since user data is often stored for model training. This concern was the overarching factor that pushed Italy to ban ChatGPT, claiming OpenAI was not legally authorized to gather user data. 
""Employees can easily expose sensitive and proprietary enterprise data when interacting with generative AI chatbot solutions,"" says Litan. ""These applications may indefinitely store information captured through user inputs, and even use information to train other models -- further compromising confidentiality.""
Litan highlights that, in addition to compromising user confidentiality, the stored information also poses the risk of ""falling into the wrong hands"" in an instance of a security breach.
4. Cybersecurity
The advanced capabilities of generative AI models, such as coding, can also fall into the wrong hands, causing cybersecurity concerns.
""In addition to more advanced social engineering and phishing threats, attackers could use these tools for easier malicious code generation,"" says Litan. 
Litan says even though vendors who offer generative AI solutions typically assure customers that their models are trained to reject malicious cybersecurity requests, these suppliers don't equip end users with the ability to verify all the security measures that have been implemented. 
5. Copyright issues
Copyright is a big concern because generative AI models are trained on massive amounts of internet data that is used to generate an output. 
This process of training means that works that have not been explicitly shared by the original source can then be used to generate new content. 
Copyright is a particularly thorny issue for AI-generated art of any form, including photos and music. 
To create an image from a prompt, AI-generating tools, such as DALL-E, will refer back to the large database of photos they were trained on. The result of this process is that the final product might include aspects of an artist's work or style that are not attributed to them. 
Since the exact works that generative AI models are trained on are not explicitly disclosed, it is hard to mitigate these copyright issues. 
What's next?
Despite the many risks associated to generative AI, Litan doesn't think that organizations should stop exploring the technology. Instead, they should create an enterprise-wide strategy that targets AI trust, risk, and security management. 
""AI developers must urgently work with policymakers, including new regulatory authorities that may emerge, to establish policies and practices for generative AI oversight and risk management,"" says Litan. 
 

What is generative AI?
In simple terms, generative AI is a subfield of artificial intelligence in which computer algorithms are used to generate outputs that resemble human-created content, be it text, images, graphics, music, computer code or otherwise.
In generative AI, algorithms are designed to learn from training data that includes examples of the desired output. By analyzing the patterns and structures within the training data, generative AI models can produce new content that shares characteristics with the original input data. In doing so, generative AI has the capacity to generate content that appears authentic and human-like.
How does generative AI work?
Generative AI is based on machine learning processes inspired by the inner workings of the human brain, known as neural networks. Training the model involves feeding algorithms large amounts of data, which serves as the foundation for the AI model to learn from. This can consist of text, code, graphics, or any other type of content relevant to the task at hand.
Once the training data has been collected, the AI model analyzes the patterns and relationships within the data to understand the underlying rules governing the content. The AI model continuously fine-tunes its parameters as it learns, improving its ability to simulate human-generated content. The more content the AI model generates, the more sophisticated and convincing its outputs become.
Examples of generative AI
Generative AI has made significant advancements in recent years, with several tools capturing the public attention and creating a stir amongst content creators. Big tech companies have also jumped on the bandwagon, with Google, Microsoft, Amazon, and others all lining up their own generative AI tools.
Depending on the application, generative AI tools may rely on an input prompt that guides it towards producing a desired outcome — think ChatGPT and DALL-E 2.
Some of the most notable examples of generative AI tools include:
ChatGPT: Developed by OpenAI, ChatGPT is an AI language model that can generate human-like text based on given prompts.
DALL-E 2: Another generative AI model from OpenAI, DALL-E is designed to create images and artwork based on text-based prompts.
Midjourney: Developed by San Francisco-based research lab Midjourney Inc., Midjourney interprets text prompts and context to produce visual content, like DALL-E 2.
GitHub Copilot: An AI-powered coding tool created by GitHub and OpenAI, GitHub Copilot suggests code completions for users of development environments like Visual Studio and JetBrains.
Benefits of generative AI
The most compelling advantage generative AI proposes is efficiency, in that it can enable businesses to automate specific tasks and focus their time, energy and resources on more important strategic objectives. This often results in lower labor costs and an increase in operational efficiency.
Generative AI can offer additional advantages to businesses and entrepreneurs, including:
Easily customizing or personalizing marketing content.
Generating new ideas, designs, or content.
Writing, checking, and optimizing computer code.
Drafting templates for essays or articles.
Enhancing customer support with chatbots and virtual assistants.
Facilitating data augmentation for machine learning models.
Analyzing data to improve decision-making.
Streamlining research and development processes.
Use cases of generative AI
Despite generative AI still being in its relative infancy, the technology has already found a firm foothold in various applications and industries.
In content creation, for instance, generative AI can produce text, images and even music, assisting marketers, journalists, and artists with their creative processes. In customer support, AI-driven chatbots and virtual assistants can provide more personalized assistance and reduce response times while reducing the burden on customer service agents.
Other uses of generative AI include:
Healthcare: Generative AI is used in medicine to accelerate the discovery of novel drugs, saving time and money in research.
Marketing: Advertisers use generative AI to craft personalized campaigns and adapt content to consumers’ preferences.
Education: Some educators use generative AI models to develop customized learning materials and assessments that cater to students’ individual learning styles.
Finance: Financial analysts use generative AI to examine market patterns and predict stock market trends.
Environment: Climate scientists employ generative AI models to predict weather patterns and simulate the effects of climate change.
Dangers and limitations of generative AI
It’s important to note that generative AI presents numerous issues requiring attention. One major concern is its potential for spreading misinformation or malicious or sensitive content, which could cause profound damage to people and businesses — and potentially pose a threat to national security.
These risks have not escaped policymakers. In April 20XX, the European Union proposed new copyright rules for generative AI that would require companies to disclose any copyrighted material used to develop these tools. Hopes are that such rules will encourage transparency and ethics in AI development, while minimizing any misuse or infringement of intellectual property. This should also offer some protection to content creators whose work may be unwittingly mimicked or plagiarized by generative AI tools.
The automation of tasks by generative AI could also affect the workforce and contribute to job displacement, requiring impacted employees to reskill or upskill. Additionally, generative AI models can unintentionally learn and amplify biases present in training data, leading to problematic outputs that perpetuate stereotypes and harmful ideologies.
ChatGPT, Bing AI and Google Bard have all drawn controversy for producing incorrect or harmful outputs since their launch, and these concerns must be addressed as generative AI evolves, particularly given the difficulty of scrutinizing the sources used to train AI models.
Generative AI vs. general AI
Generative AI and general AI represent different aspects of artificial intelligence. Generative AI focuses on creating new content or ideas based on existing data. It has specific applications and is a subset of AI that excels at solving particular tasks.
General AI, also known as artificial general intelligence, broadly refers to the concept of AI systems that possess human-like intelligence. General AI is still the stuff of science fiction; it represents an imagined future stage of AI development in which computers are able to think, reason and act autonomously.
Is generative AI the future?
It depends on who you ask, but many experts believe that generative AI has a significant role to play in the future of various industries. The capabilities of generative AI have already proven valuable in areas like content creation, software development and healthcare, and as the technology continues to evolve, so too will its applications and use cases.
That said, the future of generative AI is inextricably tied to addressing the potential risks it presents. Ensuring AI is used ethically by minimizing biases, enhancing transparency and accountability and upholding data governance will be critical as the technology progresses. At the same time, striking a balance between automation and human involvement will be crucial for maximizing the benefits of generative AI while mitigating any potential negative consequences on the workforce.






STOCKHOLM, April 27 (Reuters) - Companies deploying generative AI tools, such as ChatGPT, will have to disclose any copyrighted material used to develop their systems, according to an early EU agreement that could pave the way for the world's first comprehensive laws governing the technology.
The European Commission began drafting the AI Act nearly two years ago to regulate emerging artificial intelligence technology, which underwent a boom in investment and popularity following the release of OpenAI's AI-powered chatbot ChatGPT.
Members of the European Parliament agreed to push the draft through to the next stage, the trilogue, during which EU lawmakers and member states will thrash out the final details of the bill.
Under the proposals, AI tools will be classified according to their perceived risk level: from minimal through to limited, high, and unacceptable. Areas of concern could include biometric surveillance, spreading misinformation or discriminatory language.
While high-risk tools will not be banned, those using them will need to be highly transparent in their operations.
Companies deploying generative AI tools, such as ChatGPT or image generator Midjourney, will also have to disclose any copyrighted material used to develop their systems.
This provision was a late addition drawn up within the past two weeks, according to a source familiar with discussions. Some committee members initially proposed banning copyrighted material being used to train generative AI models altogether, the source said, but this was abandoned in favour of a transparency requirement.
""Against conservative wishes for more surveillance and leftist fantasies of over-regulation, parliament found a solid compromise that would regulate AI proportionately, protect citizens' rights, as well as foster innovation and boost the economy,"" said Svenja Hahn, a European Parliament deputy.
Macquarie analyst Fred Havemeyer said the EU's proposal was ""tactful"" rather than a ""ban first, and ask questions later"" approach proposed by some.
""The EU has been on the frontier of regulating AI technology,"" he told Reuters.
RACE TO MARKET
Microsoft-backed (MSFT.O) OpenAI provoked awe and anxiety around the world when it unveiled ChatGPT late last year. The chatbot became the fastest-growing consumer application in history, reaching 100 million monthly active users in a matter of weeks.
The ensuing race among tech companies to bring generative AI products to market concerned some onlookers, with Twitter-owner Elon Musk backing a proposal to halt development of such systems for six months. Shortly after signing the letter, the Financial Times reported Musk was planning to launch his own startup to rival OpenAI.


Sharon Goldman
@sharongoldman

December 5, 20XX-1

The hidden danger of ChatGPT and generative AI | The AI Beat
Since OpenAI launched its early demo of ChatGPT last Wednesday, the tool already has over a million users, according to CEO Sam Altman — a milestone, he points out, that took GPT-3 nearly 24 months to get to and DALL-E over 2 months. 
The “interactive, conversational model,” based on the company’s GPT-3.5 text-generator, certainly has the tech world in full swoon mode. Aaron Levie, CEO of Box, tweeted that “ChatGPT is one of those rare moments in technology where you see a glimmer of how everything is going to be different going forward.” Y Combinator cofounder Paul Graham tweeted that “clearly something big is happening.” Alberto Romero, author of The Algorithmic Bridge, calls it “by far, the best chatbot in the world.” And even Elon Musk weighed in, tweeting that ChatGPT is “scary good. We are not far from dangerously strong AI.” 
But there is a hidden problem lurking within ChatGPT: That is, it quickly spits out eloquent, confident responses that often sound plausible and true even if they are not. 
ChatGPT can sound plausible even if its output is false.
Like other generative large language models, ChatGPT makes up facts. Some call it “hallucination” or “stochastic parroting,” but these models are trained to predict the next word for a given input, not whether a fact is correct or not. 
Some have noted that what sets ChatGPT apart is that it is so darn good at making its hallucinations sound reasonable. 
Technology analyst Benedict Evans, for example, asked ChatGPT to “write a bio for Benedict Evans.” The result, he tweeted, was “plausible, almost entirely untrue.” 
More troubling is the fact that there are obviously an untold number of queries where the user would only know if the answer was untrue if they already knew the answer to the posed question. 
That’s what Arvind Narayanan, a computer science professor at Princeton, pointed out in a tweet: “People are excited about using ChatGPT for learning. It’s often very good. But the danger is that you can’t tell when it’s wrong unless you already know the answer. I tried some basic information security questions. In most cases the answers sounded plausible but were in fact BS.” 
Fact-checking generative AI
Back in the waning days of print magazines in the 2000s, I spent several years as a fact-checker for publications including GQ and Rolling Stone. Each fact had to include authoritative primary or secondary sources — and Wikipedia was frowned upon. 
Few publications have staff fact-checkers anymore, which puts the onus on reporters and editors to make sure they get their facts straight — especially at a time when misinformation already moves like lightning across social media, while search engines are constantly under pressure to surface verifiable information and not BS. 
That’s certainly why Stack Overflow, the Q&A site for coders and programmers, has temporarily banned users from sharing ChatGPT responses. 
And if StackOverflow can’t keep up with misinformation due to AI, it’s hard to imagine others being able to manage a tsunami of potential AI-driven BS. As Gary Marcus tweeted, “If StackOverflow can’t keep up with plausible but incorrect information, what about social media and search engines?” 
And while many are salivating at the idea that LLMs like ChatGPT could someday replace traditional search engines, others are strongly pushing back. 
Emily Bender, professor of linguistics at the University of Washington, has long pushed back on this notion. 
She recently emphasized again that LLMs are “not fit” for search —” both because they are designed to just make sh** up and because they don’t support information literacy.” She pointed to a paper she co-authored on the topic published in March. 
Is it better for ChatGPT to look right? Or be right? 
BS is obviously something that humans have perfected over the centuries. And ChatGPT and other large language models have no idea what it means, really, to “BS.” But OpenAI made this weakness very clear in its blog announcing the demo and explained that fixing it is “challenging,” saying: 
“ChatGPT sometimes writes plausible sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: (1) during RL [reinforcement learning] training, there’s currently no source of truth; (2) training the model to be more cautious causes it to decline questions that it can answer correctly; and (3) supervised training misleads the model because the ideal answer depends on what the model knows, rather than what the human demonstrator knows.” 
So, it’s clear that OpenAI knows perfectly well that ChatGPT is filled with BS under the surface. They never meant the technology to offer up a source of truth. 
But the question is: Are human users okay with that? 
Unfortunately, they might be. If it sounds good, many humans may think that’s good enough. And, perhaps, that’s where the real danger lies beneath the surface of ChatGPT. 





By JAKOB HANKE VELA
Send tips here | Tweet @HankeVela | Listen to Playbook and view in your browser
LABELING AI CONTENT        
TODAY: EU PUSHES FOR ‘AI LABEL’ TO FIGHT DEEPFAKES: Brussels wants to prevent artificial intelligence from blurring the lines between fact and fiction — and will today ask companies for the first time ever to come up with a label to identify AI-generated texts and images to fight disinformation, officials tell Playbook.
Brave new world: Generative AI is making breathtaking advances — from writing texts and code to creating ever more realistic pictures and videos — which will have enormous consequences not just for the future of society and work, but for politics, Commission officials reckon. 
Balenc-ai-ga: The fake images of the Pope and famous politicians wearing a Balenciaga coat that went viral earlier this year have clearly spooked them — and they now want to label such deepfakes.
Fake porn: “Today it is mostly still a game, but tomorrow you could see a fake porn with a candidate,” one official who is working on the file but was not authorized to speak on the record told Playbook, referring to AI-generated images of politicians. 
Race to regulate: The Commission (the EU’s executive, which proposes and enforces laws) — has proposed an AI Act to regulate high-risk applications and ban the most dangerous ones. But even before that act enters into force, the Commission will urge industry to cut down on trickery by labeling AI-generated work.
Happening today: Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton will meet representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation. They include Microsoft, Google, Meta, TikTok, Twitch and smaller companies — but not Twitter, which has left the code — as well as NGOs.
Disinformation risks: “I will ask the signatories to create a dedicated and separate track within the code” to deal with disinformation generated by Artificial Intelligence, Jourová told Playbook. “It should … aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them.”
EU pushes for safeguards: How does Brussels want the companies to tackle the risks? “Signatories who integrate generative AI into their services like Bingchat for Microsoft, Bard for Google should build in necessary safeguards that these services cannot be used by malicious actors to generate disinformation,” Jourová said.
Clear labels: “Signatories who have services with a potential to disseminate AI-generated disinformation should in turn put in place technology to recognize such content and clearly label this to users.”
More about this label: Two officials working on the file told Playbook the label should apply to all AI-generated material that can be used to create disinformation, including text, images, audio and video.
Voluntary — for now: It wouldn’t be mandatory, given that it would be part of the voluntary Code of Practice. However, the Commission aims to make the code enforceable by including it as a code of conduct in the Digital Services Act (DSA). Obligations on labeling AI content may also make it into the AI Act during negotiations between EU countries, Parliament, and the Commission, one official said.
How can companies do this? “They can develop, and they probably already have tools to check whether an image was AI-generated or not,” the first official said.
Playbook wonders: Given how easy it is for AI to proliferate across jurisdictions, will such a technology ever be able to identify all deepfakes — or won’t we, on the contrary, one day need some chain of custody procedure for authentic images that can be used, for example, as evidence in court?
Stay tuned: Jourová will present her initiative at a press point tomorrow at 11:15 a.m.
SPEAKING OF WHICH: While the Commission is calling on others to do more, it was recently reported that it awarded and signed a €3.7 million tender to help analyze issues like disinformation, foreign meddling in elections and global threats from a French firm that’s mired in controversy.
Avisa Partners has previously been accused of manipulating information in France and working for authoritarian regimes. The company was recently at the center of a controversy as the organizer of a cybersecurity forum boycotted by the French armed forces ministry and several government officials. More here for our Pro Cybersecurity subscribers.
Looking into this: The Commission is looking into the allegations and “is in contact with French counterparts to seek more clarity on those claim[s],” Peter Stano, the Commission’s spokesperson for foreign affairs and security policy, told my POLITICO Pro Technology colleagues. The EU executive is “closely monitoring the implementation of this project,” he added. 
Jean Tillinac, from Avisa Partners, told my Pro Tech colleagues that the bid was “defended by a team of seasoned experts from our Strategic Intelligence Division” doing research and which was different from the “Digital Communications Division” facing criticism.



Annex I – Glossary of Terms
Algorithm: a formula given to a computer for it to complete a task (i.e., a set of rules for a computer) 
Artificial intelligence: a subset of computer science that deals with computer systems performing tasks with similar, equal, or superior intelligence to that of a human (e.g., decision-making, object classification and detection, speech recognition and translation)
Artificial general intelligence (AGI): also known as strong AI, AGI is a type of artificial intelligence that is considered human-like, and still in its preliminary stages (more of a hypothetical existence in present day)
Artificial narrow intelligence (ANI): also known as weak AI, ANI is a type of artificial intelligence that can only focus on one task or problem at a given time (e.g., playing a game against a human competitor). This is the current existing form of AI.
Artificial neural network (ANN): a network modeled after the human brain by creating an artificial neural system via a pattern-recognizing computer algorithm that learns from, interprets, and classifies sensory data.
Big data: large amounts of structured and unstructured data that is too complex to be handled by standard data-processing software.
Chatbots: a chat robot that can converse with a human user through text or voice commands. Utilized by e-commerce, education, health, and business industries for ease of communication and to answer user questions. 
Cognitive computing: computerized model that mimics human thought processes by data mining, NLP, and pattern recognition.
Computer vision: when a machine processes visual input from image files (JPEGs) or camera feeds
Data mining: the process of sorting through large sets of data to identify recurring patterns while establishing problem-solving relationships.
Deep learning: a machine learning technique that teaches computers how to learn by rote (i.e., machines mimic learning as a human mind would, by using classification techniques)
Generative AI: Generative artificial intelligence or generative AI is a type of artificial intelligence (AI) system capable of generating text, images, or other media in response to prompts. Generative AI models learn the patterns and structure of their input training data, and then generate new data that has similar characteristics. 
Genetic algorithm: an algorithm based on principles of genetics that is used to find solutions efficiently and quickly to difficult problems.
Machine learning (ML): focuses on developing programs that access and use data on their own, leading machines to learn for themselves and improve from learned experiences.
Natural language processing (NLP): helps computers process, interpret, and analyze human language and its characteristics by using natural language data. 
Pattern recognition: automated recognition of patterns found in data.
Reinforcement learning: a machine learning method where the reinforcement algorithm learns by interacting with its environment and is then penalized or rewarded based on decisions it makes.
Strong AI: see artificial general intelligence (AGI)  
Structured data: clearly defined data with easily searchable patterns.
Supervised learning: a type of machine learning where output datasets teach machines to generate desired outcomes or algorithms (akin to a teacher-student relationship).
Transfer learning: a system that uses previously learned data and applies it to a new set of tasks.
Turing Test: a test created by computer scientist Alan Turing (1950) to see if machines could exhibit intelligence equal to or indistinguishable from that of a human.
Unstructured data: data without easily searchable patterns (e.g., audio, video, social media content)
Unsupervised learning: a type of machine learning where an algorithm is trained with information that is neither classified nor labeled, thus allowing the algorithm to act without guidance.",15,8.8,"Summary
This is a great case study with some minor issues that do not influence the overall quality of the text.

My main suggestion is to try to keep the text’s cohesion even throughout the study. Avoid short one-sentence paragraphs and make any connections and causations explicit. List fewer items and instead provide more context for the most important ones.

Keep up the great work!


Per Competency Score",9.0,"Observations
With this competence, we basically evaluate the style of the case study. Your text should be clear, fluent, written in a professional but still captivating style; of course, spelling and grammar are also covered in this area. Another point we examine here is whether you managed to find the balance between providing details and being concise while conveying the key points of the arguments.",,"Tips to Improve
The text is cohesive, coherent, and informative, with only a few minor typos.","Trainee's Answer
INTRODUCTION
The purpose of this speaking note is to identify potential benefits and risks of generative AI, including the specific disinformation risk related to it. Furthermore, it will be shown as the EU addresses some issues created by the generative AI focusing on the importance of the fight against the disinformation in the context of defending democracy and the EU values.
DEFINITION OF GENERATIVE ARTIFICIAL INTELLIGENCE (GAI)
Generative AI is a subfield of artificial intelligence in which computer algorithms are used to generate outputs that resemble human-created content be it text images graphics music computer code or otherwise. Algorithms are designed to learn from training data that includes examples of the desired output.
GENERATIVE AI AND THE POTENTIAL BENEFITS
Generative AI brings many advantages to business and entrepreneurs including: 
Efficiency because generative AI enables business to automate specific tasks and focus their time energy and resources on more important strategic objectives.
Analysis of data to improve decision-making.
Generation of new ideas, designs or content.
Writing checking and optimizing computer code
Enhance customer support with chatbots and virtual assistant.
Furthermore, the generative AI can be used in various applications and industries, such as, for examples, in healthcare for accelerating the discovery of novel drugs and education for developing customized learning materials.
GENERATIVE AI AND THE DISADVANTAGES
It increases the number of automation of tasks and therefore this situation affects the workforce and contribute to job displacement. In particular, the impacted employees are required to reskill or upskill.
AI models can unintentionally learn and amplify biases present in training data, leading to problematic outputs that perpetuate stereotypes and harmful ideologies. The main issue in that regards is that it is difficult to scrutinize the sources used to train AI models.
Privacy since user data is often stored for model training and sensitive data can be exposed when interacting with generative AI.
Cybersecurity.
Copyright issues because the AI models to generate output refer to a large database they were trained on. However, the original source and what can be used are not indicated.
GENERATIVE AI AND THE DISINFORMATION RISK
Generative AI can contribute to spread misinformation or malicious or sensitive content that could result in damages for people and business.
Large language models, such as ChatGPT, make up facts. They are trained to predict the next word for a given input not whether a fact is correct or not. Furthermore, they are prone to mistake because of a misunderstanding of the prompt or a blatantly wring answer to the question since they rely on training and data to provide answers.
Considering the above, disinformation generated by generative AI can threat the security of the EU countries and the principle of democracy.  In particular, the technology can be used by criminals and extremists to manipulate people.
EU PROPOSALS IN THE FIELD OF GENERATIVE AI
According to an EU agreement, the European Union introduced new copyright rules for generative AI requiring companies developing generative AI tools, such as ChatGPT, to disclose any copyrighted material used to develop these tools.
Following the above agreement, the Commission proposed the first-ever legal framework on AI, namely the AI Act as part of the wider AI package including the updated Coordinated Plan on AI. The aim of this proposal is, on the one hand, to provide AI developers, deployers and users with clear requirements and obligations regarding specific uses of AI and, on the other hand, to reduce administrative and financial burdens for business.
At the same time the proposal wants to guarantee the safety and fundamental rights of people and business in the field of AI. This will strengthen uptake investment and innovation in AI across EU.
Under the proposal, AI tools will be classified according to their perceived risk level. In particular, 4 levels of risk in AI are identified:
Unacceptable risk: all the AI systems having this level of risk are a clear threat to safety and they will be banned.
High risk: All the AI systems having this level of risk are subject to strict obligations before thy can be put on the market.
Limited risk: All the AI systems having this level of risk have specific transparency obligations.
Minimal or no risk: All the AI systems having this level of risk o no risk are free use.
CONCLUSION
Despite the beneficial of the generative AI in real-world applications, there are still many risks which can be generated by it, affecting EU values and fundamental rights, as explained in the above paragraphs. However, the EU is trying to provide a relevant legislation framework to solve some of the issues raised by the generative AI. In that regard, the EU legislation seems to be considered a step forward to create a transparent, safe and non-discriminatory AI system in the EU.  Furthermore, it is necessary that the companies using the generative AI collaborate and apply the EU regulation to obtain results. They should adopt measures to avoid that disinformation can be spread by controlling the sources used to train the AI models. Considering that the AI is a fast-evolving technology it is also important that the EU regulation would be flexible enough to approach the future challenges of AI."
2,0_Case Study_Drones,"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions.

Following a request by the European Commission, the Single European Sky Air traffic management Research Joint Undertaking - whose role is to develop the new generation European air traffic management system – has today unveiled its blueprint to make drone use in low-level airspace safe, secure and environmentally friendly. This paper is part of the Commission's drive to deliver on its ambitious Aviation Strategy and unleash the full economic potential of drones by 20XX+2. This requires an effective legislative framework that can foster European leadership and competitiveness, while addressing a number of legitimate concerns, the first of which is safety. 
You are working as an administrator in DG Mobility and Transport, and you have been asked to prepare a press release announcing the publication of the blueprint.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete. 
You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated. 
The case study is designed to assess the following competencies: Analysis and Problem Solving, Communicating (Drafting Skills), Delivering Quality & Results, and Prioritising & Organising.
More specifically, you are asked to write an internal note to the press office (2-3 pages) containing the following background information:
Opportunities and threats of unmanned or remotely piloted vehicles in the European Airspace
Blueprint for drone use in low-level airspace
Next steps

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly and legibly as possible.","ABBREVIATIONS USED
				
ATC – Air traffic Control
ATM – Air Traffic Management
CE  marking - The letters ‘CE’ appear on many products traded on the extended Single Market in the European Economic Area (EEA). They signify that products sold in the EEA have been assessed to meet high safety, health, and environmental protection requirements.
Clean Sky - The largest European research programme developing innovative, cutting-edge technology aimed at reducing CO2, gas emissions and noise levels produced by aircraft.
EASA – European Air Safety Agency
FAA – US Federal Aviation Administration
Geofencing - a virtual geographic boundary, defined by GNSS technology that enables software to prevent a drone entering a defined zone

GNSS - Global Navigation Satellite System

IATA – International Air Transport Association

ICAO – International Civil Aviation Organization
JARUS  - Joint Authorities for Rulemaking on Unmanned Systems 
NOTAM – Notice to Airmen
NPA - Notice of proposed Amendment
RPAS - Remotely Piloted Aircraft Systems 
SESAR – Single European Sky ATM Research
SME – Small and Medium Enterprises
SWIM – System wide information management
UA - Unmanned Aircraft
U-space - a set of new services and specific procedures designed to support safe, efficient and secure access to airspace for large numbers of drones 
BACKGROUND INFORMATION","Subject:		Single European Sky - Drones
Importance:	Highest

Hi,

this morning, SESAR has unveiled its blueprint to make drone use in low-level airspace safe, secure and environmentally friendly. This “U-space” covers altitudes of up to 150 metres and will pave the way for the development of a strong and dynamic EU drone services market. The paper outlines a number of basic principles: 
Safe: safety at low altitude levels will be just as good as that for traditional manned aviation. The concept is to develop a system similar to that of Air Traffic Management for manned aviation.
Automated: the system will provide information for highly automated or autonomous drones to fly safely and avoid obstacles or collisions.
Up and running by 20XX+2: for the basic services like registration, e-identification and geo-fencing. However, further U-Space services and their corresponding standards will need to be developed in the future.
The European Aviation Safety Agency (EASA) is currently working with Member States and industry to produce effective EU-wide safety rules that are proportionate to the risk of the operation. These rules will implement the EU's basic aviation safety regulation, which the European Parliament and the Council (i.e. the EU Member States) are expected to adopt in the coming months.
The Commission, through the SESAR Joint Undertaking, will further finance a range of drone projects, focusing on the integration of drones into the aviation system.

Could you prepare a draft press release, announcing this blueprint within its wider context and send it to the Press Service by tonight?




Louis Blériot,
Head of Unit","RIGA DECLARATION
ON REMOTELY PILOTED AIRCRAFT (drones)
""FRAMING THE FUTURE OF AVIATION""

Riga - 6 March 20XX-2


Today Europe is taking a decisive step towards the future of aviation. The European aviation community gathered in Riga to exchange views on how, and under which conditions, drones can help create promising new opportunities in Europe, offering sustainable jobs and new prospects for growth both for the manufacturing industry and for future users of drones in all sectors of society. Drones offer new services and applications going beyond traditional aviation and offer the promise to perform existing services in a more affordable and environmentally friendly way. They are a truly transformational technology.

The Latvian Presidency of the Council of the European Union, European Commission representatives, Directors General of Civil Aviation of the EU Member States, data protection authorities and leaders of manufacturing industry and service providers confirmed the importance of joint European action, building on the orientations given in the EC Communication on opening the Remotely Piloted Aircraft Systems (RPAS) market. 

The aviation community stressed the necessity for European regulators to ensure that all the conditions are met for the safe and sustainable emergence of innovative drone services. At the same time regulations must help the industry to thrive and adequately deal with citizens’ concerns.
The aviation community established the following principles to guide the regulatory framework in Europe:
1. Drones need to be treated as new types of aircraft with proportionate rules based on the risk of each operation.
The provision of drone services must not be less safe than is accepted from civil aviation in general. The incremental integration of drones in the aviation system must not reduce the level of safety presently achieved in civil aviation. Although no one is on board the drone, people in other aircraft or on the ground could get hurt in case of an accident or an unscheduled landing. The way safety is regulated must be proportional to the operational risk involved.
Rules should be simple and performance based, to allow a small start-up company or individuals to start low-risk, low-altitude operations under minimal rules and to develop, with light-touch risk-based regulation, similar to the modern product safety regulations applied in other sectors. Higher risk operations would be gradually subject to more stringent regulations or operational limitations. At the other end of the spectrum, where the operational risk is highest, such as with large drones operating alongside manned aircraft, the regulation will need to be quite similar to that applying to manned aviation, with strict standards on the design, manufacturing, maintenance and operation of drones, as well as on the training of drone pilots and maintenance personnel.

2. EU rules for the safe provision of drone services need to be developed now.
Safety rules, including on remote pilot and operator qualifications, should be developed at the European level by the European Aviation Safety Agency, building on the experience developed in the EU Member States. The essential requirements should be harmonised at the global level to the maximum extent possible, and full use should be made of the established cooperation in the Joint Authorities for Rulemaking on Unmanned Systems (JARUS) and at ICAO, and should be completed by international industry standard setting bodies. Important efforts need to be put into resourcing these activities, especially JARUS, in order to ensure that the progressive risk-based approach is consistent with what is done in the rest of the world.
This basic regulatory framework should be put in place without delay, in order to help the private sector to take well-informed investment decisions, and to provide a basic set of rules for the many operators who are increasingly eager to begin providing services. The European Aviation Safety Agency should consult stakeholders by the middle of next year on the regulatory framework for the operations of drones and on concrete regulatory proposals for low-risk operations. By the end of next year the Agency will use the results of the consultation to propose a position on these matters. The proposal for the revision of the basic European Safety Regulation, which the European Commission has announced for next year, should contain the necessary new provisions and essential requirements for the progressive risk-based regulation of drones, based on the Agency's recommendations.

3. Technologies and standards need to be developed for the full integration of drones in the European airspace.
The success of drone activities and safety regulations also depends on the financial effort to develop and validate key missing technologies and the ensuing required standards. Both industry and public authorities stressed the need for adequate investment in the technologies that are required to integrate drones into the aviation system — the SESAR programme. Clean Sky and other initiatives should complete the SESAR investments. That would create spin-offbenef1ts for traditional aviation and so frame the future of ﬂying.

4. Public acceptance is key to the growth of drone services.
The respect of citizens’ fundamental rights, such as the right to privacy and the protection of personal data, must be guaranteed. Many drone services involve data-gathering such as ﬁlming, etc. The responsible authorities, such as the national and European Data Protection Authorities, should develop the necessary guidelines and monitoring mechanisms to ensure the full respect of existing protection rules, including in relation to drones. Rules need to clarify what is acceptable and what is not, and they require to be properly enforced.
Drones may cause nuisances and negative externalities, such as noise. These nuisances need to be addressed, possibly at the local level, to maintain public acceptance.
Drones also pose potential security risks. The design of drones can and should take into account those risks by using methods such as cyber-defence or geofencing. However, the malicious use of drones cannot be entirely prevented by design or operational restrictions. It is the task of the national police and justice systems to address those risks.
5. The operator of a drone is responsible for its use.
When a drone service is delivered in prohibited airspace, in an unsafe manner, or for illegal purposes, the authorities should be able to act and hold the operator accountable. Where lacking, this will need to be clarified in national law. Moreover, in order to enforce responsibility, it will be necessary for drones to have at all times an identiﬁable owner or operator. The regulator should seek the least bureaucratic way to achieve this. For instance, the mandating of electronic identity chips on drones - “IDrones” - as is today envisaged in some states, could be formalised through a safety rule, which would contribute to the effective implementation of privacy and security requirements. Standardised web-portals in the Member States for the registration of operators and their operations could be another solution. The involved authorities need to work closely together.
Drone accidents will happen. Member States should clarify the applicable insurance and third party liability regime and monitor the compensation mechanisms for potential victims. The establishment of compensation funds to cover victims of accidents caused by uninsured drone users, as used in the motor insurance sector, could be envisaged. Reporting on drone incidents should be integrated into the overall incident reporting requirements. Systematic and coherent incident reporting will improve safety and will be instrumental for insurance companies in their risk analysis on which third party liability insurance premiums are based.
To allow a short reaction time, the development of drone services and drone technologies needs close monitoring. To this end, the EU should establish an easy access for SMEs to information required for drone manufacturing and service provision, together with an observatory to keep track of the growing number of operations in Europe and the evolution of innovation. This monitoring will permit informed decisions relative to the establishment of priorities for future legislation. It will also help regulators to learn from experience and verify that the rules are fit for purpose, namely to ensure that new technologies and drone services can develop in full respect of the required high levels of safety, security, privacy and environmental protection. An annual progress report should be published.
The European aviation community gathered in Riga today is committed to working together on the basis of these principles to allow businesses to provide drone services everywhere in Europe as from 20XX-1 onwards.



Introduction
The demand for drone services is steadily increasing, with the potential to generate significant economic growth and societal benefits, as recognised in the 20XX-2 EU Aviation Strategy, and more recently in the SESAR Drones Outlook Study and Warsaw Declaration on drones. In order to realise this potential, the Declaration calls for “urgent action on the airspace dimension, in particular the development of the concept of U-space”. Ultimately, U-space will enable complex drone operations with a high degree of automation to take place in all types of operational environments, including urban areas. U-space must be flexible enough to encourage innovation, support the development of new businesses and facilitate the overall growth of the European drone services market while properly addressing, at EU level, safety and security issues, respecting the privacy of citizens, and minimising the environmental impact. This blueprint outlines the proposed vision for U-space and how it could be rolled out. Rather than providing a definitive solution, this blueprint provides the basis to better define the way drones will operate in Europe in the future. 
What is U-space?
U-space is a set of new services and specific procedures designed to support safe, efficient and secure access to airspace for large numbers of drones. These services rely on a high level of digitalisation and automation of functions, whether they are on board the drone itself, or are part of the ground-based environment. U-space provides an enabling framework to support routine drone operations, as well as a clear and effective interface to manned aviation.

What are the key principles of U-space?
The delivery of U-space relies upon the following key principles:
To ensure the safety of all airspace users operating in the U-space framework, as well as people on the ground.
To provide a scalable, flexible and adaptable system that can respond to changes in demand, volume, technology, business models and applications, while managing the interface with manned aviation.
To enable high-density operations with multiple automated drones under the supervision of fleet operators.
To guarantee equitable and fair access to airspace for all users.
To enable competitive and cost-effective service provision at all times, supporting the business models of drone operators.
To minimise deployment and operating costs by leveraging, as much as possible, existing aeronautical services and infrastructure, including GNSS as well as those from other sectors, such as mobile communication services.
To accelerate deployment by adopting technologies and standards from other sectors where they meet the needs of U-space.
To follow a risk-based and performance-driven approach when setting up appropriate requirements for safety, security [including cyber-security] and resilience [including failure mode management], while minimising environmental impact and respecting the privacy of citizens, including data protection.


How will U-space operate?
Subject to compliance with applicable regulations, operational limitations and technical requirements linked to the operation of the drone, U-space facilitates any kind of mission, from the delivery of goods, aerial work, and search and rescue, to more complex future applications such as urban air mobility.
U-space services are offered to both private [leisure and professional] and public users of drones, for all types of missions. Some services will meet privacy and security needs expressed by the relevant authorities. In addition, the criticality of these services will lead to the establishment of performance requirements for both structural elements and service delivery, covering, for example, safety, security, availability, continuity and resilience.
The U-space framework comprises an extensive and scalable range of services relying on agreed EU standards and delivered by service providers. These services do not replicate the function of ATC ‚ as known in ATM, but deliver key services to organise the safe and efficient operation of drones and ensure a proper interface with manned aviation, ATC and relevant authorities. They may include the provision of data, supporting services for drone operators such as flight planning assistance and more structured services such as tracking or capacity management.



Unmanned aircraft (most people call them ‘drones’) is a sector of aviation that is developing very fast and has a great potential for producing new jobs and growth. The term ‘unmanned aircraft’ includes very large aircraft similar in size and complexity to manned aircraft, but also very small consumer electronics aircraft. Especially the smaller ones are increasingly being used in the Europe Union (EU), but under a fragmented regulatory framework. Basic national safety rules apply, but the rules differ across the EU and a number of key safeguards are not addressed in a coherent way.
On request by the European Commission, Member States and other stakeholders, the Agency started to develop a proposals for an operation centric, proportionate, risk- and performance-based regulatory framework for all unmanned aircraft (UA) establishing three categories with different safety requirements, proportionate to the risk:
‘open’ (low risk) is a UA operation category that, considering the risks involved, does not require a prior authorisation by the competent authority before the operation takes place;
‘specific’ (medium risk) is a UA operation category that, considering the risks involved, requires an authorisation by the competent authority before the operation takes place and takes into account the mitigation measures identified in an operational risk assessment, except for certain standard scenarios where a declaration by the operator is sufficient;
‘certified’ (high risk) is a UA operation category that, considering the risks involved, requires the certification of the UA, a licensed remote pilot and an operator approved by the competent authority, in order to ensure an appropriate level of safety.
Following the publication of an advance NPA, a Technical Opinion, a ‘Prototype’ regulation was drafted for the ‘open’ and ‘specific’ categories. The ‘Prototype’ regulation was published proposing actual rules providing the necessary clarity, notably on what are the responsibilities of the Member States and what is the flexibility offered to them.
A significant number of comments has been received and together with the significant inputs provided by an expert group have been taken into account to further develop the regulation text leading to the publication of an NPA. An impact assessment details analysis of several potential options considered. The analysis benefited also from feedback provided by stakeholders.
The NPA has taken into consideration the developments in the international arena e.g. work done in the International Civil Aviation Organisation (ICAO); in the Joint Authorities for the Rulemaking of Unmanned Systems (JARUS) and of course in the USA (Federal Aviation Administration- FAA).
The proposal provides a framework to safely operate drones while allowing this industry to remain agile, to innovate and continue to grow. The risk posed to people on the ground and to other aircraft as well as privacy, security and data protection issues created by such drones are also taken into account.
The proposed regulation defines the technical and operational requirements for the drones. Technical requirements refer for example to the remote identification of drones.  Operational requirements refer among others to geofencing; a system that ensures the drones does not enter a prohibited zone. The proposal also addresses the pilots’ qualifications. Furthermore, drone operators will have to register themselves, except when they operate drones lighter than 250g.
This proposal is breaking new grounds by combining Product legislation and Aviation legislation. Indeed, design requirements for small drones will be implemented by using the legislation relative to making products available on the market (the well-known CE marking). The standard CE mark will be accompanied by the identification of the class of the drone (from C0 to C4) and by a do’s and don’ts leaflet that will be found in all drone boxes. Based on the drone class an operator will know in which area he can operate and what competence is required.
The proposal allows a high degree of flexibility for EASA Member States; they will be able to define zones in their territory where either drones operations are prohibited or restricted (for example to protect sensitive areas), or where certain requirements are alleviated.
For operations that pose higher risks, an operational risk assessment will define the requirements that the operator needs to comply before flying the drone.
The proposal also provides special alleviations for people flying model aircraft - which are also drones – to recognise the good safety records in aero modelling identifying 3 options:
Member States may issue a special authorisation to model clubs and associations defining deviations from the UAS regulation;
Operations can be conducted in specific zones designated by Member States; or
Operations can be conducted in the open category according the operational limitations defined for one of the Subcategory (A3)
EASA will submit a final Opinion to the European Commission at the end of 20XX, which will take into account the feedback, received to this proposal.




Drone Alliance Europe (DAE) is a coalition of leading technology companies representing the commercial drone industry before European political leaders, regulators, and other industry stakeholders, as well as international regulatory and advisory bodies.
The commercial drone industry has the potential to bring tremendous economic growth, jobs, innovation, and broad societal benefits. Amid exponential industry growth and opportunity, it is critical to pursue a forward-leaning regulatory framework to fully realise this potential and further promote European leadership in research, production, and application of this technology.
Our Mission
The Alliance leverages the experience and perspectives of member companies throughout the policymaking process to expedite the safe and widespread integration of commercial drones into European airspace. Together, the DAE represents a strong, united voice working toward the expeditious development of:
Proportionate, risk-based, pan-European regulations that facilitate a clear path toward authorization of expanded operations throughout the continent, including fully autonomous and beyond visual line of sight operations
A low-cost, interoperable unmanned traffic management (UTM) framework that promotes the safe and secure integration of expanded drone operations essential to industry growth
A regulatory framework that embraces the flexible use of licensed, unlicensed, and spectrum sharing opportunities for drone technology necessary to support safe integration, innovation, and technology leadership throughout the Digital Single Market

Our Members



Secure your drone – or pay the price 
By Nick Gibbons - cyber security expert and partner at BLM
Drone technology offers many benefits – from the potential for speedy Amazon deliveries from the sky, to saving lives, as witnessed recently when the Lochaber mountain rescue team used one to find a hurt climber. 
But on the flip side, there are risks associated with aerial technology, such as drone jacking or hacking. 
Typically, when the conversation moves to the subject of drone-jacking, people immediately envisage a Hollywood-style breach of national security, probably in or around the White House before Will Smith leaps in to save the day. 
However, attacks on this technology represent very real risks for the growing number of businesses using drones, such as engineers surveying buildings and infrastructure, e-commerce giants sending deliveries or companies gathering surveillance for insurance claims. 
Earlier this year, Amazon announced an expansion to its research and development team in Cambridge. This will see 400 technology specialists fine-tuning the technology behind delivery drones. Despite claims that such deliveries are “pipe dreams”, there is a growing market for commercial drone technology, and with this comes a growing risk of drone-jacking. 
Last November, a report from security software company McAfee predicted cybercriminals will soon turn their attention to targeting drones, particularly those used for law enforcement, filming and deliveries. 
Drones without adequate security in place will be vulnerable to hacks, as well as physical attacks. The report speculates 20XX will see an increase in availability, via the dark web, of pre-packaged software and toolkits for hacking drones. In these cases, hacking of the drone itself or its supporting software may result in either physical misuse or data breaches. Hacking for the physical diversion of a drone carries the potential for personal injury or property damage, actual theft of the drone or indeed, the item it was carrying. 
Theft of data is another real risk, particularly if the drone contains personal or sensitive information, whether customer data included for delivery purposes or footage collected via an attached camera. 
The loss of data via drone-jacking leaves businesses and authorities with many privacy concerns, especially with the EU’s General Data Protection Regulation (GDPR) coming into force in May 20XX+1. In recent years, there have been a raft of data breaches resulting in an invasion of privacy for customers of companies, including TalkTalk and Camelot, and breaches of the GDPR could entail fines of up to four per cent of a company’s global turnover. 
Attacks are becoming more sophisticated and wide-reaching; recently, we saw the extensive damage hackers can unleash with the WannaCry cyber attack bringing organisations across the globe to a standstill. 
If cyber attacks start targeting drones, drone-jacking could leave businesses and their customers equally exposed with regards to personal and commercial data, and the prospect of big fines levied by the Information Commissioner’s Office. 
Although the use of drones is already, to an extent, covered by a range of laws and regulations, including the Data Protection Act, more specific, targeted legislation is necessary, as are effective insurance products for organisations using drones. This is especially important with the European Commission predicting full integration of drones into European airspace by 20XX+10. 
The UK Government is clearly live to the emerging risks of drone technology. Following a recent consultation exercise, a registration system is to be launched for drones weighing 250g or more. The UK Government is considering the best legislative option for introducing the new rules. 
Currently, a combination of existing insurance policies are required to cover risks associated with drone technology. As the risk of electronic theft of sensitive data rises, the market for specialised policies grows. 
In the case of drone-jacking, it would be wise for a business to consider cyber risk policies available for first and third parties. These can provide protection against business interruption, reputational risks, loss or theft of third party corporate data notification expenses and the payment of compensation to individuals affected by security or privacy breaches. Care should be taken, however, when selecting a particular cyber policy, including detailed discussions with a specialised brokers. 
So while drones have life-saving potential for Scotland’s mountain rescue teams and a business may find investing in the technology an attractive proposition, an outbreak of drone-jacking could be hugely costly. It is critical that companies consider the security breaches drone-jacking could leave them open to, and invest in the appropriate protection – just in case Will Smith is not available. 



Drone flew 'within wingspan' of plane approaching Heathrow 
Rob Davies
A drone flew within 20 metres of a plane on the approach to Heathrow, while another shocked pilots by appearing at 3,000 metres (10,000ft), a monthly update on near-misses has revealed.
Commercial jet pilots reported two “category A” incidents, the most serious class of near-miss, involving unmanned aerial vehicles (UAVs), known as drones.
The latest report comes amid concern that drone near-misses are on the rise, potentially posing a threat to recreational and commercial planes.
In one case, an Airbus A320 pilot on the approach to Heathrow in October last year spotted a drone within just 20 metres, or “possibly within the wingspan” of the aircraft.
Investigators concluded that the drone had flown so close to the passenger jet that “providence had played a major part in the aircraft not colliding”. They also noted that the “blue and disc-like” craft appeared to be custom-made, rather than a commercially available model.
In the second of two serious UAV incidents, an A320 pilot taking off from Heathrow saw a red drone overhead, about 50 metres away from his right wing at about 1,000 metres.
The pilot noted that there would have been a “distinct possibility of damage” had a collision occurred, while investigators found that “a collision had only been narrowly avoided and chance had played a major part”.
A third drone sighting, deemed a less serious category B incident, involved an unmanned aircraft at an altitude that surprised pilots, who had “no time to react”.
The UK Airprox Board, which issues monthly reports on the threat of mid-air collisions, reported a pilot saying: “Was that a drone? At 10,000 ft!”
Large drones are not permitted to fly above 120 metres, or close to airports.
The “large drone”, which appeared to be stationary, came within 60 metres (200ft) of the aircraft, a distance deemed less risky than the category A incidents, but nonetheless “a situation where safety was not assured”.
A fourth drone sighting, involving a pilot on a sightseeing trip near the Binevenagh mountain in Northern Ireland, was deemed to be at the lowest level of risk, category E.
In all four cases, police were alerted but the operator of the drone could not be traced.
Ministers are considering measures to enforce registration of all new drones so they can be better monitored, while the Department for Transport is also reviewing drone safety.
Pilots believe a collision with an airliner could be catastrophic and that the impact of a drone strike on a light plane or helicopter would almost certainly bring it down.
The British Airline Pilots Association has warned that the number of incidents could soar as people fly drones received as Christmas presents, often with little or no handling experience or understanding of the rules.
There have been 59 drone near-misses reported in the past 12 months. Drone sightings were among 21 incidents reported to the UK Airprox Board, six of which were deemed to be in the most serious category.
Among the other category A incidents was a near-miss in which a model aircraft was flown close to a Chinook military helicopter coming in to land at RAF Benson.





European Commission demands EU laws on drones after string of near-misses with aeroplanes
, Brussels correspondent 
30 September 20XX-1 • 8:20am 
The European Commission has called for fresh impetus behind its stalled plans for EU-wide regulation of drones, after a string of near-misses with airplanes across Europe last year.
There were more than 1,200 “safety occurrences"" involving drones in Europe last year, including several involving planes, the commission, the EU’s civil service, said.
On April 22, a drone passed by the wingtip of  with 156 passengers as it came into land at Liverpool John Lennon Airport. In 2016 three planes narrowly missed drones near Heathrow airport,  for tougher .
“If we don't move fast enough, the near misses between drones and airplanes could one day have disastrous consequences,” Violeta Bulc, the EU’s transport commissioner said.
“Drones offer tremendous opportunities for new services and businesses,” she said, “but safety always comes first”.
The commission drafts laws, which are then amended separately by the European Parliament and national governments sitting in the Council of Ministers. A bill can only enter into force across the EU when an identical text is agreed by MEPs and the council. 



North Wales Police use drones to fight crime
10 January 20XX
North Wales Police has become the latest force in Wales to use drones to help in the fight against crime.
Fifteen officers and staff have been trained to use the unmanned aircraft to capture video and images to be used in investigations. 
This includes searching for missing people as well as gathering evidence from road traffic investigations and major crime incidents.
Drone were used to investigate a .
The team's two drones, which can also carry a thermal imaging camera, have already been used to search for missing people and investigate incidents during a trial last year.
Insp Craig Jones from the force's operational planning unit said they were highly effective in gathering images over difficult terrain or hard to reach areas and helped officers gain information, quickly and safely.
The live images they take can be seen by police on the ground and they were recently used to help firefighters tackle a large blaze at the Gateway to Wales Hotel.
Stuart Millington, of North Wales Fire and Rescue Service, said the ability to see aerial moving images that show fire hotspots was a ""significantly useful tool"" in ongoing incidents.
An agreement with the force means the fire service can call on the police drone pilots to help them deal with incidents when needed.
North Wales Police's Deputy Chief Constable Gareth Pritchard added the drones were a highly cost effective tool in fighting crime and helping communities.
""Being able to launch a drone in the air in a few minutes could help save lives and secure vital evidence if a crime was in progress,"" he said.

 



Drone makers zero in on commercial opportunities

Louise Lucas in Hong Kong July 5, 20XX-1
They have been used to shoot weddings, Hollywood movies and terrorists. But now drones, and their makers, are navigating a third path between hobbyists and warfare into the industrial world, threatening a shake-up of the burgeoning $6bn industry. 
New uses for unmanned aerial vehicles (UAVs), to give drones their technical name, are emerging almost daily: delivering packages, pizzas and blood; surveying mines; pre-emptive firefighting; even collecting whale snot to help conserve the mammals. 
“We are developing the UAV into a means of production,” said Paul Xu, vice-president of DJI, at a conference in Shenzhen last month. His company has given China undisputed leadership in the sector, with its 70 per cent market share of non-military drones 
However, if Shenzhen-based DJI, valued at $8bn-$10bn at its last funding round in 20XX-2, is to keep that lead, it will need to adapt to new market dynamics. 
The industry dismisses talk of “peak” consumer drone, but few expect that part of the business to maintain its heady growth rates. Outside China, casualties abound: in California, Lily Robotics shut up shop in January, while 3D Robotics switched its focus to software and Parrot, of France, axed jobs. New entrants are cut from an altogether different cloth, with industrial and tech groups, including Qualcomm, Intel and Boeing hovering over the space. 
Regulators too are braced for change, as the industry lobbies for more openings. In a first step, the US Federal Aviation Administration, in effect, opened the skies to commercial drones a year ago, with limited safety rules covering the sector. 
Since the FAA rule changes, says Michael Perry, director of strategic partnerships at DJI, the enterprise industry has been scaling up rapidly, encouraged by the more certain regulatory environment. “Before we had conversations [with businesses] but then they said: ‘How will my legal team deal with this?’ The last thing we want is vagaries. People won’t invest if they aren’t sure.” 
DJI, the creation of Frank Wang, a radio-controlled helicopter enthusiast from Hangzhou who transformed his boyhood hobby into a company with sales of $1.5bn, is now looking into areas ranging from agriculture to eliminating mosquitoes. 
“Personal drone vendors are now aggressively trying to position themselves in the commercial market,” says Gerald Van Hoy, senior research analyst at Gartner, although the firm says the 3m drones it expects to be shipped this year will still be overwhelmingly for the consumer market. These figures are up 39 per cent on 20XX-1 and should translate into revenues of $6bn.",9,7.8,"Summary
The text primarily focuses on the burgeoning drone industry, specifically within the context of the European Union. 
The author outlines the potential opportunities and threats that drones pose, elaborating on aspects like job creation, services, and safety concerns. 
A significant part of the document is dedicated to explaining a blueprint for safe drone use in low-level airspace, coined ""U-space,"" along with its principles and intended services. 
The document concludes by stressing the need for safety regulations to harness the full potential of drones.
Suggestions for improvement:
Organization: The text has a structured format with clear section headings, making it easier to follow. However, the topics could be sequenced better to improve flow, especially when transitioning from threats to the blueprint.
Evidence support: While the text identifies potential uses and challenges of drones, it could benefit from the inclusion of case studies, surveys, or expert opinions to substantiate the claims.
Grammar and mechanics: The text has multiple grammatical and spelling errors, impacting its readability and professionalism.

Per Competency Score",7.0,,"Grammar and mechanics: The text has multiple grammatical and spelling errors, impacting its readability and professionalism.

Per Competency Scores
Communication 7/10
The layout is generally clear and logical, but could benefit from improved transitions and summarizing statements. A table of contents may also enhance navigation.

The author should focus on making the text clearer through the rectification of spelling and grammatical errors, and by including more substantiating evidence for claims.

The text does not have a specifically titled Introduction section.

The text has a specifically titled Conclusions section but this is far too short and should be more comprehensive.

The text does not have a specifically titled Recommendations section.

The tone of the document is formal and informative, suitable for its intended audience.

The document is relatively easy to read, with clear headings and sections. However, it could benefit from bullet points or numbered lists to enhance readability.

Spelling:
steadly should be steadily
incresing should be increasing
adn should be and
Udertaking should be Undertaking
enivronmentally should be environmentally

Grammar:
""Drones has the potential"" should be ""Drones have the potential""
""risks shall be adequately taken into account"" should be ""risks should be adequately taken into account""
""to lower them at an accetable level"" should be ""to lower them to an acceptable level""
""safery requirements shall be furhter development"" should be ""safety requirements shall be further developed""
""noice"" should be ""noise""",,"Trainee's Answer
16.06.20XX
 
1. BACKGROUND 
The demand for drone services is steadly incresing, with the potential to generate significant economic growth adn societal benefits. The EC is committed to deliver on its ambitious Aviation Strategy and unleash the full potential of drones in 20XX+2, therefore requiring an effective legislative framework able to foster European leadership and competitiveness, while addressing related concerns such as safety. In this context, on the 16th of June 20XX the Single European Sky Air traffic management Research Joint Udertaking published a blueprint, which intends to make drone use in low-level airspace safe, secure and enivronmentally friendly. 
 
2. UNMANNED OR REMOTELY PILOTED VEHICLES IN THE EUROPEAN AIRSPACE: OPPORTUNITIES AND THREATS
There are opportunities and threats related to unmanned or remotely piloted vehicles. The main opportunities refer to:
a. Sustaniable jobs and new prospects for growth both for manufacturing industry and potentially all involved sectors of society;
b. New services and applications, while performing existing services in a more affordable and environmentally friendly way.
For instance, drones can be been used to help in the fight against crime, searching for missing people, gathering evidence from road traffic investigations. They can also be used in other domains, such as to shoot weddings, Hollywood movies, to deliver packages, pizzas and blood. As a matter of fact, new uses for drones are emerging on a daily basis. 
 
On the other side, the main threats refers to the followind areas:
a. The respect of citizens' fundamental rights, such as the right of privacy and the protection of personal data.
b. The integration of drones into the aviation system.
c. Drones may cause noice.
d. Security risks.
These risks shall be adequately taken into account in order to lower them at an accetable level. In addition, considering that a zero risk level is not reachable, national police and justice should also be involved to adress those risks. 
 
3.  BLUEPRINT FOR DRONE USE IN LOW-LEVEL AIRSPACE
The blueprint for drone use in low-level airspace intends to make their use safe, secure and environmentally friendly.
The airspace refers to altitudes of up to 150 meter The set of new services and specific procedures designed to support safe, efficient and secure access to airspace for large number of drones is also also called ""U-space"". 
The key principles of the U-space are as follows:
a. to ensure safety of all airspace users, as well as people on the ground. 
b. to provide a scalable, flexible and adaptable system.
c. to enable high-density operations.
d. to guarantee equitable and fair access to airspace for all users.
e. to enable competitive and cost-effective service provision at all times.
f. to minimise deployment and operating costs by leveraging on existing aeronautical services and infrastructure.
g. to accelerate deployment by adopting techonologies and standard from other sectors where they meet the needs of U-space.
h. to follow a risk-based and performance-driven approach in relation to safety, security and resilience, while minimising environmental impact and respecting the privacy of citizens.
Tne U-space will operate subject to compliance with applicable regulations, operational limitations and technical requirements linked to the operation of the drone. U-space services are offered to both private and public users of drones. The U-space framework comprises an extensive and scalable range of services relying on agreed EU standards and delivered by service providers. 
The goal is to have wihtin 20XX+2 already in place basic services like registration, e-identification and geo-fencing. 
 
4. NEXT STEPS
To enanche the opportunities related to the drones, different safery requirements shall be furhter development and included in the legislation. They could be related to the risk level.
 
5. CONCLUSIONS
 Drones has the potential to generate significant economic growth adn societal benefits, bur risks"
4,0_Case study - Animal welfare - LONG,"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. 

Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG SANTE. 
A citizen’s initiative (“End the cage age”) collected almost 1.4 million signatures demanding a Commission proposal to ban all use of cages for farm animals. DG SANTE has prepared a draft legislative proposal, based on an impact assessment and several rounds of stakeholder consultations. An inter-service consultation (ISC) with the other DGs was recently closed. The Director-General of SANTE now needs to decide how to move forward on this file, so that a compromise text can be agreed in the college of Commissioners.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes, as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the candidate’s drafting skills (Communication) and may be used to assess also the following competencies: Critical thinking, analysing & creative problem-solving, and Decision-making and getting results.

Specifically, your task will be to draft a concise briefing note for your Director-General. This note must include: 

Summary of the main issues, notably the remaining problems to solve
Arguments and facts to help the Director-General make a decision on the file

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.",,"Subject: Briefing for the Director-General – Animal welfare legislative proposal
---
Dear [your name],
Welcome to your first day in the unit! You will have to hit the ground running - we have received an urgent request for a briefing. Our Director-General, Ms Heinrich, needs a summary of state of play concerning the draft revised animal welfare regulation, for her decision on the way forward.
As you have seen in the draft regulation text, we have followed the “preferred options” identified in our thorough impact assessment (those marked green in the impact assessment options table). This draft legislative proposal is what we as DG SANTE believe best serves our policy objectives and this is what we need to defend as far as possible. We received strong support for an ambition line in all the stakeholder consultations.
In the recent inter-service consultation, we also received green light (positive opinion) by all DGs except one. DG AGRI has unfortunately not been able to accept our draft legislative proposal. This means we will either need to make small compromise adjustments to the original proposal and change our preferred option, or we try to somehow convince DG AGRI to accept our main line.
In your briefing, please outline the main issues at hand and explain the options for next step so that our Director-General can make an informed decision on it. She did invite us to already make a recommendation based on our knowledge of the file if we have a preference.
You should keep the briefing short and concise, no more than two pages.
I have placed a file with various materials on your desk. It should contain what you need for the draft briefing. Please have a first version done already today at X o’clock so I can check it before passing it on to Ms Heinrich.
Thank","you and best of luck,
Wiebke
---
Head of Unit
Animal welfare unit, DG SANTE

Attachment 2: Inter-service consultation reply AGRI

Answer of DG AGRI to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 1 (sent on 16 May 202X 14:56:54) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | DENKER Nicholas (AGRI.F.002) | No automatic forward of notifications to this responsible officer |
Opinion | Negative opinion  |  |
Authorised in the DG by | ROBINSON Michael (AGRI.F) |
Comments | For laying hens/cage ban, either the low ambition option or status quo should apply, for protection of the single market and to ensure competitive pricing of European high standard food products, compared with lower-standard import products from third countries with only minimum requirements of animal welfare rules. |  |



Attachment 3: Inter-service consultation reply ENV

Answer of DG ENV to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 2 (sent on 14 May 202X 17:32:04) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | SVOBODA Lisa (ENV.D1) | No automatic forward of notifications to this responsible officer |
Opinion | Positive opinion |  |
Authorised in the DG by | HUEGEL-PEETERS Sabine (ENV.D) |
Comments | Thank you for consulting DG ENV on the proposed revised regulation on animal welfare. This proposal is important and in line with the European Green Deal objectives; we support the general approach and your preferred options. From our review, we have several minor editorial comments, given in track-changes in the attached document, which we request are taken on-board. |  |






Attachment 4: Inter-service consultation reply TRADE

Answer of DG TRADE to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 1 (sent on 15 May 202X 11:46:25) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | LANGE JENSEN Halfdan (TRADE.B.01) | No automatic forward of notifications to this responsible officer |
Opinion | Positive opinion |  |
Authorised in the DG by | GEORGIOU Andreia (TRADE 0) |
Comments | N/a |






Attachment 5: Press statement

Brussels, April 202X-2
Every year across the European Union, around three hundred million farmed animals are confined in cages. Unable to conduct many of their natural behaviours, these animals are treated as nothing more than production machines. No single EU Member State is completely cage free and in some Member States up to 90% of all hens, mother pigs and young calves are kept in cages and crates. This despite farming industry having had more than 15 years to voluntarily change their installations.
Over 170 organisations and caring citizens across Europe therefore joined forces to spearhead the “End the Cage Age” European citizens’ initiative. In total, 1.4 million EU citizens made their voices heard and signed the petition. Only one other citizen’s initiative has so far gathered more signatures than this.
Mr Daniel Müller, campaign leader for “End the Cage Age” said: what we see now is the battle of ethics versus economy. EU citizens do not want cheap food at any cost and certainly not at the cost of pain and suffering of our fellow creatures. Food industry and economic interests will have to adapt to this reality – and finally do what is right.
In response to our tireless campaigning, in April 202X-2, the European Commission committed to proposing legislation before the end of 202X to phase out and finally prohibit the use of animal cages. We must now ensure that a total ban on caged farming is delivered, as soon as possible. The fight also continues to pave the way not only for a cage-free Europe, but for a cage-free world by making sure that all imported products in the EU comply with cage-free standards.


Attachment 6: Website

What is a citizens' initiative?
A European citizens’ initiative is a way for you and other Europeans to take an active part in EU policymaking.
If you want the EU to act on a particular issue, you can launch a citizens’ initiative calling on the European Commission to propose new EU legislation on that issue.
For an initiative to be considered by the Commission, you need to get one million citizens from across the EU to sign it in support.
Step 1: Get started
Before launching an initiative, it is worth considering some of the key practical aspects, including:
is asking for EU legislation to be passed the best way to achieve your goals?
you must first set up a group of organisers composed of at least 7 EU citizens living in seven different EU countries. To do so, you need to find people to team up with across Europe who are willing to support your issue.
how will you organise your campaign to collect the signatures?
You can find detailed advice on all these issues on the European Citizens’ Initiative Forum




Step 2: Get your initiative registered
Before you can start collecting signatures for your initiative, you must ask the Commission to register it.
For this, you will need to:
create an organiser account. You will use this to manage your initiative and liaise with the Commission throughout its lifecycle.
provide a description of your initiative in one of the official EU languages (as well as details and relevant documents on the group of organisers, funding received, etc.)
The Commission is not obliged to register all initiatives. It only registers initiatives that meet certain criteria.
Once you ask for your initiative to be registered, we will assess whether to accept it.
You will receive an answer within 2-4 months.


Step 3: Get support
You need to get the support of at least one million people, with minimum numbers in at least seven EU countries. They must fill in a specific statement of support form.
You can collect:
on paper (pre-filled forms, downloadable from your organiser account) or
online (using the Central Online Collection System).
These forms are available in all EU official languages.
To sign, people must be:
EU nationals (nationals of an EU country)
old enough to vote in European elections or aged at least 16 in some countries
TIP – It is better to collect more signatures than you need. Sometimes the authorities in each country might not be able to validate all the statements of support you provide. Throughout the collection procedure, you must comply with data protection rules.


Step 4: Submit your initiative
Once you have received the last certificate from the national authorities, you have 3 months to submit your initiative to the Commission – together with the information on the support and funding you have received for the initiative.


What next?
If the Commission considers legislation an appropriate response to your initiative, it will start preparing a formal proposal. This can require preparatory steps like public consultations, impact assessments, etc. Once adopted by the Commission, the proposal is submitted to the European Parliament and the EU Council (or in some cases, only to the Council), which will need to adopt it for it to become law.
The Commission is not obliged to propose legislation. Even where it responds positively, the most appropriate follow-up to an initiative may be non-legislative in nature. There are a range of other measures that may be more suitable.
The European Parliament may also assess the measures taken by the Commission.

Attachment 7: E-mail message
 
From: ROBINSON Michael (AGRI)
Sent: Monday, 16 May 202X
To: MUNOZ Wiebke (SANTE)
Subject: Revised animal welfare regulation
 
---

Dear Wiebke,
Just a heads-up about the AGRI response to your animal welfare ISC - you will receive it later today. We can accept all of it, but we have a remaining concern about the proposed new rules for poultry cage rearing.
First, the proposed exception for farms less than 50 livestock units (3500 laying hens) does not make much sense. The overwhelming majority of eggs produced in the EU come from farms with more than 5000 birds (70 livestock units) and the smaller farms can anyway more easily transition to cage-free rearing if they haven’t done so already.
Longer transition time also does not help, it’s not about more time for farms to adapt. It’s about the money and about food prices.
For large-scale installations, cages are simply more efficient and use much less space. With your proposal, notably the requirement of more space per laying hen, production will necessarily be less cost-efficient, and most farms will not be able to keep the same number of birds. Consumers might say they care about animal welfare but when they make their choices in the supermarket, the thing that matters most is the price! If you implement the new rules, the price of eggs might increase by around 20-40% in countries like Spain, Portugal, and Malta where cage systems are still the norm. This means we will see a significant increase in cheap imported eggs from third countries with much worse animal welfare standards. Our European farmers cannot compete on such unfair terms.
There is also the socioeconomic element: the burden of higher food prices will be heavier on the poorest families.
Unless farmers can be compensated economically somehow for taking this risk, we don’t see any need for changing the current rules on poultry caging and we will need to block your proposal.

Call me if you want to discuss this further.

Best,
Michael


Attachment 8: Press release


MEPs endorse EU citizens’ call for gradual end to caged farming
Press releases – AGRI - 20 February 202X-2

The European Parliament has called for the end of caged farming within the next 5 years. The parliament members voted on an own initiative resolution recommending a total ban on the use of cages in animal agriculture by 202X+3.
The vote followed intensive lobbying by the “End the Cage Age” European Citizens Initiative, led by 170 non-governmental organisations (NGOs) across Europe, which garnered 1.4m signatures from EU citizens and demanded the phasing out of cages on farms. Members of the European Parliament (MEPs) voted by 558 to 37 with 85 abstentions on the non-binding resolution.
Unlevel playing field in Europe
Even though the EU has banned the use of battery cages in poultry production and sow stalls during gestation, campaigners said this was not enough, given the perceived unlevel playing field across Europe with some nations already going beyond EU laws.
According to the initiative, five out of 28 countries are currently achieving more than 80% cage-free production, i.e., Austria (97%), Luxembourg (97%), Sweden (92%), Germany (86%) and the Netherlands (82%). Bottom of the list is Malta, with 1%, followed by Spain and Portugal. About sows, the report is based on Eurostat figures, according to the initiative’s website.
In the European Parliament, a working group on cage-free farming established in 202X-10 has been actively supporting the “End the Cage Age” initiative and in October 202X-3, 101 MEPs from various political parties signed a letter of support addressed to EU Commissioners.
Speeding up the review of animal welfare legislation
Last month, the parliament’s AGRI committee adopted a motion for a resolution. Committee members called on the European Commission to speed up the review of the animal welfare legislation and back the phasing out of all cages in farming, possibly already by 202X+3. They also insisted on ensuring compliance with EU standards for all products imported into the EU.
By April this year, the European Commission will have made its decision as to whether to start a legislative process to ban caged farming. EU Food Safety commissioner Stella Kyriakides told MEPs that the Commission was considering a request contained within the resolution to apply the same animal welfare standards to meat imported from outside the EU as European farmers must meet inside the bloc.
Kyriakides also noted the call for farmers to receive compensation and support in their transition from cages. She added the phase-out would happen “as soon as feasible” but did not give a specific date.
The results for pork production could be far-reaching, as it would likely change the current practice using farrowing crates. In recent years, a lot of research initiatives have already been launched to design free farrowing concepts.



Attachment 9: E-mail message 
 
From: CALBI Ana (EFSA)
Sent: Thursday, 16 October 202X-1
To: MUNOZ Wiebke (SANTE)
Subject: Cages and antibiotics
 
---
Dear Ms Munoz,
Congratulations on your concluded impact assessment on the animal welfare regulation!
In view of your upcoming drafting process, I need to point out that there are several scientific studies pointing to higher prevalence of antimicrobial resistance, notably among e-coli bacteria, in non-cage housing systems for poultry - if not implemented correctly and with strict quality standards. I feel this did not come out clearly enough from your impact assessment.
Free-range egg production systems face more challenges related to biosecurity and use of antibiotics. The free-range layer birds have more interaction with each other compared to caged ones, leading to an increased incidence of infectious poultry diseases requiring treatment with antimicrobials, in turn leading to increased emergence of resistant commensal and pathogenic bacteria. This is a major threat to public health.
The main factor to consider is of course, as always, the number of hens per square meter, the hygiene routines, and the overall rules on veterinary prescription of antibiotics. It is the same for pigs: sows in small crates have low life quality but use less medication; pigs in free range but packed close together require lots of antibiotics and pigs in free range with sufficient space are more healthy and less prone to cause antimicrobial resistance. However, they are also much less cost-effective for industrial-size farming. 
Still, to ensure safe food production and avoid antibiotics resistance, livestock density simply must go down. 
If you could take these concerns into account in your draft revised regulation, we would be much grateful.

Best regards,
Ana Calbi

---
Head of Department
The European Food Safety Agency (EFSA)




Attachment 10: Impact assessment


								Brussels, 13 October 202X-1






COMMISSION STAFF WORKING DOCUMENT

IMPACT ASSESSMENT REPORT


Animal welfare: revised regulation


Executive summary
To address the specific objectives of the animal welfare legislation revision, four policy measures have been considered, with low, medium, and high ambition options. Impacts assessed include cost-efficiency, environmental and societal impacts and impacts on the single market. The European Food Safety Agency (EFSA) has confirmed the scientific evidence. Numerous stakeholder consultations and supporting studies have been performed.
For animals kept for economic purposes, the measures/options covered are:
1) 	Phasing out confining cages/crates for the following species and categories of animals:
Pigs
Calves
Laying hens and pullets
Rabbits and fur-producing animals.
A general transition period of between five and twelve years would be considered, depending on the level of ambition. Exceptions e.g., depending on farm size (number of “livestock units” where 1 livestock unit = 1 cow, or 2 pigs, or 71 laying hens) could be considered.
2) 	Banning the killing of day-old male chicks (or, as an alternative option, introducing an obligation of marking eggs from production systems where day-old chicks are killed). In the case of a ban, while a transition period of five years would be technically sufficient, notably if combined with stricter import rules, the impacts could be mitigated by introducing a ten years’ transition period.

3) 	Banning painful mutilations, i.e., beak trimming in poultry and tail docking in pigs (with incentives instead of bans as alternative options). For the bans, a general transition period of ten years has been considered. Incentives for voluntary action would enter into force immediately.
  
4) 	Animal welfare requirements at import. For animals and products of animal origin imported to the EU, either similar or fully equivalent animal welfare requirements with the revised EU animal welfare requirements for kept animals, as regards the use of cages, mutilations, space allowances, enrichment, the killing of day-old chicks and the welfare of fur animals would apply. A transition period of five-ten years has been considered.

A phase-out of the use of cages and stalls would considerably improve the welfare of more than 160 million laying hens, 53 million pullets (young hens), 13 million sows, two million calves, 35 million ducks and geese and 100 million rabbits. They would be able to perform a more natural and healthy behaviour.
A partial or total ban on cages and crates would have an important economic impact on the sectors concerned. For instance, for laying hens we have estimated the required investments for a transition into a cage-free system to about EUR 2,4-2,8 billion. For sows, the cost of demolishing the current system with gestation and farrowing crates could amount to around EUR 64-100 /m². These costs are likely to result in higher consumer prices. 
The situation however differs between Member States. Some have already taken measures to phase out cages and stalls whereas others have not. 
To mitigate these economic impacts, certain measures could be considered, notably awareness-raising vis-à-vis consumers, economic incentives via the Common Agricultural Policy and import rules to ensure a level playing field / reduce unfair competition.
The proposed measures would ensure a positive impact on sustainability as it would imply less intensive food production, causing less pollution to air and water. However, since cage-free animals move around more, they spend more energy and consume more feed. This could have a negative impact on the use of resources.

Table 1: Policy options (most cost-efficient option in terms of added value vs cost is shown in green):
| Low ambition option | Medium ambition option | High ambition option | Comments |
1.a. Crates/cages: pigs | Phase in of crate ban over 10 years. |   | Exceptions allowed for farms with less than 50 livestock units. |   | Allowing temporary confinement from 1 week before farrowing until weaning. |   | Cost-benefit analysis value (-) | Phase in of ban over 5 years. |   | Farms with less than 50 livestock units allowed to phase out crates over 15 years. |   | Temporary confinement allowed from 1 day before farrowing to 5 days post-farrowing. |   | Cost-benefit analysis value (+++) | Total ban phased in over 5 years. |   | No exceptions. |   | Cost-benefit analysis value (+) | Medium and high ambition options can be combined with stricter requirements of minimum living space per animal and/or voluntary guidance on antibiotics use. |
1.b. Crates/cages: calves | No legislative change. |   | Cost-benefit analysis (-) | Phase-out of all use of weaning crates over 10 years. |   | Ban on trade / import of calves kept crated. |   | Cost-benefit analysis (+) | Phase-out of all use of crates within 5 years. |   | Ban on trade / import of calves kept crated. |   | Cost-benefit analysis (++) | Strong public support for total ban. Low impact on food pricing. |
1.c. Cages:  laying hens and pullets | Phase in of ban over 12 years. |   | Farms with less than one hundred livestock units exempted. |   | Cost-benefit analysis (0) | Phase in of ban over 10 years. |   | Farms with less than 50 livestock units allowed to phase out cages over 12 years. |   | Cost-benefit analysis (++) | Total ban phased in over 5 years. |   | Cost-benefit analysis (+++) | Same as with pigs. |
1.d. Cages: rabbits and animals in fur production | No legislative change. |   | Cost-benefit analysis (-) | Transition phase 10 years.  |   | Cost-benefit analysis (+) | Transition phase 5 years. |   | Cost-benefit analysis (++) | Low economic impact (small sector). |
2. Killing of day-old male chickens (laying breeds) | Obligation of marking eggs from production systems applying this practice, starting as from 5 years. |   | Cost-benefit analysis: (0) | Ban of procedure within 10 years + economic incentives via the Common Agricultural Policy for farmers transitioning sooner |   | Immediate obligation of marking eggs from production systems not yet transitioned. |   | Cost-benefit analysis (++) | Phase in of ban over 5 years + stricter import rules to protect internal market |   | Cost-benefit analysis (+) | Strong public support for total ban. Strong impact on food pricing. |   | Viability dependent on development of technology to gender-identify eggs before hatching. |   | Possibility of launching consumer awareness campaigns to explain food price impacts (acceptability). |
3. Ban on painful mutilations (beak trimmings / tail cropping) | N/a | Immediate ban on cross-border trade in tail-docked pigs. |   | No ban on the procedures but economic incentives via the Common Agricultural Policy for voluntary transition. |   | Cost-benefit analysis (+) | Phase in over 10 years of total ban. |   | Cost-benefit analysis (+++) | No justification for no action. |   | Enforcement mechanism needed (inspections). |
4. Animal welfare requirements at import | No legislative change | Minimum set of rules apply for import (low- or medium ambition options). 10 years transition period. | Full EU rules to apply also for imported products. 5 years transition period. | Strong impact on competitiveness of EU farmers. Strong impact on the acceptability of other measures. | Possible difficulty of implementation. |
 

Background
Since 202X-10, EU legislation requires that laying hens be kept either in enriched cages, or alternative systems (single or multi-tier barn or, free-range). The current legislation allows calves being individually housed until the age of eight weeks, while sows and gilts are kept in confinement for a period of four weeks after service and from one week before the expected time of farrowing to weaning of their piglets. 
Approximately one million farms keep laying hens in the EU. Forty-five percent of these are kept in enriched cages. 
There is currently a trend towards using less cages in many EU Member States such as France, the Netherlands and Poland to answer to consumer’s expectations. E.g., Austria and Luxembourg have already banned the use of cages for laying hens. The animal welfare problems related to cages will however remain for many laying hens if no action is taken at EU level.

Problem drivers
Conventional livestock production systems across EU countries are put under pressure by competitive global markets, a rise in input costs and the search for maximum profit margins by farmers and all food business operators along the production chain. The demand of certain consumers’ segments for low price food is expected to be more prevalent in the current inflationary context.
This pressure over production costs has led to further intensification (and specialisation) of the farming and killing practices, as business operators increase the volume of production to reduce overheads costs per livestock unit. Evidence shows that, while the number of livestock farms is decreasing, their size is increasing. Small farms are replaced by very large industrial scale installations.
This trend has led to certain detrimental effects on animal welfare due to high densities, certain management practices, housing/transport conditions and stunning methods, as well as due to certain breeding strategies.
Current EU rules also do not consider new scientific evidence and huge technological developments in relation to agricultural practices, zootechnics and transport operations. For instance, this new scientific evidence relates to a new understanding of stocking densities, behaviour (need for an enriched environment), mutilation practices, journey times and space allowances for animal transports, and stunning methods used for pigs, poultry, and farmed fish.
The lack of update of the EU animal welfare legislation has led Member States to adopt an increasing number of national measures going beyond EU minimum requirements to respond to the growing citizens’ concerns towards animal welfare, leading to a fragmented legal landscape, including as regards animal welfare labelling.
At the same time, consumers are growing more aware and more demanding. The upward trend of societal demands for better animal welfare protection is not reflected in the current legislative requirements. 

Figure 1: Problem tree 

Economic and environmental impacts of the preferred package of options: cages for laying hens
The policy option assessed to be most cost-efficient is a total prohibition on the use of cages for laying hens with a transition period of 5 years (from the date of entry into force of the revised legislation).
However, if no similar requirements apply for eggs and egg products imported into the EU from third countries, since the EU consumers’ demand for eggs is not expected to decrease and since EU production is expected to decrease, an increase in eggs obtained from caged hens imported from non-EU countries with lower standards is expected, thus limiting the positive animal welfare impact of the measure.
The required investments for a transition into a cage-free system for laying hens would amount to around EUR 2,4-2,8 billion.
A prohibition of cages would decrease the number of laying hens by an estimated 30% (i.e., from 186,8 million to 102,9 million) in farms which currently have cage systems.

SME’s
Small farms tend to use cage-free systems more than big farms. A prohibition would therefore primarily have a positive competitiveness impact on small farms.

Public authorities
It is likely that a prohibition would generate additional enforcement costs in the short term for the national competent authorities, however these will come back to current levels in the medium term.

Consumers
A prohibition would lead to an expected increase in the price of eggs, but to which extent is not clear. Some estimates by the EU poultry industry suggest a + 20% price gap between eggs from cages and those from barn systems. However, sales data from the Netherlands and Germany suggests a much smaller difference in prices: less than one eurocent per egg.
With an average per capita consumption of 210 eggs per year, or 4,04 eggs per week, this would mean that transitioning to cage-free systems would add less than four eurocents per person to consumers’ weekly food shopping bill. Furthermore, the experience from Germany, where enriched cages are progressively phased out, even suggests that the price for barn eggs may eventually be the same as for eggs from enriched cages.
 
Environmental impacts
A prohibition would have a positive impact on sustainability as it would imply less intensive production leading to less air and water pollution and less greenhouse gas emissions.



Attachment 11: Website

| A gestation crate, also known as a sow stall, is a metal enclosure in which a   used for breeding may be kept during pregnancy. A standard crate measures 2 m x 60 cm. | Sow stalls contain no bedding material and are instead floored with slatted plastic, concrete, or metal to allow waste to be efficiently collected below. This waste is then flushed into open-air pits known as . A few days before giving birth (farrowing), sows are moved to farrowing crates where they are able to lie down, with an attached crate from which their piglets can nurse. | Most pregnant sows in the US are kept in gestation crates. The crates are banned for new installations in Austria and Canada, but many sows are still confined there in pig breeding facilities. The crates are banned in the United Kingdom, Canada, Switzerland, and Sweden. However, farrowing crates, in which female breeding pigs can be kept for up to five weeks, are not banned in the UK. | Opponents of the crates argue that they constitute animal abuse, while proponents say they are needed to prevent sows from fighting among themselves. |




Attachment 12: Website



Page contents |  | Submission and examination |  |  | Submission and examination | The  initiative was submitted to the Commission on 2 October 202X-3, having gathered 1,397,113 statements of support. See . | The organisers met with the Commissioner for Health and Food Safety, Stella Kyriakides on 30 October 202X-3. | A  took place at the European Parliament on 25 January 202X-2. See . | The initiative was debated at the European Parliament’s plenary session on 20 February 202X-2. In the  adopted on the same day, the European Parliament expressed its strong support for the initiative. See European Parliament’s . | Answer of the European Commission | In its response on 4 April 202X-2, the Commission commits to table, by the end of 202X, a legislative proposal to phase out, and finally prohibit, the use of cage systems for all animals mentioned in the initiative. | In parallel to the legislation and to facilitate a balanced and economically viable transition to cage-free farming, the Commission will seek specific supporting measures in key related policy areas, such as trade and research and innovation.  | In particular, the new Common Agricultural Policy will provide financial support and incentives – such as the new eco-schemes instrument – to help farmers upgrade to more animal-friendly facilities in line with the new standards. |



Attachment 13: News article



 -  -  
Health and food safety Commissioner will fight for ethical food systems in Europe
30 October 202X-3
Earlier today, Commissioner Kyriakides met with the representatives of the citizens’ initiative ‘End the Cage Age’. EURACTIV interviewed the Commissioner after her meeting with the campaign team.
Stella Kyriakides is European Commissioner for Health and Food Safety and in charge of the EU animal welfare legislation. She spoke to EURACTIV about the call for revised animal welfare legislation and the possibility for action ahead.
This is one of the most strongly supported citizens’ initiatives so far with almost 1.4 million signatures collected. How will the Commission respond to all who signed this petition?
I am impressed by the hard work by these dedicated young people. I promised them today that the Commission will investigate this very carefully.
In fact, we recently completed a review of our legislation and have found that there is indeed scope for improvement. However, first we will hear the views of the European Parliament and we will consult across the Commission services and then reply about next steps.
Your colleague, the Commissioner for Agriculture, is less enthusiastic. How will you get the farming community onboard?
As always, there will be a balancing act between several interests. Farmers produce the food we eat and they deserve to be heard as well. Many farmers also already made this transition, showing it is possible to rear animals cage-free.
The Commission always performs a thorough impact assessment, so any legislative proposal will be based on solid facts and on careful consideration of all relevant impacts. We always seek a sustainable compromise.
There could also be other possibilities to make animal welfare more attractive for farmers by e.g., economic incentives, subsidies, trade schemes and awareness campaigns. It is not just about laws and penalties.
On the other hand, I think the farming industry has known for a long time that this is coming, they have had plenty of time to prepare and many Member States have in fact already taken significant steps in the direction of free-range animal rearing.
But is there not a risk that ‘money will talk’, how can you weigh the economic impacts against animal suffering – how will the comparison be done in an impact assessment?
No, economic interests are not the only interests we take into account. It is true that our assessment is expressed as a cost-benefit ratio, but among those ‘benefits’, we consider also softer values such as social, health and environmental impacts – and ethical choices. I guarantee you that industry interests will not dominate this process. 
On the contrary, I think what we see here is a strong message from European citizens that animal rights and animal welfare must be respected, and I agree with them. We cannot ignore this question any longer.",27,6.0,"Summary

According to the Notice of Competitions of current EPSO competitions, the only competency that will be assessed in the Case Study exam is Written Communication",6.0,"Observations

The central theme, which is the proposal for a new Regulation on animal welfare, is communicated relatively clearly, though it could benefit from a more straightforward presentation.

The central message, focusing on the need for animal welfare and the options to improve it, is discernible but could be presented more clearly.

The text mostly follows a logical flow but suffers from some inconsistencies, such as numbering and jumbled points in the ""ISSUE AND POSSIBLE OPTIONS"" section.

While the layout is relatively clear, it could be improved with consistent bullet points and perhaps the inclusion of sub-headers within sections.

Titles and subtitles are broadly adequate. 

The tone of the document is formal and suits the context of a briefing note.

The language is generally straightforward, but it could be simplified further to enhance accessibility.

There does not appear to be overt bias in the communication.

The document includes a clearly titled INTRODUCTION section, setting the stage for the main content.

There is a clearly titled RECOMMENDATION section, but it might benefit from a more structured presentation.

A clearly titled CONCLUSIONS section is missing from the document.

There are some supporting statistics, specifically about the estimated economic impact and the number of signatures on the petition.

EU member states are alluded to but not specifically mentioned by name.

No Non-EU countries are mentioned in the text.

Spelling and Grammar mistakes:

“a decision has to be made on:” should end with a full stop or lead into the listed items with more grammatical consistency.
""and being able"" should be ""and being able,"" removing the extra space and adding a comma for clarity.
""mantain"" should be ""maintain.""",,Tips to Improve,"Trainee's Answer
BRIEFING NOTE 
INTRODUCTION 
The issue is the proposal for a new Regulation on animal welfare that comes after a citizen initiative coordinated by 170 NGOs supported by a petition signed by more than 1.7 Million EU Citizens. This has been supported by the European Parliament through the adoption by a large majority of a resolution which demands the phasing out of cages on farms. The new regulation should ensure better living condition of selected species and categories of animals. The measure will have some implications on the economy, as farms will have to sustain the costs to adapt to the new standards and this might ultimately affect prices. 
ISSUE AND POSSIBLE OPTIONS 
The measure essentially focuses on:
1. the phasing out of cages/crates for pigs, calves, laying hens and pullets, and rabbits and fur-producing animals. A phasing out period between five and ten years. 
2. banning the killing of day-old chicks, with an obligation of marking eggs. If combined with stricter import rules, a period of five years should be sufficient.  
3. banning painful mutilations. with incentives for complying farms, with a transition period of ten years.
4. welfare requirements at imports. Either similar of fully equivalent standards with a possible transition period of 5 to 10 years.
While all DGs agree on the proposal, DG AGRI has expressed a negative opinion in particular on the issue of phasing out cages for hens, production of eggs and the risks for prices to raise. Insofar, this remains the main issue at stake. 
Furthermore, EFSA has expressed concerns over a cage-free environment given the increased risk of anti-microbial resistance of animals and the consequent more important use of antibiotics. 
The estimated economic impact of cage-free system would be around 2,4-2,8 Million EUR. 
While the EC has committed to present a proposal by the end of the year, a decision has to be made on: 
1. the time-span of implementation of the measures (5 to 12 years)
3. the entity of subsidies (probably under the new CAP)
2. the animal standards requirements at imports. 
 
RECOMMENDATION
The primary objective is to preserve as much as possible the draft Regulation as it aligns with DG SANTE's policy objectives. The main obstacle would be to give some concessions in order to bring onboard DG AGRI and  being able to present the legislative initiative to the Council and Parliament as committed. 
It is clear that DG AGRI is open to compromise if we respond to their concern on the costs of the measure and the risk of raising prices. 
I suggest first of all, to stress that in MS where these measures have already been implemented, cage-free eggs production has not brought to a high price increase for the consumers, and in the long-run the costs are equivalent to cage-produced eggs.
Second, there is only a minority of MS that relies on a heavy production of cage-produced eggs. The Commission could respond to their concerns with two possible measures: 
1. Provide incentives from the CAP to their phasing out, but we should mantain the foreseen timespan of five years, not to move too much away from the European Parliament proposal (3 years);
2. Introduce stricter rules for eggs import, with an obligation to have the same standards as EU. 
These measures will help mitigate the costs addressing DG AGRI's major concern."
1,0_Lithium Supply Chain (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG MOVE. 
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Analysis and Problem Solving, Communicating (Drafting Skills), Delivering Quality & Results, and Prioritising & Organising.

Specifically, your task will be to draft a memo for your Head of Unit.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations


ACEA - European Automobile Manufacturers’ Association 

DLE - direct lithium extraction

DLP - direct lithium to product 

ECHA - European Chemicals Agency

ESG - environmental, social, and governance

EV – Electric Vehicle

INN – Investing News Network

IRA – Inflation reduction Act (US)

LCE - lithium carbonate equivalent

LiPo – Lithium Polymer







EMAIL 1","Subject: Towards a sustainable, circular, European battery supply chain 
Dear YOU,

In December 20XX-2, the Commission presented a proposal for a regulation on batteries and waste batteries. The proposal aims to strengthen the functioning of the internal market, promoting a circular economy and reducing the environmental and social impact throughout all stages of the battery life cycle. The initiative is closely linked to the European Green Deal, the Circular Economy Action Plan, and the New Industrial Strategy. 
At the end of last year, The Council and the European Parliament reached a provisional political agreement on the proposal. For the first time the legislation will regulate the entire life cycle of a battery – from the supply chain of raw materials, over the production to reuse and recycling of batteries – and ensure that they are safe, sustainable, and competitive.
As you know, our unit has the lead on this important file and our DG intends to launch the formal interservice consultation over the coming weeks. Before this, our DG wants to organize an internal reflection and brainstorming meeting, and I have been appointed to chair this meeting.
Could you produce an internal memo, summarizing the main ins and outs of this file and the agenda for the internal meeting with concrete proposals and recommendations to fine-tune the original proposal, in line with the political priorities of the co-legislators. 
I’m on mission tomorrow so please could you get this done for me today. It doesn’t need to be long – in fact the shorter, the better.  

Many thanks",",

Ferdinand
Head of Unit




Is Europe Moving Fast Enough to Build a Resilient Lithium Supply Chain? 
Priscila Barrera
Nov. 16, 20XX-1


Europe will soon release its Critical Raw Materials Act to identify potential strategic projects and build up reserves where supply is at risk.
Europe’s green energy transition plans give a central role to the electrification of transportation. 
The European Union (EU) has ambitious goals to become climate neutral by 2050, meaning it would be an economy with net-zero greenhouse gas emissions. Recently proposed legislation is looking to effectively ban all internal combustion engine cars by 2035.
In 20XX-2, electric car registrations for the year were close to 1,729,000, up from 1,061,000 in 2020, with prospects for the region remaining positive. Last year, the market share of battery electric cars almost doubled to around 10 percent, but challenges faced by carmakers continue to weigh on demand as inflation and fears of a recession put pressure on targets. 
In its most recent forecast, the European Automobile Manufacturers’ Association (ACEA) said it expects the overall EU car market to shrink again this year, slipping by 1 percent to reach 9.6 million units.
“To ensure a return to growth — with an even greater share of electric vehicle sales so climate targets can be met — we urgently need the right framework conditions to be put in place,” said Oliver Zipse, ACEA president and CEO of BMW. “These include greater resilience in Europe’s supply chains, an EU Critical Raw Materials Act that ensures strategic access to the raw materials needed for e-mobility, and an accelerated roll-out of charging infrastructure.”
As sales of electric vehicles increase, carmakers are looking to secure supply of key metals used in batteries, including lithium. Today, Europe is quite dependent on Australia and Chile for lithium supply and China for lithium refining, but the region is taking steps to strengthen its supply chain for the important battery metal. 
What is the European Critical Raw Materials Act? 
In September, news broke that Europe will be putting forward the European Critical Raw Materials Act, a new piece of legislation. Its aim is to identify potential strategic projects and build up reserves where supply is at risk.
European Commission President Ursula von der Leyen said the bloc has learned its lesson about the risks of being dependent on Russia, and realizes the need to be vigilant toward China.
""In the case of China, it is the risk of dependency on technologies and raw materials,"" she said, adding that the EU needs to boost its production capacity and shift more towards trustworthy suppliers.
In October, von der Leyen said the EU is witnessing quite an acceleration of trends and tensions with China. 
""The Chinese system is fundamentally different from ours and we are aware of the nature of the rivalry,'' she said.
The moves from the EU are in line with pushes seen in other regions such as North America, where the US has committed billions of dollars to reach its carbon emissions targets.
In June, the Biden administration launched the Inflation Reduction Act, which includes climate incentives. The legislation, which was signed into law in August, requires automakers to source 50 percent of critical minerals used in electric vehicle batteries from North America or free trade agreement countries by 2024, with that amount rising to 80 percent by the end of 20XX+3.
For its part, Canada recently ordered three Chinese companies to divest from lithium companies following a “multi-step national security review process.” China has opposed the move, and Canada is expected to release its China strategy soon.
Europe-Asia relationship in the lithium space 
Jack Bedder of Project Blue said Asia will always be a part of the European lithium-ion battery supply chain. Major Asian companies, including Panasonic, Samsung, BYD Company and CATL, all have operating capacity on the continent.
“As a result, it will be almost impossible to detach fully from Chinese-owned supply across all stages of the lithium-ion supply chain,” he told the Investing News Network.
However, as lithium processing capacity is built up globally at non-Chinese-owned companies, particularly within the EU, the opportunities to reduce the EU's dependency on China-owned supply will improve. “It is very unlikely that the EU will implement legislation directly prohibiting lithium supply from Chinese-owned companies, as further constraints on supply availability to the European market will only hinder growth in the industry over the coming decade,” Bedder added.
For Allan Pedersen of Wood Mackenzie, Europe cannot move forward without influence from Asia in the short to medium term.
That’s due to a few reasons. As mentioned, many of the battery plants being constructed in Europe have Asian companies behind them, and the cathodes needed in batteries are still largely produced in Asia, where the know-how is strongest. Additionally, lithium refining is mainly done in China and most mineral concentrate is produced in Australia.
“China has a multi-year advantage over the rest of the world in terms of investing in the entire supply chain — it will be challenging for Europe to catch up to that in terms of investment in know-how, processing equipment and resources,” he said. 
“This doesn’t mean that Europe cannot make progress in this space. In lithium, we see some resource developments and processing facilities being considered and constructed.”
For the analyst, in the long-term Europe has the potential to become more self-sufficient for raw materials as recycling becomes a larger part of the supply landscape and can supplement domestic resources.
European Commission could classify lithium as toxic. 
Although Europe is pushing to build a resilient supply chain by partnering with allies and developing domestic resources, it might not all be good news for miners in the region — at the end of last year, the European Commission said it will weigh a proposal from the European Chemicals Agency to classify lithium carbonate, chloride and hydroxide as dangerous for human health.
If the proposal is approved, this could undermine the EU’s attempt to create and support a domestic battery materials supply chain, research firm Rystad Energy said in a statement. “The EU currently relies heavily on imports of lithium to supply its nascent electric vehicle production sector and the classification may increase its reliance on other regions, at a time when the union is focused on energy security and reducing emissions,” the document reads.
If the classification goes ahead, it would not stop lithium usage, but it is highly likely to have an impact on at least four stages: lithium mining, processing, cathode production and recycling.
“This potential ruling comes at a time when the EU is itself scrambling to build and establish local lithium supply chains. The permitting issue has repeatedly been highlighted at recent industry events as one of the main barriers to new mining projects ramping up quickly in the EU,” according to Rystad Energy analysts. “There is also further risk of potential projects losing local community support for building lithium mines and processing operations.”
Editorial Disclosure: The Investing News Network does not guarantee the accuracy or thoroughness of the information reported in the interviews it conducts. The opinions expressed in these interviews do not reflect the opinions of the Investing News Network and do not constitute investment advice. All readers are encouraged to perform their own due diligence.




Lithium salts could be declared health hazard in EU
June 9, 20XX-1 by Igor Todorović


A major lithium producer threatened to close its plant in Germany if the European Union declares the material dangerous to human health. The European Chemicals Agency or ECHA initiated the process.
The European Union has been making its environmental and climate rules stricter for decades. The administration in Brussels wants to make the entire continent carbon neutral by mid-century. At the same time, it is striving to achieve the highest level of protection from pollution in the world.
The energy transition and the decarbonization of industrial activity and power plants imply massive deployment of renewables, mostly solar and wind farms. However, as they depend on unstable weather conditions, the electric power system requires energy storage, in which the EU counts a lot on batteries.
Dangerous critical raw material
Lithium-ion solutions still dominate the sector, though there are other technologies emerging that could popularize less harmful material for home units and the batteries for electronic devices, electric vehicles, and utility systems. At the same time, the European Commission is struggling to secure supply chains that would make the availability of lithium stable and make the EU almost self-sufficient by 20XX+7.
The European Union has added lithium to a list of critical raw materials as demand is expected to increase dramatically in the coming years.
Initiatives to open mines and ore processing plants such as the ones in Serbia and Portugal have caused a public uproar as environmentalists and the local population are fearful about the impact on nature and people’s livelihoods. In other projects, engineers are trying to make the extraction of lithium from geothermal waters cost effective and harmless, without any mining.
Stricter rules for handling lithium would lift costs
However, the entire concept could falter with the European Commission’s upcoming legislation. Namely, it is considering the proposal from the European Chemicals Agency, ECHA, to declare key lithium salts hazardous for human health, Reuters reported. If lithium carbonate, lithium chloride and lithium hydroxide are classified as dangerous, it would complicate the import procedure, production, and handling of the materials.
ECHA’s Risk Assessment Committee accepted the demand from France in September to classify lithium salts as damaging for fertility and unborn children and to declare the substances harmful for breastfed children.
Adding lithium salts to the list of materials hazardous for health may prompt the revision of a range of projects in the industry.
Stricter rules mean higher costs, so any lithium ore processing plant project, like the one in the Jadar area in Serbia, would need to be given a second look regarding its environmental impact and feasibility.
Albemarle, based in Charlotte, North Carolina, has indicated it may be forced to close its plant in Langelsheim in north Germany if the plan is accepted. In that case, Chief Financial Officer Scott Tozier said, the company wouldn’t be able to import lithium chloride, its primary feedstock.
The unit’s annual revenue is USD 500 million, and the plant has over 600 employees. Tozier warned a decision to declare lithium salts hazardous would prompt an exodus of EU producers including battery recyclers.
The decision is expected to be reached by early next year, the article adds.





The Really Big Battery Deal in the IRA That People Are Missing
By Zachary Shahan – Published September 23, 20XX-1
When it comes to electric vehicles and the Inflation Reduction Act of 2022, almost all the discussion has been around the consumer tax credit for buying an electric vehicle, including the interesting new battery aspects of that. That’s a big topic, but there’s a whole other battery angle separate from the consumer tax credit, and it’s huge.
The short summary of the whole thing is that the IRA incentives for nearly every stage of battery production and the battery supply chain are very attractive, and since they stack on top of each other, the IRA is likely to stimulate a “gold rush” of sorts in battery mineral mining, battery mineral refining, battery cell production, battery recycling, and battery pack production in the United States. When you also consider that consumers will need to get batteries whose components don’t come from China, and that come from North America eventually, then it’s essentially a given that everyone in the industry now knows it should have battery mineral mining and refining as well as battery cell and pack production in North America.

SK Innovation Georgia battery factory rendering, courtesy of SK Innovation.
The Current EV Battery Mineral Situation
First, let’s note where we’re starting from. The USA currently mines and refines close to 0% of the minerals that go into EV battery packs. China, on the other hands, mines or refines the majority of all the big ones, including lithium, cobalt, nickel, and graphite. Here’s a chart on Chinese EV battery mineral domination:

Money, Money, Money
Looking at the data, the idea that Joe Biden was going to stimulate a gold rush in the EV battery mineral mining and refining space was a dream some of us had, but it seemed like one of the more outlandish dreams we could have in this time and age. However, the market does respond to three things pretty well: money, money, money, and money. And the Biden administration, Prime Minister Manchin, Senate Majority Leader Chuck Schumer, and others involved in crafting the legislation took note and decided to offer all four.
The slight joke here, aimed at emphasizing the key point, is that the IRA seems to be offering cash money (tax credits) for mining battery minerals, for refining battery minerals, for putting together battery cells, and for putting together battery packs (or “modules”). If you do all those things, you don’t get one bonus, you get four bonuses. If you count all the different minerals in a battery, the number of potential bonuses is much larger. Those bonuses add up, and they make it much more appealing to bring full-cycle battery production to the USA. At the very least, it should open mining and refining projects — which are more or less non-existent in the United States — by making them much more bankable. (Side note: Canadian and Mexican locations hoping to attract battery manufacturing investment may not have figured it out yet, but their competitive position versus the US took a major hit when Biden signed the IRA.)
That’s why we recently got news of Tesla reportedly deciding to scrap some investments it had already made in Germany (but not all of them) and move some battery cell production stateside. That’s why Tesla is reportedly exploring lithium refining in Texas now as well. That’s why GM is reportedly accelerating its exploration of EV battery mineral supplies from US soil. “Our thought process was that we would do this over a period of time, but with the IRA, we are actively working on figuring out how to accelerate,” said Sham Kunjur, GM’s executive director for EV raw materials. But this is only the beginning. These are just the leaks from early movers and leaky groups. Whether it’s Tesla, GM, Volkswagen, Ford, Panasonic, SK Innovation, LG Energy Solution (previously known as LG Chem), Samsung SDI, Albemarle, Livent, Piedmont Lithium, Talon Metals, Lithium Americas, Pilbara Minerals, or others, corporate teams are looking at the IRA, having their lawyers look at it, and starting to look much more seriously at what production opportunities they can launch in the United States.
Looking at the Actual IRA Language
Section 45X of the IRA concerns “components produced and sold after December 31, 2022.” Near the beginning, it states that “any taxable year is an amount equal to the sum of the credit amounts determined under subsection (b) with respect to each eligible component.” In other words, if you get a tax credit for one component of a battery (raw lithium, for example), you can also go and get a tax credit for another component or even later stage of the same component (the refined lithium, for example). The tax credits are for each major stage of the production process, and that means you can get them for various components of a battery and various stages of processing or putting together those components. You can get the following credits:
10% of the cost of battery electrode active materials
$35/kWh of battery cell capacity
$10/kW of battery module capacity (or, for a battery module that does not use battery cells, $45/kWh)
10% of the cost of producing a battery mineral.
Also, while there’s a phaseout for some of these between 2030 and 2032, there is no phaseout at all for the critical mineral subsidies! That’s long-term stability for a market that needs it.
What Minerals & Battery Components Are Eligible?
Regarding electrode active materials, those include “cathode materials, anode materials, anode foils, and electrochemically active materials, including solvents, additives, and electrolyte salts that contribute to the electrochemical processes necessary for energy storage.”
Applicable critical minerals include aluminum/alumina, antimony/antimony trisulfide concentrate, barite/barium sulfate, beryllium/copper-beryllium master alloy, cerium/cerium oxide, cesium/cesium formate/cesium carbonate, chromium/ferrochromium, cobalt/cobalt sulfate, graphite/graphitic carbon, lithium/lithium carbonate and lithium hydroxide, manganese, nickel/nickel sulphate, and many others.
Notably, at the end, it’s noted that only production that takes place in the United States is eligible for these tax credits. This creates a “USA premium” in the supply of raw materials to facilities that want to get the maximum benefit from 45X. Any manufacturer will be eligible for a 45X tax credit which covers the yearly cost of production if their facility is using raw material from the US. For most manufacturing, raw material cost is the most significant component of OPEX after labor and energy. So, Biden, Schumer, Manchin, and their aides have been very clever here: “want the maximum benefit, Buy American.”
So, let’s go back to the example of Tesla (or you can use Ford, GM, or some other company in this hypothetical if you prefer). Tesla could, theoretically, get a tax credit for mining lithium, get a tax credit for refining lithium, get a tax credit for mining nickel, get a tax credit for refining nickel, get a tax credit for producing battery anodes, get a tax credit for producing battery cells, and get a tax credit for producing battery modules. Of course, Tesla isn’t going to do all those things. However, I think that helps to explain the potential here. Whereas Tesla won’t do all those things itself, companies and investors will be pouring into the United States to do them, and some automakers will deepen their vertical integration in the battery space as well.
As a final note, and perhaps as a teaser for something we’ll come back to, while the incentives from the IRA are attractive, so is the potential for pricing control over raw materials! Whether Ford, GM, or Tesla, having more secure, stable, predictable control over key raw material costs could go a long way in being competitive and financially sustainable in the coming decade. How much is that pricing control worth as we go from ~5% EV market share in the US auto industry to 50% or more?

Russia may launch lithium production in the coming four years
June 17, 20XX-1
| As said at the SPIEF Oleg Kazanov, Director of the All-Russian Institute of Mineral Resources (VIMS) under Federal Subsoil Resources Management Agency, Russia may start lithium mining based on the ore deposits in the Murmansk region in 3-4 years and become one of the world’s five largest producers in eight years’ time.  |  |
“Russia has a lithium resource base, which is 10% of the world’s reserves and explored back in the 60s of the previous century. This is almost 4 million tons in 15 explored deposits. The first two objects in the Murmansk region will gain licensing and active subsoil use by the end of the current year. I think production might start there already in the next three or four years. Moreover, these are world-class deposits, both in terms of the lithium reserves and content,” O. Kazanov said.
According to him, now the demand for lithium is boosting in the world. Its driver is the battery industry. “Already in the next 10 years, we will see an increase from the current 100,000 tons of lithium consumption to about 700,000 tons. In total, 88 deposits of ore lithium will be launched in the world soon, but it is not enough to cover its entire global demand,” the expert notes.
Meanwhile, in Russia, a peculiar situation has developed in the lithium industry. The country has huge reserves of ore lithium reaching 10% of the world’s. Besides, Russia discovered lithium reserves in solutions in the bottom waters of the oil and gas fields in the Angara-Lena region, but they have not been fully assessed yet. The lithium content in solutions is very high by the world standards, i.e., about 300 mg/l.
There are two large lithium processing plants in Russia the Krasnoyarsk chemical-metallurgical plant, which buy raw lithium from Chile, bring it up to battery quality and ship to Southeast Asia.
Against the background of this situation, Federal Subsoil Resources Management Agency has recognized development of the lithium ore and brine reserves as a priority area.
Lithium ore mining technologies already exist; they scale well, especially considering increase of the demand for lithium and its price rise. “I think already on ore lithium, in the prospect of the next eight years, we are going to be among the top five producers of this metal along with Chile, Argentina, China and Australia,” O. Kazanov noted.
The next stage in the Russia’s lithium industry development after the ore deposits have been commissioned will be application of the technologies for lithium production from solutions. In the world, this is the DLE technology mainly used for solutions at geothermal power plants. In Russia, lithium solutions are found in the bottom waters of oil and gas fields. This water is somehow extracted from the subsoil and injected back into the reservoir to maintain pressure in an oil and gas well.
The engineering center created based on the Krasnoyarsk chemical-metallurgical plant and VIMS developed its own technologies for lithium extraction just during a year, and now they are tested under the laboratory conditions.

By Marcelo Azevedo, Magdalena Baczyńska, Ken Hoffman, and Aleksandra Krauze
Lithium is the driving force behind electric vehicles, but will supply keep pace with demand? New technologies and sources of supply can fill the gap. 
Despite expectations that lithium demand will rise from approximately 500,000 metric tons of lithium carbonate equivalent (LCE) in 2021 to some three million to four million metric tons in 2030, we believe that the lithium industry will be able to provide enough product to supply the burgeoning lithium-ion battery industry. Alongside increasing the conventional lithium supply, which is expected to expand by over 300 percent between 2021 and 2030, direct lithium extraction (DLE) and direct lithium to product (DLP) can be the driving forces behind the industry’s ability to respond more swiftly to soaring demand. Although DLE and DLP technologies are still in their infancy and subject to volatility given the industry’s “hockey stick” 1 demand growth and lead times, they offer significant promise of increasing supply, reducing the industry’s environmental, social, and governance (ESG) footprint, and lowering costs, with already announced capacity contributing to around 10 percent of the 2030 lithium supply, as well as to other less advanced projects in the pipeline.
However, satisfying the demand for lithium will not be a trivial problem. Despite COVID-19’s impact on the automotive sector, electric vehicle (EV) sales grew by around 50 percent in 2020 and doubled to approximately seven million units in 2021. At the same time, surging EV demand has seen lithium prices skyrocket by around 550 percent in a year: by the beginning of March 2022, the lithium carbonate price had passed $75,000 per metric ton and lithium hydroxide prices had exceeded $65,000 per metric ton (compared with a five-year average of around $14,500 per metric ton). 
Lithium is needed to produce virtually all traction batteries currently used in EVs as well as consumer electronics. Lithium-ion (Li-ion) batteries are widely used in many other applications as well, from energy storage to air mobility. As battery content varies based on its active materials mix, and with new battery technologies entering the market, there are many uncertainties around how the battery market will affect future lithium demand. For example, a lithium metal anode, which boosts energy density in batteries, has nearly double the lithium requirements per kilowatt-hour compared with the current widely used mixes incorporating a graphite anode.
So, will there be enough lithium to cover the needs of a new electrified world? As discussed in our recent article, “The raw-materials challenge: How the metals and mining sector will be at the core of enabling the energy transition,” arriving at a considered answer and understanding the entire supply-and-demand context will be crucial for every player along the value chain—mining companies, refiners, battery manufacturers, and automotive OEMs.
Lithium demand factors
Over the next decade, McKinsey forecasts continued growth of Li-ion batteries at an annual compound rate of approximately 30 percent. By 2030, EVs, along with energy-storage systems, e-bikes, electrification of tools, and other battery-intensive applications, could account for 4,000 to 4,500 gigawatt-hours of Li-ion demand.
  
Not long ago, in 2015, less than 30 percent of lithium demand was for batteries; the bulk of demand was split between ceramics and glasses (35 percent) and greases, metallurgical powders, polymers, and other industrial uses (35-plus percent). By 2030, batteries are expected to account for 95 percent of lithium demand, and total needs will grow annually by 25 to 26 percent to reach 3.3 million to 3.8 million metric tons LCE depending on the scenarios outlined in Exhibit 2. 


Reuse and recycle
A frequently asked question is whether L-ion batteries can be recycled. With expected battery lifetimes of around ten to 15 years for passenger vehicles, and the possibility of extending EV battery life through use in the energy-storage sector, battery recycling is expected to increase during the current decade, but not to game-changing levels. Depending on the recycling process employed, it is possible to recover between zero and 80 percent of the lithium contained in end-of-life batteries. By 2030, such secondary supply is expected to account for slightly more than 6 percent of total lithium production (Exhibit 7).",3,4.0,"Summary
Unfortunately, this is an unsuccessful case study that contains the basis of a good one, but it needs more elaboration.
First and foremost,  while list format is more than welcome in some cases (e.g. pro/con lists), we expect a coherent, consistent, professional, and easy-flowing text. Make every connection and causation explicit, no matter how obvious they are; thus, you can enhance the cohesion of your text and achieve stronger content points. Merge short, one-sentence paragraphs to improve your case study's narrative arch.
Keep it as simple as you can: use sentence structure and length you are confident with, as some style issues can lessen the effect even of an impeccably discussed problem point. Typos and some grammar aspects (e.g., article use, verb agreement, verb forms) can be controlled with some attention even in an exam situation. They can heavily influence your score for the communication competence.
Keep track of all the information: take notes, for it's better to sort out or merge details while writing than leave out something.
If the source documents provide some insight into the given subject matter’s international aspects, then it is worth discussing it in a few sentences to provide a full picture.
It is helpful to frame your text with an introduction and conclusion; first, you can put the issue in context; second, you can enhance the professional feel of the study; and, finally, you can show that you finished the text as you intended and not because the time ran out.
It is always great to spend a few sentences on future options, possibilities, or even problems to give an even more professional impression.
For time management issues and other practical ideas, please check out our Tips & Tricks menu and our webinars.

Per Competency Score",3.0,"Observations
With this competence, we basically evaluate the style of the case study. Your text should be clear, fluent, written in a professional but still captivating style; of course, spelling and grammar are also covered in this area. Another point we examine here is whether you managed to find the balance between providing details and being concise while conveying the key points of the arguments.",,"Tips to Improve

The text reads like an outline: it is short, lacks cohesion and coherence, it is full of typos and grammatical inaccuracies to the extent that it is unreadable.","Trainee's Answer
For: Ferdinand Porsche (HoU DG MOVE)
01/03/2023
INTERNAL MEETING MEMO on sustainable, circular, European battery supply chain
FACTS
EU legislation is to ban combustion engine cars by 2035, plan with net-zero economy, climate neutral by 2050.
Impossible to detach fuly from Chinese lithium-ion supply, but as the lithium processing companies are mostly EU-based dependency on China will improve. Lithium refining done mostly in China, cathodes produced there as well, mineral concentrate in Australia. China has years of advancement of supply chain and know how in the field.
Outlook on less China dependency is thus more long term and legislation against China is therefore not likely to not hamper EU market development. EU has real potential to become self sufficient as regards raw materials via recycling in addtion to domestic supply.
However, last year EU Commisions was considering ESHA proposal to classify lithium as toxic - bad news for EU mining, specifically for lithium mining, processing, cathode production and recycling.
This brings problems in factries in Portugal and Germany, and also in Serbia.
Important development in the US in connection with Inflation Reduction Act of 2022, which has incentivised the whole battery cycle through tax credits. The attractiveness of this package is in stacking of bonuses (credits) on all steps of production of batteries, from refining to putting together of battery packs; and 50% pricing control on raw materials, all of which produces long term incentives.This creates attractiveness for companies to move business to the US, to have the whole process done in the US as the bonuses are linked to purely US based manufacture and assembly.
Russia has 10% of raw materials, so the EU could consider this source.
Direct lithium extraction (DLE) and DL product could provide for 10% of demannd of lithium supply by 2030, recycling of batteries could provide for 6% by the same date. Batteries will represent 95% of total demand of lithium by 2030.
 
AGENDA FOR INTERNAL MEETING
PROPOSALS/RECOMMENDATIONS in line with political priorities
1) Strong support of lithium mining from geothermal sources due to lack of health hazard
2) Legislation aimed at gradual cessation of supply of lithium-ion from Asia whilst increasing EU based supply via recycling and non-hazardous sources.
3) Introduction of incentivisation of producers similar to US, for example 10 Eur per kwh, 10 Eur per cell assembly etc,, to attract companies and create strong base in long term.
4) Increase supply from Chile, Argentina, Australia in shot and medium term."
4,0_Case study - Animal welfare - LONG,"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. 

Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG SANTE. 
A citizen’s initiative (“End the cage age”) collected almost 1.4 million signatures demanding a Commission proposal to ban all use of cages for farm animals. DG SANTE has prepared a draft legislative proposal, based on an impact assessment and several rounds of stakeholder consultations. An inter-service consultation (ISC) with the other DGs was recently closed. The Director-General of SANTE now needs to decide how to move forward on this file, so that a compromise text can be agreed in the college of Commissioners.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes, as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the candidate’s drafting skills (Communication) and may be used to assess also the following competencies: Critical thinking, analysing & creative problem-solving, and Decision-making and getting results.

Specifically, your task will be to draft a concise briefing note for your Director-General. This note must include: 

Summary of the main issues, notably the remaining problems to solve
Arguments and facts to help the Director-General make a decision on the file

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.",,"Subject: Briefing for the Director-General – Animal welfare legislative proposal
---
Dear [your name],
Welcome to your first day in the unit! You will have to hit the ground running - we have received an urgent request for a briefing. Our Director-General, Ms Heinrich, needs a summary of state of play concerning the draft revised animal welfare regulation, for her decision on the way forward.
As you have seen in the draft regulation text, we have followed the “preferred options” identified in our thorough impact assessment (those marked green in the impact assessment options table). This draft legislative proposal is what we as DG SANTE believe best serves our policy objectives and this is what we need to defend as far as possible. We received strong support for an ambition line in all the stakeholder consultations.
In the recent inter-service consultation, we also received green light (positive opinion) by all DGs except one. DG AGRI has unfortunately not been able to accept our draft legislative proposal. This means we will either need to make small compromise adjustments to the original proposal and change our preferred option, or we try to somehow convince DG AGRI to accept our main line.
In your briefing, please outline the main issues at hand and explain the options for next step so that our Director-General can make an informed decision on it. She did invite us to already make a recommendation based on our knowledge of the file if we have a preference.
You should keep the briefing short and concise, no more than two pages.
I have placed a file with various materials on your desk. It should contain what you need for the draft briefing. Please have a first version done already today at X o’clock so I can check it before passing it on to Ms Heinrich.
Thank","you and best of luck,
Wiebke
---
Head of Unit
Animal welfare unit, DG SANTE

Attachment 2: Inter-service consultation reply AGRI

Answer of DG AGRI to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 1 (sent on 16 May 202X 14:56:54) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | DENKER Nicholas (AGRI.F.002) | No automatic forward of notifications to this responsible officer |
Opinion | Negative opinion  |  |
Authorised in the DG by | ROBINSON Michael (AGRI.F) |
Comments | For laying hens/cage ban, either the low ambition option or status quo should apply, for protection of the single market and to ensure competitive pricing of European high standard food products, compared with lower-standard import products from third countries with only minimum requirements of animal welfare rules. |  |



Attachment 3: Inter-service consultation reply ENV

Answer of DG ENV to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 2 (sent on 14 May 202X 17:32:04) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | SVOBODA Lisa (ENV.D1) | No automatic forward of notifications to this responsible officer |
Opinion | Positive opinion |  |
Authorised in the DG by | HUEGEL-PEETERS Sabine (ENV.D) |
Comments | Thank you for consulting DG ENV on the proposed revised regulation on animal welfare. This proposal is important and in line with the European Green Deal objectives; we support the general approach and your preferred options. From our review, we have several minor editorial comments, given in track-changes in the attached document, which we request are taken on-board. |  |






Attachment 4: Inter-service consultation reply TRADE

Answer of DG TRADE to the consultation ""ISC/202X/04537"" of DG SANTE

Version | 1 (sent on 15 May 202X 11:46:25) |  |
Deadline |  | 16 May 202X |  |
Responsible officer |  | LANGE JENSEN Halfdan (TRADE.B.01) | No automatic forward of notifications to this responsible officer |
Opinion | Positive opinion |  |
Authorised in the DG by | GEORGIOU Andreia (TRADE 0) |
Comments | N/a |






Attachment 5: Press statement

Brussels, April 202X-2
Every year across the European Union, around three hundred million farmed animals are confined in cages. Unable to conduct many of their natural behaviours, these animals are treated as nothing more than production machines. No single EU Member State is completely cage free and in some Member States up to 90% of all hens, mother pigs and young calves are kept in cages and crates. This despite farming industry having had more than 15 years to voluntarily change their installations.
Over 170 organisations and caring citizens across Europe therefore joined forces to spearhead the “End the Cage Age” European citizens’ initiative. In total, 1.4 million EU citizens made their voices heard and signed the petition. Only one other citizen’s initiative has so far gathered more signatures than this.
Mr Daniel Müller, campaign leader for “End the Cage Age” said: what we see now is the battle of ethics versus economy. EU citizens do not want cheap food at any cost and certainly not at the cost of pain and suffering of our fellow creatures. Food industry and economic interests will have to adapt to this reality – and finally do what is right.
In response to our tireless campaigning, in April 202X-2, the European Commission committed to proposing legislation before the end of 202X to phase out and finally prohibit the use of animal cages. We must now ensure that a total ban on caged farming is delivered, as soon as possible. The fight also continues to pave the way not only for a cage-free Europe, but for a cage-free world by making sure that all imported products in the EU comply with cage-free standards.


Attachment 6: Website

What is a citizens' initiative?
A European citizens’ initiative is a way for you and other Europeans to take an active part in EU policymaking.
If you want the EU to act on a particular issue, you can launch a citizens’ initiative calling on the European Commission to propose new EU legislation on that issue.
For an initiative to be considered by the Commission, you need to get one million citizens from across the EU to sign it in support.
Step 1: Get started
Before launching an initiative, it is worth considering some of the key practical aspects, including:
is asking for EU legislation to be passed the best way to achieve your goals?
you must first set up a group of organisers composed of at least 7 EU citizens living in seven different EU countries. To do so, you need to find people to team up with across Europe who are willing to support your issue.
how will you organise your campaign to collect the signatures?
You can find detailed advice on all these issues on the European Citizens’ Initiative Forum




Step 2: Get your initiative registered
Before you can start collecting signatures for your initiative, you must ask the Commission to register it.
For this, you will need to:
create an organiser account. You will use this to manage your initiative and liaise with the Commission throughout its lifecycle.
provide a description of your initiative in one of the official EU languages (as well as details and relevant documents on the group of organisers, funding received, etc.)
The Commission is not obliged to register all initiatives. It only registers initiatives that meet certain criteria.
Once you ask for your initiative to be registered, we will assess whether to accept it.
You will receive an answer within 2-4 months.


Step 3: Get support
You need to get the support of at least one million people, with minimum numbers in at least seven EU countries. They must fill in a specific statement of support form.
You can collect:
on paper (pre-filled forms, downloadable from your organiser account) or
online (using the Central Online Collection System).
These forms are available in all EU official languages.
To sign, people must be:
EU nationals (nationals of an EU country)
old enough to vote in European elections or aged at least 16 in some countries
TIP – It is better to collect more signatures than you need. Sometimes the authorities in each country might not be able to validate all the statements of support you provide. Throughout the collection procedure, you must comply with data protection rules.


Step 4: Submit your initiative
Once you have received the last certificate from the national authorities, you have 3 months to submit your initiative to the Commission – together with the information on the support and funding you have received for the initiative.


What next?
If the Commission considers legislation an appropriate response to your initiative, it will start preparing a formal proposal. This can require preparatory steps like public consultations, impact assessments, etc. Once adopted by the Commission, the proposal is submitted to the European Parliament and the EU Council (or in some cases, only to the Council), which will need to adopt it for it to become law.
The Commission is not obliged to propose legislation. Even where it responds positively, the most appropriate follow-up to an initiative may be non-legislative in nature. There are a range of other measures that may be more suitable.
The European Parliament may also assess the measures taken by the Commission.

Attachment 7: E-mail message
 
From: ROBINSON Michael (AGRI)
Sent: Monday, 16 May 202X
To: MUNOZ Wiebke (SANTE)
Subject: Revised animal welfare regulation
 
---

Dear Wiebke,
Just a heads-up about the AGRI response to your animal welfare ISC - you will receive it later today. We can accept all of it, but we have a remaining concern about the proposed new rules for poultry cage rearing.
First, the proposed exception for farms less than 50 livestock units (3500 laying hens) does not make much sense. The overwhelming majority of eggs produced in the EU come from farms with more than 5000 birds (70 livestock units) and the smaller farms can anyway more easily transition to cage-free rearing if they haven’t done so already.
Longer transition time also does not help, it’s not about more time for farms to adapt. It’s about the money and about food prices.
For large-scale installations, cages are simply more efficient and use much less space. With your proposal, notably the requirement of more space per laying hen, production will necessarily be less cost-efficient, and most farms will not be able to keep the same number of birds. Consumers might say they care about animal welfare but when they make their choices in the supermarket, the thing that matters most is the price! If you implement the new rules, the price of eggs might increase by around 20-40% in countries like Spain, Portugal, and Malta where cage systems are still the norm. This means we will see a significant increase in cheap imported eggs from third countries with much worse animal welfare standards. Our European farmers cannot compete on such unfair terms.
There is also the socioeconomic element: the burden of higher food prices will be heavier on the poorest families.
Unless farmers can be compensated economically somehow for taking this risk, we don’t see any need for changing the current rules on poultry caging and we will need to block your proposal.

Call me if you want to discuss this further.

Best,
Michael


Attachment 8: Press release


MEPs endorse EU citizens’ call for gradual end to caged farming
Press releases – AGRI - 20 February 202X-2

The European Parliament has called for the end of caged farming within the next 5 years. The parliament members voted on an own initiative resolution recommending a total ban on the use of cages in animal agriculture by 202X+3.
The vote followed intensive lobbying by the “End the Cage Age” European Citizens Initiative, led by 170 non-governmental organisations (NGOs) across Europe, which garnered 1.4m signatures from EU citizens and demanded the phasing out of cages on farms. Members of the European Parliament (MEPs) voted by 558 to 37 with 85 abstentions on the non-binding resolution.
Unlevel playing field in Europe
Even though the EU has banned the use of battery cages in poultry production and sow stalls during gestation, campaigners said this was not enough, given the perceived unlevel playing field across Europe with some nations already going beyond EU laws.
According to the initiative, five out of 28 countries are currently achieving more than 80% cage-free production, i.e., Austria (97%), Luxembourg (97%), Sweden (92%), Germany (86%) and the Netherlands (82%). Bottom of the list is Malta, with 1%, followed by Spain and Portugal. About sows, the report is based on Eurostat figures, according to the initiative’s website.
In the European Parliament, a working group on cage-free farming established in 202X-10 has been actively supporting the “End the Cage Age” initiative and in October 202X-3, 101 MEPs from various political parties signed a letter of support addressed to EU Commissioners.
Speeding up the review of animal welfare legislation
Last month, the parliament’s AGRI committee adopted a motion for a resolution. Committee members called on the European Commission to speed up the review of the animal welfare legislation and back the phasing out of all cages in farming, possibly already by 202X+3. They also insisted on ensuring compliance with EU standards for all products imported into the EU.
By April this year, the European Commission will have made its decision as to whether to start a legislative process to ban caged farming. EU Food Safety commissioner Stella Kyriakides told MEPs that the Commission was considering a request contained within the resolution to apply the same animal welfare standards to meat imported from outside the EU as European farmers must meet inside the bloc.
Kyriakides also noted the call for farmers to receive compensation and support in their transition from cages. She added the phase-out would happen “as soon as feasible” but did not give a specific date.
The results for pork production could be far-reaching, as it would likely change the current practice using farrowing crates. In recent years, a lot of research initiatives have already been launched to design free farrowing concepts.



Attachment 9: E-mail message 
 
From: CALBI Ana (EFSA)
Sent: Thursday, 16 October 202X-1
To: MUNOZ Wiebke (SANTE)
Subject: Cages and antibiotics
 
---
Dear Ms Munoz,
Congratulations on your concluded impact assessment on the animal welfare regulation!
In view of your upcoming drafting process, I need to point out that there are several scientific studies pointing to higher prevalence of antimicrobial resistance, notably among e-coli bacteria, in non-cage housing systems for poultry - if not implemented correctly and with strict quality standards. I feel this did not come out clearly enough from your impact assessment.
Free-range egg production systems face more challenges related to biosecurity and use of antibiotics. The free-range layer birds have more interaction with each other compared to caged ones, leading to an increased incidence of infectious poultry diseases requiring treatment with antimicrobials, in turn leading to increased emergence of resistant commensal and pathogenic bacteria. This is a major threat to public health.
The main factor to consider is of course, as always, the number of hens per square meter, the hygiene routines, and the overall rules on veterinary prescription of antibiotics. It is the same for pigs: sows in small crates have low life quality but use less medication; pigs in free range but packed close together require lots of antibiotics and pigs in free range with sufficient space are more healthy and less prone to cause antimicrobial resistance. However, they are also much less cost-effective for industrial-size farming. 
Still, to ensure safe food production and avoid antibiotics resistance, livestock density simply must go down. 
If you could take these concerns into account in your draft revised regulation, we would be much grateful.

Best regards,
Ana Calbi

---
Head of Department
The European Food Safety Agency (EFSA)




Attachment 10: Impact assessment


								Brussels, 13 October 202X-1






COMMISSION STAFF WORKING DOCUMENT

IMPACT ASSESSMENT REPORT


Animal welfare: revised regulation


Executive summary
To address the specific objectives of the animal welfare legislation revision, four policy measures have been considered, with low, medium, and high ambition options. Impacts assessed include cost-efficiency, environmental and societal impacts and impacts on the single market. The European Food Safety Agency (EFSA) has confirmed the scientific evidence. Numerous stakeholder consultations and supporting studies have been performed.
For animals kept for economic purposes, the measures/options covered are:
1) 	Phasing out confining cages/crates for the following species and categories of animals:
Pigs
Calves
Laying hens and pullets
Rabbits and fur-producing animals.
A general transition period of between five and twelve years would be considered, depending on the level of ambition. Exceptions e.g., depending on farm size (number of “livestock units” where 1 livestock unit = 1 cow, or 2 pigs, or 71 laying hens) could be considered.
2) 	Banning the killing of day-old male chicks (or, as an alternative option, introducing an obligation of marking eggs from production systems where day-old chicks are killed). In the case of a ban, while a transition period of five years would be technically sufficient, notably if combined with stricter import rules, the impacts could be mitigated by introducing a ten years’ transition period.

3) 	Banning painful mutilations, i.e., beak trimming in poultry and tail docking in pigs (with incentives instead of bans as alternative options). For the bans, a general transition period of ten years has been considered. Incentives for voluntary action would enter into force immediately.
  
4) 	Animal welfare requirements at import. For animals and products of animal origin imported to the EU, either similar or fully equivalent animal welfare requirements with the revised EU animal welfare requirements for kept animals, as regards the use of cages, mutilations, space allowances, enrichment, the killing of day-old chicks and the welfare of fur animals would apply. A transition period of five-ten years has been considered.

A phase-out of the use of cages and stalls would considerably improve the welfare of more than 160 million laying hens, 53 million pullets (young hens), 13 million sows, two million calves, 35 million ducks and geese and 100 million rabbits. They would be able to perform a more natural and healthy behaviour.
A partial or total ban on cages and crates would have an important economic impact on the sectors concerned. For instance, for laying hens we have estimated the required investments for a transition into a cage-free system to about EUR 2,4-2,8 billion. For sows, the cost of demolishing the current system with gestation and farrowing crates could amount to around EUR 64-100 /m². These costs are likely to result in higher consumer prices. 
The situation however differs between Member States. Some have already taken measures to phase out cages and stalls whereas others have not. 
To mitigate these economic impacts, certain measures could be considered, notably awareness-raising vis-à-vis consumers, economic incentives via the Common Agricultural Policy and import rules to ensure a level playing field / reduce unfair competition.
The proposed measures would ensure a positive impact on sustainability as it would imply less intensive food production, causing less pollution to air and water. However, since cage-free animals move around more, they spend more energy and consume more feed. This could have a negative impact on the use of resources.

Table 1: Policy options (most cost-efficient option in terms of added value vs cost is shown in green):
| Low ambition option | Medium ambition option | High ambition option | Comments |
1.a. Crates/cages: pigs | Phase in of crate ban over 10 years. |   | Exceptions allowed for farms with less than 50 livestock units. |   | Allowing temporary confinement from 1 week before farrowing until weaning. |   | Cost-benefit analysis value (-) | Phase in of ban over 5 years. |   | Farms with less than 50 livestock units allowed to phase out crates over 15 years. |   | Temporary confinement allowed from 1 day before farrowing to 5 days post-farrowing. |   | Cost-benefit analysis value (+++) | Total ban phased in over 5 years. |   | No exceptions. |   | Cost-benefit analysis value (+) | Medium and high ambition options can be combined with stricter requirements of minimum living space per animal and/or voluntary guidance on antibiotics use. |
1.b. Crates/cages: calves | No legislative change. |   | Cost-benefit analysis (-) | Phase-out of all use of weaning crates over 10 years. |   | Ban on trade / import of calves kept crated. |   | Cost-benefit analysis (+) | Phase-out of all use of crates within 5 years. |   | Ban on trade / import of calves kept crated. |   | Cost-benefit analysis (++) | Strong public support for total ban. Low impact on food pricing. |
1.c. Cages:  laying hens and pullets | Phase in of ban over 12 years. |   | Farms with less than one hundred livestock units exempted. |   | Cost-benefit analysis (0) | Phase in of ban over 10 years. |   | Farms with less than 50 livestock units allowed to phase out cages over 12 years. |   | Cost-benefit analysis (++) | Total ban phased in over 5 years. |   | Cost-benefit analysis (+++) | Same as with pigs. |
1.d. Cages: rabbits and animals in fur production | No legislative change. |   | Cost-benefit analysis (-) | Transition phase 10 years.  |   | Cost-benefit analysis (+) | Transition phase 5 years. |   | Cost-benefit analysis (++) | Low economic impact (small sector). |
2. Killing of day-old male chickens (laying breeds) | Obligation of marking eggs from production systems applying this practice, starting as from 5 years. |   | Cost-benefit analysis: (0) | Ban of procedure within 10 years + economic incentives via the Common Agricultural Policy for farmers transitioning sooner |   | Immediate obligation of marking eggs from production systems not yet transitioned. |   | Cost-benefit analysis (++) | Phase in of ban over 5 years + stricter import rules to protect internal market |   | Cost-benefit analysis (+) | Strong public support for total ban. Strong impact on food pricing. |   | Viability dependent on development of technology to gender-identify eggs before hatching. |   | Possibility of launching consumer awareness campaigns to explain food price impacts (acceptability). |
3. Ban on painful mutilations (beak trimmings / tail cropping) | N/a | Immediate ban on cross-border trade in tail-docked pigs. |   | No ban on the procedures but economic incentives via the Common Agricultural Policy for voluntary transition. |   | Cost-benefit analysis (+) | Phase in over 10 years of total ban. |   | Cost-benefit analysis (+++) | No justification for no action. |   | Enforcement mechanism needed (inspections). |
4. Animal welfare requirements at import | No legislative change | Minimum set of rules apply for import (low- or medium ambition options). 10 years transition period. | Full EU rules to apply also for imported products. 5 years transition period. | Strong impact on competitiveness of EU farmers. Strong impact on the acceptability of other measures. | Possible difficulty of implementation. |
 

Background
Since 202X-10, EU legislation requires that laying hens be kept either in enriched cages, or alternative systems (single or multi-tier barn or, free-range). The current legislation allows calves being individually housed until the age of eight weeks, while sows and gilts are kept in confinement for a period of four weeks after service and from one week before the expected time of farrowing to weaning of their piglets. 
Approximately one million farms keep laying hens in the EU. Forty-five percent of these are kept in enriched cages. 
There is currently a trend towards using less cages in many EU Member States such as France, the Netherlands and Poland to answer to consumer’s expectations. E.g., Austria and Luxembourg have already banned the use of cages for laying hens. The animal welfare problems related to cages will however remain for many laying hens if no action is taken at EU level.

Problem drivers
Conventional livestock production systems across EU countries are put under pressure by competitive global markets, a rise in input costs and the search for maximum profit margins by farmers and all food business operators along the production chain. The demand of certain consumers’ segments for low price food is expected to be more prevalent in the current inflationary context.
This pressure over production costs has led to further intensification (and specialisation) of the farming and killing practices, as business operators increase the volume of production to reduce overheads costs per livestock unit. Evidence shows that, while the number of livestock farms is decreasing, their size is increasing. Small farms are replaced by very large industrial scale installations.
This trend has led to certain detrimental effects on animal welfare due to high densities, certain management practices, housing/transport conditions and stunning methods, as well as due to certain breeding strategies.
Current EU rules also do not consider new scientific evidence and huge technological developments in relation to agricultural practices, zootechnics and transport operations. For instance, this new scientific evidence relates to a new understanding of stocking densities, behaviour (need for an enriched environment), mutilation practices, journey times and space allowances for animal transports, and stunning methods used for pigs, poultry, and farmed fish.
The lack of update of the EU animal welfare legislation has led Member States to adopt an increasing number of national measures going beyond EU minimum requirements to respond to the growing citizens’ concerns towards animal welfare, leading to a fragmented legal landscape, including as regards animal welfare labelling.
At the same time, consumers are growing more aware and more demanding. The upward trend of societal demands for better animal welfare protection is not reflected in the current legislative requirements. 

Figure 1: Problem tree 

Economic and environmental impacts of the preferred package of options: cages for laying hens
The policy option assessed to be most cost-efficient is a total prohibition on the use of cages for laying hens with a transition period of 5 years (from the date of entry into force of the revised legislation).
However, if no similar requirements apply for eggs and egg products imported into the EU from third countries, since the EU consumers’ demand for eggs is not expected to decrease and since EU production is expected to decrease, an increase in eggs obtained from caged hens imported from non-EU countries with lower standards is expected, thus limiting the positive animal welfare impact of the measure.
The required investments for a transition into a cage-free system for laying hens would amount to around EUR 2,4-2,8 billion.
A prohibition of cages would decrease the number of laying hens by an estimated 30% (i.e., from 186,8 million to 102,9 million) in farms which currently have cage systems.

SME’s
Small farms tend to use cage-free systems more than big farms. A prohibition would therefore primarily have a positive competitiveness impact on small farms.

Public authorities
It is likely that a prohibition would generate additional enforcement costs in the short term for the national competent authorities, however these will come back to current levels in the medium term.

Consumers
A prohibition would lead to an expected increase in the price of eggs, but to which extent is not clear. Some estimates by the EU poultry industry suggest a + 20% price gap between eggs from cages and those from barn systems. However, sales data from the Netherlands and Germany suggests a much smaller difference in prices: less than one eurocent per egg.
With an average per capita consumption of 210 eggs per year, or 4,04 eggs per week, this would mean that transitioning to cage-free systems would add less than four eurocents per person to consumers’ weekly food shopping bill. Furthermore, the experience from Germany, where enriched cages are progressively phased out, even suggests that the price for barn eggs may eventually be the same as for eggs from enriched cages.
 
Environmental impacts
A prohibition would have a positive impact on sustainability as it would imply less intensive production leading to less air and water pollution and less greenhouse gas emissions.



Attachment 11: Website

| A gestation crate, also known as a sow stall, is a metal enclosure in which a   used for breeding may be kept during pregnancy. A standard crate measures 2 m x 60 cm. | Sow stalls contain no bedding material and are instead floored with slatted plastic, concrete, or metal to allow waste to be efficiently collected below. This waste is then flushed into open-air pits known as . A few days before giving birth (farrowing), sows are moved to farrowing crates where they are able to lie down, with an attached crate from which their piglets can nurse. | Most pregnant sows in the US are kept in gestation crates. The crates are banned for new installations in Austria and Canada, but many sows are still confined there in pig breeding facilities. The crates are banned in the United Kingdom, Canada, Switzerland, and Sweden. However, farrowing crates, in which female breeding pigs can be kept for up to five weeks, are not banned in the UK. | Opponents of the crates argue that they constitute animal abuse, while proponents say they are needed to prevent sows from fighting among themselves. |




Attachment 12: Website



Page contents |  | Submission and examination |  |  | Submission and examination | The  initiative was submitted to the Commission on 2 October 202X-3, having gathered 1,397,113 statements of support. See . | The organisers met with the Commissioner for Health and Food Safety, Stella Kyriakides on 30 October 202X-3. | A  took place at the European Parliament on 25 January 202X-2. See . | The initiative was debated at the European Parliament’s plenary session on 20 February 202X-2. In the  adopted on the same day, the European Parliament expressed its strong support for the initiative. See European Parliament’s . | Answer of the European Commission | In its response on 4 April 202X-2, the Commission commits to table, by the end of 202X, a legislative proposal to phase out, and finally prohibit, the use of cage systems for all animals mentioned in the initiative. | In parallel to the legislation and to facilitate a balanced and economically viable transition to cage-free farming, the Commission will seek specific supporting measures in key related policy areas, such as trade and research and innovation.  | In particular, the new Common Agricultural Policy will provide financial support and incentives – such as the new eco-schemes instrument – to help farmers upgrade to more animal-friendly facilities in line with the new standards. |



Attachment 13: News article



 -  -  
Health and food safety Commissioner will fight for ethical food systems in Europe
30 October 202X-3
Earlier today, Commissioner Kyriakides met with the representatives of the citizens’ initiative ‘End the Cage Age’. EURACTIV interviewed the Commissioner after her meeting with the campaign team.
Stella Kyriakides is European Commissioner for Health and Food Safety and in charge of the EU animal welfare legislation. She spoke to EURACTIV about the call for revised animal welfare legislation and the possibility for action ahead.
This is one of the most strongly supported citizens’ initiatives so far with almost 1.4 million signatures collected. How will the Commission respond to all who signed this petition?
I am impressed by the hard work by these dedicated young people. I promised them today that the Commission will investigate this very carefully.
In fact, we recently completed a review of our legislation and have found that there is indeed scope for improvement. However, first we will hear the views of the European Parliament and we will consult across the Commission services and then reply about next steps.
Your colleague, the Commissioner for Agriculture, is less enthusiastic. How will you get the farming community onboard?
As always, there will be a balancing act between several interests. Farmers produce the food we eat and they deserve to be heard as well. Many farmers also already made this transition, showing it is possible to rear animals cage-free.
The Commission always performs a thorough impact assessment, so any legislative proposal will be based on solid facts and on careful consideration of all relevant impacts. We always seek a sustainable compromise.
There could also be other possibilities to make animal welfare more attractive for farmers by e.g., economic incentives, subsidies, trade schemes and awareness campaigns. It is not just about laws and penalties.
On the other hand, I think the farming industry has known for a long time that this is coming, they have had plenty of time to prepare and many Member States have in fact already taken significant steps in the direction of free-range animal rearing.
But is there not a risk that ‘money will talk’, how can you weigh the economic impacts against animal suffering – how will the comparison be done in an impact assessment?
No, economic interests are not the only interests we take into account. It is true that our assessment is expressed as a cost-benefit ratio, but among those ‘benefits’, we consider also softer values such as social, health and environmental impacts – and ethical choices. I guarantee you that industry interests will not dominate this process. 
On the contrary, I think what we see here is a strong message from European citizens that animal rights and animal welfare must be respected, and I agree with them. We cannot ignore this question any longer.",28,6.0,"Summary

According to the Notice of Competitions of current EPSO competitions, the only competency that will be assessed in the Case Study exam is Written Communication",6.0,"Observations

The candidate has identified the main areas of concern and has done a commendable job in structuring the information clearly.
 
I would have preferred to see a more detailed introduction and background section, as well as a section that dealt with the main issues. This could have immediately flagged the problem with DG AGRI and clearly listed the main issues that the legislative proposal includes.
E.g.,
The legislative proposal includes new or stricter rules in four areas: 
1.	restricting the use of cages/crates;
2.	ending the killing of day-old male chickens;
3.	banning painful and unnecessary mutilations; and
4.	setting animal welfare requirements at import.

In the policy recommendations section, some more detailed information could have been useful. 

E.g., The timing for bans were subject to being based on low, medium or high ambition options for each measure, so perhaps briefly mentioning these would aid the reader in grasping the issue more fully. It would also enable you to refer to these later on when weighing which option could lead to DG AGRI’s positive response.

Although there is concrete data to back up the arguments against the recommended policies, there is a lack of hard numbers for the arguments in favour. This makes it difficult to convey why the policies should be followed. 
E.g.:
- Perhaps mention that the impact assessment shows a lower price impact than what DG AGRI claims. 
- Also, could expand by explaining that it is not the main issue for small farmers, as cage rearing is mostly done by large-scale industrial farms. 
- Additionally, that for several member states, the cage ban will make no difference as they have already adopted the ban with national legislation. The cage ban therefore helps create a more level playing field. 

Could have also included more concrete options for the way forward in reaching an agreement with DG AGRI.

E.g.: Compromise on cage ban or compromise on import rules. Could more fully analyse the reasoning for each option and add suggestions that lead to a solution, such as accept the high-ambition proposal on laying hen cages in exchange for increasing the level of ambition in terms of the export rules (full alignment with EU rules also for third countries).

Overall, there is a tendency to veer towards being too concise, to the detriment of strengthening the arguments and proposals.

There are some grammatical issues that slightly impact the readability of the document.",,"Tips to Improve

Ensure you have an impactful introduction and conclusion/summary. 

Ensure enough time to proofread for grammar issues and typos.

Ensure that arguments are fully explored from all viewpoints relevant to the briefing. 

Explore key issues without the tendency to generalize and provide relevant data to back up arguments.","Trainee's Answer
Note to the Director - General Ms. Heinrich
                                                                                                                                     
 
         Thursday, 1 June 202X
 
 
Subject: Animal welfare regulation state of the play and way forward
 
This note aims to describe the state of the play of the animal welfare regulation, provide arguments in favour and against the different policies options and suggest the way forward for the DG.
1. STATE OF THE PLAY OF ANIMAL WELFARE, CHALLENGES AND LEGAL LANDSCAPE
1.1. Drivers to the current animal welfare problems
Different drivers are involved compromising the animal welfare, such as pressure to reduce production costs, lack of incentives to invest, outdated legislation and fragmented legal landscape. All these factors influence the current problems of animal welfare, such as harmful practices and stunning methods for animals, excess of breeding, lack of monitoring and enforcement. Consequently, animal welfare are compromised with a negative impact on the single market.
Last but not least, societal demands are not met, with citizens concerns increasing on ethics and sustainability of animals.
 1.2. Legal landscape
On the legal landscape, the actual legislation requires laying hens be kept either in enriches caes, or alternative systems. The current legislation allows calves being individually housed, while sows and gilts are kept in confinement. There is a trend towards using less cages in many EU Member States (MS), while others have already banned the use of cages. In the current scenario, if no action is taken at EU level, the animal welfare problems related to cages will remain.
Two years ago, the EP (European Parliament) voted on a resolution recommending a total ban on the use of cages in animals by 202x=3. As stated by Commissioner Kyriakides, the phase-out would happen ""as soon as feasible"". To make this happen, we propose the following policy options following the economic and environmental impact of the banning.
2. WAY FORWARD
2. 1. Policies recommended
Following an impact assessment including cost-efficiency, environmental and societal impacts and impacts on the single market. The most cost-efficient options have been suggested which range from high to medium ambition options, namely:
- phasing out confining ages/crates in over five years for pigs, calves, laying hens, pullets and rabbits.This transition period would be from the date of entry into force of the revised legislation.
- phasing out within 10 years: killing of day-old male chickens, painful mutilations, animal welfare requirements at import.
2.2. Arguments in favour of the recommended policies
Two main arguments in favour of these policy recommendations. First, they are the most positive in terms of cost-efficiency as per the risk assessment. Also from the risk assessment, it must be highligted that these policies are between the high-medium level of ambition.
Secondly, another positive impact would be on the environmental side, since less intensive production would lead to less air and water pollution and less greenhouse gass emissions. 
Another report quantifying the cost-efficiency and environmental aspects of the recommended policies is being developed, jointly with the other DGs working on the file.
On a separate note, all DGs are in favour of these policy recommendations, except DG AGRI, therefore, an action plan to continue the negotiations with DG AGRI is being developed, jointly with the rest of the agreeing DGs.
2.3. Arguments against the recommended policies
The main caveats against these policy options are:
-  if no similar requirement apply for eggs and egg products imported into the EU, an increase in eggs obtained from caged hens imported from non-EU cuntries is expected, thus limiting the positive animal welfare impact of the measure.
- this prohibition of cages would decrease the number of laying hens by an estimated 30% (from 186,8 to 102,9 million).
- the required investment for a transition to a cage-free system for laying hens would be 2,4-2,8  billion Euros.
- the price of eggs would increase for consumers (up to a 20% difference in some sales data, to be further analyzed).
2.4. Way forward
Based on the technical analyses conducted, we strongly recommend the policies options above, since the environmental and cost-efficiency reasons seem to be solid and count with the public opinion.
This recommendation prevails if we look at the negotiations performed with the other DGs. With most of DGs being in favour of these policy recommendations. Regarding the different point of view of DG AGRI, an action plan to continue the negotiations with DG AGRI will be drafted this week jointly with the rest of the agreeing DGs. 
Once we have your opinion on this proposition, we would be able to timely move ahead with the required actions (which include the discussions with DG AGRI)."
3,0_Generative AI (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. 

Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG CONNECT in the unit in charge of fighting against disinformation.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Critical thinking, analysing & creative problem-solving, Decision-making and getting results, Information management,  Communication.

Specifically, your task will be to draft a 2 to 2.5 - page speaking note for the Commisioner to clarify the intentions of the Commission with respect to generative AI (GAI). This document must include: 

What is GAI and what are the potential benefits.
What are the dangers associated with GAI and how does the EU want to address them.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations

AI - Artificial intelligence
AIA – Artificial Intelligence Act
AGI - Artificial general intelligence 
ANI - Artificial narrow intelligence
ANN - Artificial neural network
DSA – Digital Services Act
GAI – Generative AI
ML - Machine learning
NLP - Natural language processing


EMAIL 1","Subject: Press Release on generative AI

Dear YOU,

Earlier today, Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton met with representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation.
Jourová asked the signatories to create a dedicated and separate track within the code to deal with disinformation generated by Artificial Intelligence. It should aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them. 
Jourová will present her initiative at a press point tomorrow at 11:15 a.m. so could you prepare her talking points and send them to me this evening before closing of the office hours. She has asked to stress the importance of the fight against disinformation in the context of defending democracy and the EU values. 

Many thanks",",

Charles
Head of Unit





What are the most pressing dangers of AI?
As AI systems prove to be increasingly beneficial in real-world applications, they have broadened their reach, causing risks of misuse, overuse, and explicit abuse to proliferate. As AI systems increase in capability and as they are integrated more fully into societal infrastructure, the implications of losing meaningful control over them become more concerning. New research efforts are aimed at re-conceptualizing the foundations of the field to make AI systems less reliant on explicit, and easily mis specified, objectives. A particularly visible danger is that AI can make it easier to build machines that can spy and even kill at scale. But there are many other important and subtler dangers at present.
Techno-Solutionism
One of the most pressing dangers of AI is techno-solutionism, the view that AI can be seen as a panacea when it is merely a tool. As we see more AI advances, the temptation to apply AI decision-making to all societal problems increases. But technology often creates larger problems in the process of solving smaller ones. For example, systems that streamline and automate the application of social services can quickly become rigid and deny access to migrants or others who fall between the cracks. 
When given the choice between algorithms and humans, some believe algorithms will always be the less-biased choice. Yet, in 2018, Amazon found it necessary to discard a proprietary recruiting tool because the historical data it was trained on resulted in a system that was systematically biased against women. Automated decision-making can often serve to replicate, exacerbate, and even magnify the same bias we wish it would remedy.
Indeed, far from being a cure-all, technology can actually create feedback loops that worsen discrimination. Recommendation algorithms, like Google’s page rank, are trained to identify and prioritize the most “relevant” items based on how other users engage with them. As biased users feed the algorithm biased information, it responds with more bias, which informs users’ understandings and deepens their bias, and so on. Because all technology is the product of a biased system, techno-solutionism’s flaws run deep: a creation is limited by the limitations of its creator.
Dangers of Adopting a Statistical Perspective on Justice
Automated decision-making may produce skewed results that replicate and amplify existing biases. A potential danger, then, is when the public accepts AI-derived conclusions as certainties. This determinist approach to AI decision-making can have dire implications in both criminal and healthcare settings. AI-driven approaches like PredPol, software originally developed by the Los Angeles Police Department and UCLA that purports to help protect one in 33 US citizens, predict when, where, and how crime will occur. A 2016 case study of a US city noted that the approach disproportionately projected crimes in areas with higher populations of non-white and low-income residents. When datasets disproportionately represent the lower power members of society, flagrant discrimination is a likely result.
Sentencing decisions are increasingly decided by proprietary algorithms that attempt to assess whether a defendant will commit future crimes, leading to concerns that justice is being outsourced to software. As AI becomes increasingly capable of analyzing more and more factors that may correlate with a defendant's perceived risk, courts and society at large may mistake an algorithmic probability for fact. This dangerous reality means that an algorithmic estimate of an individual’s risk to society may be interpreted by others as a near certainty—a misleading outcome even the original tool designers warned against. Even though a statistically driven AI system could be built to report a degree of credence along with every prediction, there’s no guarantee that the people using these predictions will make intelligent use of them. Taking probability for certainty means that the past will always dictate the future.
There is an aura of neutrality and impartiality associated with AI decision-making in some corners of the public consciousness, resulting in systems being accepted as objective even though they may be the result of biased historical decisions or even blatant discrimination. All data insights rely on some measure of interpretation. As a concrete example, an audit of a resume-screening tool found that the two main factors it associated most strongly with positive future job performance were whether the applicant was named Jared, and whether he played high school lacrosse. Undesirable biases can be hidden behind both the opaque nature of the technology used and the use of proxies, nominally innocent attributes that enable a decision that is fundamentally biased. An algorithm fueled by data in which gender, racial, class, and ableist biases are pervasive can effectively reinforce these biases without ever explicitly identifying them in the code. 
Without transparency concerning either the data or the AI algorithms that interpret it, the public may be left in the dark as to how decisions that materially impact their lives are being made. Lacking adequate information to bring a legal claim, people can lose access to both due process and redress when they feel they have been improperly or erroneously judged by AI systems. Large gaps in case law make applying Title VII—the primary existing legal framework in the US for employment discrimination—to cases of algorithmic discrimination incredibly difficult. These concerns are exacerbated by algorithms that go beyond traditional considerations such as a person’s credit score to instead consider any and all variables correlated to the likelihood that they are a safe investment. A statistically significant correlation has been shown among Europeans between loan risk and whether a person uses a Mac or PC and whether they include their name in their email address—which turn out to be proxies for affluence. Companies that use such attributes, even if they do indeed provide improvements in model accuracy, may be breaking the law when these attributes also clearly correlate with a protected class like race. Loss of autonomy can also result from AI-created “information bubbles” that narrowly constrict each individual’s online experience to the point that they are unaware that valid alternative perspectives even exist.
Disinformation and Threat to Democracy
AI systems are being used in the service of disinformation on the internet, giving them the potential to become a threat to democracy and a tool for fascism. From deepfake videos to online bots manipulating public discourse by feigning consensus and spreading fake news, there is the danger of AI systems undermining social trust. The technology can be co-opted by criminals, rogue states, ideological extremists, or simply special interest groups, to manipulate people for economic gain or political advantage. Disinformation poses serious threats to society, as it effectively changes and manipulates evidence to create social feedback loops that undermine any sense of objective truth. The debates about what is real quickly evolve into debates about who gets to decide what is real, resulting in renegotiations of power structures that often serve entrenched interests. 
Discrimination and Risk in the Medical Setting
While personalized medicine is a good potential application of AI, there are dangers. Current business models for AI-based health applications tend to focus on building a single system—for example, a deterioration predictor—that can be sold to many buyers. However, these systems often do not generalize beyond their training data. Even differences in how clinical tests are ordered can throw off predictors, and, over time, a system’s accuracy will often degrade as practices change. Clinicians and administrators are not well-equipped to monitor and manage these issues, and insufficient thought given to the human factors of AI integration has led to oscillation between mistrust of the system (ignoring it) and over-reliance on the system (trusting it even when it is wrong), a central concern of the 2016 AI100 report.
These concerns are troubling in general in the high-risk setting that is healthcare, and even more so because marginalized populations—those that already face discrimination from the health system from both structural factors (like lack of access) and scientific factors (like guidelines that were developed from trials on other populations)—may lose even more. Today and in the near future, AI systems built on machine learning are used to determine post-operative personalized pain management plans for some patients and in others to predict the likelihood that an individual will develop breast cancer. AI algorithms are playing a role in decisions concerning distributing organs, vaccines, and other elements of healthcare. Biases in these approaches can have literal life-and-death stakes.
In 2019, the story broke that Optum, a health-services algorithm used to determine which patients may benefit from extra medical care, exhibited fundamental racial biases. The system designers ensured that race was precluded from consideration, but they also asked the algorithm to consider the future cost of a patient to the healthcare system. While intended to capture a sense of medical severity, this feature in fact served as a proxy for race: controlling for medical needs, care for Black patients averages $1,800 less per year.
New technologies are being developed every day to treat serious medical issues. A new algorithm trained to identify melanomas was shown to be more accurate than doctors in a recent study, but the potential for the algorithm to be biased against Black patients is significant as the algorithm was trained using majority light-skinned groups. The stakes are especially high for melanoma diagnoses, where the five-year survival rate is 17 percentage points less for Black Americans than white. While technology has the potential to generate quicker diagnoses and thus close this survival gap, a machine-learning algorithm is only as good as its data set. An improperly trained algorithm could do more harm than good for patients at risk, missing cancers altogether or generating false positives. As new algorithms saturate the market with promises of medical miracles, losing sight of the biases ingrained in their outcomes could contribute to a loss of human biodiversity, as individuals who are left out of initial data sets are denied adequate care. While the exact long-term effects of algorithms in healthcare are unknown, their potential for bias replication means any advancement they produce for the population in aggregate—from diagnosis to resource distribution—may come at the expense of the most vulnerable.








Regulatory framework proposal on artificial intelligence 
The Commission is proposing the first-ever legal framework on AI, which addresses the risks of AI and positions Europe to play a leading role globally. 

© gorodenkoff - iStock Getty Images Plus
The regulatory proposal aims to provide AI developers, deployers and users with clear requirements and obligations regarding specific uses of AI. At the same time, the proposal seeks to reduce administrative and financial burdens for business, in particular small and medium-sized enterprises (SMEs).
The proposal is part of a wider AI package, which also includes the updated Coordinated Plan on AI. Together, the Regulatory framework and Coordinated Plan will guarantee the safety and fundamental rights of people and businesses when it comes to AI. And they will strengthen uptake, investment and innovation in AI across the EU.
Why do we need rules on AI?
The proposed AI regulation ensures that Europeans can trust what AI has to offer. While most AI systems pose limited to no risk and can contribute to solving many societal challenges, certain AI systems create risks that we must address to avoid undesirable outcomes.
For example, it is often not possible to find out why an AI system has made a decision or prediction and taken a particular action. So, it may become difficult to assess whether someone has been unfairly disadvantaged, such as in a hiring decision or in an application for a public benefit scheme.
Although existing legislation provides some protection, it is insufficient to address the specific challenges AI systems may bring.
The proposed rules will:
address risks specifically created by AI applications.
propose a list of high-risk applications.
set clear requirements for AI systems for high-risk applications.
define specific obligations for AI users and providers of high-risk applications.
propose a conformity assessment before the AI system is put into service or placed on the market.
propose enforcement after such an AI system is placed in the market.
propose a governance structure at European and national level.
A risk-based approach

The Regulatory Framework defines 4 levels of risk in AI:
Unacceptable risk
High risk
Limited risk
Minimal or no risk
Unacceptable risk
All AI systems considered a clear threat to the safety, livelihoods and rights of people will be banned, from social scoring by governments to toys using voice assistance that encourages dangerous behaviour.
High risk
AI systems identified as high-risk include AI technology used in:
critical infrastructures (e.g., transport), that could put the life and health of citizens at risk.
educational or vocational training, that may determine the access to education and professional course of someone’s life (e.g., scoring of exams).
safety components of products (e.g., AI application in robot-assisted surgery).
employment, management of workers and access to self-employment (e.g., CV-sorting software for recruitment procedures).
essential private and public services (e.g., credit scoring denying citizens opportunity to obtain a loan).
law enforcement that may interfere with people’s fundamental rights (e.g., evaluation of the reliability of evidence).
migration, asylum, and border control management (e.g., verification of authenticity of travel documents).
administration of justice and democratic processes (e.g., applying the law to a concrete set of facts).
High-risk AI systems will be subject to strict obligations before they can be put on the market:
adequate risk assessment and mitigation systems.
high quality of the datasets feeding the system to minimize risks and discriminatory outcomes.
logging of activity to ensure traceability of results.
detailed documentation providing all information necessary on the system and its purpose for authorities to assess its compliance.
clear and adequate information to the user.
appropriate human oversight measures to minimize risk.
high level of robustness, security and accuracy.
All remote biometric identification systems are considered high risk and subject to strict requirements. The use of remote biometric identification in publicly accessible spaces for law enforcement purposes is, in principle, prohibited.
Narrow exceptions are strictly defined and regulated, such as such as when necessary to search for a missing child, to prevent a specific and imminent terrorist threat or to detect, locate, identify, or prosecute a perpetrator or suspect of a serious criminal offence.
Such use is subject to authorization by a judicial or other independent body and to appropriate limits in time, geographic reach and the data bases searched.
Limited risk
Limited risk refers to AI systems with specific transparency obligations. When using AI systems such as chatbots, users should be aware that they are interacting with a machine so they can take an informed decision to continue or step back.
Minimal or no risk
The proposal allows the free use of minimal-risk AI. This includes applications such as AI-enabled video games or spam filters. Most AI systems currently used in the EU fall into this category.



How does it all work in practice for providers of high-risk AI systems?
Once an AI system is on the market, authorities oversee market surveillance, users ensure human oversight and monitoring, and providers have a post-market monitoring system in place. Providers and users will also report serious incidents and malfunctioning.
Future-proof legislation
As AI is a fast-evolving technology, the proposal has a future-proof approach, allowing rules to adapt to technological change. AI applications should remain trustworthy even after they have been placed on the market. This requires ongoing quality and risk management by providers.




The 5 biggest risks of generative AI, according to an expert 
AI makes our lives easier in many different ways. However, these benefits can come with costs. 



Written by Sabrina Ortiz, Associate Editor on April 25, 20XX

Generative AIs, such as ChatGPT, have revolutionized how we interact with and view AI. Activities like writing, coding, and applying for jobs have become much easier and quicker. With all the positives, however, there are some pretty serious risks.
A major concern with AI is trust and security, which has even caused some countries to completely ban ChatGPT as a whole or to reconsider policy around AI to protect users from harm. 
According to Gartner analyst Avivah Litan, some of the biggest risks of generative AI concern trust and security and include hallucinations, deepfakes, data privacy, copyright issues, and cybersecurity problems.
1. Hallucinations
Hallucinations refer to the errors that AI models are prone to make because, although they are advanced, they are still not human and rely on training and data to provide answers. 
If you've used an AI chatbot, then you have probably experienced these hallucinations through a misunderstanding of your prompt or a blatantly wrong answer to your question.
Litan says the training data can lead to biased or factually incorrect responses, which can be a serious problem when people are relying on these bots for information. 
""Training data can lead to biased, off base or wrong responses, but these can be difficult to spot, particularly as solutions are increasingly believable and relied upon,"" says Litan. 
2. Deepfakes
A deepfake uses generative AI to create videos, photos, and voice recordings that are fake but take the image and likeness of another individual. 
Perfect examples are the AI-generated viral photo of Pope Francis in a puffer jacket or the AI-generated Drake and the Weeknd song, which garnered hundreds of thousands of streams. 
""These fake images, videos and voice recordings have been used to attack celebrities and politicians, to create and spread misleading information, and even to create fake accounts or take over and break into existing legitimate accounts,"" says Litan. 
Like hallucinations, deepfakes can contribute to the massive spread of fake content, leading to the spread of misinformation, which is a serious societal problem. 
3. Data privacy
Privacy is also a major concern with generative AI since user data is often stored for model training. This concern was the overarching factor that pushed Italy to ban ChatGPT, claiming OpenAI was not legally authorized to gather user data. 
""Employees can easily expose sensitive and proprietary enterprise data when interacting with generative AI chatbot solutions,"" says Litan. ""These applications may indefinitely store information captured through user inputs, and even use information to train other models -- further compromising confidentiality.""
Litan highlights that, in addition to compromising user confidentiality, the stored information also poses the risk of ""falling into the wrong hands"" in an instance of a security breach.
4. Cybersecurity
The advanced capabilities of generative AI models, such as coding, can also fall into the wrong hands, causing cybersecurity concerns.
""In addition to more advanced social engineering and phishing threats, attackers could use these tools for easier malicious code generation,"" says Litan. 
Litan says even though vendors who offer generative AI solutions typically assure customers that their models are trained to reject malicious cybersecurity requests, these suppliers don't equip end users with the ability to verify all the security measures that have been implemented. 
5. Copyright issues
Copyright is a big concern because generative AI models are trained on massive amounts of internet data that is used to generate an output. 
This process of training means that works that have not been explicitly shared by the original source can then be used to generate new content. 
Copyright is a particularly thorny issue for AI-generated art of any form, including photos and music. 
To create an image from a prompt, AI-generating tools, such as DALL-E, will refer back to the large database of photos they were trained on. The result of this process is that the final product might include aspects of an artist's work or style that are not attributed to them. 
Since the exact works that generative AI models are trained on are not explicitly disclosed, it is hard to mitigate these copyright issues. 
What's next?
Despite the many risks associated to generative AI, Litan doesn't think that organizations should stop exploring the technology. Instead, they should create an enterprise-wide strategy that targets AI trust, risk, and security management. 
""AI developers must urgently work with policymakers, including new regulatory authorities that may emerge, to establish policies and practices for generative AI oversight and risk management,"" says Litan. 
 

What is generative AI?
In simple terms, generative AI is a subfield of artificial intelligence in which computer algorithms are used to generate outputs that resemble human-created content, be it text, images, graphics, music, computer code or otherwise.
In generative AI, algorithms are designed to learn from training data that includes examples of the desired output. By analyzing the patterns and structures within the training data, generative AI models can produce new content that shares characteristics with the original input data. In doing so, generative AI has the capacity to generate content that appears authentic and human-like.
How does generative AI work?
Generative AI is based on machine learning processes inspired by the inner workings of the human brain, known as neural networks. Training the model involves feeding algorithms large amounts of data, which serves as the foundation for the AI model to learn from. This can consist of text, code, graphics, or any other type of content relevant to the task at hand.
Once the training data has been collected, the AI model analyzes the patterns and relationships within the data to understand the underlying rules governing the content. The AI model continuously fine-tunes its parameters as it learns, improving its ability to simulate human-generated content. The more content the AI model generates, the more sophisticated and convincing its outputs become.
Examples of generative AI
Generative AI has made significant advancements in recent years, with several tools capturing the public attention and creating a stir amongst content creators. Big tech companies have also jumped on the bandwagon, with Google, Microsoft, Amazon, and others all lining up their own generative AI tools.
Depending on the application, generative AI tools may rely on an input prompt that guides it towards producing a desired outcome — think ChatGPT and DALL-E 2.
Some of the most notable examples of generative AI tools include:
ChatGPT: Developed by OpenAI, ChatGPT is an AI language model that can generate human-like text based on given prompts.
DALL-E 2: Another generative AI model from OpenAI, DALL-E is designed to create images and artwork based on text-based prompts.
Midjourney: Developed by San Francisco-based research lab Midjourney Inc., Midjourney interprets text prompts and context to produce visual content, like DALL-E 2.
GitHub Copilot: An AI-powered coding tool created by GitHub and OpenAI, GitHub Copilot suggests code completions for users of development environments like Visual Studio and JetBrains.
Benefits of generative AI
The most compelling advantage generative AI proposes is efficiency, in that it can enable businesses to automate specific tasks and focus their time, energy and resources on more important strategic objectives. This often results in lower labor costs and an increase in operational efficiency.
Generative AI can offer additional advantages to businesses and entrepreneurs, including:
Easily customizing or personalizing marketing content.
Generating new ideas, designs, or content.
Writing, checking, and optimizing computer code.
Drafting templates for essays or articles.
Enhancing customer support with chatbots and virtual assistants.
Facilitating data augmentation for machine learning models.
Analyzing data to improve decision-making.
Streamlining research and development processes.
Use cases of generative AI
Despite generative AI still being in its relative infancy, the technology has already found a firm foothold in various applications and industries.
In content creation, for instance, generative AI can produce text, images and even music, assisting marketers, journalists, and artists with their creative processes. In customer support, AI-driven chatbots and virtual assistants can provide more personalized assistance and reduce response times while reducing the burden on customer service agents.
Other uses of generative AI include:
Healthcare: Generative AI is used in medicine to accelerate the discovery of novel drugs, saving time and money in research.
Marketing: Advertisers use generative AI to craft personalized campaigns and adapt content to consumers’ preferences.
Education: Some educators use generative AI models to develop customized learning materials and assessments that cater to students’ individual learning styles.
Finance: Financial analysts use generative AI to examine market patterns and predict stock market trends.
Environment: Climate scientists employ generative AI models to predict weather patterns and simulate the effects of climate change.
Dangers and limitations of generative AI
It’s important to note that generative AI presents numerous issues requiring attention. One major concern is its potential for spreading misinformation or malicious or sensitive content, which could cause profound damage to people and businesses — and potentially pose a threat to national security.
These risks have not escaped policymakers. In April 20XX, the European Union proposed new copyright rules for generative AI that would require companies to disclose any copyrighted material used to develop these tools. Hopes are that such rules will encourage transparency and ethics in AI development, while minimizing any misuse or infringement of intellectual property. This should also offer some protection to content creators whose work may be unwittingly mimicked or plagiarized by generative AI tools.
The automation of tasks by generative AI could also affect the workforce and contribute to job displacement, requiring impacted employees to reskill or upskill. Additionally, generative AI models can unintentionally learn and amplify biases present in training data, leading to problematic outputs that perpetuate stereotypes and harmful ideologies.
ChatGPT, Bing AI and Google Bard have all drawn controversy for producing incorrect or harmful outputs since their launch, and these concerns must be addressed as generative AI evolves, particularly given the difficulty of scrutinizing the sources used to train AI models.
Generative AI vs. general AI
Generative AI and general AI represent different aspects of artificial intelligence. Generative AI focuses on creating new content or ideas based on existing data. It has specific applications and is a subset of AI that excels at solving particular tasks.
General AI, also known as artificial general intelligence, broadly refers to the concept of AI systems that possess human-like intelligence. General AI is still the stuff of science fiction; it represents an imagined future stage of AI development in which computers are able to think, reason and act autonomously.
Is generative AI the future?
It depends on who you ask, but many experts believe that generative AI has a significant role to play in the future of various industries. The capabilities of generative AI have already proven valuable in areas like content creation, software development and healthcare, and as the technology continues to evolve, so too will its applications and use cases.
That said, the future of generative AI is inextricably tied to addressing the potential risks it presents. Ensuring AI is used ethically by minimizing biases, enhancing transparency and accountability and upholding data governance will be critical as the technology progresses. At the same time, striking a balance between automation and human involvement will be crucial for maximizing the benefits of generative AI while mitigating any potential negative consequences on the workforce.






STOCKHOLM, April 27 (Reuters) - Companies deploying generative AI tools, such as ChatGPT, will have to disclose any copyrighted material used to develop their systems, according to an early EU agreement that could pave the way for the world's first comprehensive laws governing the technology.
The European Commission began drafting the AI Act nearly two years ago to regulate emerging artificial intelligence technology, which underwent a boom in investment and popularity following the release of OpenAI's AI-powered chatbot ChatGPT.
Members of the European Parliament agreed to push the draft through to the next stage, the trilogue, during which EU lawmakers and member states will thrash out the final details of the bill.
Under the proposals, AI tools will be classified according to their perceived risk level: from minimal through to limited, high, and unacceptable. Areas of concern could include biometric surveillance, spreading misinformation or discriminatory language.
While high-risk tools will not be banned, those using them will need to be highly transparent in their operations.
Companies deploying generative AI tools, such as ChatGPT or image generator Midjourney, will also have to disclose any copyrighted material used to develop their systems.
This provision was a late addition drawn up within the past two weeks, according to a source familiar with discussions. Some committee members initially proposed banning copyrighted material being used to train generative AI models altogether, the source said, but this was abandoned in favour of a transparency requirement.
""Against conservative wishes for more surveillance and leftist fantasies of over-regulation, parliament found a solid compromise that would regulate AI proportionately, protect citizens' rights, as well as foster innovation and boost the economy,"" said Svenja Hahn, a European Parliament deputy.
Macquarie analyst Fred Havemeyer said the EU's proposal was ""tactful"" rather than a ""ban first, and ask questions later"" approach proposed by some.
""The EU has been on the frontier of regulating AI technology,"" he told Reuters.
RACE TO MARKET
Microsoft-backed (MSFT.O) OpenAI provoked awe and anxiety around the world when it unveiled ChatGPT late last year. The chatbot became the fastest-growing consumer application in history, reaching 100 million monthly active users in a matter of weeks.
The ensuing race among tech companies to bring generative AI products to market concerned some onlookers, with Twitter-owner Elon Musk backing a proposal to halt development of such systems for six months. Shortly after signing the letter, the Financial Times reported Musk was planning to launch his own startup to rival OpenAI.


Sharon Goldman
@sharongoldman

December 5, 20XX-1

The hidden danger of ChatGPT and generative AI | The AI Beat
Since OpenAI launched its early demo of ChatGPT last Wednesday, the tool already has over a million users, according to CEO Sam Altman — a milestone, he points out, that took GPT-3 nearly 24 months to get to and DALL-E over 2 months. 
The “interactive, conversational model,” based on the company’s GPT-3.5 text-generator, certainly has the tech world in full swoon mode. Aaron Levie, CEO of Box, tweeted that “ChatGPT is one of those rare moments in technology where you see a glimmer of how everything is going to be different going forward.” Y Combinator cofounder Paul Graham tweeted that “clearly something big is happening.” Alberto Romero, author of The Algorithmic Bridge, calls it “by far, the best chatbot in the world.” And even Elon Musk weighed in, tweeting that ChatGPT is “scary good. We are not far from dangerously strong AI.” 
But there is a hidden problem lurking within ChatGPT: That is, it quickly spits out eloquent, confident responses that often sound plausible and true even if they are not. 
ChatGPT can sound plausible even if its output is false.
Like other generative large language models, ChatGPT makes up facts. Some call it “hallucination” or “stochastic parroting,” but these models are trained to predict the next word for a given input, not whether a fact is correct or not. 
Some have noted that what sets ChatGPT apart is that it is so darn good at making its hallucinations sound reasonable. 
Technology analyst Benedict Evans, for example, asked ChatGPT to “write a bio for Benedict Evans.” The result, he tweeted, was “plausible, almost entirely untrue.” 
More troubling is the fact that there are obviously an untold number of queries where the user would only know if the answer was untrue if they already knew the answer to the posed question. 
That’s what Arvind Narayanan, a computer science professor at Princeton, pointed out in a tweet: “People are excited about using ChatGPT for learning. It’s often very good. But the danger is that you can’t tell when it’s wrong unless you already know the answer. I tried some basic information security questions. In most cases the answers sounded plausible but were in fact BS.” 
Fact-checking generative AI
Back in the waning days of print magazines in the 2000s, I spent several years as a fact-checker for publications including GQ and Rolling Stone. Each fact had to include authoritative primary or secondary sources — and Wikipedia was frowned upon. 
Few publications have staff fact-checkers anymore, which puts the onus on reporters and editors to make sure they get their facts straight — especially at a time when misinformation already moves like lightning across social media, while search engines are constantly under pressure to surface verifiable information and not BS. 
That’s certainly why Stack Overflow, the Q&A site for coders and programmers, has temporarily banned users from sharing ChatGPT responses. 
And if StackOverflow can’t keep up with misinformation due to AI, it’s hard to imagine others being able to manage a tsunami of potential AI-driven BS. As Gary Marcus tweeted, “If StackOverflow can’t keep up with plausible but incorrect information, what about social media and search engines?” 
And while many are salivating at the idea that LLMs like ChatGPT could someday replace traditional search engines, others are strongly pushing back. 
Emily Bender, professor of linguistics at the University of Washington, has long pushed back on this notion. 
She recently emphasized again that LLMs are “not fit” for search —” both because they are designed to just make sh** up and because they don’t support information literacy.” She pointed to a paper she co-authored on the topic published in March. 
Is it better for ChatGPT to look right? Or be right? 
BS is obviously something that humans have perfected over the centuries. And ChatGPT and other large language models have no idea what it means, really, to “BS.” But OpenAI made this weakness very clear in its blog announcing the demo and explained that fixing it is “challenging,” saying: 
“ChatGPT sometimes writes plausible sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: (1) during RL [reinforcement learning] training, there’s currently no source of truth; (2) training the model to be more cautious causes it to decline questions that it can answer correctly; and (3) supervised training misleads the model because the ideal answer depends on what the model knows, rather than what the human demonstrator knows.” 
So, it’s clear that OpenAI knows perfectly well that ChatGPT is filled with BS under the surface. They never meant the technology to offer up a source of truth. 
But the question is: Are human users okay with that? 
Unfortunately, they might be. If it sounds good, many humans may think that’s good enough. And, perhaps, that’s where the real danger lies beneath the surface of ChatGPT. 





By JAKOB HANKE VELA
Send tips here | Tweet @HankeVela | Listen to Playbook and view in your browser
LABELING AI CONTENT        
TODAY: EU PUSHES FOR ‘AI LABEL’ TO FIGHT DEEPFAKES: Brussels wants to prevent artificial intelligence from blurring the lines between fact and fiction — and will today ask companies for the first time ever to come up with a label to identify AI-generated texts and images to fight disinformation, officials tell Playbook.
Brave new world: Generative AI is making breathtaking advances — from writing texts and code to creating ever more realistic pictures and videos — which will have enormous consequences not just for the future of society and work, but for politics, Commission officials reckon. 
Balenc-ai-ga: The fake images of the Pope and famous politicians wearing a Balenciaga coat that went viral earlier this year have clearly spooked them — and they now want to label such deepfakes.
Fake porn: “Today it is mostly still a game, but tomorrow you could see a fake porn with a candidate,” one official who is working on the file but was not authorized to speak on the record told Playbook, referring to AI-generated images of politicians. 
Race to regulate: The Commission (the EU’s executive, which proposes and enforces laws) — has proposed an AI Act to regulate high-risk applications and ban the most dangerous ones. But even before that act enters into force, the Commission will urge industry to cut down on trickery by labeling AI-generated work.
Happening today: Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton will meet representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation. They include Microsoft, Google, Meta, TikTok, Twitch and smaller companies — but not Twitter, which has left the code — as well as NGOs.
Disinformation risks: “I will ask the signatories to create a dedicated and separate track within the code” to deal with disinformation generated by Artificial Intelligence, Jourová told Playbook. “It should … aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them.”
EU pushes for safeguards: How does Brussels want the companies to tackle the risks? “Signatories who integrate generative AI into their services like Bingchat for Microsoft, Bard for Google should build in necessary safeguards that these services cannot be used by malicious actors to generate disinformation,” Jourová said.
Clear labels: “Signatories who have services with a potential to disseminate AI-generated disinformation should in turn put in place technology to recognize such content and clearly label this to users.”
More about this label: Two officials working on the file told Playbook the label should apply to all AI-generated material that can be used to create disinformation, including text, images, audio and video.
Voluntary — for now: It wouldn’t be mandatory, given that it would be part of the voluntary Code of Practice. However, the Commission aims to make the code enforceable by including it as a code of conduct in the Digital Services Act (DSA). Obligations on labeling AI content may also make it into the AI Act during negotiations between EU countries, Parliament, and the Commission, one official said.
How can companies do this? “They can develop, and they probably already have tools to check whether an image was AI-generated or not,” the first official said.
Playbook wonders: Given how easy it is for AI to proliferate across jurisdictions, will such a technology ever be able to identify all deepfakes — or won’t we, on the contrary, one day need some chain of custody procedure for authentic images that can be used, for example, as evidence in court?
Stay tuned: Jourová will present her initiative at a press point tomorrow at 11:15 a.m.
SPEAKING OF WHICH: While the Commission is calling on others to do more, it was recently reported that it awarded and signed a €3.7 million tender to help analyze issues like disinformation, foreign meddling in elections and global threats from a French firm that’s mired in controversy.
Avisa Partners has previously been accused of manipulating information in France and working for authoritarian regimes. The company was recently at the center of a controversy as the organizer of a cybersecurity forum boycotted by the French armed forces ministry and several government officials. More here for our Pro Cybersecurity subscribers.
Looking into this: The Commission is looking into the allegations and “is in contact with French counterparts to seek more clarity on those claim[s],” Peter Stano, the Commission’s spokesperson for foreign affairs and security policy, told my POLITICO Pro Technology colleagues. The EU executive is “closely monitoring the implementation of this project,” he added. 
Jean Tillinac, from Avisa Partners, told my Pro Tech colleagues that the bid was “defended by a team of seasoned experts from our Strategic Intelligence Division” doing research and which was different from the “Digital Communications Division” facing criticism.



Annex I – Glossary of Terms
Algorithm: a formula given to a computer for it to complete a task (i.e., a set of rules for a computer) 
Artificial intelligence: a subset of computer science that deals with computer systems performing tasks with similar, equal, or superior intelligence to that of a human (e.g., decision-making, object classification and detection, speech recognition and translation)
Artificial general intelligence (AGI): also known as strong AI, AGI is a type of artificial intelligence that is considered human-like, and still in its preliminary stages (more of a hypothetical existence in present day)
Artificial narrow intelligence (ANI): also known as weak AI, ANI is a type of artificial intelligence that can only focus on one task or problem at a given time (e.g., playing a game against a human competitor). This is the current existing form of AI.
Artificial neural network (ANN): a network modeled after the human brain by creating an artificial neural system via a pattern-recognizing computer algorithm that learns from, interprets, and classifies sensory data.
Big data: large amounts of structured and unstructured data that is too complex to be handled by standard data-processing software.
Chatbots: a chat robot that can converse with a human user through text or voice commands. Utilized by e-commerce, education, health, and business industries for ease of communication and to answer user questions. 
Cognitive computing: computerized model that mimics human thought processes by data mining, NLP, and pattern recognition.
Computer vision: when a machine processes visual input from image files (JPEGs) or camera feeds
Data mining: the process of sorting through large sets of data to identify recurring patterns while establishing problem-solving relationships.
Deep learning: a machine learning technique that teaches computers how to learn by rote (i.e., machines mimic learning as a human mind would, by using classification techniques)
Generative AI: Generative artificial intelligence or generative AI is a type of artificial intelligence (AI) system capable of generating text, images, or other media in response to prompts. Generative AI models learn the patterns and structure of their input training data, and then generate new data that has similar characteristics. 
Genetic algorithm: an algorithm based on principles of genetics that is used to find solutions efficiently and quickly to difficult problems.
Machine learning (ML): focuses on developing programs that access and use data on their own, leading machines to learn for themselves and improve from learned experiences.
Natural language processing (NLP): helps computers process, interpret, and analyze human language and its characteristics by using natural language data. 
Pattern recognition: automated recognition of patterns found in data.
Reinforcement learning: a machine learning method where the reinforcement algorithm learns by interacting with its environment and is then penalized or rewarded based on decisions it makes.
Strong AI: see artificial general intelligence (AGI)  
Structured data: clearly defined data with easily searchable patterns.
Supervised learning: a type of machine learning where output datasets teach machines to generate desired outcomes or algorithms (akin to a teacher-student relationship).
Transfer learning: a system that uses previously learned data and applies it to a new set of tasks.
Turing Test: a test created by computer scientist Alan Turing (1950) to see if machines could exhibit intelligence equal to or indistinguishable from that of a human.
Unstructured data: data without easily searchable patterns (e.g., audio, video, social media content)
Unsupervised learning: a type of machine learning where an algorithm is trained with information that is neither classified nor labeled, thus allowing the algorithm to act without guidance.",14,6.8,"Summary
This is a good case that could have achieved an even higher score had there been more attention paid to the linguistic quality.
Some style issues can lessen the effect even of an impeccably discussed problem point. Typos and some grammar aspects (e.g., article use, verb agreement, verb forms) can be controlled with some attention even in an exam situation. They can heavily influence your score for the communication competence.
If you have to list the pros/cons of an issue, you should use similar format for both aspects while compiling relatively the same number of arguments - even if you are asked to take sides in the brief, the majority of the text should read impartial.
It is helpful to frame your text with an introduction and conclusion; first, you can put the issue in context; second, you can enhance the professional feel of the study; and, finally, you can show that you finished the text as you intended and not because the time ran out.
For time management issues and other practical ideas, please check out our Tips & Tricks menu and our webinars.


Per Competency Score",5.0,"Observations
With this competence, we basically evaluate the style of the case study. Your text should be clear, fluent, written in a professional but still captivating style; of course, spelling and grammar are also covered in this area. Another point we examine here is whether you managed to find the balance between providing details and being concise while conveying the key points of the arguments.",,"Tips to Improve
The text is informative and cohesive; there are many typos and grammatical inaccuracies that influence the readability of the text.","Trainee's Answer
Speaking Note to Commissioner Thierry Breton
9 June 20XX, DG Internal Market
Title: The Commissions standpoint to generative AI (GAI)
 
Defining GAI:
Generative Artificial Intelligence (GAI) is a subfield of an artificial intelligence (AI) system. It can generate computer algorithms, texts, images, and music. GAI learns from training data that includes examples of desired output. 
Examples of GAI are:
ChatGPT is an AI language model that can generate human-like text based on given prompts.
Midjourney interprets text prompts and context to produce images and artwork.
 
Potential Benefits of GAI:
GAI increases efficiancy, enables businesses to automate specific tasks and increase operational efficiency. It further customises marketing content, optimizing computer code, draft templates for all kind of written texts.
Potential Risks of GAI:
Five specific risks exist regarding GAI:
Hallucinations: GAI uses training data. The training data can lead to biased or incorrect responses, which is a serious probelm when people rely on it.
Deepfakes: GAI creates videos and fotos and voice recording that may be abused to attack politicians and activits, spread misleading information. GAI may further create fake accounts and take over existing legitimate accounts. Disinformation through GAI is a serious risk for democracy. Deepfake videos and online bots may spread fake news and manipulate public discourse and social trust.
Data privacy: GAI user data is often stored for model training. Therefore, employees may easily expose sensitive and proprietary entreprise data. The GAI applications may indefinitely store information and even train other GAI models with it, further compromising confidentiality.
Cybersecurity: Computer hackers could abuse GAI applications to code computer viruse or other harmful software.
Copyright issues: GAI models use big amounts of internet data sharing content that has not been explicitly shared by the original soruce. This is problematic for music and videos that have a copyright.
 
Options to address risks:
The EU has understood that fighting against desinformation in context of defending democracy and EU values is very important. Therefore, the European Commission proposes the first-ever regulatory framework on AI, namely the AI act, to address risks of AI and position Europe to play a leading role on AI globally. The existing legislation is not sufficient to address specific challenges AI systems may bring.
The new regulatory framework under the AI act defines 4 levels of risks unacceptable risk: high risk, limited risk, minimal risk. The EU lists GAI such as chatbots in the category of limited risk. In that case users need to be made aware that they are interacting with a machine so they can take an informed decision to continue or step back. 
The regulation further proposes a conformity assessment before the AI system is put into service or placed on the market. GAI companies will have to disclose any copyright material used to develop their systems. Moreover, they will have to indentify and label AI-generated texts and images to fight disinformation.
Next steps
The commission propsed the AI Act to regulate high risk applications and ban most dangerous ones. But even before the act enters into force, the Commission will make it mandatory for the GAI industry to label AI generated work.
Signing Code of Practice by big tech comapnies including Microsoft, Google, Meta and Tiktok against desinformation. The Code of Practice will ask signatories to create a dedicated track within the code to indentify specific disinformation risks by GAI and take appropriate measures to address them. The Commission plans to make the code enforcable by including a code of conduct in the Digital Services Act. Labelling AI contact may also enter the AI act."
5,0_Case Study Driverless Cars,"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions.

Automated vehicle technologies allow the transfer of driving functions from a human driver to a computer. Automation, and in particular digitalisation, of driving will change road transport in a way which is viewed as a revolution in the field of mobility. As human error is the main reason for road traffic accidents, driving which is automatically controlled by a computer is expected to make future road transport safer and more secure. It has also the potential to be more environmentally friendly, efficient and accessible. Automated vehicle technologies require an effective legislative framework that can foster European leadership and competitiveness, while addressing a number of legitimate concerns. 
You are working as an administrator in DG Mobility and Transport, and you have been asked to prepare a briefing for the next unit meeting.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete. 
You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the markers will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated. 
The case study is designed to assess the following competencies: Analysis and Problem Solving, Communicating (Drafting Skills), Delivering Quality & Results, and Prioritising & Organising.
More specifically, you are asked to write a briefing note (2-3 pages) containing the following background information:
Potentials and challenges of vehicle automation
The different levels of automation and their deployment
Regulatory and legal frameworks, state of play
Ongoing work in the EU

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly and legibly as possible.","ABBREVIATIONS USED
				
		
ACEA - European Automobile Manufacturers’ Association 
Automated vehicle - a motor vehicle (car, truck or bus) which has technology available to assist the driver so that elements of the driving task can be transferred to a computer system

Autonomous vehicle – a fully automated vehicle equipped with the technologies capable to perform all driving functions without any human intervention

CAD - connected and autonomous driving 
C-ITS - Cooperative - Intelligent Transport Systems. Systems consisting of vehicles accompanied by a communication and sensor infrastructure with which the vehicles – fitted with appropriate on-board devices - are capable of communication between themselves and with the infrastructure.
CLEPA - European automotive suppliers association 
Connected vehicle - a motor vehicle equipped with devices to communicate with other vehicles or the infrastructure via the internet

ERTRAC - European Road Transport Research Advisory Council.

NHTSA - National Highway Traffic Safety Administration (US)
UNECE - United Nations Economic Commission for Europe
SAE - Society of Automotive Engineers (US)
V2V – Vehicle to Vehicle Communication
V2I – Vehicle to Infrastructure Communication




BACKGROUND INFORMATION","Subject:		Driverless Cars

I would like you to prepare a briefing on driverless cars for this week’s Unit meeting. Please send me your briefing note that will serve as your hand out for our colleagues by tomorrow evening, so that I can have a look at it before the actual presentation.

Thanks",",

Elon SMUK,
Head of Unit



The Benefits of Driverless Cars
(Excerpt from “The Driver in the Driverless Car - How our technology choices will create the future” by VIVEK WADHWA & ALEX SALKEVER)

Few people seem to fully grasp the profound improvement in our lives that driverless cars will bring. Their adoption will slash accident and fatality rates, saving millions of lives. As well, it will remove one-third to one-half of all vehicles from city streets. A large percentage of the cars on the streets of New York, San Francisco, and London at any one time are looking for parking; but self-driving cars don’t need to park: they can continuously circulate, picking up and dropping off passengers.  The Earth Institute at Columbia University projects a 75 per cent reduction in the cost of car ownership, because fewer shared vehicles will be necessary to provide the same service collectively that personally owned vehicles provide. During peak hours, those shared vehicles will be in use 90 per cent of the time. And, with no more need for steering wheels and other systems enabling human control, vehicles will be lighter and far more fuel-efficient. 
Most important, car sharing will cost a fraction of what car ownership today costs. Owning a car for daily, personal transportation will seem impractical. Self-driving cars will also deliver incontrovertible social beneﬁts. With self-driving cars, the disabled will no longer struggle to ﬁnd transportation; they will have an on-demand personal driver. Several years ago Google’s self-driving car team contacted Steve Mahan, Executive Director of the Santa Clara Valley Blind Center. The team wanted feedback and let Mahan come along for test-drives in earlier self-driving Prius models as well as in the latest Google car. “My experience with Google has been terriﬁc, and I want it to happen,” Mahan told the Times. “Everyone in the blind community wants it to happen.” 
Other groups will also beneﬁt in tangible ways. Women and children will never worry about getting a cab ride late at night. Once all drivers are off the road, trafﬁc violations will no longer be an issue, and cops will have fewer reasons to pull over cars, which should reduce instances of the currently vicious discrimination against individuals “driving while black.” Teens will not face insurance discrimination as they do today, and their parents will not have to pay for the dubious privilege of teaching a teenager to drive. People living in the country will ﬁnally gain access to transportation services that put them nearly on par with their city cousins. Pedestrians will stop worrying about getting hit by cars in intersections.
Let me paint a picture of what streets will look like in an age of driverless cars. We will no longer need traffic lights: robot cars will synchronize wirelessly to time mass movements across city intersections and entries onto freeways or balletic dances around four-way stop signs. Having no human eyes behind the wheel will obviate much of the need for signalling and signage. When all the driverless cars are talking to each other, there will be no need for them to ever come to a complete halt and waste all their kinetic energy. So we will be able to forget traffic lights—and stop signs, yield signs, lighting on freeways, and dozens of other transportation-infrastructure elements catering to human drivers. This great elimination will save many, many billions of dollars in the United States. Equally important, self-driving cars will eliminate the need to build these types of infrastructure in less developed countries in which traffic lights, freeways, and other modern trafﬁc-control features have yet to be put in place. The future cost savings to those countries will be astronomical. In that future, the beneﬁts of self-driving cars will be far more evenly distributed.
Eliminating human drivers will also allow automobile designers to build cars from a completely different mind set. Driverless cars will not need steering columns, brake pedals, accelerator pedals or any of the other components drivers use for slowing or accelerating. They will not need a gearshift panel in the middle of the driver compartment or an emergency brake pedal. The A.I. system driving the car will also reduce accidents to negligible levels. 
…




Robots and artificial intelligence: MEPs call for EU-wide liability rules 

Press Releases Plenary session 
16-02-20XX - 13:09  


As human-robot interactions become commonplace, MEPs stress that EU-wide rules are needed to guarantee a standard level of safety and security. © AP Images/European Union - EP

EU-wide rules are needed for the fast-evolving field of robotics, e.g. to enforce ethical standards or establish liability for accidents involving driverless cars, say MEPs in a resolution voted on Thursday. 
MEPs ask the EU Commission to propose rules on robotics and artificial intelligence, in order to fully exploit their economic potential and to guarantee a standard level of safety and security. They note that regulatory standards for robots are being planned in several countries, and point out that the EU needs to take the lead on setting these standards, so as not to be forced to follow those set by third countries.
Rapporteur Mady Delvaux (S&D, LU) said “Although I am pleased that the plenary adopted my report on robotics, I am also disappointed that the right-wing coalition of ALDE, EPP and ECR refused to take account of possible negative consequences on the job market. They rejected an open-minded and forward-looking debate and thus disregarded the concerns of our citizens.”
Liability rules and the impact of robots on the workforce
MEPs stress that draft legislation is urgently needed to clarify liability issues, especially for self-driving cars. They call for a mandatory insurance scheme and a supplementary fund to ensure that victims of accidents involving driverless cars are fully compensated.
MEPs also ask the Commission to consider creating a specific legal status for robots in the long run, in order to establish who is liable if they cause damage.
The rapid development of robots might result in changes in the labour market through the creation, displacement and loss of certain jobs. MEPs urge the Commission to follow these trends closely.
A Code of Ethical Conduct and a new European Agency for robotics
The growing use of robotics also raises ethical issues, for example to do with privacy and safety, stress MEPs. They propose a voluntary ethical code of conduct on robotics for researchers and designers to ensure that they operate in accordance with legal and ethical standards and that robot design and use respect human dignity.
They also ask the Commission to consider creating a European agency for robotics and artificial intelligence, to supply public authorities with technical, ethical and regulatory expertise.
The resolution was passed by 396 votes to 123, with 85 abstentions. The Commission will not be obliged to follow the Parliament’s recommendations, but must state its reasons if it refuses.





PRESS RELEASE
10-03-20XX
Regulatory and legal framework for automated vehicles
Road traffic is a highly regulated area as it bears huge risks for all traffic users in public spaces. The automation of vehicles changes the driving risks in many regards and therefore requires an assessment of all traffic and vehicle related regulation. Different national jurisdictions can hinder the development and deployment of new technologies for systems or vehicles. European mobility requires a harmonised approach towards these new technologies, while fragmented regulatory approaches would hinder implementation and jeopardise European competitiveness.
Regulation of road traffic
The Vienna Convention on Road Traffic of 1968 (‘Vienna Convention of 1968') is an international treaty designed to facilitate international road traffic and to increase road safety by establishing standard traffic rules among the contracting parties. All EU Member States are signatories of the Vienna Convention — only the UK and Spain have not ratified it. 
One of the fundamental principles of the Vienna Convention is the concept, as laid down in Article 8, that a driver is always fully in control and responsible for the behaviour of a vehicle in traffic.
The amended convention (20XX-1) still demands that every vehicle must have a driver. However, in the future it will be in accordance with the Convention that highly automated systems will have a driver who may take the hands off the wheel, but must be ready at all times to take over the driving functions, and who can override the system and switch it on and off. A further amendment process is therefore necessary to permit driverless vehicles. Systems with high or full automation are mostly still incompatible with the Vienna Convention because a driver may not be required in these systems, depending on the use case.
Technical requirements
Technical requirements for vehicles are internationally harmonised in the framework of the two following UNECE Agreements:
The 1958 Agreement provides the framework for establishing international UN Regulations with uniform performance—oriented test provisions and administrative procedures for granting type approvals, for the conformity of production and for the mutual recognition of the type approvals granted. The 1958 Agreement currently has 54 contracting parties and 135 annexed UN Regulations.
The 1998 Agreement concerns the establishing of global technical regulations for the construction of new vehicles, including performance requirements. Its purpose is to further enhance the process of international harmonisation through the development of global technical regulations (GTR). The 1998 Agreement has 35 Contracting Parties and 16 UN GTRs, established in the UN Global Registry (March 20XX-2).
The European Union is a contracting party to the 1958 and the 1998 Agreement. 
Under the European vehicle type approval system, manufacturers can obtain approval for a new vehicle type in one EU Member State if it meets the EU technical requirements. The manufacturer can then market it EU—wide with no need for further approval tests or checks in other Member States. The approval is granted by a national authority in charge of type approval. The completion of the type approval examination results in issuance of a Certificate of Conformity, which is a statement by the manufacturer that the vehicle conforms to the relevant legal requirements as stipulated by EU legislation.
The common legal framework for the approval of motor vehicles and their trailers is provided by a Framework Directive. Within the EU, mass—produced cars may only be used on public roads if they are type—approved in compliance with the administrative procedures and technical requirements established by the Directive.
General regulatory environment
The regulatory environment relating to cyber security, data privacy, and liability issues is of particular importance in the development of automated vehicles.
Today's connected vehicles are already equipped with extensive IT communication capabilities. In-vehicle networks for information and entertainment co-exist with automotive control networks. The different networks have different degrees of relevance for the safe functioning of the vehicle and for cyber security risks and data protection issues.
Automated vehicles are extended vehicles, meaning that they have external software and hardware extensions as some of their features. These extensions are developed, implemented and managed by the vehicle manufacturer. The connection between the in—vehicle system and the manufacturer's central server has to be secure, so that all data transfers are protected from unauthorised disclosure and manipulation.
Uncontrolled, unrestricted access to vehicle data in the on-board network by third parties directly and indirectly jeopardises the safety of the vehicle, occupants and other road users. Media report increasingly on cyber security problems related to cars, for instance covering the successful attempt of hacking into a vehicle and controlling its basic driving functions via the entertainment and navigation software.
The debate on data privacy regarding connected automated vehicles is evolving in parallel with the new technologies. In general, digital services will be available in vehicles, as they are anywhere else. The ‘connected car‘ has the capability to generate, store and transmit users‘ personal data, such as their route to work, time of driving, favourite music, appointments or favourite restaurants. These data have a significant potential for other uses. As third parties can access and use sensitive driver and driving data, legislation seems necessary to protect personal privacy of consumers in connected vehicles.
The new General Data Protection Regulation establishes a single set of rules on data protection, also with regard to digital technologies, valid across the EU.
Liability issues
Traffic accidents have very large costs in economic terms, in particular regarding human lives or health, or regarding damage to an object. Liability law answers the question of who is responsible and who has to bear the costs of an accident.
In the European Union product liability is strongly harmonised by the Directive on liability for defective products (Council Directive 85/374/EEC). A producer is liable for any damage caused by a defect in his product; a product is defective when it does not provide the safety which the consumer is entitled to expect.
However, there is currently no framework in place harmonising the rules on liability for damages caused by accidents in which motor vehicles are involved — the regulation of liability of the holder of a vehicle or of the driver differ between the Member States.
Most liability regimes in the EU use a concept of causality for determining and allocating liability. From a certain level of vehicle automation on, it might be difficult to establish the exact cause of an accident and to prove if it is due to a defect with the automated vehicle or the behaviour of the driver. The new possible causes created by automation might interfere with the very objective of liability regimes to apportion risks, therefore an adaptation of liability law to the new technologies and a European harmonisation of the regimes concerning the liability of owners and/or drivers of automated vehicles seem necessary.

 


EU Commission drives home merits of autonomous vehicles
By Dave Keating | EURACTIV.com 
 Apr 6, 20XX

Can driverless cars chauffeur people to a love of the EU? The European Commission is betting it can.
Christmas came early for automated driving enthusiasts this week. Convening a two-day summit in Brussels on the subject – the first of its kind – the European Commission promised a sack of goodies in the form of dedicated funding, regulatory changes, cross-border agreements and innovation stimulus.
Driverless trucks could be a reality on European motorways within two years, officials said. They would first operate in convoys where the first truck is driven by a human being but all the trucks following are driverless.
It’s the first step in a roadmap, to be published by the Commission as part of its transport strategy on 31 May, that could see driverless cars integrated with traffic by 20XX+10.
“Owning a non-autonomous car will soon be like owning a horse,” said Carlos Moedas, the EU commissioner for research, science and innovation, who spoke at the conference.
Commission President Jean-Claude Juncker has identified driverless vehicles as an area where the EU can deliver tangible benefits to citizens. In his five-scenario white paper on the future of Europe, released last month ahead of the EU’s 60th anniversary summit in Rome, connected and autonomous driving (CAD) was used repeatedly as an example of something that cannot become a reality without the EU.
In a scenario in which the EU downgrades to only a free trade zone, “Europeans are reluctant to use connected cars due to the absence of EU-wide rules and technical standards,” the paper concluded.
Three weeks later, national leaders signed an agreement in Rome to not only allow cross-border tests and experiments but also to establish one single point of contact in each country to approve them.
Highway cruising
Trucks are expected to be the first to go driverless, both because they drive on motorways and because they are the most commercially interesting. Though convoys following a lead driven vehicle will be the first step, the next step will be completely independent automated trucks.
Motorways present the safest environment for CAD because they are free of pedestrians and are more or less in a straight line. They are also more uniform throughout Europe. In the very near future trucks will be driven within cities by a driver, but then dropped off at the motorway to continue its journey alone. When the truck arrives at its destination, a new driver would pick it up at the motorway exit.
“Lisbon to Warsaw today is four and a half days, but that could be brought down to one and a half,” José Manuel Viegas, secretary-general of the International Transport Forum at the OECD, told euractiv.com.
“It’s very useful for trucks and buses not only because it would save on labour costs and operation, but because it could operate 24 hours a day.” 
Semi-autonomous ‘platoons’ of trucks from around Europe will travel to Rotterdam in early April as part of an experiment backed by the Dutch Council presidency.
Vienna Convention needs updating
Despite the Commission’s enthusiasm, this isn’t low-hanging fruit. It isn’t only the EU that is causing regulatory uncertainty in this field. Globally, rules on driving are harmonised by the UN’s 1968 Vienna Convention on Road Traffic.
Joost Vantomme, smart mobility Director at the European Automobile Manufacturers’ Association (ACEA), said the rules need to be clarified. “Article eight says you need to have a driver in the vehicle, and they need to be in control of the vehicle,” he said. “But what is a driver? Can it be a computer? And what does it mean to be in control of the vehicle?”
As the technology for automated driving has called article eight into question, different countries have interpreted these rules differently. Antti Vehviläinen, director-general of the Finnish Transport Agency, told the conference that Finland has chosen a loose interpretation. “The driver does not need to be in the car, he just needs to be in control,” he said.
The EU’s early efforts at clarification could mean that the bloc ends up setting the standards later adopted at the UN. It can take four to five years to modify a UN treaty, and work has not even begun yet.
Public worry
But is automated driving really the vote-winner that the Commission is imagining? There was much worry at the conference that fears over driverless cars are going to trump the benefits. What will someone think if they are driving on the motorway and see a driverless car next to them?
In Gothenburg Sweden, they’re about to find out. Volvo is launching a project this year called DriveMe, which will put driverless vehicles on real roads with other drivers. The company wants to test how other drivers react, as well as other safety considerations.
The safety worries are a significant hurdle. At a special break-away panel dedicated to the human factors in CAD, most people agreed that people will over-trust automation and this could present dangers. Almost everyone agreed that operating an automated vehicle should require special training, and half said vehicles should alert others when they are in automated mode.
This will be a difficult question for regulators, Viegas admitted. “A minister will know that giving approval today and then having a fatal accident tomorrow will result in him being fired,” he said. “You need to be able to guarantee that the automated vehicle would not fail in a scenario in which a human would not fail.”
Still, the mood at the Brussels conference was positive. There was a general consensus that, as long as safety concerns can be addressed, the EU is on to a winner by identifying autonomous vehicles as an area where it will demonstrate innovation leadership and quick regulatory adjustment.
“Imagine on our roads trucks platooning with big signs saying ‘Europe on the move’,” said Roberto Vavassori, president of the European automotive suppliers association CLEPA. “It would be a sign that EU legislation is there to improve quality of life for our people,” he told the conference enthusiastically.



Autonomous driving levels 0 to 5: Understanding the differences
The National Highway Traffic Safety Administration adopted the Society of Automotive Engineers' (SAE) levels for automated driving systems, ranging from complete driver control to full autonomy. 
By Hope Reese | January 20, 20X-1, 10:47 AM PST 
Between Tesla's announcement that every car in production will now have the capability for full autonomy by 20XX+1 and the Obama administration's plan to invest almost $4 billion in autonomous vehicle research over the next 10 years, the race to create the best driverless car has never been hotter.
The rise of driverless vehicles is going to have a major impact on businesses and professionals. Automated vehicles could replace corporate fleets for deliveries or transporting employees, for example. And workers could gain productive hours in the day by working instead of driving during daily commutes. Innovations in this field are also poised to completely change the car insurance industry by reducing accidents—a new report predicts that accidents will drop by 80% by 20XX+20
But, what does ""autonomous driving"" really mean? The US Department of Transportation's National Highway Traffic Safety Administration (NHTSA) defined five different levels of autonomous driving. In October 20XX-1, the NHTSA updated their policy to reflect that they have officially adopted the levels of autonomy outlined in the SAE International's J3016 document.
The NHTSA is ""working to transform government for the 21st century, harnessing innovation and technology that will improve people's lives,"" according to a representative. ""This is an area of rapid change, which requires the Department Of Transport and NHTSA to remain flexible and adaptable as new information and technologies emerge. Amid that rapid change, the North Star for Department Of Transport and NHTSA remains safety."" 
It's important to remember that the levels of autonomy describe the system, not the vehicle, said Bryant Walker Smith, professor at the University of South Carolina School of Law and School of Engineering and one of the top experts in the driverless cars world. ""A Level 5 automated driving system could be in a vehicle with or without a steering wheel,"" he explained.
Here's what you need to know about levels 0-5. The biggest difference is that, starting at Level 3, the automated driving system becomes able to monitor the driving environment.
Level 0: This one is pretty basic. The driver (human) controls it all: steering, brakes, throttle, power. It's what you've been doing all along.
Level 1: This driver-assistance level means that most functions are still controlled by the driver, but a specific function (like steering or accelerating) can be done automatically by the car.
Level 2: In level 2, at least one driver assistance system of ""both steering and acceleration/ deceleration using information about the driving environment"" is automated, like cruise control and lane-centering. It means that the ""driver is disengaged from physically operating the vehicle by having his or her hands off the steering wheel AND foot off pedal at the same time,"" according to the SAE. The driver must still always be ready to take control of the vehicle, however. 
Level 3: Drivers are still necessary in level 3 cars, but are able to completely shift ""safety-critical functions"" to the vehicle, under certain traffic or environmental conditions. It means that the driver is still present and will intervene if necessary, but is not required to monitor the situation in the same way it does for the previous levels. Jim McBride, autonomous vehicles expert at Ford, said this is ""the biggest demarcation is between Levels 3 and 4."" He's focused on getting Ford straight to Level 4, since Level 3, which involves transferring control from car to human, can often pose difficulties. ""We're not going to ask the driver to instantaneously intervene—that's not a fair proposition,"" McBride said.
Level 4: This is what is meant by ""fully autonomous."" Level 4 vehicles are ""designed to perform all safety-critical driving functions and monitor roadway conditions for an entire trip."" However, it's important to note that this is limited to the ""operational design domain (ODD)"" of the vehicle - meaning it does not cover every driving scenario.
Level 5: This refers to a fully-autonomous system that expects the vehicle's performance to equal that of a human driver, in every driving scenario—including extreme environments like dirt roads that are unlikely to be navigated by driverless vehicles in the near future. 
Why it matters
So why are the levels important? They serve as general guidelines for how technologically advanced a vehicle is. In terms of what consumers need to know, Thilo Koslowski, former analyst for Gartner, thinks that ultimately, there are three stages that will be relevant: ""automated, autonomous, and driverless."" It's important to distinguish between ""autonomous"" and ""driverless,"" he said: ""driverless is a more advanced stage of autonomous.""
But while drivers themselves may be less concerned with the distinctions, the differences could be significant when it comes to issues like car insurance, which is expected to change radically in the era of self-driving cars. 
KPMG, a consulting firm, has issued a report on how the car insurance business will be affected, since the number of accidents are predicted to go down 80% over the coming 20 years. The different levels are important because they ""change the risk profile of the car,"" according to KPMG expert Jerry Albright. ""Insurance companies need to understand how these new capabilities affect driving risk."" Joe Schneider, managing director at KPMG, put it this way: ""It's like a baby, going from crawling to walking to running."" Albright said, ""The car becomes safer and safer as it moves towards fully-autonomous driving.""



Study Service 

Internal Memo

Challenges for automated vehicles in the EU

The potential impact of the deployment of automated vehicles raises many questions. The answers are still under discussion, having ethical, legal, financial, economic and technical dimensions. While most of the scientific discussion has to date dealt with the development of the technology, the focus recently is shifting towards topics such as user acceptance and legal issues. Policy makers, in particular, face challenges in designing the appropriate legal and regulatory framework so that new technologies are used properly and for the benefit of society.

Legal framework for road safety

Regulation of automated vehicles faces challenges to establish rules for technologies not yet applied. In particular, appropriate safety requirements have to be agreed. Traffic rules and the regulatory framework need to be adapted. In addition, it has to be decided how the safety of automated vehicles should be tested and by whom. The further development of vehicle automation will demand an adaption of driving education and licensing.

Infrastructure and technical standards

Automated and connected vehicles need special features in infrastructure. What needs to be done at the infrastructure level has yet to be clarified. An important prerequisite for intelligent transport systems will be an agreement on what communication is needed between vehicles (V2V), between vehicles and infrastructure (V2I) and vehicles to anyone else. Technical standardisation is necessary for international compatibility and interoperability.

Data processing

The new technologies raise questions as to how data privacy and cyber security will be addressed. The highly or fully automated vehicle will process data and make decisions: this raises ethical issues which have to be solved in a societal dialogue. The programmed algorithms will make decisions in conflicting situations, such as a choice between two unavoidable crash scenarios. How will the decision be taken? What 'best driving behaviour' should be reflected by the system?

Liability issues

In case of malfunction of an automated vehicle, who is liable when such malfunctions result in an accident: the manufacturer, the owner or the driver has to be clarified.




Examples for the different levels of automation

Level 0 - Park Distance Control (already deployed): The system assists the driver to manoeuvre into tight spaces by communicating distance from obstacles by means of acoustic or optical signals.

Level 1 - Park Assist (already deployed): The system automatically steers the car into parallel and bay parking spaces, and also out of parallel parking spaces. The system assists the driver by automatically carrying out the optimum steering movements in order to reverse - park on the ideal line. The measurement of the parking space, the allocation of the starting position and the steering movements are automatically undertaken – all the driver has to do is operate the accelerator and the brake. This means that the driver retains control of the car at all times.

Level 2 - Traffic Jam Assist (already deployed): The function controls the vehicle longitudinally to follow the traffic flow in low speeds (lower than 30 km/h). The system can be seen as an extension of the Adaptive Cruise Control with Stop&Go functionality, i.e. no lane change support.

Level 3 - Traffic Jam Chauffeur (already deployed): Conditional Automated Driving up to 60 km/h on motorways or similar roads. The system can be activated in a traffic jam scenario. It detects a slow-driving vehicle in front and then handles the vehicle both longitudinally and laterally. Later versions of this functionality might include lane change functionality.

Level 4 - Highway Pilot (possible deployment 20XX+4): Automated driving up to 130 km/h on motorways or motorway-like roads from entrance to exit, on all lanes, including overtaking movements. The driver must deliberately activate the system, but does not have to monitor it constantly. The driver can override or switch off the system at all times. There is no request from the system to the driver to take over when the system is in its normal operation area on the motorway. Depending on the deployment of vehicle-to-vehicle communication and cooperative systems, ad-hoc convoys could also be created.

Level 5 – The fully automated vehicle should be able to handle all driving from point A to point B, without any input from the passenger. According to ERTRAC only a rough estimation for possible deployment can be given: 20XX+10.




Self-driving cars could cost America's professional drivers up to 25,000 jobs a month, Goldman Sachs says

Anita Balakrishnan | @MsABalakrishnan 
Published 2:45 PM ET Mon, 22 May 20XX
The full impact of self-driving cars on society is several decades away — but when it hits, the job losses will be substantial for American truck drivers, according to a new report from Goldman Sachs. When autonomous vehicle saturation peaks, U.S. drivers could see job losses at a rate of 25,000 a month, or 300,000 a year, according to a report from Goldman Sachs Economics Research. Truck drivers, more so than bus or taxi drivers, will see the bulk of that job loss, according to the report. That makes sense, given today's employment: In 20XX-3, there were 4 million driver jobs in the U.S., 3.1 million of which were truck drivers, Goldman said. That represents 2 per cent of total employment. The report estimates that semi- and fully autonomous car sales will have about 20 per cent share of car sales around 20XX+10. The report comes as fierce competition to make self-driving cars is shaking up companies from the inside out. 
Uber formally launched Uber Freight last week with a self-driving executive at the helm, expanding its reach in the trucking industry, even as it fights in court with Alphabet over whether some of its technology is stolen. And at Ford, the CEO will be replaced by a self-driving car expert, in an effort to ""transform Ford for the future."" Near term, the analysts predict that occupations like secretaries, cashiers, bank tellers, waiters and real estate agents could also be at risk of automation.
To be sure, the report estimates that the full effects of self-driving cars will be delayed by regulation and slow adoption. The report as a whole strikes an optimistic tone on the future of the labor market, noting that many different employment and productivity measures in the United States do not show massive disruption from labor-replacing technologies. 
Industries like department stores, telecom, printing, publishing and manufacturing have seen the biggest job losses over the past 13 years, while sectors like food services, education, computer design and home healthcare have been winners, the report said. ""Demand for health care, education and food services is likely to rise further with aggregate income, and should also benefit from broader trends including aging and consumers' desire for new experiences,"" the report said. ""More fundamentally, we suspect that several of the skills central to those sectors — including empathy, humor, creativity and problem solving — are hard to codify and automate.""",31,6.0,"Summary

According to the Notice of Competitions of current EPSO competitions, the only competency that will be assessed in the Case Study exam is Written Communication",6.0,"Observations

The thesis of the content, which is the state and implications of driverless cars in the EU, is well communicated but could be enhanced by a clearer structure.

The central message is clear but could be better communicated with the inclusion of an Introduction and Conclusions section.

The communication generally follows a logical flow, although it could benefit from a more structured layout with clearly defined sections.

The layout is not visually pleasing due to the lack of titles and subtitles, which would make the document easier to navigate.

Titles and subtitles are lacking, making it difficult to quickly identify the main points and sub-points.

The tone of the document is informative and neutral, aiming to present a balanced view of the subject.

The language is mostly concise but could be simplified for better understanding. Some sentences are overly complex.

There doesn't appear to be any bias in the communication; it presents both the pros and cons of driverless cars.

The document lacks a clearly titled Introduction section.
The document also lacks a clearly titled Recommendations section.
There is a Conclusion section, but it is not populated with content

Supporting statistics are mentioned, particularly in the discussion about job loss due to automation.

The text mentions the European Union but does not specify individual EU member states except Spain.

The text does not contain information on Non-EU countries.

Spelling mistakes include: ""cyty"" (city), ""sharinig"" (sharing), ""ownershi"" (ownership), ""desinged"" (designed), ""technologiacl"" (technological), ""angorigthm"" (algorithm), ""Eingineers"" (Engineers), ""accellerating"" (accelerating), ""authonom"" (autonomy), ""incopatibel"" (incompatible), ""secutrity"" (security), ""Uncotnrolled"" (Uncontrolled), ""cnnected"" (connected), ""laibility"" (liability), ""holde"" (holder), ""coomunication"" (communication), ""ronotics"" (robotics), ""artificail"" (artificial), ""Parlaiment"" (Parliament), ""conpensated"" (compensated), ""transfort"" (transport).

Grammar mistakes include inconsistent tense usage, missing articles, and incorrect sentence structures.",,Tips to Improve,"Trainee's Answer
16 November 20XX
Briefing note: Driverless cars and vehicle automation in the EU
. Potential and challenges of vehicle automation
The adoption of driverless cars may decrease car accidents and fatalities, it may remove up to half of the vehicles from cyty streets, and car sharinig will cost a fraction of what car ownershi today costs. Specific social groups such as disabled people, women and children will benefit to have a on-demand driver available both day and night. Insurance discrimination or bias in police checks will be eliminated. Cars will also be desinged in a completely different way, and technologiacl improvements may push the creation of new high-skilled jobs in the automotive industry. 
However, the Study Service of the European Parliament highlight many ethical, financial, economic, and technical challenges. The scientific discussion focused on technologial issues, but it recently shifted to user acceptance and legal issues. Questions about how data privacy and cybersecurity need to be addressed thoroughly. Ethical issues regarding the data processing of the algorithm of a highly or fully automated vehicle. potential issues may be how the angorigthm take  a decision in an unavoidable crash scenario. How the system will develop its ""best driving behaviour"". There may be liability issues in case of malfunctioning of an automated vehicle.
A possible social impact of automated cars on the job market is a job loss by professional drivers, as cited by Anita Balakrishnan in her article for CNBC of May 22, 20XX. A Goldman Sachs report estimates that the adoption of self-driving cars in the United States may translate in the loss of 25 thousangs jobs per month when autonomous vehicle saturation will peak. The full effects of self-driving cars will be delayed by regulation and slow adoption. However, on February 16 also Mady Delvaux (S&D, LU) noticed that there might be negative consequences of the adoption of autonomous vehicles on the European Union job market.
3. The different levels of automation and their development
The Society fo Automotive Eingineers (SAE) defines six levels of automation for driving systems:
- Level 0: The human drivers contols completely the vehicle. An example is the park disance control.
- Level 1: most functions are still controlled by the driver, but a specific function (accellerating or steering) can be automatic. An example is the park assist system.
- Level 2: the driver is disengaged from physically operationg the vehicle by having his or her hands off the wheel and foot off the pedal at the same time. Examples are the cruise control system or the lane-centering and the more advanced traffic jam assist.
- Level 3: drivers are needed, but safety-critical functions may be completely shifted to the vehicle under certain traffic or environmental conditions. An example cited by ERTRAC is the Traffic Jam Chaffeur. 
- Level 4: the vehicle is fully autonomous. A system under deployment (ERTRAC estimated its release in four years) at this level of authonom is the Highway Pilot.
- Level 5: the system is fully autonomous and its performance is expected to equal that of a human driver in every driving scenario. The deployment of this vehicle is estimated only in ten years.
4. Regulatory and legal frameworks, state of play
Road traffic is regulated by the Vienna Convention of 1968. Amost all EU Member States (with the exception of Spain) ratified the convention, that established standard traffic rules among contracting parties to facilitate road traffic and increase road safety. The Convention was amended last year, and it maintains the fundamental principle that a vehicle needs a driver. However, hthe amended Convention allows that the driver might be not always fully in control of the vehicle. Even with a highly automate system however, the driver must be present and ready at all times to regain the control of the vehicle. A further amendement is needed to permit driverless vehicles. System with high and full automation are mostly incopatibel with the Vinenna Convention.
Technical requirements for vehicles are internationally harmonised in the 1958 and 1998 UNECE Agreements, of which the EU is a contracting party. Under the European vehicle type approval syste, new vehicle types need a Certificate of Conformity, as stipulated by EU legislation. Also motor vehicles and their trailers must be approves according to a Framework Directive.
The regulatory environment relating to cyber secutrity, data privacy and liability issues is particularly important.  Uncotnrolled or unrestricted access to vehicle data in the on-board network by third parties may jeopardise the safety of the vehicle, its occupants and other road users. The new General Data Protection Regulation establishes a single set of rules on data protection, also with regard to digital technologies valid across the EU. However, a dembate regarding data privacy and cnnected automatic vehicles and safety is evolving with thenew technologies.
In the EU product liability is harmonized by the Directive on liability for defective products. However, there is currently no framework in place harmonizing the rules on laibility  (of the holde or the driver) for damages caused by accidents in which motor vehicles are involved, it differs between Member States. From a certain level of automation it might be difficult to establish causality for determining the liability of the owner or the driver. An adaptation of liability law to the new technologies and a European harmonization of the regimes concering the liability of owners and drivers of automated vehicles is necessary. 
Need of adapting of driving education and licensing.
Prerequisite to infrastructural investments will be to create an agreement on what coomunication is needed between vehicles (V2V) and between vehicles and infrastructure (V2I). Technical standardization will be needed.
 
5. Ongoing work in the EU
On February 16 a EU parliament resolution said that EU-wide rules are needed for the fast-evolving field of robotics. In particular, MEPs referred to the need of enforcing ethical standards and establish liability rules for accidents involving driverless cars.
The Parliament asked to the Commission to propose rules on robotics and Artifical intelligence.
Draft legislation is urgently needed to clarify liability issues for self-driving cars. A possible regulation may be a mandatory insurance scheme and a suppliementary fund to ensure that victims of accidents involving driverless cars are fully conpensated.
MEPS asked the Commission to consider creating a European agency for ronotics and artificail intelligence, to develop technical ethical and regulatory expertise on the subject. 
The resolution passed, and the Commission will need to state its reasons if it refuses to follow the Parlaiment's recommendations.
On April 6 the European Commission promised dedicated funding, regulatory changes, cross-border agreeements ad innovation stimulus regarding the development of automated vehicles. Officials said that driverless trucks could be a reality in the EU in two years.
On May 31 the Commission published its transfort strategy, that could see driverless cars integrated with traffic within the next 10 years.
The strategy will start with trucks
6.Conclusion"
5,0_Case Study Driverless Cars,"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions.

Automated vehicle technologies allow the transfer of driving functions from a human driver to a computer. Automation, and in particular digitalisation, of driving will change road transport in a way which is viewed as a revolution in the field of mobility. As human error is the main reason for road traffic accidents, driving which is automatically controlled by a computer is expected to make future road transport safer and more secure. It has also the potential to be more environmentally friendly, efficient and accessible. Automated vehicle technologies require an effective legislative framework that can foster European leadership and competitiveness, while addressing a number of legitimate concerns. 
You are working as an administrator in DG Mobility and Transport, and you have been asked to prepare a briefing for the next unit meeting.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete. 
You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the markers will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated. 
The case study is designed to assess the following competencies: Analysis and Problem Solving, Communicating (Drafting Skills), Delivering Quality & Results, and Prioritising & Organising.
More specifically, you are asked to write a briefing note (2-3 pages) containing the following background information:
Potentials and challenges of vehicle automation
The different levels of automation and their deployment
Regulatory and legal frameworks, state of play
Ongoing work in the EU

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly and legibly as possible.","ABBREVIATIONS USED
				
		
ACEA - European Automobile Manufacturers’ Association 
Automated vehicle - a motor vehicle (car, truck or bus) which has technology available to assist the driver so that elements of the driving task can be transferred to a computer system

Autonomous vehicle – a fully automated vehicle equipped with the technologies capable to perform all driving functions without any human intervention

CAD - connected and autonomous driving 
C-ITS - Cooperative - Intelligent Transport Systems. Systems consisting of vehicles accompanied by a communication and sensor infrastructure with which the vehicles – fitted with appropriate on-board devices - are capable of communication between themselves and with the infrastructure.
CLEPA - European automotive suppliers association 
Connected vehicle - a motor vehicle equipped with devices to communicate with other vehicles or the infrastructure via the internet

ERTRAC - European Road Transport Research Advisory Council.

NHTSA - National Highway Traffic Safety Administration (US)
UNECE - United Nations Economic Commission for Europe
SAE - Society of Automotive Engineers (US)
V2V – Vehicle to Vehicle Communication
V2I – Vehicle to Infrastructure Communication




BACKGROUND INFORMATION","Subject:		Driverless Cars

I would like you to prepare a briefing on driverless cars for this week’s Unit meeting. Please send me your briefing note that will serve as your hand out for our colleagues by tomorrow evening, so that I can have a look at it before the actual presentation.

Thanks",",

Elon SMUK,
Head of Unit



The Benefits of Driverless Cars
(Excerpt from “The Driver in the Driverless Car - How our technology choices will create the future” by VIVEK WADHWA & ALEX SALKEVER)

Few people seem to fully grasp the profound improvement in our lives that driverless cars will bring. Their adoption will slash accident and fatality rates, saving millions of lives. As well, it will remove one-third to one-half of all vehicles from city streets. A large percentage of the cars on the streets of New York, San Francisco, and London at any one time are looking for parking; but self-driving cars don’t need to park: they can continuously circulate, picking up and dropping off passengers.  The Earth Institute at Columbia University projects a 75 per cent reduction in the cost of car ownership, because fewer shared vehicles will be necessary to provide the same service collectively that personally owned vehicles provide. During peak hours, those shared vehicles will be in use 90 per cent of the time. And, with no more need for steering wheels and other systems enabling human control, vehicles will be lighter and far more fuel-efficient. 
Most important, car sharing will cost a fraction of what car ownership today costs. Owning a car for daily, personal transportation will seem impractical. Self-driving cars will also deliver incontrovertible social beneﬁts. With self-driving cars, the disabled will no longer struggle to ﬁnd transportation; they will have an on-demand personal driver. Several years ago Google’s self-driving car team contacted Steve Mahan, Executive Director of the Santa Clara Valley Blind Center. The team wanted feedback and let Mahan come along for test-drives in earlier self-driving Prius models as well as in the latest Google car. “My experience with Google has been terriﬁc, and I want it to happen,” Mahan told the Times. “Everyone in the blind community wants it to happen.” 
Other groups will also beneﬁt in tangible ways. Women and children will never worry about getting a cab ride late at night. Once all drivers are off the road, trafﬁc violations will no longer be an issue, and cops will have fewer reasons to pull over cars, which should reduce instances of the currently vicious discrimination against individuals “driving while black.” Teens will not face insurance discrimination as they do today, and their parents will not have to pay for the dubious privilege of teaching a teenager to drive. People living in the country will ﬁnally gain access to transportation services that put them nearly on par with their city cousins. Pedestrians will stop worrying about getting hit by cars in intersections.
Let me paint a picture of what streets will look like in an age of driverless cars. We will no longer need traffic lights: robot cars will synchronize wirelessly to time mass movements across city intersections and entries onto freeways or balletic dances around four-way stop signs. Having no human eyes behind the wheel will obviate much of the need for signalling and signage. When all the driverless cars are talking to each other, there will be no need for them to ever come to a complete halt and waste all their kinetic energy. So we will be able to forget traffic lights—and stop signs, yield signs, lighting on freeways, and dozens of other transportation-infrastructure elements catering to human drivers. This great elimination will save many, many billions of dollars in the United States. Equally important, self-driving cars will eliminate the need to build these types of infrastructure in less developed countries in which traffic lights, freeways, and other modern trafﬁc-control features have yet to be put in place. The future cost savings to those countries will be astronomical. In that future, the beneﬁts of self-driving cars will be far more evenly distributed.
Eliminating human drivers will also allow automobile designers to build cars from a completely different mind set. Driverless cars will not need steering columns, brake pedals, accelerator pedals or any of the other components drivers use for slowing or accelerating. They will not need a gearshift panel in the middle of the driver compartment or an emergency brake pedal. The A.I. system driving the car will also reduce accidents to negligible levels. 
…




Robots and artificial intelligence: MEPs call for EU-wide liability rules 

Press Releases Plenary session 
16-02-20XX - 13:09  


As human-robot interactions become commonplace, MEPs stress that EU-wide rules are needed to guarantee a standard level of safety and security. © AP Images/European Union - EP

EU-wide rules are needed for the fast-evolving field of robotics, e.g. to enforce ethical standards or establish liability for accidents involving driverless cars, say MEPs in a resolution voted on Thursday. 
MEPs ask the EU Commission to propose rules on robotics and artificial intelligence, in order to fully exploit their economic potential and to guarantee a standard level of safety and security. They note that regulatory standards for robots are being planned in several countries, and point out that the EU needs to take the lead on setting these standards, so as not to be forced to follow those set by third countries.
Rapporteur Mady Delvaux (S&D, LU) said “Although I am pleased that the plenary adopted my report on robotics, I am also disappointed that the right-wing coalition of ALDE, EPP and ECR refused to take account of possible negative consequences on the job market. They rejected an open-minded and forward-looking debate and thus disregarded the concerns of our citizens.”
Liability rules and the impact of robots on the workforce
MEPs stress that draft legislation is urgently needed to clarify liability issues, especially for self-driving cars. They call for a mandatory insurance scheme and a supplementary fund to ensure that victims of accidents involving driverless cars are fully compensated.
MEPs also ask the Commission to consider creating a specific legal status for robots in the long run, in order to establish who is liable if they cause damage.
The rapid development of robots might result in changes in the labour market through the creation, displacement and loss of certain jobs. MEPs urge the Commission to follow these trends closely.
A Code of Ethical Conduct and a new European Agency for robotics
The growing use of robotics also raises ethical issues, for example to do with privacy and safety, stress MEPs. They propose a voluntary ethical code of conduct on robotics for researchers and designers to ensure that they operate in accordance with legal and ethical standards and that robot design and use respect human dignity.
They also ask the Commission to consider creating a European agency for robotics and artificial intelligence, to supply public authorities with technical, ethical and regulatory expertise.
The resolution was passed by 396 votes to 123, with 85 abstentions. The Commission will not be obliged to follow the Parliament’s recommendations, but must state its reasons if it refuses.





PRESS RELEASE
10-03-20XX
Regulatory and legal framework for automated vehicles
Road traffic is a highly regulated area as it bears huge risks for all traffic users in public spaces. The automation of vehicles changes the driving risks in many regards and therefore requires an assessment of all traffic and vehicle related regulation. Different national jurisdictions can hinder the development and deployment of new technologies for systems or vehicles. European mobility requires a harmonised approach towards these new technologies, while fragmented regulatory approaches would hinder implementation and jeopardise European competitiveness.
Regulation of road traffic
The Vienna Convention on Road Traffic of 1968 (‘Vienna Convention of 1968') is an international treaty designed to facilitate international road traffic and to increase road safety by establishing standard traffic rules among the contracting parties. All EU Member States are signatories of the Vienna Convention — only the UK and Spain have not ratified it. 
One of the fundamental principles of the Vienna Convention is the concept, as laid down in Article 8, that a driver is always fully in control and responsible for the behaviour of a vehicle in traffic.
The amended convention (20XX-1) still demands that every vehicle must have a driver. However, in the future it will be in accordance with the Convention that highly automated systems will have a driver who may take the hands off the wheel, but must be ready at all times to take over the driving functions, and who can override the system and switch it on and off. A further amendment process is therefore necessary to permit driverless vehicles. Systems with high or full automation are mostly still incompatible with the Vienna Convention because a driver may not be required in these systems, depending on the use case.
Technical requirements
Technical requirements for vehicles are internationally harmonised in the framework of the two following UNECE Agreements:
The 1958 Agreement provides the framework for establishing international UN Regulations with uniform performance—oriented test provisions and administrative procedures for granting type approvals, for the conformity of production and for the mutual recognition of the type approvals granted. The 1958 Agreement currently has 54 contracting parties and 135 annexed UN Regulations.
The 1998 Agreement concerns the establishing of global technical regulations for the construction of new vehicles, including performance requirements. Its purpose is to further enhance the process of international harmonisation through the development of global technical regulations (GTR). The 1998 Agreement has 35 Contracting Parties and 16 UN GTRs, established in the UN Global Registry (March 20XX-2).
The European Union is a contracting party to the 1958 and the 1998 Agreement. 
Under the European vehicle type approval system, manufacturers can obtain approval for a new vehicle type in one EU Member State if it meets the EU technical requirements. The manufacturer can then market it EU—wide with no need for further approval tests or checks in other Member States. The approval is granted by a national authority in charge of type approval. The completion of the type approval examination results in issuance of a Certificate of Conformity, which is a statement by the manufacturer that the vehicle conforms to the relevant legal requirements as stipulated by EU legislation.
The common legal framework for the approval of motor vehicles and their trailers is provided by a Framework Directive. Within the EU, mass—produced cars may only be used on public roads if they are type—approved in compliance with the administrative procedures and technical requirements established by the Directive.
General regulatory environment
The regulatory environment relating to cyber security, data privacy, and liability issues is of particular importance in the development of automated vehicles.
Today's connected vehicles are already equipped with extensive IT communication capabilities. In-vehicle networks for information and entertainment co-exist with automotive control networks. The different networks have different degrees of relevance for the safe functioning of the vehicle and for cyber security risks and data protection issues.
Automated vehicles are extended vehicles, meaning that they have external software and hardware extensions as some of their features. These extensions are developed, implemented and managed by the vehicle manufacturer. The connection between the in—vehicle system and the manufacturer's central server has to be secure, so that all data transfers are protected from unauthorised disclosure and manipulation.
Uncontrolled, unrestricted access to vehicle data in the on-board network by third parties directly and indirectly jeopardises the safety of the vehicle, occupants and other road users. Media report increasingly on cyber security problems related to cars, for instance covering the successful attempt of hacking into a vehicle and controlling its basic driving functions via the entertainment and navigation software.
The debate on data privacy regarding connected automated vehicles is evolving in parallel with the new technologies. In general, digital services will be available in vehicles, as they are anywhere else. The ‘connected car‘ has the capability to generate, store and transmit users‘ personal data, such as their route to work, time of driving, favourite music, appointments or favourite restaurants. These data have a significant potential for other uses. As third parties can access and use sensitive driver and driving data, legislation seems necessary to protect personal privacy of consumers in connected vehicles.
The new General Data Protection Regulation establishes a single set of rules on data protection, also with regard to digital technologies, valid across the EU.
Liability issues
Traffic accidents have very large costs in economic terms, in particular regarding human lives or health, or regarding damage to an object. Liability law answers the question of who is responsible and who has to bear the costs of an accident.
In the European Union product liability is strongly harmonised by the Directive on liability for defective products (Council Directive 85/374/EEC). A producer is liable for any damage caused by a defect in his product; a product is defective when it does not provide the safety which the consumer is entitled to expect.
However, there is currently no framework in place harmonising the rules on liability for damages caused by accidents in which motor vehicles are involved — the regulation of liability of the holder of a vehicle or of the driver differ between the Member States.
Most liability regimes in the EU use a concept of causality for determining and allocating liability. From a certain level of vehicle automation on, it might be difficult to establish the exact cause of an accident and to prove if it is due to a defect with the automated vehicle or the behaviour of the driver. The new possible causes created by automation might interfere with the very objective of liability regimes to apportion risks, therefore an adaptation of liability law to the new technologies and a European harmonisation of the regimes concerning the liability of owners and/or drivers of automated vehicles seem necessary.

 


EU Commission drives home merits of autonomous vehicles
By Dave Keating | EURACTIV.com 
 Apr 6, 20XX

Can driverless cars chauffeur people to a love of the EU? The European Commission is betting it can.
Christmas came early for automated driving enthusiasts this week. Convening a two-day summit in Brussels on the subject – the first of its kind – the European Commission promised a sack of goodies in the form of dedicated funding, regulatory changes, cross-border agreements and innovation stimulus.
Driverless trucks could be a reality on European motorways within two years, officials said. They would first operate in convoys where the first truck is driven by a human being but all the trucks following are driverless.
It’s the first step in a roadmap, to be published by the Commission as part of its transport strategy on 31 May, that could see driverless cars integrated with traffic by 20XX+10.
“Owning a non-autonomous car will soon be like owning a horse,” said Carlos Moedas, the EU commissioner for research, science and innovation, who spoke at the conference.
Commission President Jean-Claude Juncker has identified driverless vehicles as an area where the EU can deliver tangible benefits to citizens. In his five-scenario white paper on the future of Europe, released last month ahead of the EU’s 60th anniversary summit in Rome, connected and autonomous driving (CAD) was used repeatedly as an example of something that cannot become a reality without the EU.
In a scenario in which the EU downgrades to only a free trade zone, “Europeans are reluctant to use connected cars due to the absence of EU-wide rules and technical standards,” the paper concluded.
Three weeks later, national leaders signed an agreement in Rome to not only allow cross-border tests and experiments but also to establish one single point of contact in each country to approve them.
Highway cruising
Trucks are expected to be the first to go driverless, both because they drive on motorways and because they are the most commercially interesting. Though convoys following a lead driven vehicle will be the first step, the next step will be completely independent automated trucks.
Motorways present the safest environment for CAD because they are free of pedestrians and are more or less in a straight line. They are also more uniform throughout Europe. In the very near future trucks will be driven within cities by a driver, but then dropped off at the motorway to continue its journey alone. When the truck arrives at its destination, a new driver would pick it up at the motorway exit.
“Lisbon to Warsaw today is four and a half days, but that could be brought down to one and a half,” José Manuel Viegas, secretary-general of the International Transport Forum at the OECD, told euractiv.com.
“It’s very useful for trucks and buses not only because it would save on labour costs and operation, but because it could operate 24 hours a day.” 
Semi-autonomous ‘platoons’ of trucks from around Europe will travel to Rotterdam in early April as part of an experiment backed by the Dutch Council presidency.
Vienna Convention needs updating
Despite the Commission’s enthusiasm, this isn’t low-hanging fruit. It isn’t only the EU that is causing regulatory uncertainty in this field. Globally, rules on driving are harmonised by the UN’s 1968 Vienna Convention on Road Traffic.
Joost Vantomme, smart mobility Director at the European Automobile Manufacturers’ Association (ACEA), said the rules need to be clarified. “Article eight says you need to have a driver in the vehicle, and they need to be in control of the vehicle,” he said. “But what is a driver? Can it be a computer? And what does it mean to be in control of the vehicle?”
As the technology for automated driving has called article eight into question, different countries have interpreted these rules differently. Antti Vehviläinen, director-general of the Finnish Transport Agency, told the conference that Finland has chosen a loose interpretation. “The driver does not need to be in the car, he just needs to be in control,” he said.
The EU’s early efforts at clarification could mean that the bloc ends up setting the standards later adopted at the UN. It can take four to five years to modify a UN treaty, and work has not even begun yet.
Public worry
But is automated driving really the vote-winner that the Commission is imagining? There was much worry at the conference that fears over driverless cars are going to trump the benefits. What will someone think if they are driving on the motorway and see a driverless car next to them?
In Gothenburg Sweden, they’re about to find out. Volvo is launching a project this year called DriveMe, which will put driverless vehicles on real roads with other drivers. The company wants to test how other drivers react, as well as other safety considerations.
The safety worries are a significant hurdle. At a special break-away panel dedicated to the human factors in CAD, most people agreed that people will over-trust automation and this could present dangers. Almost everyone agreed that operating an automated vehicle should require special training, and half said vehicles should alert others when they are in automated mode.
This will be a difficult question for regulators, Viegas admitted. “A minister will know that giving approval today and then having a fatal accident tomorrow will result in him being fired,” he said. “You need to be able to guarantee that the automated vehicle would not fail in a scenario in which a human would not fail.”
Still, the mood at the Brussels conference was positive. There was a general consensus that, as long as safety concerns can be addressed, the EU is on to a winner by identifying autonomous vehicles as an area where it will demonstrate innovation leadership and quick regulatory adjustment.
“Imagine on our roads trucks platooning with big signs saying ‘Europe on the move’,” said Roberto Vavassori, president of the European automotive suppliers association CLEPA. “It would be a sign that EU legislation is there to improve quality of life for our people,” he told the conference enthusiastically.



Autonomous driving levels 0 to 5: Understanding the differences
The National Highway Traffic Safety Administration adopted the Society of Automotive Engineers' (SAE) levels for automated driving systems, ranging from complete driver control to full autonomy. 
By Hope Reese | January 20, 20X-1, 10:47 AM PST 
Between Tesla's announcement that every car in production will now have the capability for full autonomy by 20XX+1 and the Obama administration's plan to invest almost $4 billion in autonomous vehicle research over the next 10 years, the race to create the best driverless car has never been hotter.
The rise of driverless vehicles is going to have a major impact on businesses and professionals. Automated vehicles could replace corporate fleets for deliveries or transporting employees, for example. And workers could gain productive hours in the day by working instead of driving during daily commutes. Innovations in this field are also poised to completely change the car insurance industry by reducing accidents—a new report predicts that accidents will drop by 80% by 20XX+20
But, what does ""autonomous driving"" really mean? The US Department of Transportation's National Highway Traffic Safety Administration (NHTSA) defined five different levels of autonomous driving. In October 20XX-1, the NHTSA updated their policy to reflect that they have officially adopted the levels of autonomy outlined in the SAE International's J3016 document.
The NHTSA is ""working to transform government for the 21st century, harnessing innovation and technology that will improve people's lives,"" according to a representative. ""This is an area of rapid change, which requires the Department Of Transport and NHTSA to remain flexible and adaptable as new information and technologies emerge. Amid that rapid change, the North Star for Department Of Transport and NHTSA remains safety."" 
It's important to remember that the levels of autonomy describe the system, not the vehicle, said Bryant Walker Smith, professor at the University of South Carolina School of Law and School of Engineering and one of the top experts in the driverless cars world. ""A Level 5 automated driving system could be in a vehicle with or without a steering wheel,"" he explained.
Here's what you need to know about levels 0-5. The biggest difference is that, starting at Level 3, the automated driving system becomes able to monitor the driving environment.
Level 0: This one is pretty basic. The driver (human) controls it all: steering, brakes, throttle, power. It's what you've been doing all along.
Level 1: This driver-assistance level means that most functions are still controlled by the driver, but a specific function (like steering or accelerating) can be done automatically by the car.
Level 2: In level 2, at least one driver assistance system of ""both steering and acceleration/ deceleration using information about the driving environment"" is automated, like cruise control and lane-centering. It means that the ""driver is disengaged from physically operating the vehicle by having his or her hands off the steering wheel AND foot off pedal at the same time,"" according to the SAE. The driver must still always be ready to take control of the vehicle, however. 
Level 3: Drivers are still necessary in level 3 cars, but are able to completely shift ""safety-critical functions"" to the vehicle, under certain traffic or environmental conditions. It means that the driver is still present and will intervene if necessary, but is not required to monitor the situation in the same way it does for the previous levels. Jim McBride, autonomous vehicles expert at Ford, said this is ""the biggest demarcation is between Levels 3 and 4."" He's focused on getting Ford straight to Level 4, since Level 3, which involves transferring control from car to human, can often pose difficulties. ""We're not going to ask the driver to instantaneously intervene—that's not a fair proposition,"" McBride said.
Level 4: This is what is meant by ""fully autonomous."" Level 4 vehicles are ""designed to perform all safety-critical driving functions and monitor roadway conditions for an entire trip."" However, it's important to note that this is limited to the ""operational design domain (ODD)"" of the vehicle - meaning it does not cover every driving scenario.
Level 5: This refers to a fully-autonomous system that expects the vehicle's performance to equal that of a human driver, in every driving scenario—including extreme environments like dirt roads that are unlikely to be navigated by driverless vehicles in the near future. 
Why it matters
So why are the levels important? They serve as general guidelines for how technologically advanced a vehicle is. In terms of what consumers need to know, Thilo Koslowski, former analyst for Gartner, thinks that ultimately, there are three stages that will be relevant: ""automated, autonomous, and driverless."" It's important to distinguish between ""autonomous"" and ""driverless,"" he said: ""driverless is a more advanced stage of autonomous.""
But while drivers themselves may be less concerned with the distinctions, the differences could be significant when it comes to issues like car insurance, which is expected to change radically in the era of self-driving cars. 
KPMG, a consulting firm, has issued a report on how the car insurance business will be affected, since the number of accidents are predicted to go down 80% over the coming 20 years. The different levels are important because they ""change the risk profile of the car,"" according to KPMG expert Jerry Albright. ""Insurance companies need to understand how these new capabilities affect driving risk."" Joe Schneider, managing director at KPMG, put it this way: ""It's like a baby, going from crawling to walking to running."" Albright said, ""The car becomes safer and safer as it moves towards fully-autonomous driving.""



Study Service 

Internal Memo

Challenges for automated vehicles in the EU

The potential impact of the deployment of automated vehicles raises many questions. The answers are still under discussion, having ethical, legal, financial, economic and technical dimensions. While most of the scientific discussion has to date dealt with the development of the technology, the focus recently is shifting towards topics such as user acceptance and legal issues. Policy makers, in particular, face challenges in designing the appropriate legal and regulatory framework so that new technologies are used properly and for the benefit of society.

Legal framework for road safety

Regulation of automated vehicles faces challenges to establish rules for technologies not yet applied. In particular, appropriate safety requirements have to be agreed. Traffic rules and the regulatory framework need to be adapted. In addition, it has to be decided how the safety of automated vehicles should be tested and by whom. The further development of vehicle automation will demand an adaption of driving education and licensing.

Infrastructure and technical standards

Automated and connected vehicles need special features in infrastructure. What needs to be done at the infrastructure level has yet to be clarified. An important prerequisite for intelligent transport systems will be an agreement on what communication is needed between vehicles (V2V), between vehicles and infrastructure (V2I) and vehicles to anyone else. Technical standardisation is necessary for international compatibility and interoperability.

Data processing

The new technologies raise questions as to how data privacy and cyber security will be addressed. The highly or fully automated vehicle will process data and make decisions: this raises ethical issues which have to be solved in a societal dialogue. The programmed algorithms will make decisions in conflicting situations, such as a choice between two unavoidable crash scenarios. How will the decision be taken? What 'best driving behaviour' should be reflected by the system?

Liability issues

In case of malfunction of an automated vehicle, who is liable when such malfunctions result in an accident: the manufacturer, the owner or the driver has to be clarified.




Examples for the different levels of automation

Level 0 - Park Distance Control (already deployed): The system assists the driver to manoeuvre into tight spaces by communicating distance from obstacles by means of acoustic or optical signals.

Level 1 - Park Assist (already deployed): The system automatically steers the car into parallel and bay parking spaces, and also out of parallel parking spaces. The system assists the driver by automatically carrying out the optimum steering movements in order to reverse - park on the ideal line. The measurement of the parking space, the allocation of the starting position and the steering movements are automatically undertaken – all the driver has to do is operate the accelerator and the brake. This means that the driver retains control of the car at all times.

Level 2 - Traffic Jam Assist (already deployed): The function controls the vehicle longitudinally to follow the traffic flow in low speeds (lower than 30 km/h). The system can be seen as an extension of the Adaptive Cruise Control with Stop&Go functionality, i.e. no lane change support.

Level 3 - Traffic Jam Chauffeur (already deployed): Conditional Automated Driving up to 60 km/h on motorways or similar roads. The system can be activated in a traffic jam scenario. It detects a slow-driving vehicle in front and then handles the vehicle both longitudinally and laterally. Later versions of this functionality might include lane change functionality.

Level 4 - Highway Pilot (possible deployment 20XX+4): Automated driving up to 130 km/h on motorways or motorway-like roads from entrance to exit, on all lanes, including overtaking movements. The driver must deliberately activate the system, but does not have to monitor it constantly. The driver can override or switch off the system at all times. There is no request from the system to the driver to take over when the system is in its normal operation area on the motorway. Depending on the deployment of vehicle-to-vehicle communication and cooperative systems, ad-hoc convoys could also be created.

Level 5 – The fully automated vehicle should be able to handle all driving from point A to point B, without any input from the passenger. According to ERTRAC only a rough estimation for possible deployment can be given: 20XX+10.




Self-driving cars could cost America's professional drivers up to 25,000 jobs a month, Goldman Sachs says

Anita Balakrishnan | @MsABalakrishnan 
Published 2:45 PM ET Mon, 22 May 20XX
The full impact of self-driving cars on society is several decades away — but when it hits, the job losses will be substantial for American truck drivers, according to a new report from Goldman Sachs. When autonomous vehicle saturation peaks, U.S. drivers could see job losses at a rate of 25,000 a month, or 300,000 a year, according to a report from Goldman Sachs Economics Research. Truck drivers, more so than bus or taxi drivers, will see the bulk of that job loss, according to the report. That makes sense, given today's employment: In 20XX-3, there were 4 million driver jobs in the U.S., 3.1 million of which were truck drivers, Goldman said. That represents 2 per cent of total employment. The report estimates that semi- and fully autonomous car sales will have about 20 per cent share of car sales around 20XX+10. The report comes as fierce competition to make self-driving cars is shaking up companies from the inside out. 
Uber formally launched Uber Freight last week with a self-driving executive at the helm, expanding its reach in the trucking industry, even as it fights in court with Alphabet over whether some of its technology is stolen. And at Ford, the CEO will be replaced by a self-driving car expert, in an effort to ""transform Ford for the future."" Near term, the analysts predict that occupations like secretaries, cashiers, bank tellers, waiters and real estate agents could also be at risk of automation.
To be sure, the report estimates that the full effects of self-driving cars will be delayed by regulation and slow adoption. The report as a whole strikes an optimistic tone on the future of the labor market, noting that many different employment and productivity measures in the United States do not show massive disruption from labor-replacing technologies. 
Industries like department stores, telecom, printing, publishing and manufacturing have seen the biggest job losses over the past 13 years, while sectors like food services, education, computer design and home healthcare have been winners, the report said. ""Demand for health care, education and food services is likely to rise further with aggregate income, and should also benefit from broader trends including aging and consumers' desire for new experiences,"" the report said. ""More fundamentally, we suspect that several of the skills central to those sectors — including empathy, humor, creativity and problem solving — are hard to codify and automate.""",30,7.5,"Summary

This is a great case study that could have achieved an even higher result had there been more attention paid to its linguistic quality.
First and foremost, use sentence structure and length you are confident with, as some style issues can lessen the effect even of an impeccably discussed problem point. Typos and some grammar aspects (e.g., article use, verb agreement, verb forms) can be controlled with some attention even in an exam situation. They can heavily influence your score for the communication competence.
For time management issues and other practical ideas, please check out our Tips & Tricks menu and our webinars.
Keep up the good work!

Per Competency Score",5.0,"Observations

With this competence, we basically evaluate the style of the case study. Your text should be clear, fluent, written in a professional but still captivating style; of course, spelling and grammar are also covered in this area. Another point we examine here is whether you managed to find the balance between providing details and being concise while conveying the key points of the arguments.",,"Tips to Improve

The text is cohesive, coherent and informative, but the amount of typos and grammatical inaccuracies heavily undermine its impact and readability.","Trainee's Answer
16 November 20XX
Dear Elon,
Please find below the briefing concerning driverless cars for this week Unit meeting. Here are summarized potentials and challenges of vehicle automation, the different levels of automation and their deployment. I have also made an overview of current regulatory and legal frameworks, and the ongoing work in the EU.
 
Digitalisation of driving is the future of mobility. Automated vehicle could make road transport safer and more secure. Driving automation technologies would be more eco-friendly, efficient and accessible. Thus it requires adequate regulations and legal framework to overcome challenges for an efficient use of the technologies.
1.POTENTIALS AND CHALLENGES OF VEHICLE AUTOMATION
Vehicle automation is the key future in transport development. Many benefits could result in implementing driving digitalisation while some challenges and questions still need to be addressed. 
POTENTIALS
Using driverles cars is first money saving. It could remove to one-half of all vehicles from the streets allowing 70 % cost reduction of car ownership via shared automated vehicles.Less infrastructures buildings will be needed, that reduces expenses linked to traffic equipments (signage, traffic lights etc.).
This could lead to social benefits at it could ease acces to transport for specific groups of people: disable person, women or person living outside cities could have on-demand personal transportation. 
Roads will become safer as the number of streets accidents should drop due to traffic reduction. 
Discrimation against individuals ( police intervention in traffic violations) and insurance discrimination could be impacted positively.
The use of driverless will also be eco-friendly as traffic will be reduced due to more automated car sharing offer and there will be more energy saving with no more use of public lights for instance. The resulting changes in car equipments and design will make vehicles lighter and more fuel-efficient e.g. no more brake pedals or steering wheels.
CHALLENGES
There are unresolved issues related to ethics i.e human dignity respect, privacy and safety worries like the control of the vehicle in emergency case.
Another concern is the lack of regulation or rules to clarify liabilty matters for accidents involving driverless car. There is an absense of EU-wide rules and technical standards in these subjects.
People also worry about potential negative impact on the labour market:  loss of certain jobs due to automation e.g. for professional drivers.
There are still questions on cyber security risks and data protection issues related to connected automated vehicle.
2. THE DIFFERENT LEVELS OF AUTOMATION AND THEIR DEPLOYMENT
It is important to clarify the meaning of ""autonomous driving"". The NHTSA defined the five levels of autonomy describing the IT system in vehicles. They are:
Level 0: fully control by human.This is already deployed e.g. Park Distance Control.
Level 1: a specific function are done automatically by the car. This is already deployed e.g. Park Assist.
Level 2: at least one driver assistance system is automated. This is already deployed e.g. Traffic Jam Assist.
Level 3: safety-critical functions can be completly shifted to the vehicle (under certain traffic and environmental conditions). This is already deployed e.g. Traffic Jam Chauffeur.
Level 4: ""fully autonomous"" i.e. vehicles are designed to perform all safety critical driving functions and monitor roadway condition for an entire trip. This does not cover all driving scenario. This is could be deployed by 20XX+4 e.g. Higway Pilot.
Level 5: fully-autonomous system i.e. vehicles' performance ishould equal that of a human driver in every driving scenario. This is could be deployed by 20XX+10 e.g. ""The fully automated vehicle"".
3. REGULATORY AND LEGAL FRAMEWORK, STATE OF PLAY
To answer challenges related to the use of automated vehicles, the European Commission already set in place a number of regulations.
The Vienna convention on Road Traffic of 1968 signed by all members states (in exception of Spain, an international treaty, establishes standard traffic rules among the contracting parties. But the convention and its amendment still demand that all vehicle must have a driver to take over the driving control in emergency cases. Thus high or full automation of vehicle are incompatibe with the Vienna convention.
The EU is a contracting party to the 1958 and the 1998 UNECE Agreements providing international harmonised framework in technical requirements for vehicles. The 1958 agreement, the EU vehicle type approval system granted by a national authority provides a Certificate of Conformity respecting legal requirements stipulated by the EU legislation.The Framework Directive of the 1998 Agreement establishes procedures and technical requirements for cars to be used on public roads.
The New General Data Protection Regulation establishes set of rules on data protection across the EU to ensure unauthorised disclosure and manipulation of automated vehicle data.
Within the EU there is no common harmonised rules on liabilty for damages caused by accidents involving motor vehicle. An adaption of liabilty law and a European harmonisation of the regimes concerning the liabilty of owners and/or drivers of automated vehicles is necessary.
4.ONGOING WORK IN THE EU
The commission is still working on main issues related to automated vehicle in the EU. The legal framework for road safety has to be adapted. There is also a need to redefine infrastructure and technical standards. Reflection on questions concerning data processing and liabilty are as well underway.
On 16 February, MEPs proposed to the commision a code of Ethical conduct to ensure legal and ethical standards application and human dignity respect. MEPS stressed the need to draft legislation concerning liabiliites issues for selfdriving cars and to follow closely the impact of robots development on the labor market. It also suggests the creation of a European agency for robotics and artificial intelligence to supply public authorities with technical, ethical and regulatory expertise.
Driverless cars integrated with traffic by 20XX+10 is part of the Commission transport strategy. Trucks are expected to go first driverless in motorways. As part of an experiment semi-autonomous platoons of trucks from around Europe started travelling to Rotterdam in early April.
 
Many advantages can be considered in vehicle automation as the key future in transport development. Lot of  benefits can result in implementing driving digitalisation like money and energy saving or improvement in transportation availabilty. However some challenges and questions still need to be addressed.The commission is still working on main issues related to automated vehicle in the EU: The legal framework and standards. Reflection on questions concerning data processing and liabilty are also underway.
 
I hope this will be usefull and clear for the colleagues.
Please get back to me if you have comments or think that further information should be added.
Thank you.
Regards,
XXX
Economist officer - DG mobility and transport"
2,0_Case Study_Drones,"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions.

Following a request by the European Commission, the Single European Sky Air traffic management Research Joint Undertaking - whose role is to develop the new generation European air traffic management system – has today unveiled its blueprint to make drone use in low-level airspace safe, secure and environmentally friendly. This paper is part of the Commission's drive to deliver on its ambitious Aviation Strategy and unleash the full economic potential of drones by 20XX+2. This requires an effective legislative framework that can foster European leadership and competitiveness, while addressing a number of legitimate concerns, the first of which is safety. 
You are working as an administrator in DG Mobility and Transport, and you have been asked to prepare a press release announcing the publication of the blueprint.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete. 
You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated. 
The case study is designed to assess the following competencies: Analysis and Problem Solving, Communicating (Drafting Skills), Delivering Quality & Results, and Prioritising & Organising.
More specifically, you are asked to write an internal note to the press office (2-3 pages) containing the following background information:
Opportunities and threats of unmanned or remotely piloted vehicles in the European Airspace
Blueprint for drone use in low-level airspace
Next steps

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly and legibly as possible.","ABBREVIATIONS USED
				
ATC – Air traffic Control
ATM – Air Traffic Management
CE  marking - The letters ‘CE’ appear on many products traded on the extended Single Market in the European Economic Area (EEA). They signify that products sold in the EEA have been assessed to meet high safety, health, and environmental protection requirements.
Clean Sky - The largest European research programme developing innovative, cutting-edge technology aimed at reducing CO2, gas emissions and noise levels produced by aircraft.
EASA – European Air Safety Agency
FAA – US Federal Aviation Administration
Geofencing - a virtual geographic boundary, defined by GNSS technology that enables software to prevent a drone entering a defined zone

GNSS - Global Navigation Satellite System

IATA – International Air Transport Association

ICAO – International Civil Aviation Organization
JARUS  - Joint Authorities for Rulemaking on Unmanned Systems 
NOTAM – Notice to Airmen
NPA - Notice of proposed Amendment
RPAS - Remotely Piloted Aircraft Systems 
SESAR – Single European Sky ATM Research
SME – Small and Medium Enterprises
SWIM – System wide information management
UA - Unmanned Aircraft
U-space - a set of new services and specific procedures designed to support safe, efficient and secure access to airspace for large numbers of drones 
BACKGROUND INFORMATION","Subject:		Single European Sky - Drones
Importance:	Highest

Hi,

this morning, SESAR has unveiled its blueprint to make drone use in low-level airspace safe, secure and environmentally friendly. This “U-space” covers altitudes of up to 150 metres and will pave the way for the development of a strong and dynamic EU drone services market. The paper outlines a number of basic principles: 
Safe: safety at low altitude levels will be just as good as that for traditional manned aviation. The concept is to develop a system similar to that of Air Traffic Management for manned aviation.
Automated: the system will provide information for highly automated or autonomous drones to fly safely and avoid obstacles or collisions.
Up and running by 20XX+2: for the basic services like registration, e-identification and geo-fencing. However, further U-Space services and their corresponding standards will need to be developed in the future.
The European Aviation Safety Agency (EASA) is currently working with Member States and industry to produce effective EU-wide safety rules that are proportionate to the risk of the operation. These rules will implement the EU's basic aviation safety regulation, which the European Parliament and the Council (i.e. the EU Member States) are expected to adopt in the coming months.
The Commission, through the SESAR Joint Undertaking, will further finance a range of drone projects, focusing on the integration of drones into the aviation system.

Could you prepare a draft press release, announcing this blueprint within its wider context and send it to the Press Service by tonight?




Louis Blériot,
Head of Unit","RIGA DECLARATION
ON REMOTELY PILOTED AIRCRAFT (drones)
""FRAMING THE FUTURE OF AVIATION""

Riga - 6 March 20XX-2


Today Europe is taking a decisive step towards the future of aviation. The European aviation community gathered in Riga to exchange views on how, and under which conditions, drones can help create promising new opportunities in Europe, offering sustainable jobs and new prospects for growth both for the manufacturing industry and for future users of drones in all sectors of society. Drones offer new services and applications going beyond traditional aviation and offer the promise to perform existing services in a more affordable and environmentally friendly way. They are a truly transformational technology.

The Latvian Presidency of the Council of the European Union, European Commission representatives, Directors General of Civil Aviation of the EU Member States, data protection authorities and leaders of manufacturing industry and service providers confirmed the importance of joint European action, building on the orientations given in the EC Communication on opening the Remotely Piloted Aircraft Systems (RPAS) market. 

The aviation community stressed the necessity for European regulators to ensure that all the conditions are met for the safe and sustainable emergence of innovative drone services. At the same time regulations must help the industry to thrive and adequately deal with citizens’ concerns.
The aviation community established the following principles to guide the regulatory framework in Europe:
1. Drones need to be treated as new types of aircraft with proportionate rules based on the risk of each operation.
The provision of drone services must not be less safe than is accepted from civil aviation in general. The incremental integration of drones in the aviation system must not reduce the level of safety presently achieved in civil aviation. Although no one is on board the drone, people in other aircraft or on the ground could get hurt in case of an accident or an unscheduled landing. The way safety is regulated must be proportional to the operational risk involved.
Rules should be simple and performance based, to allow a small start-up company or individuals to start low-risk, low-altitude operations under minimal rules and to develop, with light-touch risk-based regulation, similar to the modern product safety regulations applied in other sectors. Higher risk operations would be gradually subject to more stringent regulations or operational limitations. At the other end of the spectrum, where the operational risk is highest, such as with large drones operating alongside manned aircraft, the regulation will need to be quite similar to that applying to manned aviation, with strict standards on the design, manufacturing, maintenance and operation of drones, as well as on the training of drone pilots and maintenance personnel.

2. EU rules for the safe provision of drone services need to be developed now.
Safety rules, including on remote pilot and operator qualifications, should be developed at the European level by the European Aviation Safety Agency, building on the experience developed in the EU Member States. The essential requirements should be harmonised at the global level to the maximum extent possible, and full use should be made of the established cooperation in the Joint Authorities for Rulemaking on Unmanned Systems (JARUS) and at ICAO, and should be completed by international industry standard setting bodies. Important efforts need to be put into resourcing these activities, especially JARUS, in order to ensure that the progressive risk-based approach is consistent with what is done in the rest of the world.
This basic regulatory framework should be put in place without delay, in order to help the private sector to take well-informed investment decisions, and to provide a basic set of rules for the many operators who are increasingly eager to begin providing services. The European Aviation Safety Agency should consult stakeholders by the middle of next year on the regulatory framework for the operations of drones and on concrete regulatory proposals for low-risk operations. By the end of next year the Agency will use the results of the consultation to propose a position on these matters. The proposal for the revision of the basic European Safety Regulation, which the European Commission has announced for next year, should contain the necessary new provisions and essential requirements for the progressive risk-based regulation of drones, based on the Agency's recommendations.

3. Technologies and standards need to be developed for the full integration of drones in the European airspace.
The success of drone activities and safety regulations also depends on the financial effort to develop and validate key missing technologies and the ensuing required standards. Both industry and public authorities stressed the need for adequate investment in the technologies that are required to integrate drones into the aviation system — the SESAR programme. Clean Sky and other initiatives should complete the SESAR investments. That would create spin-offbenef1ts for traditional aviation and so frame the future of ﬂying.

4. Public acceptance is key to the growth of drone services.
The respect of citizens’ fundamental rights, such as the right to privacy and the protection of personal data, must be guaranteed. Many drone services involve data-gathering such as ﬁlming, etc. The responsible authorities, such as the national and European Data Protection Authorities, should develop the necessary guidelines and monitoring mechanisms to ensure the full respect of existing protection rules, including in relation to drones. Rules need to clarify what is acceptable and what is not, and they require to be properly enforced.
Drones may cause nuisances and negative externalities, such as noise. These nuisances need to be addressed, possibly at the local level, to maintain public acceptance.
Drones also pose potential security risks. The design of drones can and should take into account those risks by using methods such as cyber-defence or geofencing. However, the malicious use of drones cannot be entirely prevented by design or operational restrictions. It is the task of the national police and justice systems to address those risks.
5. The operator of a drone is responsible for its use.
When a drone service is delivered in prohibited airspace, in an unsafe manner, or for illegal purposes, the authorities should be able to act and hold the operator accountable. Where lacking, this will need to be clarified in national law. Moreover, in order to enforce responsibility, it will be necessary for drones to have at all times an identiﬁable owner or operator. The regulator should seek the least bureaucratic way to achieve this. For instance, the mandating of electronic identity chips on drones - “IDrones” - as is today envisaged in some states, could be formalised through a safety rule, which would contribute to the effective implementation of privacy and security requirements. Standardised web-portals in the Member States for the registration of operators and their operations could be another solution. The involved authorities need to work closely together.
Drone accidents will happen. Member States should clarify the applicable insurance and third party liability regime and monitor the compensation mechanisms for potential victims. The establishment of compensation funds to cover victims of accidents caused by uninsured drone users, as used in the motor insurance sector, could be envisaged. Reporting on drone incidents should be integrated into the overall incident reporting requirements. Systematic and coherent incident reporting will improve safety and will be instrumental for insurance companies in their risk analysis on which third party liability insurance premiums are based.
To allow a short reaction time, the development of drone services and drone technologies needs close monitoring. To this end, the EU should establish an easy access for SMEs to information required for drone manufacturing and service provision, together with an observatory to keep track of the growing number of operations in Europe and the evolution of innovation. This monitoring will permit informed decisions relative to the establishment of priorities for future legislation. It will also help regulators to learn from experience and verify that the rules are fit for purpose, namely to ensure that new technologies and drone services can develop in full respect of the required high levels of safety, security, privacy and environmental protection. An annual progress report should be published.
The European aviation community gathered in Riga today is committed to working together on the basis of these principles to allow businesses to provide drone services everywhere in Europe as from 20XX-1 onwards.



Introduction
The demand for drone services is steadily increasing, with the potential to generate significant economic growth and societal benefits, as recognised in the 20XX-2 EU Aviation Strategy, and more recently in the SESAR Drones Outlook Study and Warsaw Declaration on drones. In order to realise this potential, the Declaration calls for “urgent action on the airspace dimension, in particular the development of the concept of U-space”. Ultimately, U-space will enable complex drone operations with a high degree of automation to take place in all types of operational environments, including urban areas. U-space must be flexible enough to encourage innovation, support the development of new businesses and facilitate the overall growth of the European drone services market while properly addressing, at EU level, safety and security issues, respecting the privacy of citizens, and minimising the environmental impact. This blueprint outlines the proposed vision for U-space and how it could be rolled out. Rather than providing a definitive solution, this blueprint provides the basis to better define the way drones will operate in Europe in the future. 
What is U-space?
U-space is a set of new services and specific procedures designed to support safe, efficient and secure access to airspace for large numbers of drones. These services rely on a high level of digitalisation and automation of functions, whether they are on board the drone itself, or are part of the ground-based environment. U-space provides an enabling framework to support routine drone operations, as well as a clear and effective interface to manned aviation.

What are the key principles of U-space?
The delivery of U-space relies upon the following key principles:
To ensure the safety of all airspace users operating in the U-space framework, as well as people on the ground.
To provide a scalable, flexible and adaptable system that can respond to changes in demand, volume, technology, business models and applications, while managing the interface with manned aviation.
To enable high-density operations with multiple automated drones under the supervision of fleet operators.
To guarantee equitable and fair access to airspace for all users.
To enable competitive and cost-effective service provision at all times, supporting the business models of drone operators.
To minimise deployment and operating costs by leveraging, as much as possible, existing aeronautical services and infrastructure, including GNSS as well as those from other sectors, such as mobile communication services.
To accelerate deployment by adopting technologies and standards from other sectors where they meet the needs of U-space.
To follow a risk-based and performance-driven approach when setting up appropriate requirements for safety, security [including cyber-security] and resilience [including failure mode management], while minimising environmental impact and respecting the privacy of citizens, including data protection.


How will U-space operate?
Subject to compliance with applicable regulations, operational limitations and technical requirements linked to the operation of the drone, U-space facilitates any kind of mission, from the delivery of goods, aerial work, and search and rescue, to more complex future applications such as urban air mobility.
U-space services are offered to both private [leisure and professional] and public users of drones, for all types of missions. Some services will meet privacy and security needs expressed by the relevant authorities. In addition, the criticality of these services will lead to the establishment of performance requirements for both structural elements and service delivery, covering, for example, safety, security, availability, continuity and resilience.
The U-space framework comprises an extensive and scalable range of services relying on agreed EU standards and delivered by service providers. These services do not replicate the function of ATC ‚ as known in ATM, but deliver key services to organise the safe and efficient operation of drones and ensure a proper interface with manned aviation, ATC and relevant authorities. They may include the provision of data, supporting services for drone operators such as flight planning assistance and more structured services such as tracking or capacity management.



Unmanned aircraft (most people call them ‘drones’) is a sector of aviation that is developing very fast and has a great potential for producing new jobs and growth. The term ‘unmanned aircraft’ includes very large aircraft similar in size and complexity to manned aircraft, but also very small consumer electronics aircraft. Especially the smaller ones are increasingly being used in the Europe Union (EU), but under a fragmented regulatory framework. Basic national safety rules apply, but the rules differ across the EU and a number of key safeguards are not addressed in a coherent way.
On request by the European Commission, Member States and other stakeholders, the Agency started to develop a proposals for an operation centric, proportionate, risk- and performance-based regulatory framework for all unmanned aircraft (UA) establishing three categories with different safety requirements, proportionate to the risk:
‘open’ (low risk) is a UA operation category that, considering the risks involved, does not require a prior authorisation by the competent authority before the operation takes place;
‘specific’ (medium risk) is a UA operation category that, considering the risks involved, requires an authorisation by the competent authority before the operation takes place and takes into account the mitigation measures identified in an operational risk assessment, except for certain standard scenarios where a declaration by the operator is sufficient;
‘certified’ (high risk) is a UA operation category that, considering the risks involved, requires the certification of the UA, a licensed remote pilot and an operator approved by the competent authority, in order to ensure an appropriate level of safety.
Following the publication of an advance NPA, a Technical Opinion, a ‘Prototype’ regulation was drafted for the ‘open’ and ‘specific’ categories. The ‘Prototype’ regulation was published proposing actual rules providing the necessary clarity, notably on what are the responsibilities of the Member States and what is the flexibility offered to them.
A significant number of comments has been received and together with the significant inputs provided by an expert group have been taken into account to further develop the regulation text leading to the publication of an NPA. An impact assessment details analysis of several potential options considered. The analysis benefited also from feedback provided by stakeholders.
The NPA has taken into consideration the developments in the international arena e.g. work done in the International Civil Aviation Organisation (ICAO); in the Joint Authorities for the Rulemaking of Unmanned Systems (JARUS) and of course in the USA (Federal Aviation Administration- FAA).
The proposal provides a framework to safely operate drones while allowing this industry to remain agile, to innovate and continue to grow. The risk posed to people on the ground and to other aircraft as well as privacy, security and data protection issues created by such drones are also taken into account.
The proposed regulation defines the technical and operational requirements for the drones. Technical requirements refer for example to the remote identification of drones.  Operational requirements refer among others to geofencing; a system that ensures the drones does not enter a prohibited zone. The proposal also addresses the pilots’ qualifications. Furthermore, drone operators will have to register themselves, except when they operate drones lighter than 250g.
This proposal is breaking new grounds by combining Product legislation and Aviation legislation. Indeed, design requirements for small drones will be implemented by using the legislation relative to making products available on the market (the well-known CE marking). The standard CE mark will be accompanied by the identification of the class of the drone (from C0 to C4) and by a do’s and don’ts leaflet that will be found in all drone boxes. Based on the drone class an operator will know in which area he can operate and what competence is required.
The proposal allows a high degree of flexibility for EASA Member States; they will be able to define zones in their territory where either drones operations are prohibited or restricted (for example to protect sensitive areas), or where certain requirements are alleviated.
For operations that pose higher risks, an operational risk assessment will define the requirements that the operator needs to comply before flying the drone.
The proposal also provides special alleviations for people flying model aircraft - which are also drones – to recognise the good safety records in aero modelling identifying 3 options:
Member States may issue a special authorisation to model clubs and associations defining deviations from the UAS regulation;
Operations can be conducted in specific zones designated by Member States; or
Operations can be conducted in the open category according the operational limitations defined for one of the Subcategory (A3)
EASA will submit a final Opinion to the European Commission at the end of 20XX, which will take into account the feedback, received to this proposal.




Drone Alliance Europe (DAE) is a coalition of leading technology companies representing the commercial drone industry before European political leaders, regulators, and other industry stakeholders, as well as international regulatory and advisory bodies.
The commercial drone industry has the potential to bring tremendous economic growth, jobs, innovation, and broad societal benefits. Amid exponential industry growth and opportunity, it is critical to pursue a forward-leaning regulatory framework to fully realise this potential and further promote European leadership in research, production, and application of this technology.
Our Mission
The Alliance leverages the experience and perspectives of member companies throughout the policymaking process to expedite the safe and widespread integration of commercial drones into European airspace. Together, the DAE represents a strong, united voice working toward the expeditious development of:
Proportionate, risk-based, pan-European regulations that facilitate a clear path toward authorization of expanded operations throughout the continent, including fully autonomous and beyond visual line of sight operations
A low-cost, interoperable unmanned traffic management (UTM) framework that promotes the safe and secure integration of expanded drone operations essential to industry growth
A regulatory framework that embraces the flexible use of licensed, unlicensed, and spectrum sharing opportunities for drone technology necessary to support safe integration, innovation, and technology leadership throughout the Digital Single Market

Our Members



Secure your drone – or pay the price 
By Nick Gibbons - cyber security expert and partner at BLM
Drone technology offers many benefits – from the potential for speedy Amazon deliveries from the sky, to saving lives, as witnessed recently when the Lochaber mountain rescue team used one to find a hurt climber. 
But on the flip side, there are risks associated with aerial technology, such as drone jacking or hacking. 
Typically, when the conversation moves to the subject of drone-jacking, people immediately envisage a Hollywood-style breach of national security, probably in or around the White House before Will Smith leaps in to save the day. 
However, attacks on this technology represent very real risks for the growing number of businesses using drones, such as engineers surveying buildings and infrastructure, e-commerce giants sending deliveries or companies gathering surveillance for insurance claims. 
Earlier this year, Amazon announced an expansion to its research and development team in Cambridge. This will see 400 technology specialists fine-tuning the technology behind delivery drones. Despite claims that such deliveries are “pipe dreams”, there is a growing market for commercial drone technology, and with this comes a growing risk of drone-jacking. 
Last November, a report from security software company McAfee predicted cybercriminals will soon turn their attention to targeting drones, particularly those used for law enforcement, filming and deliveries. 
Drones without adequate security in place will be vulnerable to hacks, as well as physical attacks. The report speculates 20XX will see an increase in availability, via the dark web, of pre-packaged software and toolkits for hacking drones. In these cases, hacking of the drone itself or its supporting software may result in either physical misuse or data breaches. Hacking for the physical diversion of a drone carries the potential for personal injury or property damage, actual theft of the drone or indeed, the item it was carrying. 
Theft of data is another real risk, particularly if the drone contains personal or sensitive information, whether customer data included for delivery purposes or footage collected via an attached camera. 
The loss of data via drone-jacking leaves businesses and authorities with many privacy concerns, especially with the EU’s General Data Protection Regulation (GDPR) coming into force in May 20XX+1. In recent years, there have been a raft of data breaches resulting in an invasion of privacy for customers of companies, including TalkTalk and Camelot, and breaches of the GDPR could entail fines of up to four per cent of a company’s global turnover. 
Attacks are becoming more sophisticated and wide-reaching; recently, we saw the extensive damage hackers can unleash with the WannaCry cyber attack bringing organisations across the globe to a standstill. 
If cyber attacks start targeting drones, drone-jacking could leave businesses and their customers equally exposed with regards to personal and commercial data, and the prospect of big fines levied by the Information Commissioner’s Office. 
Although the use of drones is already, to an extent, covered by a range of laws and regulations, including the Data Protection Act, more specific, targeted legislation is necessary, as are effective insurance products for organisations using drones. This is especially important with the European Commission predicting full integration of drones into European airspace by 20XX+10. 
The UK Government is clearly live to the emerging risks of drone technology. Following a recent consultation exercise, a registration system is to be launched for drones weighing 250g or more. The UK Government is considering the best legislative option for introducing the new rules. 
Currently, a combination of existing insurance policies are required to cover risks associated with drone technology. As the risk of electronic theft of sensitive data rises, the market for specialised policies grows. 
In the case of drone-jacking, it would be wise for a business to consider cyber risk policies available for first and third parties. These can provide protection against business interruption, reputational risks, loss or theft of third party corporate data notification expenses and the payment of compensation to individuals affected by security or privacy breaches. Care should be taken, however, when selecting a particular cyber policy, including detailed discussions with a specialised brokers. 
So while drones have life-saving potential for Scotland’s mountain rescue teams and a business may find investing in the technology an attractive proposition, an outbreak of drone-jacking could be hugely costly. It is critical that companies consider the security breaches drone-jacking could leave them open to, and invest in the appropriate protection – just in case Will Smith is not available. 



Drone flew 'within wingspan' of plane approaching Heathrow 
Rob Davies
A drone flew within 20 metres of a plane on the approach to Heathrow, while another shocked pilots by appearing at 3,000 metres (10,000ft), a monthly update on near-misses has revealed.
Commercial jet pilots reported two “category A” incidents, the most serious class of near-miss, involving unmanned aerial vehicles (UAVs), known as drones.
The latest report comes amid concern that drone near-misses are on the rise, potentially posing a threat to recreational and commercial planes.
In one case, an Airbus A320 pilot on the approach to Heathrow in October last year spotted a drone within just 20 metres, or “possibly within the wingspan” of the aircraft.
Investigators concluded that the drone had flown so close to the passenger jet that “providence had played a major part in the aircraft not colliding”. They also noted that the “blue and disc-like” craft appeared to be custom-made, rather than a commercially available model.
In the second of two serious UAV incidents, an A320 pilot taking off from Heathrow saw a red drone overhead, about 50 metres away from his right wing at about 1,000 metres.
The pilot noted that there would have been a “distinct possibility of damage” had a collision occurred, while investigators found that “a collision had only been narrowly avoided and chance had played a major part”.
A third drone sighting, deemed a less serious category B incident, involved an unmanned aircraft at an altitude that surprised pilots, who had “no time to react”.
The UK Airprox Board, which issues monthly reports on the threat of mid-air collisions, reported a pilot saying: “Was that a drone? At 10,000 ft!”
Large drones are not permitted to fly above 120 metres, or close to airports.
The “large drone”, which appeared to be stationary, came within 60 metres (200ft) of the aircraft, a distance deemed less risky than the category A incidents, but nonetheless “a situation where safety was not assured”.
A fourth drone sighting, involving a pilot on a sightseeing trip near the Binevenagh mountain in Northern Ireland, was deemed to be at the lowest level of risk, category E.
In all four cases, police were alerted but the operator of the drone could not be traced.
Ministers are considering measures to enforce registration of all new drones so they can be better monitored, while the Department for Transport is also reviewing drone safety.
Pilots believe a collision with an airliner could be catastrophic and that the impact of a drone strike on a light plane or helicopter would almost certainly bring it down.
The British Airline Pilots Association has warned that the number of incidents could soar as people fly drones received as Christmas presents, often with little or no handling experience or understanding of the rules.
There have been 59 drone near-misses reported in the past 12 months. Drone sightings were among 21 incidents reported to the UK Airprox Board, six of which were deemed to be in the most serious category.
Among the other category A incidents was a near-miss in which a model aircraft was flown close to a Chinook military helicopter coming in to land at RAF Benson.





European Commission demands EU laws on drones after string of near-misses with aeroplanes
, Brussels correspondent 
30 September 20XX-1 • 8:20am 
The European Commission has called for fresh impetus behind its stalled plans for EU-wide regulation of drones, after a string of near-misses with airplanes across Europe last year.
There were more than 1,200 “safety occurrences"" involving drones in Europe last year, including several involving planes, the commission, the EU’s civil service, said.
On April 22, a drone passed by the wingtip of  with 156 passengers as it came into land at Liverpool John Lennon Airport. In 2016 three planes narrowly missed drones near Heathrow airport,  for tougher .
“If we don't move fast enough, the near misses between drones and airplanes could one day have disastrous consequences,” Violeta Bulc, the EU’s transport commissioner said.
“Drones offer tremendous opportunities for new services and businesses,” she said, “but safety always comes first”.
The commission drafts laws, which are then amended separately by the European Parliament and national governments sitting in the Council of Ministers. A bill can only enter into force across the EU when an identical text is agreed by MEPs and the council. 



North Wales Police use drones to fight crime
10 January 20XX
North Wales Police has become the latest force in Wales to use drones to help in the fight against crime.
Fifteen officers and staff have been trained to use the unmanned aircraft to capture video and images to be used in investigations. 
This includes searching for missing people as well as gathering evidence from road traffic investigations and major crime incidents.
Drone were used to investigate a .
The team's two drones, which can also carry a thermal imaging camera, have already been used to search for missing people and investigate incidents during a trial last year.
Insp Craig Jones from the force's operational planning unit said they were highly effective in gathering images over difficult terrain or hard to reach areas and helped officers gain information, quickly and safely.
The live images they take can be seen by police on the ground and they were recently used to help firefighters tackle a large blaze at the Gateway to Wales Hotel.
Stuart Millington, of North Wales Fire and Rescue Service, said the ability to see aerial moving images that show fire hotspots was a ""significantly useful tool"" in ongoing incidents.
An agreement with the force means the fire service can call on the police drone pilots to help them deal with incidents when needed.
North Wales Police's Deputy Chief Constable Gareth Pritchard added the drones were a highly cost effective tool in fighting crime and helping communities.
""Being able to launch a drone in the air in a few minutes could help save lives and secure vital evidence if a crime was in progress,"" he said.

 



Drone makers zero in on commercial opportunities

Louise Lucas in Hong Kong July 5, 20XX-1
They have been used to shoot weddings, Hollywood movies and terrorists. But now drones, and their makers, are navigating a third path between hobbyists and warfare into the industrial world, threatening a shake-up of the burgeoning $6bn industry. 
New uses for unmanned aerial vehicles (UAVs), to give drones their technical name, are emerging almost daily: delivering packages, pizzas and blood; surveying mines; pre-emptive firefighting; even collecting whale snot to help conserve the mammals. 
“We are developing the UAV into a means of production,” said Paul Xu, vice-president of DJI, at a conference in Shenzhen last month. His company has given China undisputed leadership in the sector, with its 70 per cent market share of non-military drones 
However, if Shenzhen-based DJI, valued at $8bn-$10bn at its last funding round in 20XX-2, is to keep that lead, it will need to adapt to new market dynamics. 
The industry dismisses talk of “peak” consumer drone, but few expect that part of the business to maintain its heady growth rates. Outside China, casualties abound: in California, Lily Robotics shut up shop in January, while 3D Robotics switched its focus to software and Parrot, of France, axed jobs. New entrants are cut from an altogether different cloth, with industrial and tech groups, including Qualcomm, Intel and Boeing hovering over the space. 
Regulators too are braced for change, as the industry lobbies for more openings. In a first step, the US Federal Aviation Administration, in effect, opened the skies to commercial drones a year ago, with limited safety rules covering the sector. 
Since the FAA rule changes, says Michael Perry, director of strategic partnerships at DJI, the enterprise industry has been scaling up rapidly, encouraged by the more certain regulatory environment. “Before we had conversations [with businesses] but then they said: ‘How will my legal team deal with this?’ The last thing we want is vagaries. People won’t invest if they aren’t sure.” 
DJI, the creation of Frank Wang, a radio-controlled helicopter enthusiast from Hangzhou who transformed his boyhood hobby into a company with sales of $1.5bn, is now looking into areas ranging from agriculture to eliminating mosquitoes. 
“Personal drone vendors are now aggressively trying to position themselves in the commercial market,” says Gerald Van Hoy, senior research analyst at Gartner, although the firm says the 3m drones it expects to be shipped this year will still be overwhelmingly for the consumer market. These figures are up 39 per cent on 20XX-1 and should translate into revenues of $6bn.",11,7.0,"Summary
According to the Notice of Competitions of current EPSO competitions, the only competency that will be assessed in the Case Study exam is Written Communication",10.0,"Observations

The central theme, which is the European Commission's Aviation Strategy for drones, is communicated but could be clearer.

The central message is somewhat clear but gets lost amidst the details and technical jargon.

The flow of the document is somewhat logical but could benefit from a more structured layout.

The layout is not visually pleasing and lacks clear headings and sub-headings.

The document lacks adequate titles and subtitles to guide the reader.

The tone of the document is formal and technical.

The language is not concise and is complicated, making it difficult for a layperson to understand.

There doesn't appear to be any bias in the communication.

The document lacks a clearly titled Introduction section.
The document also lacks a clearly titled Recommendations section.
There is no clearly titled Conclusions section in the document.

There are few if any supporting statistics in the text.

The text mentions EU member states but does not specify which ones.

The text does not contain information on Non-EU countries.

Spelling mistakes:
lever should be ""level""
hightailed should be ""highlighted""
follwing should be ""following""
unnammed should be ""unmanned""

Grammar mistakes:
""how drone can bring business can bring opportunities"" should be ""how drones can bring business opportunities""
""When a drone services is used"" should be ""When a drone service is used""
""in the same time to address"" should be ""while at the same time addressing""
""low lever airspace safe"" should be ""low-level airspace safe""",,Tips to Improve,"Trainee's Answer
 
The Commission drive to deliver on its ambitious Aviation Strategy to promote the economic potential of drones by 20xx+2 by promoting a legislative framework to encourage leadership and competitiveness and in the same time to address several concerns like safety issues.
SESAR published its blueprint to make drone use in low lever airspace safe, secure and environmental friendly:  Following main principles were outlined:
Safety: similar concept developed like the Air Traffic Management for named aviation
Automated: the system will provide information for automated and autonomous drones to fly safely and avoid collisions
Up and running by 20xx-2 for basic services like registration, e-identification and geo-fencing. For further services and their standards will be developed in the future.
The European aviation community gathered at Riga exchanged views and how drone can bring business can bring opportunities but also hightailed risks/threats in this context.
1. Safety issues: Regulatory framework for drones must achieve the same level of safety as the current civil aviation.
2. Regulatory framework: basic regulatory framework must be put in place without delay, in order to help the private sector to take well informed investment decisions.
3. Develop key technologies and required standards
4. Public acceptance of drone services. Respect of the fundamental rights of citizens such as privacy and personal data must be guaranteed. Potential cyber security issues must be addressed by national police and justice department. Nuisances can have negative impact like noise.
5. Responsibilities: When a drone services is used on an unsafe manner or illegally the authorities should be able to act and hold the operator accountable. National law should incorporate new aspects in this specific area.
Drone accidents will happen and member state should clarify the applicable insurance and third party liability regime and monitor compensation mechanism for potential victims.
BLUE Print
U-space  is a new framework to support the routine drone operations, as well a clear effective interface to named aviation.
The new Framework contains:
1. Safety regulation for airspace and people on the ground
2. Provide scalable, flexible and adaptable system that can respond to changes in demand volume, technology business.
3. Enable high density operations
4. Guarantee equitable and fair access to airspace for all users
5. Enable competitive and cost efficient service provision for business  involved.
6. To accelerate deployment by adopting technologies and standards
7. to follow a risk based and performance driven approach when setting up safety security requirements
U-space services are offered  for both private and public services, always subject to applicable regulations.
Will deliver key services to organize the safe and efficient operations of drones and ensure a proper interface with named aviation ATC and relevant authorities.
 As Next steps, in order to address several incidents reported by the press the EASA on the request by the European Commission the agency started to develop a proposal for an operation centric, proportionate, risk and performance based regulatory framework for all  UA establishing three categories:
 -  open Low Risk - not require authorization by the competent authority
- specific - medium risk UA  - requires an authorization by the competent authority before the operation takes place
- certified- high risks requires the certification of the UA, a licensed remote pilot and operator approved by the competent authority in order to ensure an appropriate level of safety.
The proposed regulation defines the technical and operational requirements for drones. The proposal is breaking new grounds by combining Product legislation and Aviation legislation.
The proposal also provides special alleviations for people flying model aircraft by providing 3 options:
1. Member states may issue a special authorization to model clubs from the UAS regulation
2. Operation can be conducted in the specific zones designated by the Member states
3. Operations can be conducted in the open category according the operational limitations defined for the subcategory
Drone Alliance Europe has brought new perspective and experience via policymaking proposed together with DAE the follwing:
- proportionate, risk based, pan-European regulations that facilitate clear path towards expanded authorizations on the continent, including fully autonomous and beyond visual line of sight operations.
- a low cost interoperable unnammed traffic management UTM that promotes the safe and secure integration of expanded drone operations  for industry growth
- a regulatory framework that embraces the flexible use of licensed, unlicensed and spectrum sharing opportunities for drone technology necessary  to support safe integration, innovation and technology and leadership via the Digital Single Market
June 16, 20XX"
3,0_Generative AI (LONG),"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. 

Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions. 
For this exercise, you will take on the role of an Administrator working at the European Commission’s DG CONNECT in the unit in charge of fighting against disinformation.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete.

You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the assessors will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated.

The case study is designed to assess the following competencies: Critical thinking, analysing & creative problem-solving, Decision-making and getting results, Information management,  Communication.

Specifically, your task will be to draft a 2 to 2.5 - page speaking note for the Commisioner to clarify the intentions of the Commission with respect to generative AI (GAI). This document must include: 

What is GAI and what are the potential benefits.
What are the dangers associated with GAI and how does the EU want to address them.

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly as possible.","Abbreviations

AI - Artificial intelligence
AIA – Artificial Intelligence Act
AGI - Artificial general intelligence 
ANI - Artificial narrow intelligence
ANN - Artificial neural network
DSA – Digital Services Act
GAI – Generative AI
ML - Machine learning
NLP - Natural language processing


EMAIL 1","Subject: Press Release on generative AI

Dear YOU,

Earlier today, Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton met with representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation.
Jourová asked the signatories to create a dedicated and separate track within the code to deal with disinformation generated by Artificial Intelligence. It should aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them. 
Jourová will present her initiative at a press point tomorrow at 11:15 a.m. so could you prepare her talking points and send them to me this evening before closing of the office hours. She has asked to stress the importance of the fight against disinformation in the context of defending democracy and the EU values. 

Many thanks",",

Charles
Head of Unit





What are the most pressing dangers of AI?
As AI systems prove to be increasingly beneficial in real-world applications, they have broadened their reach, causing risks of misuse, overuse, and explicit abuse to proliferate. As AI systems increase in capability and as they are integrated more fully into societal infrastructure, the implications of losing meaningful control over them become more concerning. New research efforts are aimed at re-conceptualizing the foundations of the field to make AI systems less reliant on explicit, and easily mis specified, objectives. A particularly visible danger is that AI can make it easier to build machines that can spy and even kill at scale. But there are many other important and subtler dangers at present.
Techno-Solutionism
One of the most pressing dangers of AI is techno-solutionism, the view that AI can be seen as a panacea when it is merely a tool. As we see more AI advances, the temptation to apply AI decision-making to all societal problems increases. But technology often creates larger problems in the process of solving smaller ones. For example, systems that streamline and automate the application of social services can quickly become rigid and deny access to migrants or others who fall between the cracks. 
When given the choice between algorithms and humans, some believe algorithms will always be the less-biased choice. Yet, in 2018, Amazon found it necessary to discard a proprietary recruiting tool because the historical data it was trained on resulted in a system that was systematically biased against women. Automated decision-making can often serve to replicate, exacerbate, and even magnify the same bias we wish it would remedy.
Indeed, far from being a cure-all, technology can actually create feedback loops that worsen discrimination. Recommendation algorithms, like Google’s page rank, are trained to identify and prioritize the most “relevant” items based on how other users engage with them. As biased users feed the algorithm biased information, it responds with more bias, which informs users’ understandings and deepens their bias, and so on. Because all technology is the product of a biased system, techno-solutionism’s flaws run deep: a creation is limited by the limitations of its creator.
Dangers of Adopting a Statistical Perspective on Justice
Automated decision-making may produce skewed results that replicate and amplify existing biases. A potential danger, then, is when the public accepts AI-derived conclusions as certainties. This determinist approach to AI decision-making can have dire implications in both criminal and healthcare settings. AI-driven approaches like PredPol, software originally developed by the Los Angeles Police Department and UCLA that purports to help protect one in 33 US citizens, predict when, where, and how crime will occur. A 2016 case study of a US city noted that the approach disproportionately projected crimes in areas with higher populations of non-white and low-income residents. When datasets disproportionately represent the lower power members of society, flagrant discrimination is a likely result.
Sentencing decisions are increasingly decided by proprietary algorithms that attempt to assess whether a defendant will commit future crimes, leading to concerns that justice is being outsourced to software. As AI becomes increasingly capable of analyzing more and more factors that may correlate with a defendant's perceived risk, courts and society at large may mistake an algorithmic probability for fact. This dangerous reality means that an algorithmic estimate of an individual’s risk to society may be interpreted by others as a near certainty—a misleading outcome even the original tool designers warned against. Even though a statistically driven AI system could be built to report a degree of credence along with every prediction, there’s no guarantee that the people using these predictions will make intelligent use of them. Taking probability for certainty means that the past will always dictate the future.
There is an aura of neutrality and impartiality associated with AI decision-making in some corners of the public consciousness, resulting in systems being accepted as objective even though they may be the result of biased historical decisions or even blatant discrimination. All data insights rely on some measure of interpretation. As a concrete example, an audit of a resume-screening tool found that the two main factors it associated most strongly with positive future job performance were whether the applicant was named Jared, and whether he played high school lacrosse. Undesirable biases can be hidden behind both the opaque nature of the technology used and the use of proxies, nominally innocent attributes that enable a decision that is fundamentally biased. An algorithm fueled by data in which gender, racial, class, and ableist biases are pervasive can effectively reinforce these biases without ever explicitly identifying them in the code. 
Without transparency concerning either the data or the AI algorithms that interpret it, the public may be left in the dark as to how decisions that materially impact their lives are being made. Lacking adequate information to bring a legal claim, people can lose access to both due process and redress when they feel they have been improperly or erroneously judged by AI systems. Large gaps in case law make applying Title VII—the primary existing legal framework in the US for employment discrimination—to cases of algorithmic discrimination incredibly difficult. These concerns are exacerbated by algorithms that go beyond traditional considerations such as a person’s credit score to instead consider any and all variables correlated to the likelihood that they are a safe investment. A statistically significant correlation has been shown among Europeans between loan risk and whether a person uses a Mac or PC and whether they include their name in their email address—which turn out to be proxies for affluence. Companies that use such attributes, even if they do indeed provide improvements in model accuracy, may be breaking the law when these attributes also clearly correlate with a protected class like race. Loss of autonomy can also result from AI-created “information bubbles” that narrowly constrict each individual’s online experience to the point that they are unaware that valid alternative perspectives even exist.
Disinformation and Threat to Democracy
AI systems are being used in the service of disinformation on the internet, giving them the potential to become a threat to democracy and a tool for fascism. From deepfake videos to online bots manipulating public discourse by feigning consensus and spreading fake news, there is the danger of AI systems undermining social trust. The technology can be co-opted by criminals, rogue states, ideological extremists, or simply special interest groups, to manipulate people for economic gain or political advantage. Disinformation poses serious threats to society, as it effectively changes and manipulates evidence to create social feedback loops that undermine any sense of objective truth. The debates about what is real quickly evolve into debates about who gets to decide what is real, resulting in renegotiations of power structures that often serve entrenched interests. 
Discrimination and Risk in the Medical Setting
While personalized medicine is a good potential application of AI, there are dangers. Current business models for AI-based health applications tend to focus on building a single system—for example, a deterioration predictor—that can be sold to many buyers. However, these systems often do not generalize beyond their training data. Even differences in how clinical tests are ordered can throw off predictors, and, over time, a system’s accuracy will often degrade as practices change. Clinicians and administrators are not well-equipped to monitor and manage these issues, and insufficient thought given to the human factors of AI integration has led to oscillation between mistrust of the system (ignoring it) and over-reliance on the system (trusting it even when it is wrong), a central concern of the 2016 AI100 report.
These concerns are troubling in general in the high-risk setting that is healthcare, and even more so because marginalized populations—those that already face discrimination from the health system from both structural factors (like lack of access) and scientific factors (like guidelines that were developed from trials on other populations)—may lose even more. Today and in the near future, AI systems built on machine learning are used to determine post-operative personalized pain management plans for some patients and in others to predict the likelihood that an individual will develop breast cancer. AI algorithms are playing a role in decisions concerning distributing organs, vaccines, and other elements of healthcare. Biases in these approaches can have literal life-and-death stakes.
In 2019, the story broke that Optum, a health-services algorithm used to determine which patients may benefit from extra medical care, exhibited fundamental racial biases. The system designers ensured that race was precluded from consideration, but they also asked the algorithm to consider the future cost of a patient to the healthcare system. While intended to capture a sense of medical severity, this feature in fact served as a proxy for race: controlling for medical needs, care for Black patients averages $1,800 less per year.
New technologies are being developed every day to treat serious medical issues. A new algorithm trained to identify melanomas was shown to be more accurate than doctors in a recent study, but the potential for the algorithm to be biased against Black patients is significant as the algorithm was trained using majority light-skinned groups. The stakes are especially high for melanoma diagnoses, where the five-year survival rate is 17 percentage points less for Black Americans than white. While technology has the potential to generate quicker diagnoses and thus close this survival gap, a machine-learning algorithm is only as good as its data set. An improperly trained algorithm could do more harm than good for patients at risk, missing cancers altogether or generating false positives. As new algorithms saturate the market with promises of medical miracles, losing sight of the biases ingrained in their outcomes could contribute to a loss of human biodiversity, as individuals who are left out of initial data sets are denied adequate care. While the exact long-term effects of algorithms in healthcare are unknown, their potential for bias replication means any advancement they produce for the population in aggregate—from diagnosis to resource distribution—may come at the expense of the most vulnerable.








Regulatory framework proposal on artificial intelligence 
The Commission is proposing the first-ever legal framework on AI, which addresses the risks of AI and positions Europe to play a leading role globally. 

© gorodenkoff - iStock Getty Images Plus
The regulatory proposal aims to provide AI developers, deployers and users with clear requirements and obligations regarding specific uses of AI. At the same time, the proposal seeks to reduce administrative and financial burdens for business, in particular small and medium-sized enterprises (SMEs).
The proposal is part of a wider AI package, which also includes the updated Coordinated Plan on AI. Together, the Regulatory framework and Coordinated Plan will guarantee the safety and fundamental rights of people and businesses when it comes to AI. And they will strengthen uptake, investment and innovation in AI across the EU.
Why do we need rules on AI?
The proposed AI regulation ensures that Europeans can trust what AI has to offer. While most AI systems pose limited to no risk and can contribute to solving many societal challenges, certain AI systems create risks that we must address to avoid undesirable outcomes.
For example, it is often not possible to find out why an AI system has made a decision or prediction and taken a particular action. So, it may become difficult to assess whether someone has been unfairly disadvantaged, such as in a hiring decision or in an application for a public benefit scheme.
Although existing legislation provides some protection, it is insufficient to address the specific challenges AI systems may bring.
The proposed rules will:
address risks specifically created by AI applications.
propose a list of high-risk applications.
set clear requirements for AI systems for high-risk applications.
define specific obligations for AI users and providers of high-risk applications.
propose a conformity assessment before the AI system is put into service or placed on the market.
propose enforcement after such an AI system is placed in the market.
propose a governance structure at European and national level.
A risk-based approach

The Regulatory Framework defines 4 levels of risk in AI:
Unacceptable risk
High risk
Limited risk
Minimal or no risk
Unacceptable risk
All AI systems considered a clear threat to the safety, livelihoods and rights of people will be banned, from social scoring by governments to toys using voice assistance that encourages dangerous behaviour.
High risk
AI systems identified as high-risk include AI technology used in:
critical infrastructures (e.g., transport), that could put the life and health of citizens at risk.
educational or vocational training, that may determine the access to education and professional course of someone’s life (e.g., scoring of exams).
safety components of products (e.g., AI application in robot-assisted surgery).
employment, management of workers and access to self-employment (e.g., CV-sorting software for recruitment procedures).
essential private and public services (e.g., credit scoring denying citizens opportunity to obtain a loan).
law enforcement that may interfere with people’s fundamental rights (e.g., evaluation of the reliability of evidence).
migration, asylum, and border control management (e.g., verification of authenticity of travel documents).
administration of justice and democratic processes (e.g., applying the law to a concrete set of facts).
High-risk AI systems will be subject to strict obligations before they can be put on the market:
adequate risk assessment and mitigation systems.
high quality of the datasets feeding the system to minimize risks and discriminatory outcomes.
logging of activity to ensure traceability of results.
detailed documentation providing all information necessary on the system and its purpose for authorities to assess its compliance.
clear and adequate information to the user.
appropriate human oversight measures to minimize risk.
high level of robustness, security and accuracy.
All remote biometric identification systems are considered high risk and subject to strict requirements. The use of remote biometric identification in publicly accessible spaces for law enforcement purposes is, in principle, prohibited.
Narrow exceptions are strictly defined and regulated, such as such as when necessary to search for a missing child, to prevent a specific and imminent terrorist threat or to detect, locate, identify, or prosecute a perpetrator or suspect of a serious criminal offence.
Such use is subject to authorization by a judicial or other independent body and to appropriate limits in time, geographic reach and the data bases searched.
Limited risk
Limited risk refers to AI systems with specific transparency obligations. When using AI systems such as chatbots, users should be aware that they are interacting with a machine so they can take an informed decision to continue or step back.
Minimal or no risk
The proposal allows the free use of minimal-risk AI. This includes applications such as AI-enabled video games or spam filters. Most AI systems currently used in the EU fall into this category.



How does it all work in practice for providers of high-risk AI systems?
Once an AI system is on the market, authorities oversee market surveillance, users ensure human oversight and monitoring, and providers have a post-market monitoring system in place. Providers and users will also report serious incidents and malfunctioning.
Future-proof legislation
As AI is a fast-evolving technology, the proposal has a future-proof approach, allowing rules to adapt to technological change. AI applications should remain trustworthy even after they have been placed on the market. This requires ongoing quality and risk management by providers.




The 5 biggest risks of generative AI, according to an expert 
AI makes our lives easier in many different ways. However, these benefits can come with costs. 



Written by Sabrina Ortiz, Associate Editor on April 25, 20XX

Generative AIs, such as ChatGPT, have revolutionized how we interact with and view AI. Activities like writing, coding, and applying for jobs have become much easier and quicker. With all the positives, however, there are some pretty serious risks.
A major concern with AI is trust and security, which has even caused some countries to completely ban ChatGPT as a whole or to reconsider policy around AI to protect users from harm. 
According to Gartner analyst Avivah Litan, some of the biggest risks of generative AI concern trust and security and include hallucinations, deepfakes, data privacy, copyright issues, and cybersecurity problems.
1. Hallucinations
Hallucinations refer to the errors that AI models are prone to make because, although they are advanced, they are still not human and rely on training and data to provide answers. 
If you've used an AI chatbot, then you have probably experienced these hallucinations through a misunderstanding of your prompt or a blatantly wrong answer to your question.
Litan says the training data can lead to biased or factually incorrect responses, which can be a serious problem when people are relying on these bots for information. 
""Training data can lead to biased, off base or wrong responses, but these can be difficult to spot, particularly as solutions are increasingly believable and relied upon,"" says Litan. 
2. Deepfakes
A deepfake uses generative AI to create videos, photos, and voice recordings that are fake but take the image and likeness of another individual. 
Perfect examples are the AI-generated viral photo of Pope Francis in a puffer jacket or the AI-generated Drake and the Weeknd song, which garnered hundreds of thousands of streams. 
""These fake images, videos and voice recordings have been used to attack celebrities and politicians, to create and spread misleading information, and even to create fake accounts or take over and break into existing legitimate accounts,"" says Litan. 
Like hallucinations, deepfakes can contribute to the massive spread of fake content, leading to the spread of misinformation, which is a serious societal problem. 
3. Data privacy
Privacy is also a major concern with generative AI since user data is often stored for model training. This concern was the overarching factor that pushed Italy to ban ChatGPT, claiming OpenAI was not legally authorized to gather user data. 
""Employees can easily expose sensitive and proprietary enterprise data when interacting with generative AI chatbot solutions,"" says Litan. ""These applications may indefinitely store information captured through user inputs, and even use information to train other models -- further compromising confidentiality.""
Litan highlights that, in addition to compromising user confidentiality, the stored information also poses the risk of ""falling into the wrong hands"" in an instance of a security breach.
4. Cybersecurity
The advanced capabilities of generative AI models, such as coding, can also fall into the wrong hands, causing cybersecurity concerns.
""In addition to more advanced social engineering and phishing threats, attackers could use these tools for easier malicious code generation,"" says Litan. 
Litan says even though vendors who offer generative AI solutions typically assure customers that their models are trained to reject malicious cybersecurity requests, these suppliers don't equip end users with the ability to verify all the security measures that have been implemented. 
5. Copyright issues
Copyright is a big concern because generative AI models are trained on massive amounts of internet data that is used to generate an output. 
This process of training means that works that have not been explicitly shared by the original source can then be used to generate new content. 
Copyright is a particularly thorny issue for AI-generated art of any form, including photos and music. 
To create an image from a prompt, AI-generating tools, such as DALL-E, will refer back to the large database of photos they were trained on. The result of this process is that the final product might include aspects of an artist's work or style that are not attributed to them. 
Since the exact works that generative AI models are trained on are not explicitly disclosed, it is hard to mitigate these copyright issues. 
What's next?
Despite the many risks associated to generative AI, Litan doesn't think that organizations should stop exploring the technology. Instead, they should create an enterprise-wide strategy that targets AI trust, risk, and security management. 
""AI developers must urgently work with policymakers, including new regulatory authorities that may emerge, to establish policies and practices for generative AI oversight and risk management,"" says Litan. 
 

What is generative AI?
In simple terms, generative AI is a subfield of artificial intelligence in which computer algorithms are used to generate outputs that resemble human-created content, be it text, images, graphics, music, computer code or otherwise.
In generative AI, algorithms are designed to learn from training data that includes examples of the desired output. By analyzing the patterns and structures within the training data, generative AI models can produce new content that shares characteristics with the original input data. In doing so, generative AI has the capacity to generate content that appears authentic and human-like.
How does generative AI work?
Generative AI is based on machine learning processes inspired by the inner workings of the human brain, known as neural networks. Training the model involves feeding algorithms large amounts of data, which serves as the foundation for the AI model to learn from. This can consist of text, code, graphics, or any other type of content relevant to the task at hand.
Once the training data has been collected, the AI model analyzes the patterns and relationships within the data to understand the underlying rules governing the content. The AI model continuously fine-tunes its parameters as it learns, improving its ability to simulate human-generated content. The more content the AI model generates, the more sophisticated and convincing its outputs become.
Examples of generative AI
Generative AI has made significant advancements in recent years, with several tools capturing the public attention and creating a stir amongst content creators. Big tech companies have also jumped on the bandwagon, with Google, Microsoft, Amazon, and others all lining up their own generative AI tools.
Depending on the application, generative AI tools may rely on an input prompt that guides it towards producing a desired outcome — think ChatGPT and DALL-E 2.
Some of the most notable examples of generative AI tools include:
ChatGPT: Developed by OpenAI, ChatGPT is an AI language model that can generate human-like text based on given prompts.
DALL-E 2: Another generative AI model from OpenAI, DALL-E is designed to create images and artwork based on text-based prompts.
Midjourney: Developed by San Francisco-based research lab Midjourney Inc., Midjourney interprets text prompts and context to produce visual content, like DALL-E 2.
GitHub Copilot: An AI-powered coding tool created by GitHub and OpenAI, GitHub Copilot suggests code completions for users of development environments like Visual Studio and JetBrains.
Benefits of generative AI
The most compelling advantage generative AI proposes is efficiency, in that it can enable businesses to automate specific tasks and focus their time, energy and resources on more important strategic objectives. This often results in lower labor costs and an increase in operational efficiency.
Generative AI can offer additional advantages to businesses and entrepreneurs, including:
Easily customizing or personalizing marketing content.
Generating new ideas, designs, or content.
Writing, checking, and optimizing computer code.
Drafting templates for essays or articles.
Enhancing customer support with chatbots and virtual assistants.
Facilitating data augmentation for machine learning models.
Analyzing data to improve decision-making.
Streamlining research and development processes.
Use cases of generative AI
Despite generative AI still being in its relative infancy, the technology has already found a firm foothold in various applications and industries.
In content creation, for instance, generative AI can produce text, images and even music, assisting marketers, journalists, and artists with their creative processes. In customer support, AI-driven chatbots and virtual assistants can provide more personalized assistance and reduce response times while reducing the burden on customer service agents.
Other uses of generative AI include:
Healthcare: Generative AI is used in medicine to accelerate the discovery of novel drugs, saving time and money in research.
Marketing: Advertisers use generative AI to craft personalized campaigns and adapt content to consumers’ preferences.
Education: Some educators use generative AI models to develop customized learning materials and assessments that cater to students’ individual learning styles.
Finance: Financial analysts use generative AI to examine market patterns and predict stock market trends.
Environment: Climate scientists employ generative AI models to predict weather patterns and simulate the effects of climate change.
Dangers and limitations of generative AI
It’s important to note that generative AI presents numerous issues requiring attention. One major concern is its potential for spreading misinformation or malicious or sensitive content, which could cause profound damage to people and businesses — and potentially pose a threat to national security.
These risks have not escaped policymakers. In April 20XX, the European Union proposed new copyright rules for generative AI that would require companies to disclose any copyrighted material used to develop these tools. Hopes are that such rules will encourage transparency and ethics in AI development, while minimizing any misuse or infringement of intellectual property. This should also offer some protection to content creators whose work may be unwittingly mimicked or plagiarized by generative AI tools.
The automation of tasks by generative AI could also affect the workforce and contribute to job displacement, requiring impacted employees to reskill or upskill. Additionally, generative AI models can unintentionally learn and amplify biases present in training data, leading to problematic outputs that perpetuate stereotypes and harmful ideologies.
ChatGPT, Bing AI and Google Bard have all drawn controversy for producing incorrect or harmful outputs since their launch, and these concerns must be addressed as generative AI evolves, particularly given the difficulty of scrutinizing the sources used to train AI models.
Generative AI vs. general AI
Generative AI and general AI represent different aspects of artificial intelligence. Generative AI focuses on creating new content or ideas based on existing data. It has specific applications and is a subset of AI that excels at solving particular tasks.
General AI, also known as artificial general intelligence, broadly refers to the concept of AI systems that possess human-like intelligence. General AI is still the stuff of science fiction; it represents an imagined future stage of AI development in which computers are able to think, reason and act autonomously.
Is generative AI the future?
It depends on who you ask, but many experts believe that generative AI has a significant role to play in the future of various industries. The capabilities of generative AI have already proven valuable in areas like content creation, software development and healthcare, and as the technology continues to evolve, so too will its applications and use cases.
That said, the future of generative AI is inextricably tied to addressing the potential risks it presents. Ensuring AI is used ethically by minimizing biases, enhancing transparency and accountability and upholding data governance will be critical as the technology progresses. At the same time, striking a balance between automation and human involvement will be crucial for maximizing the benefits of generative AI while mitigating any potential negative consequences on the workforce.






STOCKHOLM, April 27 (Reuters) - Companies deploying generative AI tools, such as ChatGPT, will have to disclose any copyrighted material used to develop their systems, according to an early EU agreement that could pave the way for the world's first comprehensive laws governing the technology.
The European Commission began drafting the AI Act nearly two years ago to regulate emerging artificial intelligence technology, which underwent a boom in investment and popularity following the release of OpenAI's AI-powered chatbot ChatGPT.
Members of the European Parliament agreed to push the draft through to the next stage, the trilogue, during which EU lawmakers and member states will thrash out the final details of the bill.
Under the proposals, AI tools will be classified according to their perceived risk level: from minimal through to limited, high, and unacceptable. Areas of concern could include biometric surveillance, spreading misinformation or discriminatory language.
While high-risk tools will not be banned, those using them will need to be highly transparent in their operations.
Companies deploying generative AI tools, such as ChatGPT or image generator Midjourney, will also have to disclose any copyrighted material used to develop their systems.
This provision was a late addition drawn up within the past two weeks, according to a source familiar with discussions. Some committee members initially proposed banning copyrighted material being used to train generative AI models altogether, the source said, but this was abandoned in favour of a transparency requirement.
""Against conservative wishes for more surveillance and leftist fantasies of over-regulation, parliament found a solid compromise that would regulate AI proportionately, protect citizens' rights, as well as foster innovation and boost the economy,"" said Svenja Hahn, a European Parliament deputy.
Macquarie analyst Fred Havemeyer said the EU's proposal was ""tactful"" rather than a ""ban first, and ask questions later"" approach proposed by some.
""The EU has been on the frontier of regulating AI technology,"" he told Reuters.
RACE TO MARKET
Microsoft-backed (MSFT.O) OpenAI provoked awe and anxiety around the world when it unveiled ChatGPT late last year. The chatbot became the fastest-growing consumer application in history, reaching 100 million monthly active users in a matter of weeks.
The ensuing race among tech companies to bring generative AI products to market concerned some onlookers, with Twitter-owner Elon Musk backing a proposal to halt development of such systems for six months. Shortly after signing the letter, the Financial Times reported Musk was planning to launch his own startup to rival OpenAI.


Sharon Goldman
@sharongoldman

December 5, 20XX-1

The hidden danger of ChatGPT and generative AI | The AI Beat
Since OpenAI launched its early demo of ChatGPT last Wednesday, the tool already has over a million users, according to CEO Sam Altman — a milestone, he points out, that took GPT-3 nearly 24 months to get to and DALL-E over 2 months. 
The “interactive, conversational model,” based on the company’s GPT-3.5 text-generator, certainly has the tech world in full swoon mode. Aaron Levie, CEO of Box, tweeted that “ChatGPT is one of those rare moments in technology where you see a glimmer of how everything is going to be different going forward.” Y Combinator cofounder Paul Graham tweeted that “clearly something big is happening.” Alberto Romero, author of The Algorithmic Bridge, calls it “by far, the best chatbot in the world.” And even Elon Musk weighed in, tweeting that ChatGPT is “scary good. We are not far from dangerously strong AI.” 
But there is a hidden problem lurking within ChatGPT: That is, it quickly spits out eloquent, confident responses that often sound plausible and true even if they are not. 
ChatGPT can sound plausible even if its output is false.
Like other generative large language models, ChatGPT makes up facts. Some call it “hallucination” or “stochastic parroting,” but these models are trained to predict the next word for a given input, not whether a fact is correct or not. 
Some have noted that what sets ChatGPT apart is that it is so darn good at making its hallucinations sound reasonable. 
Technology analyst Benedict Evans, for example, asked ChatGPT to “write a bio for Benedict Evans.” The result, he tweeted, was “plausible, almost entirely untrue.” 
More troubling is the fact that there are obviously an untold number of queries where the user would only know if the answer was untrue if they already knew the answer to the posed question. 
That’s what Arvind Narayanan, a computer science professor at Princeton, pointed out in a tweet: “People are excited about using ChatGPT for learning. It’s often very good. But the danger is that you can’t tell when it’s wrong unless you already know the answer. I tried some basic information security questions. In most cases the answers sounded plausible but were in fact BS.” 
Fact-checking generative AI
Back in the waning days of print magazines in the 2000s, I spent several years as a fact-checker for publications including GQ and Rolling Stone. Each fact had to include authoritative primary or secondary sources — and Wikipedia was frowned upon. 
Few publications have staff fact-checkers anymore, which puts the onus on reporters and editors to make sure they get their facts straight — especially at a time when misinformation already moves like lightning across social media, while search engines are constantly under pressure to surface verifiable information and not BS. 
That’s certainly why Stack Overflow, the Q&A site for coders and programmers, has temporarily banned users from sharing ChatGPT responses. 
And if StackOverflow can’t keep up with misinformation due to AI, it’s hard to imagine others being able to manage a tsunami of potential AI-driven BS. As Gary Marcus tweeted, “If StackOverflow can’t keep up with plausible but incorrect information, what about social media and search engines?” 
And while many are salivating at the idea that LLMs like ChatGPT could someday replace traditional search engines, others are strongly pushing back. 
Emily Bender, professor of linguistics at the University of Washington, has long pushed back on this notion. 
She recently emphasized again that LLMs are “not fit” for search —” both because they are designed to just make sh** up and because they don’t support information literacy.” She pointed to a paper she co-authored on the topic published in March. 
Is it better for ChatGPT to look right? Or be right? 
BS is obviously something that humans have perfected over the centuries. And ChatGPT and other large language models have no idea what it means, really, to “BS.” But OpenAI made this weakness very clear in its blog announcing the demo and explained that fixing it is “challenging,” saying: 
“ChatGPT sometimes writes plausible sounding but incorrect or nonsensical answers. Fixing this issue is challenging, as: (1) during RL [reinforcement learning] training, there’s currently no source of truth; (2) training the model to be more cautious causes it to decline questions that it can answer correctly; and (3) supervised training misleads the model because the ideal answer depends on what the model knows, rather than what the human demonstrator knows.” 
So, it’s clear that OpenAI knows perfectly well that ChatGPT is filled with BS under the surface. They never meant the technology to offer up a source of truth. 
But the question is: Are human users okay with that? 
Unfortunately, they might be. If it sounds good, many humans may think that’s good enough. And, perhaps, that’s where the real danger lies beneath the surface of ChatGPT. 





By JAKOB HANKE VELA
Send tips here | Tweet @HankeVela | Listen to Playbook and view in your browser
LABELING AI CONTENT        
TODAY: EU PUSHES FOR ‘AI LABEL’ TO FIGHT DEEPFAKES: Brussels wants to prevent artificial intelligence from blurring the lines between fact and fiction — and will today ask companies for the first time ever to come up with a label to identify AI-generated texts and images to fight disinformation, officials tell Playbook.
Brave new world: Generative AI is making breathtaking advances — from writing texts and code to creating ever more realistic pictures and videos — which will have enormous consequences not just for the future of society and work, but for politics, Commission officials reckon. 
Balenc-ai-ga: The fake images of the Pope and famous politicians wearing a Balenciaga coat that went viral earlier this year have clearly spooked them — and they now want to label such deepfakes.
Fake porn: “Today it is mostly still a game, but tomorrow you could see a fake porn with a candidate,” one official who is working on the file but was not authorized to speak on the record told Playbook, referring to AI-generated images of politicians. 
Race to regulate: The Commission (the EU’s executive, which proposes and enforces laws) — has proposed an AI Act to regulate high-risk applications and ban the most dangerous ones. But even before that act enters into force, the Commission will urge industry to cut down on trickery by labeling AI-generated work.
Happening today: Commission VP for Values and Transparency Věra Jourová and Commissioner for Internal Market Thierry Breton will meet representatives of 40-odd organizations that have signed up to the EU’s Code of Practice against disinformation. They include Microsoft, Google, Meta, TikTok, Twitch and smaller companies — but not Twitter, which has left the code — as well as NGOs.
Disinformation risks: “I will ask the signatories to create a dedicated and separate track within the code” to deal with disinformation generated by Artificial Intelligence, Jourová told Playbook. “It should … aim to identify the specific disinformation risks presented by generative AI and take appropriate measures to address them.”
EU pushes for safeguards: How does Brussels want the companies to tackle the risks? “Signatories who integrate generative AI into their services like Bingchat for Microsoft, Bard for Google should build in necessary safeguards that these services cannot be used by malicious actors to generate disinformation,” Jourová said.
Clear labels: “Signatories who have services with a potential to disseminate AI-generated disinformation should in turn put in place technology to recognize such content and clearly label this to users.”
More about this label: Two officials working on the file told Playbook the label should apply to all AI-generated material that can be used to create disinformation, including text, images, audio and video.
Voluntary — for now: It wouldn’t be mandatory, given that it would be part of the voluntary Code of Practice. However, the Commission aims to make the code enforceable by including it as a code of conduct in the Digital Services Act (DSA). Obligations on labeling AI content may also make it into the AI Act during negotiations between EU countries, Parliament, and the Commission, one official said.
How can companies do this? “They can develop, and they probably already have tools to check whether an image was AI-generated or not,” the first official said.
Playbook wonders: Given how easy it is for AI to proliferate across jurisdictions, will such a technology ever be able to identify all deepfakes — or won’t we, on the contrary, one day need some chain of custody procedure for authentic images that can be used, for example, as evidence in court?
Stay tuned: Jourová will present her initiative at a press point tomorrow at 11:15 a.m.
SPEAKING OF WHICH: While the Commission is calling on others to do more, it was recently reported that it awarded and signed a €3.7 million tender to help analyze issues like disinformation, foreign meddling in elections and global threats from a French firm that’s mired in controversy.
Avisa Partners has previously been accused of manipulating information in France and working for authoritarian regimes. The company was recently at the center of a controversy as the organizer of a cybersecurity forum boycotted by the French armed forces ministry and several government officials. More here for our Pro Cybersecurity subscribers.
Looking into this: The Commission is looking into the allegations and “is in contact with French counterparts to seek more clarity on those claim[s],” Peter Stano, the Commission’s spokesperson for foreign affairs and security policy, told my POLITICO Pro Technology colleagues. The EU executive is “closely monitoring the implementation of this project,” he added. 
Jean Tillinac, from Avisa Partners, told my Pro Tech colleagues that the bid was “defended by a team of seasoned experts from our Strategic Intelligence Division” doing research and which was different from the “Digital Communications Division” facing criticism.



Annex I – Glossary of Terms
Algorithm: a formula given to a computer for it to complete a task (i.e., a set of rules for a computer) 
Artificial intelligence: a subset of computer science that deals with computer systems performing tasks with similar, equal, or superior intelligence to that of a human (e.g., decision-making, object classification and detection, speech recognition and translation)
Artificial general intelligence (AGI): also known as strong AI, AGI is a type of artificial intelligence that is considered human-like, and still in its preliminary stages (more of a hypothetical existence in present day)
Artificial narrow intelligence (ANI): also known as weak AI, ANI is a type of artificial intelligence that can only focus on one task or problem at a given time (e.g., playing a game against a human competitor). This is the current existing form of AI.
Artificial neural network (ANN): a network modeled after the human brain by creating an artificial neural system via a pattern-recognizing computer algorithm that learns from, interprets, and classifies sensory data.
Big data: large amounts of structured and unstructured data that is too complex to be handled by standard data-processing software.
Chatbots: a chat robot that can converse with a human user through text or voice commands. Utilized by e-commerce, education, health, and business industries for ease of communication and to answer user questions. 
Cognitive computing: computerized model that mimics human thought processes by data mining, NLP, and pattern recognition.
Computer vision: when a machine processes visual input from image files (JPEGs) or camera feeds
Data mining: the process of sorting through large sets of data to identify recurring patterns while establishing problem-solving relationships.
Deep learning: a machine learning technique that teaches computers how to learn by rote (i.e., machines mimic learning as a human mind would, by using classification techniques)
Generative AI: Generative artificial intelligence or generative AI is a type of artificial intelligence (AI) system capable of generating text, images, or other media in response to prompts. Generative AI models learn the patterns and structure of their input training data, and then generate new data that has similar characteristics. 
Genetic algorithm: an algorithm based on principles of genetics that is used to find solutions efficiently and quickly to difficult problems.
Machine learning (ML): focuses on developing programs that access and use data on their own, leading machines to learn for themselves and improve from learned experiences.
Natural language processing (NLP): helps computers process, interpret, and analyze human language and its characteristics by using natural language data. 
Pattern recognition: automated recognition of patterns found in data.
Reinforcement learning: a machine learning method where the reinforcement algorithm learns by interacting with its environment and is then penalized or rewarded based on decisions it makes.
Strong AI: see artificial general intelligence (AGI)  
Structured data: clearly defined data with easily searchable patterns.
Supervised learning: a type of machine learning where output datasets teach machines to generate desired outcomes or algorithms (akin to a teacher-student relationship).
Transfer learning: a system that uses previously learned data and applies it to a new set of tasks.
Turing Test: a test created by computer scientist Alan Turing (1950) to see if machines could exhibit intelligence equal to or indistinguishable from that of a human.
Unstructured data: data without easily searchable patterns (e.g., audio, video, social media content)
Unsupervised learning: a type of machine learning where an algorithm is trained with information that is neither classified nor labeled, thus allowing the algorithm to act without guidance.",19,8.0,"Summary

According to the Notice of Competitions of current EPSO competitions, the only competency that will be assessed in the Case Study exam is Written Communication",8.0,"Observations

The central theme of Generative AI and its implications are reasonably communicated, but there's room for some improvement in terms of clarity and detail.

The central message that discusses the benefits and dangers of Generative AI, as well as the EU’s stance, is evident but could be made more impactful with cleaner writing.

The content has a logical flow, beginning with an introduction, proceeding to discuss the pros and cons of GAI, and concluding with the EU's stance.

While the layout is mostly clear, it could benefit from improved formatting, such as consistent bullet-point styles and better subheadings.

The tone is formal and appropriate for a speech by a Commissioner.

Although the language is generally straightforward, there are instances where it could be simplified for greater clarity.

There doesn't appear to be any bias; the document attempts to present a balanced view of GAI.

The document contains a clearly titled 'Introduction' section.
There is no clearly titled 'Recommendations' section.
There is a clearly titled 'Conclusion' section.

There are no supporting statistics provided in the text to strengthen the arguments. These would be expected to be included in a Commissioner's speech.

The text specifically mentions the European Union but does not list individual EU member states.

The text does not contain information on Non-EU countries. (A commissioner would put the subject into an international context especially something as strategically important as AI)

Spelling mistakes:
""Al"" should be ""AI""
""tom"" should be ""to""
""Econmic"" should be ""Economic""
""imperonate"" should be ""impersonate""
""reponsibilities"" should be ""responsibilities""
""AI lebels"" should be ""AI labels""

Grammar Mistakes:
""it´s our collective responsibility"" should be ""it's our collective responsibility""
""Today I would like to talk about a topic that´s both"" should be ""Today, I would like to talk about a topic that's both""
""it´s crucial that we, as the European Commission, are proactive"" should be ""it's crucial that we, as the European Commission, are proactive""",,Tips to Improve,"Trainee's Answer
Speaking Note for the Commissioner on Generative Al (GAI):
Date: 9 June 20XX
Introduction
Good morning everyone,
Today I would like to talk about a topic that´s both exciting and challenging: Generative Al, or GAI. As the world of technology continues to evolve at an exponential rate, it´s crucial that we, as the European Commission, are proactive in understanding and addressing the challenges posed by these advancements.
1. Understanding Generative AI (AL)
Generative AI is a subset of artificial intelligence that has capability to generate text, images, or other media in response to prompts. By learning the patterns and structures of input data, these AI models can produce new content that shares similar characteristics.
Potential Benefits:
- Innovation: GAI can stimulate creativity by producing unique content, aiding fields like art music, and literature.
- Efficiency: It can generate vast amounts of data quickly, supporting industries like medicine, finance and entertainment 
- Personalization: GAI can be used tom tailor content to individual needs, enhancinguser experiences across digital platforms.
2. The Flip Side: Dangers Associated with GAI:
As with all technologies, GAI isn´t without its risk.Some of the challenges include:
- Disinformation: Generative AI can create convincing fake news, deepfakes or fabricated evidence which can distort truth and mislead public.
- Econmic Risks: Over-reliance can lead to loss of jobs, especially in sectors reliant on content creation.
-Ethical Concerns: GAI might be used to imperonate individuals, potentially damaging reputations or violating privacy rights
3. The EU´s Stance:
The European Union recognises the duality of GAI - its potential benefits and its possible dangers. We believe in harnessing the power of GAI, but in a way that is safe, ethical, and beneficial for all.
How the EU plans to Address GAI´s Challenges:
- Regulation: We are considering regulations that ensure reponsibilities and transparent use of GAI, especially in sectors like media and public communications.
- Education: It is crucial to educate public about GAI-generated content, allowing individuals to discern between authentic and Al-generated content.
- Collaboration: We intend to work closely with the tech companies to ensure they adopt ethical practices when deploying GAI technologies. Today´s push for an ´AI lebel`s` is a testament to our commitment.
- Promoting Transparency: Encouraging tech companies to develop tools that can detect and label AI - generated content, helping users to make informed decisions.
- Protection: The EU aims to safeguard individuals from malicious users of GAI, ensuring the protection of personal data and preventing identity theft.
Conclusion:
Generative AI is a testament to human ingenuity but it´s our collective responsibility to ensure that it´s used judiciously. The European Commission is committed to leading the way, fostering an environment where GAI can thrive without compromising our share values.
Thank you"
5,0_Case Study Driverless Cars,"This is a fictitious document produced solely for the purpose of this exercise. All references to existing states, international organisations, private companies, departments, their representatives etc. should be considered as mere examples. The views expressed do not represent the position of these bodies or persons. Participants are therefore advised to rely solely on the information provided and not on any prior expertise in the field when answering the questions.

Automated vehicle technologies allow the transfer of driving functions from a human driver to a computer. Automation, and in particular digitalisation, of driving will change road transport in a way which is viewed as a revolution in the field of mobility. As human error is the main reason for road traffic accidents, driving which is automatically controlled by a computer is expected to make future road transport safer and more secure. It has also the potential to be more environmentally friendly, efficient and accessible. Automated vehicle technologies require an effective legislative framework that can foster European leadership and competitiveness, while addressing a number of legitimate concerns. 
You are working as an administrator in DG Mobility and Transport, and you have been asked to prepare a briefing for the next unit meeting.
It is important that you accept the scenario as it is presented to you. Although in real life you would have access to other sources of information and would be able to consult your colleagues, in this exercise you are limited to the information contained in the documents provided. You are, however, allowed to make logical assumptions where information is missing or incomplete. 
You may rearrange the information in any order you wish and add remarks or make notes as necessary. However, remember that the markers will base their evaluation exclusively on what you write. Therefore, be sure to explain the reasoning behind your ideas and write down all the information on which you wish to be evaluated. 
The case study is designed to assess the following competencies: Analysis and Problem Solving, Communicating (Drafting Skills), Delivering Quality & Results, and Prioritising & Organising.
More specifically, you are asked to write a briefing note (2-3 pages) containing the following background information:
Potentials and challenges of vehicle automation
The different levels of automation and their deployment
Regulatory and legal frameworks, state of play
Ongoing work in the EU

In total, you have 90 minutes for this case study. Please answer as precisely as you can and write as clearly and legibly as possible.","ABBREVIATIONS USED
				
		
ACEA - European Automobile Manufacturers’ Association 
Automated vehicle - a motor vehicle (car, truck or bus) which has technology available to assist the driver so that elements of the driving task can be transferred to a computer system

Autonomous vehicle – a fully automated vehicle equipped with the technologies capable to perform all driving functions without any human intervention

CAD - connected and autonomous driving 
C-ITS - Cooperative - Intelligent Transport Systems. Systems consisting of vehicles accompanied by a communication and sensor infrastructure with which the vehicles – fitted with appropriate on-board devices - are capable of communication between themselves and with the infrastructure.
CLEPA - European automotive suppliers association 
Connected vehicle - a motor vehicle equipped with devices to communicate with other vehicles or the infrastructure via the internet

ERTRAC - European Road Transport Research Advisory Council.

NHTSA - National Highway Traffic Safety Administration (US)
UNECE - United Nations Economic Commission for Europe
SAE - Society of Automotive Engineers (US)
V2V – Vehicle to Vehicle Communication
V2I – Vehicle to Infrastructure Communication




BACKGROUND INFORMATION","Subject:		Driverless Cars

I would like you to prepare a briefing on driverless cars for this week’s Unit meeting. Please send me your briefing note that will serve as your hand out for our colleagues by tomorrow evening, so that I can have a look at it before the actual presentation.

Thanks",",

Elon SMUK,
Head of Unit



The Benefits of Driverless Cars
(Excerpt from “The Driver in the Driverless Car - How our technology choices will create the future” by VIVEK WADHWA & ALEX SALKEVER)

Few people seem to fully grasp the profound improvement in our lives that driverless cars will bring. Their adoption will slash accident and fatality rates, saving millions of lives. As well, it will remove one-third to one-half of all vehicles from city streets. A large percentage of the cars on the streets of New York, San Francisco, and London at any one time are looking for parking; but self-driving cars don’t need to park: they can continuously circulate, picking up and dropping off passengers.  The Earth Institute at Columbia University projects a 75 per cent reduction in the cost of car ownership, because fewer shared vehicles will be necessary to provide the same service collectively that personally owned vehicles provide. During peak hours, those shared vehicles will be in use 90 per cent of the time. And, with no more need for steering wheels and other systems enabling human control, vehicles will be lighter and far more fuel-efficient. 
Most important, car sharing will cost a fraction of what car ownership today costs. Owning a car for daily, personal transportation will seem impractical. Self-driving cars will also deliver incontrovertible social beneﬁts. With self-driving cars, the disabled will no longer struggle to ﬁnd transportation; they will have an on-demand personal driver. Several years ago Google’s self-driving car team contacted Steve Mahan, Executive Director of the Santa Clara Valley Blind Center. The team wanted feedback and let Mahan come along for test-drives in earlier self-driving Prius models as well as in the latest Google car. “My experience with Google has been terriﬁc, and I want it to happen,” Mahan told the Times. “Everyone in the blind community wants it to happen.” 
Other groups will also beneﬁt in tangible ways. Women and children will never worry about getting a cab ride late at night. Once all drivers are off the road, trafﬁc violations will no longer be an issue, and cops will have fewer reasons to pull over cars, which should reduce instances of the currently vicious discrimination against individuals “driving while black.” Teens will not face insurance discrimination as they do today, and their parents will not have to pay for the dubious privilege of teaching a teenager to drive. People living in the country will ﬁnally gain access to transportation services that put them nearly on par with their city cousins. Pedestrians will stop worrying about getting hit by cars in intersections.
Let me paint a picture of what streets will look like in an age of driverless cars. We will no longer need traffic lights: robot cars will synchronize wirelessly to time mass movements across city intersections and entries onto freeways or balletic dances around four-way stop signs. Having no human eyes behind the wheel will obviate much of the need for signalling and signage. When all the driverless cars are talking to each other, there will be no need for them to ever come to a complete halt and waste all their kinetic energy. So we will be able to forget traffic lights—and stop signs, yield signs, lighting on freeways, and dozens of other transportation-infrastructure elements catering to human drivers. This great elimination will save many, many billions of dollars in the United States. Equally important, self-driving cars will eliminate the need to build these types of infrastructure in less developed countries in which traffic lights, freeways, and other modern trafﬁc-control features have yet to be put in place. The future cost savings to those countries will be astronomical. In that future, the beneﬁts of self-driving cars will be far more evenly distributed.
Eliminating human drivers will also allow automobile designers to build cars from a completely different mind set. Driverless cars will not need steering columns, brake pedals, accelerator pedals or any of the other components drivers use for slowing or accelerating. They will not need a gearshift panel in the middle of the driver compartment or an emergency brake pedal. The A.I. system driving the car will also reduce accidents to negligible levels. 
…




Robots and artificial intelligence: MEPs call for EU-wide liability rules 

Press Releases Plenary session 
16-02-20XX - 13:09  


As human-robot interactions become commonplace, MEPs stress that EU-wide rules are needed to guarantee a standard level of safety and security. © AP Images/European Union - EP

EU-wide rules are needed for the fast-evolving field of robotics, e.g. to enforce ethical standards or establish liability for accidents involving driverless cars, say MEPs in a resolution voted on Thursday. 
MEPs ask the EU Commission to propose rules on robotics and artificial intelligence, in order to fully exploit their economic potential and to guarantee a standard level of safety and security. They note that regulatory standards for robots are being planned in several countries, and point out that the EU needs to take the lead on setting these standards, so as not to be forced to follow those set by third countries.
Rapporteur Mady Delvaux (S&D, LU) said “Although I am pleased that the plenary adopted my report on robotics, I am also disappointed that the right-wing coalition of ALDE, EPP and ECR refused to take account of possible negative consequences on the job market. They rejected an open-minded and forward-looking debate and thus disregarded the concerns of our citizens.”
Liability rules and the impact of robots on the workforce
MEPs stress that draft legislation is urgently needed to clarify liability issues, especially for self-driving cars. They call for a mandatory insurance scheme and a supplementary fund to ensure that victims of accidents involving driverless cars are fully compensated.
MEPs also ask the Commission to consider creating a specific legal status for robots in the long run, in order to establish who is liable if they cause damage.
The rapid development of robots might result in changes in the labour market through the creation, displacement and loss of certain jobs. MEPs urge the Commission to follow these trends closely.
A Code of Ethical Conduct and a new European Agency for robotics
The growing use of robotics also raises ethical issues, for example to do with privacy and safety, stress MEPs. They propose a voluntary ethical code of conduct on robotics for researchers and designers to ensure that they operate in accordance with legal and ethical standards and that robot design and use respect human dignity.
They also ask the Commission to consider creating a European agency for robotics and artificial intelligence, to supply public authorities with technical, ethical and regulatory expertise.
The resolution was passed by 396 votes to 123, with 85 abstentions. The Commission will not be obliged to follow the Parliament’s recommendations, but must state its reasons if it refuses.





PRESS RELEASE
10-03-20XX
Regulatory and legal framework for automated vehicles
Road traffic is a highly regulated area as it bears huge risks for all traffic users in public spaces. The automation of vehicles changes the driving risks in many regards and therefore requires an assessment of all traffic and vehicle related regulation. Different national jurisdictions can hinder the development and deployment of new technologies for systems or vehicles. European mobility requires a harmonised approach towards these new technologies, while fragmented regulatory approaches would hinder implementation and jeopardise European competitiveness.
Regulation of road traffic
The Vienna Convention on Road Traffic of 1968 (‘Vienna Convention of 1968') is an international treaty designed to facilitate international road traffic and to increase road safety by establishing standard traffic rules among the contracting parties. All EU Member States are signatories of the Vienna Convention — only the UK and Spain have not ratified it. 
One of the fundamental principles of the Vienna Convention is the concept, as laid down in Article 8, that a driver is always fully in control and responsible for the behaviour of a vehicle in traffic.
The amended convention (20XX-1) still demands that every vehicle must have a driver. However, in the future it will be in accordance with the Convention that highly automated systems will have a driver who may take the hands off the wheel, but must be ready at all times to take over the driving functions, and who can override the system and switch it on and off. A further amendment process is therefore necessary to permit driverless vehicles. Systems with high or full automation are mostly still incompatible with the Vienna Convention because a driver may not be required in these systems, depending on the use case.
Technical requirements
Technical requirements for vehicles are internationally harmonised in the framework of the two following UNECE Agreements:
The 1958 Agreement provides the framework for establishing international UN Regulations with uniform performance—oriented test provisions and administrative procedures for granting type approvals, for the conformity of production and for the mutual recognition of the type approvals granted. The 1958 Agreement currently has 54 contracting parties and 135 annexed UN Regulations.
The 1998 Agreement concerns the establishing of global technical regulations for the construction of new vehicles, including performance requirements. Its purpose is to further enhance the process of international harmonisation through the development of global technical regulations (GTR). The 1998 Agreement has 35 Contracting Parties and 16 UN GTRs, established in the UN Global Registry (March 20XX-2).
The European Union is a contracting party to the 1958 and the 1998 Agreement. 
Under the European vehicle type approval system, manufacturers can obtain approval for a new vehicle type in one EU Member State if it meets the EU technical requirements. The manufacturer can then market it EU—wide with no need for further approval tests or checks in other Member States. The approval is granted by a national authority in charge of type approval. The completion of the type approval examination results in issuance of a Certificate of Conformity, which is a statement by the manufacturer that the vehicle conforms to the relevant legal requirements as stipulated by EU legislation.
The common legal framework for the approval of motor vehicles and their trailers is provided by a Framework Directive. Within the EU, mass—produced cars may only be used on public roads if they are type—approved in compliance with the administrative procedures and technical requirements established by the Directive.
General regulatory environment
The regulatory environment relating to cyber security, data privacy, and liability issues is of particular importance in the development of automated vehicles.
Today's connected vehicles are already equipped with extensive IT communication capabilities. In-vehicle networks for information and entertainment co-exist with automotive control networks. The different networks have different degrees of relevance for the safe functioning of the vehicle and for cyber security risks and data protection issues.
Automated vehicles are extended vehicles, meaning that they have external software and hardware extensions as some of their features. These extensions are developed, implemented and managed by the vehicle manufacturer. The connection between the in—vehicle system and the manufacturer's central server has to be secure, so that all data transfers are protected from unauthorised disclosure and manipulation.
Uncontrolled, unrestricted access to vehicle data in the on-board network by third parties directly and indirectly jeopardises the safety of the vehicle, occupants and other road users. Media report increasingly on cyber security problems related to cars, for instance covering the successful attempt of hacking into a vehicle and controlling its basic driving functions via the entertainment and navigation software.
The debate on data privacy regarding connected automated vehicles is evolving in parallel with the new technologies. In general, digital services will be available in vehicles, as they are anywhere else. The ‘connected car‘ has the capability to generate, store and transmit users‘ personal data, such as their route to work, time of driving, favourite music, appointments or favourite restaurants. These data have a significant potential for other uses. As third parties can access and use sensitive driver and driving data, legislation seems necessary to protect personal privacy of consumers in connected vehicles.
The new General Data Protection Regulation establishes a single set of rules on data protection, also with regard to digital technologies, valid across the EU.
Liability issues
Traffic accidents have very large costs in economic terms, in particular regarding human lives or health, or regarding damage to an object. Liability law answers the question of who is responsible and who has to bear the costs of an accident.
In the European Union product liability is strongly harmonised by the Directive on liability for defective products (Council Directive 85/374/EEC). A producer is liable for any damage caused by a defect in his product; a product is defective when it does not provide the safety which the consumer is entitled to expect.
However, there is currently no framework in place harmonising the rules on liability for damages caused by accidents in which motor vehicles are involved — the regulation of liability of the holder of a vehicle or of the driver differ between the Member States.
Most liability regimes in the EU use a concept of causality for determining and allocating liability. From a certain level of vehicle automation on, it might be difficult to establish the exact cause of an accident and to prove if it is due to a defect with the automated vehicle or the behaviour of the driver. The new possible causes created by automation might interfere with the very objective of liability regimes to apportion risks, therefore an adaptation of liability law to the new technologies and a European harmonisation of the regimes concerning the liability of owners and/or drivers of automated vehicles seem necessary.

 


EU Commission drives home merits of autonomous vehicles
By Dave Keating | EURACTIV.com 
 Apr 6, 20XX

Can driverless cars chauffeur people to a love of the EU? The European Commission is betting it can.
Christmas came early for automated driving enthusiasts this week. Convening a two-day summit in Brussels on the subject – the first of its kind – the European Commission promised a sack of goodies in the form of dedicated funding, regulatory changes, cross-border agreements and innovation stimulus.
Driverless trucks could be a reality on European motorways within two years, officials said. They would first operate in convoys where the first truck is driven by a human being but all the trucks following are driverless.
It’s the first step in a roadmap, to be published by the Commission as part of its transport strategy on 31 May, that could see driverless cars integrated with traffic by 20XX+10.
“Owning a non-autonomous car will soon be like owning a horse,” said Carlos Moedas, the EU commissioner for research, science and innovation, who spoke at the conference.
Commission President Jean-Claude Juncker has identified driverless vehicles as an area where the EU can deliver tangible benefits to citizens. In his five-scenario white paper on the future of Europe, released last month ahead of the EU’s 60th anniversary summit in Rome, connected and autonomous driving (CAD) was used repeatedly as an example of something that cannot become a reality without the EU.
In a scenario in which the EU downgrades to only a free trade zone, “Europeans are reluctant to use connected cars due to the absence of EU-wide rules and technical standards,” the paper concluded.
Three weeks later, national leaders signed an agreement in Rome to not only allow cross-border tests and experiments but also to establish one single point of contact in each country to approve them.
Highway cruising
Trucks are expected to be the first to go driverless, both because they drive on motorways and because they are the most commercially interesting. Though convoys following a lead driven vehicle will be the first step, the next step will be completely independent automated trucks.
Motorways present the safest environment for CAD because they are free of pedestrians and are more or less in a straight line. They are also more uniform throughout Europe. In the very near future trucks will be driven within cities by a driver, but then dropped off at the motorway to continue its journey alone. When the truck arrives at its destination, a new driver would pick it up at the motorway exit.
“Lisbon to Warsaw today is four and a half days, but that could be brought down to one and a half,” José Manuel Viegas, secretary-general of the International Transport Forum at the OECD, told euractiv.com.
“It’s very useful for trucks and buses not only because it would save on labour costs and operation, but because it could operate 24 hours a day.” 
Semi-autonomous ‘platoons’ of trucks from around Europe will travel to Rotterdam in early April as part of an experiment backed by the Dutch Council presidency.
Vienna Convention needs updating
Despite the Commission’s enthusiasm, this isn’t low-hanging fruit. It isn’t only the EU that is causing regulatory uncertainty in this field. Globally, rules on driving are harmonised by the UN’s 1968 Vienna Convention on Road Traffic.
Joost Vantomme, smart mobility Director at the European Automobile Manufacturers’ Association (ACEA), said the rules need to be clarified. “Article eight says you need to have a driver in the vehicle, and they need to be in control of the vehicle,” he said. “But what is a driver? Can it be a computer? And what does it mean to be in control of the vehicle?”
As the technology for automated driving has called article eight into question, different countries have interpreted these rules differently. Antti Vehviläinen, director-general of the Finnish Transport Agency, told the conference that Finland has chosen a loose interpretation. “The driver does not need to be in the car, he just needs to be in control,” he said.
The EU’s early efforts at clarification could mean that the bloc ends up setting the standards later adopted at the UN. It can take four to five years to modify a UN treaty, and work has not even begun yet.
Public worry
But is automated driving really the vote-winner that the Commission is imagining? There was much worry at the conference that fears over driverless cars are going to trump the benefits. What will someone think if they are driving on the motorway and see a driverless car next to them?
In Gothenburg Sweden, they’re about to find out. Volvo is launching a project this year called DriveMe, which will put driverless vehicles on real roads with other drivers. The company wants to test how other drivers react, as well as other safety considerations.
The safety worries are a significant hurdle. At a special break-away panel dedicated to the human factors in CAD, most people agreed that people will over-trust automation and this could present dangers. Almost everyone agreed that operating an automated vehicle should require special training, and half said vehicles should alert others when they are in automated mode.
This will be a difficult question for regulators, Viegas admitted. “A minister will know that giving approval today and then having a fatal accident tomorrow will result in him being fired,” he said. “You need to be able to guarantee that the automated vehicle would not fail in a scenario in which a human would not fail.”
Still, the mood at the Brussels conference was positive. There was a general consensus that, as long as safety concerns can be addressed, the EU is on to a winner by identifying autonomous vehicles as an area where it will demonstrate innovation leadership and quick regulatory adjustment.
“Imagine on our roads trucks platooning with big signs saying ‘Europe on the move’,” said Roberto Vavassori, president of the European automotive suppliers association CLEPA. “It would be a sign that EU legislation is there to improve quality of life for our people,” he told the conference enthusiastically.



Autonomous driving levels 0 to 5: Understanding the differences
The National Highway Traffic Safety Administration adopted the Society of Automotive Engineers' (SAE) levels for automated driving systems, ranging from complete driver control to full autonomy. 
By Hope Reese | January 20, 20X-1, 10:47 AM PST 
Between Tesla's announcement that every car in production will now have the capability for full autonomy by 20XX+1 and the Obama administration's plan to invest almost $4 billion in autonomous vehicle research over the next 10 years, the race to create the best driverless car has never been hotter.
The rise of driverless vehicles is going to have a major impact on businesses and professionals. Automated vehicles could replace corporate fleets for deliveries or transporting employees, for example. And workers could gain productive hours in the day by working instead of driving during daily commutes. Innovations in this field are also poised to completely change the car insurance industry by reducing accidents—a new report predicts that accidents will drop by 80% by 20XX+20
But, what does ""autonomous driving"" really mean? The US Department of Transportation's National Highway Traffic Safety Administration (NHTSA) defined five different levels of autonomous driving. In October 20XX-1, the NHTSA updated their policy to reflect that they have officially adopted the levels of autonomy outlined in the SAE International's J3016 document.
The NHTSA is ""working to transform government for the 21st century, harnessing innovation and technology that will improve people's lives,"" according to a representative. ""This is an area of rapid change, which requires the Department Of Transport and NHTSA to remain flexible and adaptable as new information and technologies emerge. Amid that rapid change, the North Star for Department Of Transport and NHTSA remains safety."" 
It's important to remember that the levels of autonomy describe the system, not the vehicle, said Bryant Walker Smith, professor at the University of South Carolina School of Law and School of Engineering and one of the top experts in the driverless cars world. ""A Level 5 automated driving system could be in a vehicle with or without a steering wheel,"" he explained.
Here's what you need to know about levels 0-5. The biggest difference is that, starting at Level 3, the automated driving system becomes able to monitor the driving environment.
Level 0: This one is pretty basic. The driver (human) controls it all: steering, brakes, throttle, power. It's what you've been doing all along.
Level 1: This driver-assistance level means that most functions are still controlled by the driver, but a specific function (like steering or accelerating) can be done automatically by the car.
Level 2: In level 2, at least one driver assistance system of ""both steering and acceleration/ deceleration using information about the driving environment"" is automated, like cruise control and lane-centering. It means that the ""driver is disengaged from physically operating the vehicle by having his or her hands off the steering wheel AND foot off pedal at the same time,"" according to the SAE. The driver must still always be ready to take control of the vehicle, however. 
Level 3: Drivers are still necessary in level 3 cars, but are able to completely shift ""safety-critical functions"" to the vehicle, under certain traffic or environmental conditions. It means that the driver is still present and will intervene if necessary, but is not required to monitor the situation in the same way it does for the previous levels. Jim McBride, autonomous vehicles expert at Ford, said this is ""the biggest demarcation is between Levels 3 and 4."" He's focused on getting Ford straight to Level 4, since Level 3, which involves transferring control from car to human, can often pose difficulties. ""We're not going to ask the driver to instantaneously intervene—that's not a fair proposition,"" McBride said.
Level 4: This is what is meant by ""fully autonomous."" Level 4 vehicles are ""designed to perform all safety-critical driving functions and monitor roadway conditions for an entire trip."" However, it's important to note that this is limited to the ""operational design domain (ODD)"" of the vehicle - meaning it does not cover every driving scenario.
Level 5: This refers to a fully-autonomous system that expects the vehicle's performance to equal that of a human driver, in every driving scenario—including extreme environments like dirt roads that are unlikely to be navigated by driverless vehicles in the near future. 
Why it matters
So why are the levels important? They serve as general guidelines for how technologically advanced a vehicle is. In terms of what consumers need to know, Thilo Koslowski, former analyst for Gartner, thinks that ultimately, there are three stages that will be relevant: ""automated, autonomous, and driverless."" It's important to distinguish between ""autonomous"" and ""driverless,"" he said: ""driverless is a more advanced stage of autonomous.""
But while drivers themselves may be less concerned with the distinctions, the differences could be significant when it comes to issues like car insurance, which is expected to change radically in the era of self-driving cars. 
KPMG, a consulting firm, has issued a report on how the car insurance business will be affected, since the number of accidents are predicted to go down 80% over the coming 20 years. The different levels are important because they ""change the risk profile of the car,"" according to KPMG expert Jerry Albright. ""Insurance companies need to understand how these new capabilities affect driving risk."" Joe Schneider, managing director at KPMG, put it this way: ""It's like a baby, going from crawling to walking to running."" Albright said, ""The car becomes safer and safer as it moves towards fully-autonomous driving.""



Study Service 

Internal Memo

Challenges for automated vehicles in the EU

The potential impact of the deployment of automated vehicles raises many questions. The answers are still under discussion, having ethical, legal, financial, economic and technical dimensions. While most of the scientific discussion has to date dealt with the development of the technology, the focus recently is shifting towards topics such as user acceptance and legal issues. Policy makers, in particular, face challenges in designing the appropriate legal and regulatory framework so that new technologies are used properly and for the benefit of society.

Legal framework for road safety

Regulation of automated vehicles faces challenges to establish rules for technologies not yet applied. In particular, appropriate safety requirements have to be agreed. Traffic rules and the regulatory framework need to be adapted. In addition, it has to be decided how the safety of automated vehicles should be tested and by whom. The further development of vehicle automation will demand an adaption of driving education and licensing.

Infrastructure and technical standards

Automated and connected vehicles need special features in infrastructure. What needs to be done at the infrastructure level has yet to be clarified. An important prerequisite for intelligent transport systems will be an agreement on what communication is needed between vehicles (V2V), between vehicles and infrastructure (V2I) and vehicles to anyone else. Technical standardisation is necessary for international compatibility and interoperability.

Data processing

The new technologies raise questions as to how data privacy and cyber security will be addressed. The highly or fully automated vehicle will process data and make decisions: this raises ethical issues which have to be solved in a societal dialogue. The programmed algorithms will make decisions in conflicting situations, such as a choice between two unavoidable crash scenarios. How will the decision be taken? What 'best driving behaviour' should be reflected by the system?

Liability issues

In case of malfunction of an automated vehicle, who is liable when such malfunctions result in an accident: the manufacturer, the owner or the driver has to be clarified.




Examples for the different levels of automation

Level 0 - Park Distance Control (already deployed): The system assists the driver to manoeuvre into tight spaces by communicating distance from obstacles by means of acoustic or optical signals.

Level 1 - Park Assist (already deployed): The system automatically steers the car into parallel and bay parking spaces, and also out of parallel parking spaces. The system assists the driver by automatically carrying out the optimum steering movements in order to reverse - park on the ideal line. The measurement of the parking space, the allocation of the starting position and the steering movements are automatically undertaken – all the driver has to do is operate the accelerator and the brake. This means that the driver retains control of the car at all times.

Level 2 - Traffic Jam Assist (already deployed): The function controls the vehicle longitudinally to follow the traffic flow in low speeds (lower than 30 km/h). The system can be seen as an extension of the Adaptive Cruise Control with Stop&Go functionality, i.e. no lane change support.

Level 3 - Traffic Jam Chauffeur (already deployed): Conditional Automated Driving up to 60 km/h on motorways or similar roads. The system can be activated in a traffic jam scenario. It detects a slow-driving vehicle in front and then handles the vehicle both longitudinally and laterally. Later versions of this functionality might include lane change functionality.

Level 4 - Highway Pilot (possible deployment 20XX+4): Automated driving up to 130 km/h on motorways or motorway-like roads from entrance to exit, on all lanes, including overtaking movements. The driver must deliberately activate the system, but does not have to monitor it constantly. The driver can override or switch off the system at all times. There is no request from the system to the driver to take over when the system is in its normal operation area on the motorway. Depending on the deployment of vehicle-to-vehicle communication and cooperative systems, ad-hoc convoys could also be created.

Level 5 – The fully automated vehicle should be able to handle all driving from point A to point B, without any input from the passenger. According to ERTRAC only a rough estimation for possible deployment can be given: 20XX+10.




Self-driving cars could cost America's professional drivers up to 25,000 jobs a month, Goldman Sachs says

Anita Balakrishnan | @MsABalakrishnan 
Published 2:45 PM ET Mon, 22 May 20XX
The full impact of self-driving cars on society is several decades away — but when it hits, the job losses will be substantial for American truck drivers, according to a new report from Goldman Sachs. When autonomous vehicle saturation peaks, U.S. drivers could see job losses at a rate of 25,000 a month, or 300,000 a year, according to a report from Goldman Sachs Economics Research. Truck drivers, more so than bus or taxi drivers, will see the bulk of that job loss, according to the report. That makes sense, given today's employment: In 20XX-3, there were 4 million driver jobs in the U.S., 3.1 million of which were truck drivers, Goldman said. That represents 2 per cent of total employment. The report estimates that semi- and fully autonomous car sales will have about 20 per cent share of car sales around 20XX+10. The report comes as fierce competition to make self-driving cars is shaking up companies from the inside out. 
Uber formally launched Uber Freight last week with a self-driving executive at the helm, expanding its reach in the trucking industry, even as it fights in court with Alphabet over whether some of its technology is stolen. And at Ford, the CEO will be replaced by a self-driving car expert, in an effort to ""transform Ford for the future."" Near term, the analysts predict that occupations like secretaries, cashiers, bank tellers, waiters and real estate agents could also be at risk of automation.
To be sure, the report estimates that the full effects of self-driving cars will be delayed by regulation and slow adoption. The report as a whole strikes an optimistic tone on the future of the labor market, noting that many different employment and productivity measures in the United States do not show massive disruption from labor-replacing technologies. 
Industries like department stores, telecom, printing, publishing and manufacturing have seen the biggest job losses over the past 13 years, while sectors like food services, education, computer design and home healthcare have been winners, the report said. ""Demand for health care, education and food services is likely to rise further with aggregate income, and should also benefit from broader trends including aging and consumers' desire for new experiences,"" the report said. ""More fundamentally, we suspect that several of the skills central to those sectors — including empathy, humor, creativity and problem solving — are hard to codify and automate.""",32,7.0,"Summary

The text focuses on the topic of driverless cars, their potential benefits and challenges, and particularly their deployment within the European Union. 
Their thesis statement revolves around the importance of EU-wide rules for regulating this new technology. 

Key points include potentials and challenges of vehicle automation, different levels of automation, regulatory and legal frameworks, and ongoing work in the EU.

The author can improve in the following areas:
Organization: While the text covers multiple facets of the topic, the flow can be made smoother. Introduction and conclusion sections are not clearly outlined.
Evidence Support: While the author cites various organizations and data, it would benefit from more in-depth analysis.
Grammar and Mechanics: There are spelling errors and grammar issues that need to be addressed.


Per Competency Score",7.0,"Observations

The layout of the text is logical but could be enhanced for clarity through improved organization and the use of subheadings.

The information is communicated clearly to some extent but would benefit from refinement in structure and grammar to improve clarity.

The text does not have a specifically titled Introduction section.

The text does not have a specifically titled Conclusions section.

The text does not have a specifically titled Recommendations section.

The tone of the document is formal and informational.

The document is relatively easy to read, but readability could be improved through better structuring and correcting grammatical and spelling errors.

Spelling Errors:
""liabililty"" should be ""liability""
""becasue"" should be ""because""
""depolyment"" should be ""deployment""
""Highghaw"" should be ""Highway""
""depoyed"" should be ""deployed""

Grammar Errors:
""The European Parliament calls for EU-wide rules for the field of robotics."" should be ""The European Parliament is calling for EU-wide rules in the field of robotics.""
""On one hand, KPMG claims that the number of accidents will go down by 80% within the upcoming 19 years."" should be ""On one hand, KPMG claims that the number of accidents will decrease by 80% within the next 19 years.""
""The Earth Institute at Columbia University projects 70% reduction in the car ownership costs becasue fewer shared vehicles will be necessary"" should be ""The Earth Institute at Columbia University projects a 70% reduction in car ownership costs because fewer shared vehicles will be needed.""
""However, it is not clear if the driverless cars is the only factor leading to this development."" should be ""However, it is unclear if driverless cars are the only factor leading to this development.""
""the regulation of liability of the holder of a vehicle or of the driver differ between the EU member states."" should be ""the regulations regarding liability for vehicle owners or drivers differ among EU member states.""",,Tips to Improve,"Trainee's Answer
Introduction
The deployment of driverless cars comes with potentials and challenges. The European Parliament calls for EU-wide rules for the field of robotics. Regulation on road traffic, technical requirements, liabililty and data protection, are on the spotlight, in the context of this deployment. 
Potentials and Challenges of vehicle automation
On one hand, KPMG claims that the number of accidents will go down by 80% within the upcoming 19 years. However, it is not clear if the driverless cars is the only factor leading to this development. The Earth Institute at Columbia University projects 70% reduction in the car ownership costs becasue fewer shared vehicles will be necessary to provide the same collective services that personally owned vehicles provide. The executive director of the Santa Clara Valley Blind Center appears to suport the use of driverless cars too.
On the other hand, regarding the impact to the labour market, iGoldman Sachs argues that 25,000 jobs per month will be lost in the USA, due to autonomous vehicles, but many different employment and productivity measures do not show massive disruption from labor-palcing techologies. An other issue arising about the depolyment of autonomous cars concerns data protection and potential breaches. 
The different levels of automation and their deployment 
Based on the European Road Transport Research Advisory Council, park distance control, park assist, traffic jum assist and chauffeur (i.e. Levels 0-3) have already been depolyed. Highghaw Pilot and fully automated vehicles (i.e. Levels 4-5) are to be depoyed in 4 years and (potentially) 10 years respectively. 
Regulatory and legal frameworks, state of play
The deployment of driverless cars needs the update and allignement of rules and regulations regarding liability, data protection, road traffic, and technical requirements. Regarding road traffic regulations, the Vienna Convention demands that every vehicle must have a driver, which could hinder the deployment of automated vehicles. As concerns the technical requirements, the EU is a contracting party to the 1958 and 1998 United Nations Economic Commision for Europe agreements that harmonize the requirements for vehicles internationally' Concerning data protection, the new General Data Protection Regulation establishes a single set of rules on data protection, also with regard to digital technologies, valid across the EU. Regarding liability, there is currently no framework in place harmonising the rules on liability for damages caused by accidents in which vehicles are involved, while the regulation of liability of the holder of a vehicle or of the driver differ between the EU member states.
Ongoing work in the EU
Firstlly, the EU Parliament has resovled on the enforcement of EU-wide rules for the field of robotics. At this direction, it has asked the EU Commission to propose rules on robotics and artificial intelligence to guarantee standard level of safety and security, to create a specific legal status for robots in order to establish who is liable if they casue damage, and to consider creating a European agency for robots and artificial intelligence to supply public authorities with technical, ethical, and regulatory expertise. Moreover, accroding to a press article of Euractiv, officials have said that driveless trucks could be a reality in European motorways within two years. Forthermore, during the EU's 60th anniversary summit in Rome, national leader signed an agreement to allow cross-boarder tests and experiments and to establish a single point of contact in each country to approve them."
